[I 2025-06-30 21:39:17,364] A new study created in memory with name: no-name-84d73ab3-f1e6-43e3-8b00-0140ade7635b
/uufs/chpc.utah.edu/common/home/u1325975/software/pkg/miniforge3/lib/python3.12/site-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [16, 32, 64] which is of type list.
  warnings.warn(message)
/uufs/chpc.utah.edu/common/home/u1325975/software/pkg/miniforge3/lib/python3.12/site-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [32, 64, 128] which is of type list.
  warnings.warn(message)
/uufs/chpc.utah.edu/common/home/u1325975/software/pkg/miniforge3/lib/python3.12/site-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [16, 32, 64, 128] which is of type list.
  warnings.warn(message)
/uufs/chpc.utah.edu/common/home/u1325975/software/pkg/miniforge3/lib/python3.12/site-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.activation.ReLU'> which is of type type.
  warnings.warn(message)
/uufs/chpc.utah.edu/common/home/u1325975/software/pkg/miniforge3/lib/python3.12/site-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.activation.LeakyReLU'> which is of type type.
  warnings.warn(message)
[I 2025-06-30 21:39:17,414] Trial 0 pruned. 
[I 2025-06-30 21:39:17,421] Trial 1 pruned. 
[I 2025-06-30 21:39:17,425] Trial 2 pruned. 
[I 2025-06-30 21:39:17,433] Trial 3 pruned. 
[I 2025-06-30 21:39:17,437] Trial 4 pruned. 
[I 2025-06-30 21:39:17,445] Trial 5 pruned. 
[I 2025-06-30 21:39:17,451] Trial 6 pruned. 
[I 2025-06-30 21:39:17,455] Trial 7 pruned. 
/uufs/chpc.utah.edu/common/home/u1325975/software/pkg/miniforge3/lib/python3.12/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
[I 2025-06-30 21:39:45,146] Trial 8 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.007123462125457461, 'weight_decay': 7.682387359737966e-05, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 8 with value: inf.
[I 2025-06-30 21:40:30,532] Trial 9 finished with value: 31.372737087974286 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.0009422142135229441, 'weight_decay': 0.001027203653765883, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 1}. Best is trial 9 with value: 31.372737087974286.
[I 2025-06-30 21:40:30,547] Trial 10 pruned. 
[I 2025-06-30 21:40:52,496] Trial 11 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.004584905797870481, 'weight_decay': 0.00024227124709792744, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 9 with value: 31.372737087974286.
[I 2025-06-30 21:41:56,687] Trial 12 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.0033303336394631894, 'weight_decay': 5.823261576622903e-05, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 9 with value: 31.372737087974286.
[I 2025-06-30 21:42:36,229] Trial 13 finished with value: 16.141186355024665 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.009210367095827076, 'weight_decay': 0.0006142474996778267, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 13 with value: 16.141186355024665.
[I 2025-06-30 21:43:07,133] Trial 14 finished with value: 16.7570311931973 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0005525665524795366, 'weight_decay': 0.000858311873964223, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 13 with value: 16.141186355024665.
[I 2025-06-30 21:43:42,176] Trial 15 finished with value: 16.958472600128182 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.00041370395625489284, 'weight_decay': 0.0005177407666325297, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 13 with value: 16.141186355024665.
[I 2025-06-30 21:44:26,180] Trial 16 finished with value: 16.208158317209264 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.00022405705422137807, 'weight_decay': 0.009906905571865299, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 13 with value: 16.141186355024665.
[I 2025-06-30 21:45:11,461] Trial 17 finished with value: 16.465896628580282 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.00021443798400403293, 'weight_decay': 0.005257851017063937, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 13 with value: 16.141186355024665.
[I 2025-06-30 21:45:11,475] Trial 18 pruned. 
[I 2025-06-30 21:45:11,494] Trial 19 pruned. 
[I 2025-06-30 21:46:03,844] Trial 20 finished with value: 15.882606916000501 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0053280106576825805, 'weight_decay': 1.8104913186831754e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 20 with value: 15.882606916000501.
[I 2025-06-30 21:46:52,388] Trial 21 finished with value: 15.839313245513308 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00481620775975695, 'weight_decay': 2.5434733039543763e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 21 with value: 15.839313245513308.
[I 2025-06-30 21:47:40,658] Trial 22 finished with value: 15.86202503178158 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005516441432113656, 'weight_decay': 1.9023426630804693e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 21 with value: 15.839313245513308.
[I 2025-06-30 21:48:29,346] Trial 23 finished with value: 15.742945167277131 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004671671661115141, 'weight_decay': 2.01565172329433e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 23 with value: 15.742945167277131.
[I 2025-06-30 21:49:17,462] Trial 24 finished with value: 15.66940120467566 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0031285684047235164, 'weight_decay': 1.7723854179023184e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 24 with value: 15.66940120467566.
[I 2025-06-30 21:50:05,925] Trial 25 finished with value: 15.926554922108247 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0025983940880439766, 'weight_decay': 8.166912351296897e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 24 with value: 15.66940120467566.
[I 2025-06-30 21:50:05,938] Trial 26 pruned. 
[I 2025-06-30 21:50:55,903] Trial 27 finished with value: 15.91440694851983 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003371322131817923, 'weight_decay': 5.358592652355796e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 24 with value: 15.66940120467566.
[I 2025-06-30 21:50:55,924] Trial 28 pruned. 
[I 2025-06-30 21:50:55,939] Trial 29 pruned. 
[I 2025-06-30 21:50:55,956] Trial 30 pruned. 
[I 2025-06-30 21:51:45,510] Trial 31 finished with value: 15.883506402037197 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006748759159061536, 'weight_decay': 2.5054941973847124e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 24 with value: 15.66940120467566.
[I 2025-06-30 21:52:35,879] Trial 32 finished with value: 15.654752956102314 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005907067765724854, 'weight_decay': 0.00010287502515671449, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 21:53:25,245] Trial 33 finished with value: 15.677129343312798 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.003110087536550699, 'weight_decay': 1.1195100638292768e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 21:53:57,892] Trial 34 finished with value: 17.06481447497315 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.002664327426741025, 'weight_decay': 1.188091341032498e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 21:53:57,910] Trial 35 pruned. 
[I 2025-06-30 21:53:57,925] Trial 36 pruned. 
[I 2025-06-30 21:53:57,940] Trial 37 pruned. 
[I 2025-06-30 21:53:57,956] Trial 38 pruned. 
[I 2025-06-30 21:54:46,498] Trial 39 finished with value: 28.357206516072576 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.009585410376619584, 'weight_decay': 5.026748886879741e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 32, 'flip_prob': 1}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 21:54:46,513] Trial 40 pruned. 
[I 2025-06-30 21:55:36,163] Trial 41 finished with value: 15.87199894654747 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004481364696293065, 'weight_decay': 4.7238921139667876e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 21:56:26,077] Trial 42 finished with value: 15.655784064159162 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.007378402106304143, 'weight_decay': 9.375364425647329e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 21:57:15,822] Trial 43 finished with value: 15.824893282066961 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.007001848163565323, 'weight_decay': 9.625299309796501e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 21:58:21,700] Trial 44 finished with value: 16.403171570794417 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.008135338185118622, 'weight_decay': 8.926051912249413e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 21:59:35,684] Trial 45 finished with value: 15.668359029445043 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005855367002439362, 'weight_decay': 2.1926692454117846e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:00:24,368] Trial 46 finished with value: 33.4036983297946 and parameters: {'kernel_size': 5, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005823929537639526, 'weight_decay': 1.7278120675821084e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 128, 'flip_prob': 1}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:01:38,344] Trial 47 finished with value: 15.68743175694895 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.009958840912458963, 'weight_decay': 1.981526252361394e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:02:52,867] Trial 48 finished with value: 16.10636279784842 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.0021843773378177325, 'weight_decay': 6.417241253956019e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:02:52,884] Trial 49 pruned. 
[I 2025-06-30 22:02:52,901] Trial 50 pruned. 
[I 2025-06-30 22:04:06,811] Trial 51 finished with value: 16.05662354864923 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.0096180544851113, 'weight_decay': 1.8424378882613585e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:05:19,704] Trial 52 finished with value: 15.826334195419166 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.00823171763619001, 'weight_decay': 1.5395011099051681e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:06:33,598] Trial 53 finished with value: 15.814152935198921 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.006113228717313875, 'weight_decay': 2.7134382268816555e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:07:48,105] Trial 54 finished with value: 15.911642989289257 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.0007411369727263334, 'weight_decay': 2.219583431553758e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:08:00,901] Trial 55 finished with value: 16.205300293080985 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.003928083768448613, 'weight_decay': 3.6937518068655215e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.25}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:08:52,865] Trial 56 finished with value: 26.106234765902343 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.005430688453597763, 'weight_decay': 1.0324942771612263e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 128, 'flip_prob': 1}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:09:29,207] Trial 57 finished with value: 16.26081393379992 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00809261983373328, 'weight_decay': 7.556925395207455e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 32 with value: 15.654752956102314.
[I 2025-06-30 22:10:42,476] Trial 58 finished with value: 15.590755557733331 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002810468817064702, 'weight_decay': 4.420395889886523e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:10:42,491] Trial 59 pruned. 
[I 2025-06-30 22:10:42,509] Trial 60 pruned. 
[I 2025-06-30 22:11:56,396] Trial 61 finished with value: 16.04979001513179 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0017374247119404304, 'weight_decay': 2.5271329550231843e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:13:09,101] Trial 62 finished with value: 15.749580033194126 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.007185791774596803, 'weight_decay': 4.363156628861151e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:14:22,014] Trial 63 finished with value: 16.44618278751579 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00010772996696414988, 'weight_decay': 1.6206227528099138e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:15:36,140] Trial 64 finished with value: 15.80299112569978 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.005363864958101513, 'weight_decay': 0.0001288947092189826, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:16:01,170] Trial 65 finished with value: 16.118643142460762 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.003160479047788975, 'weight_decay': 1.385862903446737e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:16:42,132] Trial 66 finished with value: 16.262244839962886 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004074493386960315, 'weight_decay': 1.373947789399505e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.5}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:17:50,487] Trial 67 finished with value: 17.687870299983704 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.008825650977507225, 'weight_decay': 4.065454919843914e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:18:57,464] Trial 68 finished with value: 15.81300613793644 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0012789378285663093, 'weight_decay': 7.807396472946821e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:18:57,485] Trial 69 pruned. 
[I 2025-06-30 22:19:38,786] Trial 70 finished with value: 17.198426363553125 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.006243054966061736, 'weight_decay': 0.0003106906996539559, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:20:28,251] Trial 71 finished with value: 15.842961257094064 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003737508995459656, 'weight_decay': 1.927732054528975e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:21:18,179] Trial 72 finished with value: 15.84703206439235 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004731206614309696, 'weight_decay': 1.9968203669621322e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:22:06,895] Trial 73 finished with value: 15.927405752360958 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.009860781794451219, 'weight_decay': 3.066647365968102e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:22:06,913] Trial 74 pruned. 
[I 2025-06-30 22:22:36,214] Trial 75 finished with value: 15.873254057393817 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0021745661141562797, 'weight_decay': 4.5958217983721354e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:22:36,232] Trial 76 pruned. 
[I 2025-06-30 22:23:52,760] Trial 77 finished with value: 15.94201876361918 and parameters: {'kernel_size': 5, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.007584875725879331, 'weight_decay': 4.9073138157743866e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:24:06,811] Trial 78 finished with value: 31.26812475933363 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006446933228367098, 'weight_decay': 1.5509480496727466e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 1}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:24:22,494] Trial 79 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.00440233483115646, 'weight_decay': 2.6243459700343136e-05, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:24:22,515] Trial 80 pruned. 
[I 2025-06-30 22:25:36,885] Trial 81 finished with value: 15.921823479451943 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0073482079131490866, 'weight_decay': 4.748388347406885e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:26:50,829] Trial 82 finished with value: 16.076101783522986 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0067892802898111716, 'weight_decay': 6.389130717807811e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:28:06,706] Trial 83 finished with value: 15.861731373667523 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.008682434985554599, 'weight_decay': 2.8653213867595414e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:29:22,322] Trial 84 finished with value: 15.852817202128785 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0048686058733459995, 'weight_decay': 0.00011887749994512047, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:30:38,987] Trial 85 finished with value: 16.22551119050858 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.006014485147102767, 'weight_decay': 1.9685501452114766e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 32, 'flip_prob': 0.5}. Best is trial 58 with value: 15.590755557733331.
[I 2025-06-30 22:31:52,342] Trial 86 finished with value: 15.539556323098529 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.007842596392824521, 'weight_decay': 3.986203039807763e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:31:52,360] Trial 87 pruned. 
[I 2025-06-30 22:32:40,424] Trial 88 finished with value: 15.79203264368013 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0025127565020152073, 'weight_decay': 9.605049737192033e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:32:40,444] Trial 89 pruned. 
[I 2025-06-30 22:33:09,411] Trial 90 finished with value: 17.03670330646187 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.004262693399349929, 'weight_decay': 1.0680607693411807e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:34:22,680] Trial 91 finished with value: 16.133089932244992 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.007246368326718788, 'weight_decay': 4.272628108793605e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:35:35,525] Trial 92 finished with value: 15.856690982620323 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00910181502559333, 'weight_decay': 0.00018685170254460613, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:36:48,796] Trial 93 finished with value: 15.606621866329077 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006663715804399303, 'weight_decay': 5.808500080712077e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:38:02,225] Trial 94 finished with value: 16.071257758351003 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005771585621154527, 'weight_decay': 7.090550372985746e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:39:15,428] Trial 95 finished with value: 15.898210889648556 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.005146670905020662, 'weight_decay': 5.8352996179355975e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:39:49,549] Trial 96 finished with value: 34.56913733256335 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006636589316494446, 'weight_decay': 1.3071031644568177e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 1}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:41:04,001] Trial 97 finished with value: 17.022791105534136 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.000280464637085572, 'weight_decay': 3.2432192560695292e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:41:04,023] Trial 98 pruned. 
[I 2025-06-30 22:41:23,242] Trial 99 finished with value: 16.640694690241695 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.0005466929841350151, 'weight_decay': 8.67483269209998e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:41:23,261] Trial 100 pruned. 
[I 2025-06-30 22:42:38,644] Trial 101 finished with value: 15.980899783356122 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006916333078182059, 'weight_decay': 3.914687951722817e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:43:53,467] Trial 102 finished with value: 15.921017440092568 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.008713019480373304, 'weight_decay': 1.166764144440016e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:45:07,977] Trial 103 finished with value: 16.007201198816066 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006143222407070918, 'weight_decay': 1.7366874392041187e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:46:00,021] Trial 104 finished with value: 15.68131463081083 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005629095624987271, 'weight_decay': 4.641013111874353e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:46:48,909] Trial 105 finished with value: 15.922245109810008 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0030743568069899444, 'weight_decay': 2.7209835375631475e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:47:41,422] Trial 106 finished with value: 16.36767067898329 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0048384059290705285, 'weight_decay': 5.099740846562057e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:48:29,505] Trial 107 finished with value: 15.738331386956485 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.003934834312458436, 'weight_decay': 3.5875859835024653e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:49:18,972] Trial 108 finished with value: 15.690085081229533 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0040127715905958535, 'weight_decay': 3.7321557038879764e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:50:07,278] Trial 109 finished with value: 15.909590932815517 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.003285416476817827, 'weight_decay': 5.531811040357661e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:50:07,299] Trial 110 pruned. 
[I 2025-06-30 22:50:55,999] Trial 111 finished with value: 15.669376653251636 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0039170755985334805, 'weight_decay': 3.823991990256713e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:51:44,449] Trial 112 finished with value: 15.69530313441316 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0035556055433925244, 'weight_decay': 7.0934745234365285e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:52:32,980] Trial 113 finished with value: 15.644071251943089 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.002774595339864859, 'weight_decay': 4.28074534645577e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:53:21,346] Trial 114 finished with value: 15.613625946680912 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0028682951726747494, 'weight_decay': 2.28819604504223e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:54:09,667] Trial 115 finished with value: 16.028940624175956 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0028051236816597027, 'weight_decay': 4.411331553078307e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:54:59,433] Trial 116 finished with value: 15.881884848927314 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0026943995286912935, 'weight_decay': 2.4463707043064362e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:55:40,189] Trial 117 finished with value: 16.114962422875028 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0017960145593530004, 'weight_decay': 8.996834228842423e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:56:43,630] Trial 118 finished with value: 16.046670612847738 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0022087812292387876, 'weight_decay': 1.564615162964608e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 86 with value: 15.539556323098529.
[I 2025-06-30 22:56:43,650] Trial 119 pruned. 
[I 2025-06-30 22:56:43,671] Trial 120 pruned. 
[I 2025-06-30 22:57:31,887] Trial 121 finished with value: 15.493945159799877 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.002991075183277198, 'weight_decay': 1.8660900908876813e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 22:58:21,461] Trial 122 finished with value: 15.87317242985576 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0029146987506043307, 'weight_decay': 1.9689323119477853e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 22:59:10,905] Trial 123 finished with value: 16.025032551314325 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0030582917739227196, 'weight_decay': 1.3507887338779087e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:00:00,070] Trial 124 finished with value: 15.873415013862303 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0023339517298107816, 'weight_decay': 3.2508309794870474e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:00:48,775] Trial 125 finished with value: 15.805822115857914 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0031913220435543137, 'weight_decay': 8.194913523721086e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:00:48,794] Trial 126 pruned. 
[I 2025-06-30 23:01:45,181] Trial 127 finished with value: 15.796618158578015 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.0045853366030882085, 'weight_decay': 1.638646167248621e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:02:34,610] Trial 128 finished with value: 16.287088734607128 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0008658733301694534, 'weight_decay': 2.2629893733342672e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:03:05,195] Trial 129 finished with value: 15.945731927149044 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0016072003826978908, 'weight_decay': 4.947047500209764e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:03:51,128] Trial 130 finished with value: 16.486674006369505 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0038400945854076655, 'weight_decay': 0.003761942059506557, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:05:04,065] Trial 131 finished with value: 15.77054924916582 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.007637887810409662, 'weight_decay': 1.8870266528874623e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:05:52,971] Trial 132 finished with value: 15.937781443039395 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0025430031371641393, 'weight_decay': 2.785682813411008e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:06:54,069] Trial 133 finished with value: 15.860469458344015 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0062279127958481065, 'weight_decay': 3.7791952646593626e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:07:06,703] Trial 134 finished with value: 17.42297001234181 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00893222396042708, 'weight_decay': 1.5608581330035948e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:08:23,726] Trial 135 finished with value: 16.344645142594207 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005237963115004439, 'weight_decay': 2.3728212784162983e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:08:48,703] Trial 136 finished with value: 16.04984498281189 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004246227025893607, 'weight_decay': 1.019710212993858e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:08:48,726] Trial 137 pruned. 
[I 2025-06-30 23:09:50,036] Trial 138 finished with value: 16.422443638365422 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005870830022895897, 'weight_decay': 3.0798702955855427e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': False, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:10:29,199] Trial 139 finished with value: 16.641061607315947 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 0, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.00820628299211745, 'weight_decay': 0.00014973594201884936, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:11:59,246] Trial 140 finished with value: 15.90653199485487 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0033702230377489193, 'weight_decay': 5.219289322827102e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:12:48,548] Trial 141 finished with value: 16.05263654341609 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0028042864666919217, 'weight_decay': 3.28869398742526e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:13:38,421] Trial 142 finished with value: 15.705954031369078 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.00405352744454616, 'weight_decay': 3.865074265711736e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:14:26,380] Trial 143 finished with value: 15.908071232372034 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004928694565584613, 'weight_decay': 7.882427151229638e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:15:14,826] Trial 144 finished with value: 15.74364011308733 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0037651547399370077, 'weight_decay': 0.00010581540669980265, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:16:03,523] Trial 145 finished with value: 15.814669768379265 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004456652421893953, 'weight_decay': 1.7260851194949997e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:16:03,544] Trial 146 pruned. 
[I 2025-06-30 23:16:03,568] Trial 147 pruned. 
[I 2025-06-30 23:16:52,182] Trial 148 finished with value: 15.673532310752707 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0030936539807555528, 'weight_decay': 2.5841632742513152e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:17:53,077] Trial 149 finished with value: 29.241728800891778 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0019614141067128446, 'weight_decay': 2.677994158360291e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 32, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:19:14,234] Trial 150 finished with value: 16.470524930688985 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003060256988259732, 'weight_decay': 1.298342274580657e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:20:04,856] Trial 151 finished with value: 15.839675320328821 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0032975298948770843, 'weight_decay': 3.6880261242229247e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:20:54,383] Trial 152 finished with value: 15.735727173941475 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002283545365820527, 'weight_decay': 4.23952691472491e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:21:43,489] Trial 153 finished with value: 16.07980157784209 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0029219999479817155, 'weight_decay': 2.3671851870504545e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:22:32,184] Trial 154 finished with value: 15.848060926840796 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003772456647661527, 'weight_decay': 6.906990133965495e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:23:21,827] Trial 155 finished with value: 15.979219384269802 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0075788971590496235, 'weight_decay': 5.063832886976742e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:24:12,026] Trial 156 finished with value: 15.882590826058863 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.005650868846518885, 'weight_decay': 2.9351455240952874e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:24:40,334] Trial 157 finished with value: 16.328957285511606 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0034909456095569514, 'weight_decay': 1.765361498616334e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:25:29,767] Trial 158 finished with value: 16.113201109557885 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.00940666325491025, 'weight_decay': 3.7114739741088444e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:26:45,340] Trial 159 finished with value: 15.52129960629082 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.004150230984782345, 'weight_decay': 2.107222499996181e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:26:45,363] Trial 160 pruned. 
[I 2025-06-30 23:27:59,338] Trial 161 finished with value: 15.987687600987844 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0041075773210143204, 'weight_decay': 2.045533327298634e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:29:13,572] Trial 162 finished with value: 16.072634592209038 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.004976931244206119, 'weight_decay': 2.883690873317325e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:30:26,727] Trial 163 finished with value: 15.812187449220506 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0031797414845818823, 'weight_decay': 2.4488611063866004e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:31:40,018] Trial 164 finished with value: 15.884405911144146 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.004494932597800417, 'weight_decay': 4.241485212473793e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:32:29,389] Trial 165 finished with value: 15.614431129946901 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.006832045123936597, 'weight_decay': 5.7074320390543275e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:33:34,709] Trial 166 finished with value: 16.04052443502775 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0067887622482726215, 'weight_decay': 1.0819688050935008e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:33:34,731] Trial 167 pruned. 
[I 2025-06-30 23:34:47,340] Trial 168 finished with value: 15.765403104085632 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0063459961443008426, 'weight_decay': 8.126806858997216e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:34:47,361] Trial 169 pruned. 
[I 2025-06-30 23:35:05,839] Trial 170 finished with value: 16.889068800859803 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.005767199641274209, 'weight_decay': 1.1448135609270522e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:35:57,289] Trial 171 finished with value: 15.684527811173249 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00520557060345254, 'weight_decay': 3.466406931515792e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:36:46,895] Trial 172 finished with value: 15.834683502760928 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005130724514873795, 'weight_decay': 4.677277245587625e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:37:36,306] Trial 173 finished with value: 15.65969365030459 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005503579768273554, 'weight_decay': 3.304149368673658e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:38:24,912] Trial 174 finished with value: 15.579525433166543 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005740805727171165, 'weight_decay': 3.2028132322667415e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:39:14,381] Trial 175 finished with value: 15.892866453574195 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00624546959812597, 'weight_decay': 5.093258136684158e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:40:03,909] Trial 176 finished with value: 15.801873715261339 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005830286613020634, 'weight_decay': 3.0354026870776254e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:40:53,479] Trial 177 finished with value: 15.84706053245921 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006749005062635982, 'weight_decay': 6.8532011630068355e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:41:28,944] Trial 178 finished with value: 15.83119044813622 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.005602799279317205, 'weight_decay': 2.3193403701636634e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:41:28,972] Trial 179 pruned. 
[I 2025-06-30 23:42:43,580] Trial 180 finished with value: 15.903155454976686 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0046754924435574155, 'weight_decay': 4.3723764594385565e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:43:33,624] Trial 181 finished with value: 15.750390826584116 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005077529500535926, 'weight_decay': 3.622580022559013e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:44:23,291] Trial 182 finished with value: 15.910736919501593 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005506675784029941, 'weight_decay': 2.75615389828636e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:45:13,664] Trial 183 finished with value: 15.860399134293925 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0035707362268046286, 'weight_decay': 3.3632292727152974e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:46:06,458] Trial 184 finished with value: 15.717924085930695 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002945236667492545, 'weight_decay': 5.567421222296216e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:46:56,165] Trial 185 finished with value: 15.8410757023667 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004239539230890141, 'weight_decay': 1.998747551383245e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:47:47,130] Trial 186 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00648326520080004, 'weight_decay': 9.79245436180578e-05, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:48:37,657] Trial 187 finished with value: 15.946818934113576 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005317684264967588, 'weight_decay': 3.077411383952233e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:49:33,758] Trial 188 finished with value: 29.296701776081147 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006049346311333632, 'weight_decay': 4.370214291972081e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:50:24,081] Trial 189 finished with value: 15.800602836833354 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.007210801318897212, 'weight_decay': 3.600182172624614e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:51:13,182] Trial 190 finished with value: 17.017331415471318 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0001391154318035354, 'weight_decay': 2.443846457870221e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:52:26,740] Trial 191 finished with value: 15.838657609229385 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.008022335452455025, 'weight_decay': 1.9113482463122813e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:53:42,078] Trial 192 finished with value: 15.90037943343393 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0027488096548140047, 'weight_decay': 5.941769071159258e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:54:19,368] Trial 193 finished with value: 15.90977240247873 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.008843406503606335, 'weight_decay': 7.244689379943715e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:55:32,918] Trial 194 finished with value: 15.78413961197902 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.0032009056672580136, 'weight_decay': 2.845529279478515e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:56:14,369] Trial 195 finished with value: 16.765713103731773 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00988342156751557, 'weight_decay': 2.2757291700530503e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:56:14,394] Trial 196 pruned. 
[I 2025-06-30 23:57:27,723] Trial 197 finished with value: 15.956457777793362 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004712402824037461, 'weight_decay': 0.0005133083526976695, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:58:17,011] Trial 198 finished with value: 16.092166625350547 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006832169245949836, 'weight_decay': 1.8049800709339027e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:58:41,902] Trial 199 finished with value: 16.349973635565966 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.005849144511305896, 'weight_decay': 4.718801761651692e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-06-30 23:58:41,928] Trial 200 pruned. 
[I 2025-06-30 23:59:31,069] Trial 201 finished with value: 15.737083189079831 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004124241938386172, 'weight_decay': 3.436863570554831e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:00:20,356] Trial 202 finished with value: 15.777422375911277 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.003275020479531784, 'weight_decay': 2.7376386432888153e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:01:09,112] Trial 203 finished with value: 15.952530471512445 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0036731251555704547, 'weight_decay': 4.437536027722884e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:01:57,852] Trial 204 finished with value: 15.990082050546707 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.00516326598832576, 'weight_decay': 3.925477053555793e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:02:46,527] Trial 205 finished with value: 15.924412378184583 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0029671015337453593, 'weight_decay': 5.386300050808205e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:04:04,714] Trial 206 finished with value: 16.07472060216958 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.0025227995221093814, 'weight_decay': 2.142579968890267e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:05:09,683] Trial 207 finished with value: 16.08233686224547 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0044218382437379005, 'weight_decay': 3.168281345062365e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:05:44,775] Trial 208 finished with value: 15.899689036827922 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.005553296137342598, 'weight_decay': 6.539725821857223e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:05:44,805] Trial 209 pruned. 
[I 2025-07-01 00:06:58,290] Trial 210 finished with value: 15.794232280864634 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0033329005644216372, 'weight_decay': 1.623441016845339e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:07:46,662] Trial 211 finished with value: 15.74460107978554 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0036369224847289704, 'weight_decay': 8.996609800512343e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:08:35,704] Trial 212 finished with value: 15.649222710975131 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.003411726150746611, 'weight_decay': 7.856176444099791e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:09:24,480] Trial 213 finished with value: 15.792329637939613 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.002756603176510027, 'weight_decay': 7.436251619749299e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:10:12,572] Trial 214 finished with value: 15.74736728275395 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0030702928416968325, 'weight_decay': 5.087508089904975e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:10:37,033] Trial 215 finished with value: 15.976343359733649 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0033930894300235946, 'weight_decay': 4.069786939912922e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:11:26,022] Trial 216 finished with value: 15.93118703517309 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004000032700026163, 'weight_decay': 5.880673364972486e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:12:33,384] Trial 217 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004641274265483158, 'weight_decay': 1.0813466484036394e-05, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:13:21,496] Trial 218 finished with value: 15.949955039883251 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00611726806245888, 'weight_decay': 3.2817053846573627e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:14:36,050] Trial 219 finished with value: 16.23522863017067 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0011850581311677127, 'weight_decay': 2.165191217487033e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:15:24,931] Trial 220 finished with value: 15.588127336068728 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.007523750308607497, 'weight_decay': 4.030197668171005e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:16:13,547] Trial 221 finished with value: 16.03730785055619 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.006999073242648791, 'weight_decay': 3.852028245615846e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:17:02,872] Trial 222 finished with value: 15.936493813426482 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.00808819427146239, 'weight_decay': 4.613699576967113e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:17:52,079] Trial 223 finished with value: 15.89784013979495 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.007412377980364961, 'weight_decay': 2.768277640300636e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:18:40,903] Trial 224 finished with value: 15.884052110443164 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.0066972614577271135, 'weight_decay': 0.00014827285059453274, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:19:29,362] Trial 225 finished with value: 15.687922105480542 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.00900000665822984, 'weight_decay': 6.772509025447105e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:20:19,170] Trial 226 finished with value: 15.780781626194745 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.009071772722117155, 'weight_decay': 8.484538861286103e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:21:29,426] Trial 227 finished with value: 17.951829797109383 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.00840568175932914, 'weight_decay': 6.1390938412731345e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:22:18,739] Trial 228 finished with value: 15.876900580008071 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.008927468104483367, 'weight_decay': 7.2618283132366044e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:22:18,764] Trial 229 pruned. 
[I 2025-07-01 00:23:41,268] Trial 230 finished with value: 28.405593008182922 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.007550856274955779, 'weight_decay': 5.170477458977234e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:24:30,502] Trial 231 finished with value: 15.68347912639058 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0030585768065011527, 'weight_decay': 3.743083876437031e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:25:19,684] Trial 232 finished with value: 15.818565306923833 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0026925408090448834, 'weight_decay': 3.2964553233796397e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:26:08,894] Trial 233 finished with value: 15.833759105528987 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.003022506748652891, 'weight_decay': 4.193978311733663e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:26:58,832] Trial 234 finished with value: 15.812026296654883 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.007843765241875607, 'weight_decay': 6.7430088475731974e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:27:48,471] Trial 235 finished with value: 15.629216716039332 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 64, 'lr': 0.002916531077324891, 'weight_decay': 2.5278572122978365e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:28:37,030] Trial 236 finished with value: 15.87033356276553 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 64, 'lr': 0.0029137796324711415, 'weight_decay': 2.5378010243385967e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:28:37,057] Trial 237 pruned. 
[I 2025-07-01 00:29:25,416] Trial 238 finished with value: 15.701213388047059 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.003313107560946119, 'weight_decay': 1.7450136618742302e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:30:39,541] Trial 239 finished with value: 15.692296542853224 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 64, 'lr': 0.0029864647538281825, 'weight_decay': 2.00312829663633e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:31:29,154] Trial 240 finished with value: 15.766142501594118 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.0034617980023126695, 'weight_decay': 2.541272335355312e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:32:18,535] Trial 241 finished with value: 16.337093823405798 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0006894260191364759, 'weight_decay': 3.6934320883420666e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:33:07,005] Trial 242 finished with value: 15.816777342166258 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.00231547954107536, 'weight_decay': 4.81860814361029e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:33:55,238] Trial 243 finished with value: 16.107061516424142 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0004108348263554947, 'weight_decay': 5.675272363544399e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:34:42,973] Trial 244 finished with value: 15.64637061184861 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.006172919523909882, 'weight_decay': 3.271891601661782e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:35:32,016] Trial 245 finished with value: 15.725179774810302 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0060103718948525614, 'weight_decay': 3.351090781041983e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:36:13,555] Trial 246 finished with value: 16.401521075742235 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.00537259337681419, 'weight_decay': 2.1759896538999586e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:36:55,785] Trial 247 finished with value: 15.854883944999942 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.006270124868087393, 'weight_decay': 2.8027038531709026e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:37:45,136] Trial 248 finished with value: 15.916865692375609 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0067332773497658545, 'weight_decay': 4.1000030842644965e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:38:46,317] Trial 249 finished with value: 16.465337082388043 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005656760131194326, 'weight_decay': 3.1947593354138792e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 128, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:38:46,350] Trial 250 pruned. 
[I 2025-07-01 00:39:48,640] Trial 251 finished with value: 15.958485112310274 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0032086230681249617, 'weight_decay': 4.146657397113755e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:40:35,350] Trial 252 finished with value: 16.17869099420284 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002806848665515709, 'weight_decay': 3.5351460212574813e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:40:54,848] Trial 253 finished with value: 16.65580137339477 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.005155320372481944, 'weight_decay': 1.5246082268265641e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 32, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:42:07,736] Trial 254 finished with value: 15.665086875596286 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.007055393790165219, 'weight_decay': 2.7742550119517976e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:42:56,709] Trial 255 finished with value: 15.846330801386115 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.006356385803764656, 'weight_decay': 2.9097952686688764e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:44:11,434] Trial 256 finished with value: 16.136680131334227 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.006615754070632103, 'weight_decay': 4.844770487820124e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:44:53,435] Trial 257 finished with value: 16.834353141435496 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.007361096085103507, 'weight_decay': 2.629261004627966e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:45:18,717] Trial 258 finished with value: 16.1597889631782 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.006049536196837644, 'weight_decay': 3.978458309474245e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:45:18,745] Trial 259 pruned. 
[I 2025-07-01 00:46:10,226] Trial 260 finished with value: 15.661522836613475 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.006951083905195404, 'weight_decay': 0.0001042538710970538, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:47:23,345] Trial 261 finished with value: 16.015857805337497 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.007203001179406252, 'weight_decay': 0.00010776159025995349, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:48:12,494] Trial 262 finished with value: 15.810442845000672 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.007053158078960715, 'weight_decay': 8.606218809355648e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:48:12,521] Trial 263 pruned. 
[I 2025-07-01 00:48:12,547] Trial 264 pruned. 
[I 2025-07-01 00:49:34,891] Trial 265 finished with value: 27.27227837199984 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.007830874623711083, 'weight_decay': 0.0001321394581259048, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:50:24,144] Trial 266 finished with value: 15.797480280160046 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.006854760894898047, 'weight_decay': 9.795852687168747e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:51:05,088] Trial 267 finished with value: 16.091031046465513 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.003239702393292241, 'weight_decay': 0.00021591013647081128, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:52:19,100] Trial 268 finished with value: 15.700411422457638 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.005834348584124304, 'weight_decay': 1.6354787555734667e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:53:09,226] Trial 269 finished with value: 16.04843741002602 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.0025345802042990462, 'weight_decay': 0.00012377222500310018, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:54:11,427] Trial 270 finished with value: 16.444323940033925 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.002869926186479697, 'weight_decay': 1.8640742982574978e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:55:00,974] Trial 271 finished with value: 15.991742485759694 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006456217145514865, 'weight_decay': 5.552600879005174e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:55:30,354] Trial 272 finished with value: 16.052033352360844 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003676235005899321, 'weight_decay': 2.985502959664364e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:55:30,397] Trial 273 pruned. 
[I 2025-07-01 00:56:19,042] Trial 274 finished with value: 15.905771272951732 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0030458652189026794, 'weight_decay': 6.548341302265539e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:57:08,360] Trial 275 finished with value: 15.747032415247228 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.003443258327373558, 'weight_decay': 3.1804302150484733e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:57:55,870] Trial 276 finished with value: 16.624437078380552 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.001455649687146884, 'weight_decay': 8.54073756126731e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 32, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 00:57:55,897] Trial 277 pruned. 
[I 2025-07-01 00:59:10,405] Trial 278 finished with value: 15.857632306246401 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.002123903742900131, 'weight_decay': 5.046382781934843e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:00:01,481] Trial 279 finished with value: 16.06690888499933 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0071954754400821936, 'weight_decay': 3.637872482295321e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:00:53,296] Trial 280 finished with value: 15.822431083285135 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006350808741512264, 'weight_decay': 1.1641530608132831e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:00:53,324] Trial 281 pruned. 
[I 2025-07-01 01:01:55,874] Trial 282 finished with value: 15.858585198668337 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002823514438161541, 'weight_decay': 2.58674762978757e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:03:10,358] Trial 283 finished with value: 15.890721960837796 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.008083212748970484, 'weight_decay': 2.047408485870274e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:03:23,402] Trial 284 finished with value: 16.156719810084294 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0040022502111370355, 'weight_decay': 1.0022706171025733e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:04:14,096] Trial 285 finished with value: 15.601050283364042 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.003214983135213641, 'weight_decay': 4.3695004899690496e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:05:04,528] Trial 286 finished with value: 15.75339302700226 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0034543526230697455, 'weight_decay': 6.110745934816679e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:05:04,557] Trial 287 pruned. 
[I 2025-07-01 01:05:55,319] Trial 288 finished with value: 15.66073011034803 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.005429845426151294, 'weight_decay': 1.4821648005693563e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:07:10,903] Trial 289 finished with value: 15.875022926218334 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0060350729994523835, 'weight_decay': 1.4653039039364212e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:07:58,294] Trial 290 finished with value: 16.765735732530917 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.005292675093521303, 'weight_decay': 1.3717053925382215e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:08:45,387] Trial 291 finished with value: 16.049675764075758 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0036999103630982583, 'weight_decay': 1.6510331455106074e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:09:47,576] Trial 292 finished with value: 16.22752957439142 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.004213522552286576, 'weight_decay': 1.9109911023417474e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:11:11,726] Trial 293 finished with value: 29.401428471440855 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0032474170130887656, 'weight_decay': 1.2369042800480766e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:12:01,593] Trial 294 finished with value: 15.917396670114218 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.008366219092553705, 'weight_decay': 2.2767755101851985e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:12:51,886] Trial 295 finished with value: 15.932075211174856 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0024233745028920594, 'weight_decay': 1.7966510716148895e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:12:51,918] Trial 296 pruned. 
[I 2025-07-01 01:14:08,919] Trial 297 finished with value: 15.604998233155435 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 256, 'lr': 0.0048602063610378695, 'weight_decay': 1.523183513414725e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:14:08,948] Trial 298 pruned. 
[I 2025-07-01 01:15:24,053] Trial 299 finished with value: 15.800065830276854 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 256, 'lr': 0.004513035141644339, 'weight_decay': 2.091956968880896e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:17:16,890] Trial 300 finished with value: 15.88281424367455 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 256, 'lr': 0.005615766526097471, 'weight_decay': 5.3298875303309173e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:18:32,660] Trial 301 finished with value: 15.813081591064613 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 256, 'lr': 0.004984558723661114, 'weight_decay': 3.131616597683487e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:19:47,051] Trial 302 finished with value: 15.696823873641485 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 256, 'lr': 0.006062765691842933, 'weight_decay': 1.0207015930945538e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:19:47,079] Trial 303 pruned. 
[I 2025-07-01 01:20:24,172] Trial 304 finished with value: 15.918473229995932 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.005353970137075708, 'weight_decay': 2.3942366728205267e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:21:41,170] Trial 305 finished with value: 16.083975916323453 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006433774654934084, 'weight_decay': 3.4422128805685327e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:22:33,396] Trial 306 finished with value: 16.168662987491125 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.00096496661567177, 'weight_decay': 0.00010829353116318574, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:23:04,057] Trial 307 finished with value: 16.083596078973066 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.003920970604735418, 'weight_decay': 1.766120058787104e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:23:54,802] Trial 308 finished with value: 15.755435457257672 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004646937810698864, 'weight_decay': 5.478892277640989e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:25:07,737] Trial 309 finished with value: 16.074030652004115 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.007373068677497158, 'weight_decay': 2.9946972307022295e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:25:57,357] Trial 310 finished with value: 15.768567544177063 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005689340016695437, 'weight_decay': 4.438711173317168e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:25:57,388] Trial 311 pruned. 
[I 2025-07-01 01:27:11,592] Trial 312 finished with value: 15.68663245597358 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 64, 'lr': 0.006749364292274869, 'weight_decay': 3.709692543615305e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:27:53,904] Trial 313 finished with value: 15.901132192359169 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0076618691797244905, 'weight_decay': 2.0084656357208736e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:28:43,233] Trial 314 finished with value: 15.81711753422468 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.005604175181639111, 'weight_decay': 0.005594493537732414, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:28:56,237] Trial 315 finished with value: 16.275408949950194 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002710853461370273, 'weight_decay': 2.833663417857976e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:30:02,463] Trial 316 finished with value: 17.556277085223513 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005199837490828463, 'weight_decay': 6.541755718815382e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': False, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:30:55,889] Trial 317 finished with value: 16.588040812337425 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.004823929239660132, 'weight_decay': 2.2707217915482786e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:32:09,443] Trial 318 finished with value: 15.799286798076249 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0038509591744586135, 'weight_decay': 1.657405254688763e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:32:09,472] Trial 319 pruned. 
[I 2025-07-01 01:32:09,504] Trial 320 pruned. 
[I 2025-07-01 01:32:58,559] Trial 321 finished with value: 16.08912221478964 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00343753601878463, 'weight_decay': 5.035528966748951e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:34:11,583] Trial 322 finished with value: 15.781671030843285 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0060783162165094036, 'weight_decay': 2.6242082145961707e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:34:11,613] Trial 323 pruned. 
[I 2025-07-01 01:35:01,804] Trial 324 finished with value: 16.36538540845449 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.00026238555614076155, 'weight_decay': 8.581993606201264e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:35:51,281] Trial 325 finished with value: 15.752924889511203 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 64, 'lr': 0.006831216365996745, 'weight_decay': 0.003058248446134617, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:37:06,414] Trial 326 finished with value: 15.791769279923926 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.007371672892400857, 'weight_decay': 1.332023099413139e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:37:57,688] Trial 327 finished with value: 15.790207799878452 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0026813433987313696, 'weight_decay': 7.33263898096444e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:38:48,077] Trial 328 finished with value: 15.74836940709264 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0032356749430985637, 'weight_decay': 4.161309376394412e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:40:03,252] Trial 329 finished with value: 15.80657242341305 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005429113540877248, 'weight_decay': 5.395104697616699e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:40:50,235] Trial 330 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0063968488337529045, 'weight_decay': 2.0326338916931093e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:41:43,888] Trial 331 finished with value: 16.27760080092481 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0036418051866530226, 'weight_decay': 2.8741435332321713e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:42:20,769] Trial 332 finished with value: 15.907997662898723 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0022574987623557403, 'weight_decay': 0.00013099403576109268, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:42:20,802] Trial 333 pruned. 
[I 2025-07-01 01:43:39,079] Trial 334 finished with value: 15.936558208110169 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004492856917485704, 'weight_decay': 3.7057326410751463e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:44:29,610] Trial 335 finished with value: 16.022246919141246 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.007742886344810055, 'weight_decay': 1.5150076185114228e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:45:12,677] Trial 336 finished with value: 16.520468101426644 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0057939249625428265, 'weight_decay': 6.316120401049105e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:45:35,670] Trial 337 finished with value: 16.561002198213377 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 0, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.004981627392278865, 'weight_decay': 2.2359616504420825e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:46:56,766] Trial 338 finished with value: 15.940762735574454 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006826243951914048, 'weight_decay': 3.3565062064742227e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:49:01,884] Trial 339 finished with value: 15.989591316367802 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.003939337027234399, 'weight_decay': 4.871756339100692e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:50:06,937] Trial 340 finished with value: 15.753067397572472 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0024927076349549964, 'weight_decay': 0.00040804309660603916, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:50:06,982] Trial 341 pruned. 
[I 2025-07-01 01:50:07,025] Trial 342 pruned. 
[I 2025-07-01 01:51:17,264] Trial 343 finished with value: 16.640011151735592 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006151019960841855, 'weight_decay': 7.66552240461387e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:51:34,204] Trial 344 finished with value: 16.529266308787292 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005310851135275835, 'weight_decay': 3.909609866958718e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:53:25,366] Trial 345 finished with value: 15.921863754811183 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.007070349417023031, 'weight_decay': 0.0001862886037704807, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:54:42,514] Trial 346 finished with value: 26.83588849566816 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0028673786189235165, 'weight_decay': 0.0007490272194650323, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:56:14,691] Trial 347 finished with value: 16.44450869689622 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0005780837440715578, 'weight_decay': 2.4686961117862487e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:57:48,434] Trial 348 finished with value: 16.16522226523792 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0034967339169815186, 'weight_decay': 4.343950826755014e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:58:16,585] Trial 349 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00779856627789827, 'weight_decay': 5.650476715403658e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 10, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 01:59:17,842] Trial 350 finished with value: 15.882424118862545 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.006004384855903013, 'weight_decay': 2.078305085509143e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:00:47,083] Trial 351 finished with value: 15.82048403573761 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004768998100754912, 'weight_decay': 3.1560158070843613e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:01:53,268] Trial 352 finished with value: 16.007567429082695 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.006708470917992264, 'weight_decay': 9.612455047869122e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:02:54,391] Trial 353 finished with value: 15.5623660388434 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004229350023972985, 'weight_decay': 1.1781994298312001e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:03:56,254] Trial 354 finished with value: 15.911878653467383 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.003949134716260314, 'weight_decay': 1.097633006448481e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:03:56,288] Trial 355 pruned. 
[I 2025-07-01 02:04:59,016] Trial 356 finished with value: 15.704924401367128 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004425968901573705, 'weight_decay': 1.2497317006867873e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:04:59,058] Trial 357 pruned. 
[I 2025-07-01 02:06:18,319] Trial 358 finished with value: 16.052933788018976 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.005617388274463066, 'weight_decay': 1.5988960798554856e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:07:20,595] Trial 359 finished with value: 16.23998849662389 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0018450310603576484, 'weight_decay': 1.46979580742411e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:07:20,629] Trial 360 pruned. 
[I 2025-07-01 02:08:09,185] Trial 361 finished with value: 15.672287727735057 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.006441562137209305, 'weight_decay': 1.002617527945969e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:09:17,515] Trial 362 finished with value: 15.92514599815386 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004053984884173986, 'weight_decay': 0.00010459282858299394, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:10:08,618] Trial 363 finished with value: 15.887998417882056 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 64, 'lr': 0.007153747270346301, 'weight_decay': 6.574154294593273e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:10:08,655] Trial 364 pruned. 
[I 2025-07-01 02:10:58,316] Trial 365 finished with value: 15.840700881237218 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.005873113237812809, 'weight_decay': 0.0013718470448677563, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:12:12,903] Trial 366 finished with value: 15.915554430719371 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003756227098922544, 'weight_decay': 4.644362051378775e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:13:25,449] Trial 367 finished with value: 15.939946739842744 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.005244232489592018, 'weight_decay': 2.7311473422341822e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:13:55,341] Trial 368 finished with value: 15.8791239658342 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.007442316439584529, 'weight_decay': 1.8258060930482035e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:14:44,294] Trial 369 finished with value: 15.69764386832071 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0034437442615567132, 'weight_decay': 3.996563596997209e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:15:53,638] Trial 370 finished with value: 15.890758035852457 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.006271232068137192, 'weight_decay': 5.672457151388811e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:16:49,358] Trial 371 finished with value: 16.806544708558725 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004450603886248122, 'weight_decay': 1.3407118511444096e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:17:58,364] Trial 372 finished with value: 30.07035487911677 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.005008073776453361, 'weight_decay': 3.426720155835578e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:18:48,305] Trial 373 finished with value: 16.034477598646102 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.005636499335140336, 'weight_decay': 1.8801422065519644e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:19:00,819] Trial 374 finished with value: 16.413808621234775 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.007768072926811033, 'weight_decay': 2.446404969674406e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:19:43,006] Trial 375 finished with value: 16.783625193381084 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.0025483263018895815, 'weight_decay': 7.2866787643034424e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:19:43,041] Trial 376 pruned. 
[I 2025-07-01 02:20:33,189] Trial 377 finished with value: 15.897220202854701 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0041263679046270344, 'weight_decay': 2.9525480608794755e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:20:33,224] Trial 378 pruned. 
[I 2025-07-01 02:21:27,557] Trial 379 finished with value: 15.762848617127222 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0032485387016384574, 'weight_decay': 6.21821501764348e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:21:27,589] Trial 380 pruned. 
[I 2025-07-01 02:22:10,104] Trial 381 finished with value: 16.172131760052583 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.007097157537686149, 'weight_decay': 1.6772300493844967e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:22:59,679] Trial 382 finished with value: 15.649250991674139 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0029169807177894013, 'weight_decay': 2.279439168078824e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:23:49,628] Trial 383 finished with value: 15.877462622775639 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0028396917436710974, 'weight_decay': 2.1935929953900127e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:25:03,623] Trial 384 finished with value: 15.91473989028407 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.008182865540089157, 'weight_decay': 0.008564721462531682, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:26:07,185] Trial 385 finished with value: 16.17091808119565 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.005831120567720277, 'weight_decay': 2.5735527352489523e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:26:57,444] Trial 386 finished with value: 16.01568719802163 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0022821225079888443, 'weight_decay': 1.9958085423349984e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:27:32,992] Trial 387 finished with value: 15.582723690505587 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.004758897718729073, 'weight_decay': 1.5631350053981895e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:27:33,037] Trial 388 pruned. 
[I 2025-07-01 02:28:10,010] Trial 389 finished with value: 15.861310777106134 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.004919638631301604, 'weight_decay': 1.241619813861275e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:28:46,537] Trial 390 finished with value: 15.842171222877564 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0054867801611938475, 'weight_decay': 1.6724389026380182e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:29:37,330] Trial 391 finished with value: 16.999162832947874 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.006326029674611169, 'weight_decay': 1.4189017308340937e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:30:12,920] Trial 392 finished with value: 15.898598762305198 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.009150588637267794, 'weight_decay': 1.8160847273265795e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:31:09,820] Trial 393 finished with value: 15.967796484369513 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.005396325311538278, 'weight_decay': 2.2160313411834755e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:31:47,790] Trial 394 finished with value: 16.09949083412422 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.002637088242718856, 'weight_decay': 1.1624094533522899e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:32:18,947] Trial 395 finished with value: 16.779285177135435 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0069378956552538186, 'weight_decay': 2.6488014059492934e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:33:19,628] Trial 396 finished with value: 15.959495604915064 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.005918151324352002, 'weight_decay': 1.9497708837058405e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:33:19,664] Trial 397 pruned. 
[I 2025-07-01 02:34:10,223] Trial 398 finished with value: 15.686610930493627 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.005197009081152631, 'weight_decay': 1.5891317081760016e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:35:25,318] Trial 399 finished with value: 16.597383590179472 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0003324610967988254, 'weight_decay': 8.924133661816842e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:35:25,352] Trial 400 pruned. 
[I 2025-07-01 02:36:15,209] Trial 401 finished with value: 15.79107549978495 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.006519003683101974, 'weight_decay': 2.3548527519706603e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:36:15,247] Trial 402 pruned. 
[I 2025-07-01 02:37:17,376] Trial 403 finished with value: 15.847580432735965 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.003022880281165144, 'weight_decay': 0.00014751664655564018, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:37:28,453] Trial 404 finished with value: 16.560988404073527 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.00597890397128498, 'weight_decay': 1.8189444691073516e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:38:19,191] Trial 405 finished with value: 15.787930382587973 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.00706792591616422, 'weight_decay': 3.164944136690487e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:39:34,347] Trial 406 finished with value: 15.760668282884522 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.008145325593950169, 'weight_decay': 2.124412815605215e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:40:38,289] Trial 407 finished with value: 15.554110615578459 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002654250394729803, 'weight_decay': 0.0002605222048932745, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:41:34,335] Trial 408 finished with value: 15.739779500721248 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0021561915458325792, 'weight_decay': 1.000086221136296e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:42:37,971] Trial 409 finished with value: 15.960547431304821 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0025183175975168315, 'weight_decay': 0.0004786483987743688, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:43:37,799] Trial 410 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0028129589632322123, 'weight_decay': 0.0002671668393354236, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:44:40,310] Trial 411 finished with value: 16.033991281796844 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0023637301616246335, 'weight_decay': 0.0010239831366387377, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:44:40,349] Trial 412 pruned. 
[I 2025-07-01 02:45:52,946] Trial 413 finished with value: 15.842591309711098 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0030102921465964233, 'weight_decay': 3.7490796592299605e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:46:28,537] Trial 414 finished with value: 15.770771322783476 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.002860922615898508, 'weight_decay': 0.0004236819716137614, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:47:16,347] Trial 415 finished with value: 16.215587678630587 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.0032567620096679833, 'weight_decay': 0.000254883638645007, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:48:45,891] Trial 416 finished with value: 15.87178815895921 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0025013555147486307, 'weight_decay': 3.5282735306411354e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:48:45,928] Trial 417 pruned. 
[I 2025-07-01 02:49:35,633] Trial 418 finished with value: 16.085714371074218 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0019893894171614493, 'weight_decay': 1.5077641318168985e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:50:11,244] Trial 419 finished with value: 15.595106918307525 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.004302223154093729, 'weight_decay': 6.180043958050294e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:50:46,337] Trial 420 finished with value: 15.736723810054384 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004008426989949886, 'weight_decay': 0.0005890044385755818, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:50:46,373] Trial 421 pruned. 
[I 2025-07-01 02:51:21,974] Trial 422 finished with value: 16.020092031697736 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0037377343003801183, 'weight_decay': 5.890301553642645e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:51:57,709] Trial 423 finished with value: 15.756426251297022 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004493183811433783, 'weight_decay': 8.04314990342996e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:52:33,375] Trial 424 finished with value: 15.747657668009893 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.004779209003118202, 'weight_decay': 4.958440688368508e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:53:13,183] Trial 425 finished with value: 16.56959571476737 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.003490577437580249, 'weight_decay': 7.453316265664098e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:53:47,755] Trial 426 finished with value: 16.078134854115003 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.003056600152821704, 'weight_decay': 0.0002073080318024795, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:53:47,793] Trial 427 pruned. 
[I 2025-07-01 02:54:22,631] Trial 428 finished with value: 27.923634898549555 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 64, 'lr': 0.0013153380853524064, 'weight_decay': 4.199735000910144e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:55:08,458] Trial 429 finished with value: inf and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.0049486159360722795, 'weight_decay': 6.029073353787278e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:55:56,897] Trial 430 finished with value: 15.849912153657412 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0033230573331574534, 'weight_decay': 4.725575183110811e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:56:45,798] Trial 431 finished with value: 15.826845569367423 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0016659114536228422, 'weight_decay': 6.203762133837378e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:57:21,963] Trial 432 finished with value: 15.779725988537082 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.0040059092714954695, 'weight_decay': 8.955652351747262e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:58:11,019] Trial 433 finished with value: 15.518504290535544 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002637445115504491, 'weight_decay': 1.2280067210759948e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:58:11,060] Trial 434 pruned. 
[I 2025-07-01 02:58:53,572] Trial 435 finished with value: 16.742719331337916 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.002793442924632059, 'weight_decay': 1.2110801018771812e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 02:58:53,609] Trial 436 pruned. 
[I 2025-07-01 03:00:09,151] Trial 437 finished with value: 15.777423503236001 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0025138007371395318, 'weight_decay': 1.020290689925095e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:00:47,656] Trial 438 finished with value: 16.431343571506087 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0029752622533007244, 'weight_decay': 1.6284575428142592e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 64, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:01:38,005] Trial 439 finished with value: 15.826791878656921 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0007903512294118975, 'weight_decay': 4.103674469561947e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:01:38,042] Trial 440 pruned. 
[I 2025-07-01 03:02:27,682] Trial 441 finished with value: 15.84444482827662 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0021851532005789155, 'weight_decay': 1.1230352021795234e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:02:40,594] Trial 442 finished with value: 16.788654062708204 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.003232606806813428, 'weight_decay': 0.001856122145681617, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:03:17,810] Trial 443 finished with value: 15.882025742694497 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003667980348601803, 'weight_decay': 0.0003129570108610908, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:04:19,820] Trial 444 finished with value: 15.65089259844428 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.003093500258670909, 'weight_decay': 1.6977049965507901e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:05:21,230] Trial 445 finished with value: 15.956782731015373 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003063235451308494, 'weight_decay': 1.822167772519283e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:06:22,361] Trial 446 finished with value: 15.840152402842268 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0028964151329792702, 'weight_decay': 5.197786997797065e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:07:23,555] Trial 447 finished with value: 15.715153460020955 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 256, 'lr': 0.003352777178059867, 'weight_decay': 2.4029705352033845e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:07:23,593] Trial 448 pruned. 
[I 2025-07-01 03:08:23,778] Trial 449 finished with value: 16.890310131283748 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.00010400808754370597, 'weight_decay': 2.067432833552971e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:09:19,961] Trial 450 finished with value: 15.704195100211287 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0030851480658822877, 'weight_decay': 3.902266288180303e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:10:19,440] Trial 451 finished with value: 15.6148816174485 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0036883173464140775, 'weight_decay': 6.997734331288216e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:11:59,767] Trial 452 finished with value: 16.431893388599146 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.003714114560532583, 'weight_decay': 7.036195309031328e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 128, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:12:42,945] Trial 453 finished with value: 15.92084512963097 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.003366642786826907, 'weight_decay': 8.753863525686457e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:14:16,908] Trial 454 finished with value: 15.767181870671571 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0038132947311292397, 'weight_decay': 6.372969428604124e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:15:28,853] Trial 455 finished with value: 16.488851512324075 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0036340415648324215, 'weight_decay': 7.203782226353551e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 25, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:16:01,850] Trial 456 finished with value: 16.423341075202615 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 0, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 256, 'lr': 0.004108973624534813, 'weight_decay': 1.085932217718958e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:16:01,889] Trial 457 pruned. 
[I 2025-07-01 03:17:43,349] Trial 458 finished with value: 26.777110075163428 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0024967737438668625, 'weight_decay': 9.868147797593777e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 128, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:18:42,607] Trial 459 finished with value: 15.962223331068575 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0028225553816937626, 'weight_decay': 7.783166533982974e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:18:42,647] Trial 460 pruned. 
[I 2025-07-01 03:20:21,416] Trial 461 finished with value: 15.689433255278233 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.0023337782607633834, 'weight_decay': 1.6262048963332435e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:21:37,843] Trial 462 finished with value: 15.913448130472613 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.004143517794316744, 'weight_decay': 4.511224696626266e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:22:23,220] Trial 463 finished with value: 15.969188845753864 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0030579256725487866, 'weight_decay': 1.7437699622395316e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 12, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:23:39,593] Trial 464 finished with value: 16.058844708196087 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0039027531787965194, 'weight_decay': 5.259298618541297e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:24:18,506] Trial 465 finished with value: 16.105376693772975 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.002704838546113549, 'weight_decay': 1.3225819616255412e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.5}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:25:08,532] Trial 466 finished with value: 15.822672786880997 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0031241739994330242, 'weight_decay': 8.092749550583395e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:25:21,562] Trial 467 finished with value: 16.105896554456187 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.003425278532964863, 'weight_decay': 2.099994392235074e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:26:11,691] Trial 468 finished with value: 15.836981851316503 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003654379760313921, 'weight_decay': 1.239162230761273e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[Trial 0] Skipped due to model construction error: Calculated padded input size per channel: (9 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
[Trial 1] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
[Trial 2] Skipped due to model construction error: Calculated padded input size per channel: (9 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
[Trial 3] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
[Trial 4] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
[Trial 5] Skipped due to model construction error: Calculated padded input size per channel: (7 x 1). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
[Trial 6] Skipped due to model construction error: Given input size: (64x10x2). Calculated output size: (64x3x0). Output size is too small
[Trial 7] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/10, Loss: nan
val phase, Epoch 1/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/10, Loss: nan
val phase, Epoch 2/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/10, Loss: nan
val phase, Epoch 3/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/10, Loss: nan
val phase, Epoch 4/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/10, Loss: nan
val phase, Epoch 5/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/10, Loss: nan
val phase, Epoch 6/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/10, Loss: nan
val phase, Epoch 7/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/10, Loss: nan
val phase, Epoch 8/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/10, Loss: nan
val phase, Epoch 9/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/10, Loss: nan
val phase, Epoch 10/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 1/10, Loss: 20.021058
val phase, Epoch 1/10, Loss: 32.105935
Val Best Loss: 32.105935
Epoch loss: 32.105935
train phase, Epoch 2/10, Loss: 17.793747
val phase, Epoch 2/10, Loss: 31.372737
Val Best Loss: 31.372737
Epoch loss: 31.372737
train phase, Epoch 3/10, Loss: 17.321126
val phase, Epoch 3/10, Loss: 31.865895
Val Best Loss: 31.372737
Epoch loss: 31.865895
train phase, Epoch 4/10, Loss: 17.265311
val phase, Epoch 4/10, Loss: 35.084214
Val Best Loss: 31.372737
Epoch loss: 35.084214
train phase, Epoch 5/10, Loss: 16.651401
val phase, Epoch 5/10, Loss: 34.037441
Val Best Loss: 31.372737
Epoch loss: 34.037441
train phase, Epoch 6/10, Loss: 16.670912
val phase, Epoch 6/10, Loss: 34.925274
Val Best Loss: 31.372737
Epoch loss: 34.925274
train phase, Epoch 7/10, Loss: 16.129497
val phase, Epoch 7/10, Loss: 36.998742
Val Best Loss: 31.372737
Epoch loss: 36.998742
train phase, Epoch 8/10, Loss: 15.991393
val phase, Epoch 8/10, Loss: 38.151227
Val Best Loss: 31.372737
Epoch loss: 38.151227
train phase, Epoch 9/10, Loss: 15.863458
val phase, Epoch 9/10, Loss: 39.764588
Val Best Loss: 31.372737
Epoch loss: 39.764588
train phase, Epoch 10/10, Loss: 15.546902
val phase, Epoch 10/10, Loss: 41.166417
Val Best Loss: 31.372737
Epoch loss: 41.166417
[Trial 10] Skipped due to model construction error: Given input size: (128x5x2). Calculated output size: (128x1x0). Output size is too small
train phase, Epoch 1/10, Loss: nan
val phase, Epoch 1/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/10, Loss: nan
val phase, Epoch 2/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/10, Loss: nan
val phase, Epoch 3/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/10, Loss: nan
val phase, Epoch 4/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/10, Loss: nan
val phase, Epoch 5/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/10, Loss: nan
val phase, Epoch 6/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/10, Loss: nan
val phase, Epoch 7/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/10, Loss: nan
val phase, Epoch 8/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/10, Loss: nan
val phase, Epoch 9/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/10, Loss: nan
val phase, Epoch 10/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 1/30, Loss: nan
val phase, Epoch 1/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/30, Loss: nan
val phase, Epoch 2/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/30, Loss: nan
val phase, Epoch 3/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/30, Loss: nan
val phase, Epoch 4/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/30, Loss: nan
val phase, Epoch 5/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/30, Loss: nan
val phase, Epoch 6/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/30, Loss: nan
val phase, Epoch 7/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/30, Loss: nan
val phase, Epoch 8/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/30, Loss: nan
val phase, Epoch 9/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/30, Loss: nan
val phase, Epoch 10/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 11/30, Loss: nan
val phase, Epoch 11/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 12/30, Loss: nan
val phase, Epoch 12/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 13/30, Loss: nan
val phase, Epoch 13/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 14/30, Loss: nan
val phase, Epoch 14/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 15/30, Loss: nan
val phase, Epoch 15/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 16/30, Loss: nan
val phase, Epoch 16/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 17/30, Loss: nan
val phase, Epoch 17/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 18/30, Loss: nan
val phase, Epoch 18/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 19/30, Loss: nan
val phase, Epoch 19/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 20/30, Loss: nan
val phase, Epoch 20/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 21/30, Loss: nan
val phase, Epoch 21/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 22/30, Loss: nan
val phase, Epoch 22/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 23/30, Loss: nan
val phase, Epoch 23/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 24/30, Loss: nan
val phase, Epoch 24/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 25/30, Loss: nan
val phase, Epoch 25/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 26/30, Loss: nan
val phase, Epoch 26/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 27/30, Loss: nan
val phase, Epoch 27/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 28/30, Loss: nan
val phase, Epoch 28/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 29/30, Loss: nan
val phase, Epoch 29/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 30/30, Loss: nan
val phase, Epoch 30/30, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 1/10, Loss: 25.790138
val phase, Epoch 1/10, Loss: 17.919299
Val Best Loss: 17.919299
Epoch loss: 17.919299
train phase, Epoch 2/10, Loss: 18.315667
val phase, Epoch 2/10, Loss: 17.397957
Val Best Loss: 17.397957
Epoch loss: 17.397957
train phase, Epoch 3/10, Loss: 17.970486
val phase, Epoch 3/10, Loss: 19.220793
Val Best Loss: 17.397957
Epoch loss: 19.220793
train phase, Epoch 4/10, Loss: 17.471168
val phase, Epoch 4/10, Loss: 16.910163
Val Best Loss: 16.910163
Epoch loss: 16.910163
train phase, Epoch 5/10, Loss: 17.139143
val phase, Epoch 5/10, Loss: 17.193914
Val Best Loss: 16.910163
Epoch loss: 17.193914
train phase, Epoch 6/10, Loss: 17.462781
val phase, Epoch 6/10, Loss: 16.678880
Val Best Loss: 16.678880
Epoch loss: 16.678880
train phase, Epoch 7/10, Loss: 17.343978
val phase, Epoch 7/10, Loss: 17.957825
Val Best Loss: 16.678880
Epoch loss: 17.957825
train phase, Epoch 8/10, Loss: 16.997797
val phase, Epoch 8/10, Loss: 16.466291
Val Best Loss: 16.466291
Epoch loss: 16.466291
train phase, Epoch 9/10, Loss: 16.564694
val phase, Epoch 9/10, Loss: 16.857266
Val Best Loss: 16.466291
Epoch loss: 16.857266
train phase, Epoch 10/10, Loss: 16.623019
val phase, Epoch 10/10, Loss: 16.141186
Val Best Loss: 16.141186
Epoch loss: 16.141186
train phase, Epoch 1/10, Loss: 20.366782
val phase, Epoch 1/10, Loss: 17.781527
Val Best Loss: 17.781527
Epoch loss: 17.781527
train phase, Epoch 2/10, Loss: 17.607800
val phase, Epoch 2/10, Loss: 17.479560
Val Best Loss: 17.479560
Epoch loss: 17.479560
train phase, Epoch 3/10, Loss: 17.365796
val phase, Epoch 3/10, Loss: 17.632649
Val Best Loss: 17.479560
Epoch loss: 17.632649
train phase, Epoch 4/10, Loss: 17.036518
val phase, Epoch 4/10, Loss: 20.272790
Val Best Loss: 17.479560
Epoch loss: 20.272790
train phase, Epoch 5/10, Loss: 16.797420
val phase, Epoch 5/10, Loss: 17.605974
Val Best Loss: 17.479560
Epoch loss: 17.605974
train phase, Epoch 6/10, Loss: 16.572104
val phase, Epoch 6/10, Loss: 16.908548
Val Best Loss: 16.908548
Epoch loss: 16.908548
train phase, Epoch 7/10, Loss: 16.176866
val phase, Epoch 7/10, Loss: 17.006040
Val Best Loss: 16.908548
Epoch loss: 17.006040
train phase, Epoch 8/10, Loss: 16.176224
val phase, Epoch 8/10, Loss: 16.831816
Val Best Loss: 16.831816
Epoch loss: 16.831816
train phase, Epoch 9/10, Loss: 15.902722
val phase, Epoch 9/10, Loss: 16.757031
Val Best Loss: 16.757031
Epoch loss: 16.757031
train phase, Epoch 10/10, Loss: 15.829191
val phase, Epoch 10/10, Loss: 17.436213
Val Best Loss: 16.757031
Epoch loss: 17.436213
train phase, Epoch 1/10, Loss: 23.038538
val phase, Epoch 1/10, Loss: 17.390381
Val Best Loss: 17.390381
Epoch loss: 17.390381
train phase, Epoch 2/10, Loss: 17.395476
val phase, Epoch 2/10, Loss: 17.392095
Val Best Loss: 17.390381
Epoch loss: 17.392095
train phase, Epoch 3/10, Loss: 17.063882
val phase, Epoch 3/10, Loss: 17.092559
Val Best Loss: 17.092559
Epoch loss: 17.092559
train phase, Epoch 4/10, Loss: 16.827594
val phase, Epoch 4/10, Loss: 17.429340
Val Best Loss: 17.092559
Epoch loss: 17.429340
train phase, Epoch 5/10, Loss: 16.488660
val phase, Epoch 5/10, Loss: 16.987471
Val Best Loss: 16.987471
Epoch loss: 16.987471
train phase, Epoch 6/10, Loss: 16.232240
val phase, Epoch 6/10, Loss: 17.087876
Val Best Loss: 16.987471
Epoch loss: 17.087876
train phase, Epoch 7/10, Loss: 16.050673
val phase, Epoch 7/10, Loss: 16.958473
Val Best Loss: 16.958473
Epoch loss: 16.958473
train phase, Epoch 8/10, Loss: 15.708625
val phase, Epoch 8/10, Loss: 17.276026
Val Best Loss: 16.958473
Epoch loss: 17.276026
train phase, Epoch 9/10, Loss: 15.610525
val phase, Epoch 9/10, Loss: 17.834650
Val Best Loss: 16.958473
Epoch loss: 17.834650
train phase, Epoch 10/10, Loss: 15.511875
val phase, Epoch 10/10, Loss: 17.685030
Val Best Loss: 16.958473
Epoch loss: 17.685030
train phase, Epoch 1/15, Loss: 22.601088
val phase, Epoch 1/15, Loss: 17.293130
Val Best Loss: 17.293130
Epoch loss: 17.293130
train phase, Epoch 2/15, Loss: 17.332652
val phase, Epoch 2/15, Loss: 17.064063
Val Best Loss: 17.064063
Epoch loss: 17.064063
train phase, Epoch 3/15, Loss: 16.950313
val phase, Epoch 3/15, Loss: 16.742340
Val Best Loss: 16.742340
Epoch loss: 16.742340
train phase, Epoch 4/15, Loss: 16.827583
val phase, Epoch 4/15, Loss: 16.529351
Val Best Loss: 16.529351
Epoch loss: 16.529351
train phase, Epoch 5/15, Loss: 16.378848
val phase, Epoch 5/15, Loss: 18.148651
Val Best Loss: 16.529351
Epoch loss: 18.148651
train phase, Epoch 6/15, Loss: 16.118976
val phase, Epoch 6/15, Loss: 16.411100
Val Best Loss: 16.411100
Epoch loss: 16.411100
train phase, Epoch 7/15, Loss: 16.055297
val phase, Epoch 7/15, Loss: 16.386414
Val Best Loss: 16.386414
Epoch loss: 16.386414
train phase, Epoch 8/15, Loss: 15.631903
val phase, Epoch 8/15, Loss: 16.342575
Val Best Loss: 16.342575
Epoch loss: 16.342575
train phase, Epoch 9/15, Loss: 15.376918
val phase, Epoch 9/15, Loss: 16.208158
Val Best Loss: 16.208158
Epoch loss: 16.208158
train phase, Epoch 10/15, Loss: 15.305880
val phase, Epoch 10/15, Loss: 16.522644
Val Best Loss: 16.208158
Epoch loss: 16.522644
train phase, Epoch 11/15, Loss: 14.833986
val phase, Epoch 11/15, Loss: 18.374818
Val Best Loss: 16.208158
Epoch loss: 18.374818
train phase, Epoch 12/15, Loss: 14.703545
val phase, Epoch 12/15, Loss: 17.709944
Val Best Loss: 16.208158
Epoch loss: 17.709944
train phase, Epoch 13/15, Loss: 14.507761
val phase, Epoch 13/15, Loss: 16.903756
Val Best Loss: 16.208158
Epoch loss: 16.903756
train phase, Epoch 14/15, Loss: 14.166703
val phase, Epoch 14/15, Loss: 17.396875
Val Best Loss: 16.208158
Epoch loss: 17.396875
train phase, Epoch 15/15, Loss: 13.843912
val phase, Epoch 15/15, Loss: 16.894000
Val Best Loss: 16.208158
Epoch loss: 16.894000
train phase, Epoch 1/15, Loss: 21.682302
val phase, Epoch 1/15, Loss: 17.886411
Val Best Loss: 17.886411
Epoch loss: 17.886411
train phase, Epoch 2/15, Loss: 17.355345
val phase, Epoch 2/15, Loss: 16.822879
Val Best Loss: 16.822879
Epoch loss: 16.822879
train phase, Epoch 3/15, Loss: 17.020173
val phase, Epoch 3/15, Loss: 16.933642
Val Best Loss: 16.822879
Epoch loss: 16.933642
train phase, Epoch 4/15, Loss: 16.777969
val phase, Epoch 4/15, Loss: 16.809165
Val Best Loss: 16.809165
Epoch loss: 16.809165
train phase, Epoch 5/15, Loss: 16.485892
val phase, Epoch 5/15, Loss: 16.993910
Val Best Loss: 16.809165
Epoch loss: 16.993910
train phase, Epoch 6/15, Loss: 16.074121
val phase, Epoch 6/15, Loss: 16.465897
Val Best Loss: 16.465897
Epoch loss: 16.465897
train phase, Epoch 7/15, Loss: 15.784393
val phase, Epoch 7/15, Loss: 16.660059
Val Best Loss: 16.465897
Epoch loss: 16.660059
train phase, Epoch 8/15, Loss: 15.697121
val phase, Epoch 8/15, Loss: 16.713446
Val Best Loss: 16.465897
Epoch loss: 16.713446
train phase, Epoch 9/15, Loss: 15.410450
val phase, Epoch 9/15, Loss: 17.670068
Val Best Loss: 16.465897
Epoch loss: 17.670068
train phase, Epoch 10/15, Loss: 15.072480
val phase, Epoch 10/15, Loss: 16.932210
Val Best Loss: 16.465897
Epoch loss: 16.932210
train phase, Epoch 11/15, Loss: 14.796086
val phase, Epoch 11/15, Loss: 17.003384
Val Best Loss: 16.465897
Epoch loss: 17.003384
train phase, Epoch 12/15, Loss: 14.240894
val phase, Epoch 12/15, Loss: 17.193703
Val Best Loss: 16.465897
Epoch loss: 17.193703
train phase, Epoch 13/15, Loss: 14.147388
val phase, Epoch 13/15, Loss: 16.474177
Val Best Loss: 16.465897
Epoch loss: 16.474177
train phase, Epoch 14/15, Loss: 13.928965
val phase, Epoch 14/15, Loss: 17.033635
Val Best Loss: 16.465897
Epoch loss: 17.033635
train phase, Epoch 15/15, Loss: 13.653650
val phase, Epoch 15/15, Loss: 16.803132
Val Best Loss: 16.465897
Epoch loss: 16.803132
[Trial 18] Skipped due to model construction error: Given input size: (128x5x2). Calculated output size: (128x1x0). Output size is too small
[Trial 19] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.298126
val phase, Epoch 1/20, Loss: 17.680110
Val Best Loss: 17.680110
Epoch loss: 17.680110
train phase, Epoch 2/20, Loss: 17.922785
val phase, Epoch 2/20, Loss: 16.650320
Val Best Loss: 16.650320
Epoch loss: 16.650320
train phase, Epoch 3/20, Loss: 17.423713
val phase, Epoch 3/20, Loss: 16.625736
Val Best Loss: 16.625736
Epoch loss: 16.625736
train phase, Epoch 4/20, Loss: 17.041690
val phase, Epoch 4/20, Loss: 16.463801
Val Best Loss: 16.463801
Epoch loss: 16.463801
train phase, Epoch 5/20, Loss: 17.117908
val phase, Epoch 5/20, Loss: 17.753484
Val Best Loss: 16.463801
Epoch loss: 17.753484
train phase, Epoch 6/20, Loss: 16.894508
val phase, Epoch 6/20, Loss: 16.004438
Val Best Loss: 16.004438
Epoch loss: 16.004438
train phase, Epoch 7/20, Loss: 16.766223
val phase, Epoch 7/20, Loss: 17.072421
Val Best Loss: 16.004438
Epoch loss: 17.072421
train phase, Epoch 8/20, Loss: 16.157510
val phase, Epoch 8/20, Loss: 17.167629
Val Best Loss: 16.004438
Epoch loss: 17.167629
train phase, Epoch 9/20, Loss: 16.147146
val phase, Epoch 9/20, Loss: 16.075646
Val Best Loss: 16.004438
Epoch loss: 16.075646
train phase, Epoch 10/20, Loss: 16.290243
val phase, Epoch 10/20, Loss: 15.890804
Val Best Loss: 15.890804
Epoch loss: 15.890804
train phase, Epoch 11/20, Loss: 16.048773
val phase, Epoch 11/20, Loss: 16.056500
Val Best Loss: 15.890804
Epoch loss: 16.056500
train phase, Epoch 12/20, Loss: 15.810921
val phase, Epoch 12/20, Loss: 15.882607
Val Best Loss: 15.882607
Epoch loss: 15.882607
train phase, Epoch 13/20, Loss: 15.797162
val phase, Epoch 13/20, Loss: 16.978050
Val Best Loss: 15.882607
Epoch loss: 16.978050
train phase, Epoch 14/20, Loss: 15.325082
val phase, Epoch 14/20, Loss: 16.714169
Val Best Loss: 15.882607
Epoch loss: 16.714169
train phase, Epoch 15/20, Loss: 15.451712
val phase, Epoch 15/20, Loss: 16.071338
Val Best Loss: 15.882607
Epoch loss: 16.071338
train phase, Epoch 16/20, Loss: 15.083888
val phase, Epoch 16/20, Loss: 16.278631
Val Best Loss: 15.882607
Epoch loss: 16.278631
train phase, Epoch 17/20, Loss: 15.029750
val phase, Epoch 17/20, Loss: 16.055289
Val Best Loss: 15.882607
Epoch loss: 16.055289
train phase, Epoch 18/20, Loss: 14.672996
val phase, Epoch 18/20, Loss: 17.446603
Val Best Loss: 15.882607
Epoch loss: 17.446603
train phase, Epoch 19/20, Loss: 14.417607
val phase, Epoch 19/20, Loss: 17.539102
Val Best Loss: 15.882607
Epoch loss: 17.539102
train phase, Epoch 20/20, Loss: 14.074668
val phase, Epoch 20/20, Loss: 16.322666
Val Best Loss: 15.882607
Epoch loss: 16.322666
train phase, Epoch 1/20, Loss: 19.864104
val phase, Epoch 1/20, Loss: 18.362289
Val Best Loss: 18.362289
Epoch loss: 18.362289
train phase, Epoch 2/20, Loss: 17.645437
val phase, Epoch 2/20, Loss: 16.892705
Val Best Loss: 16.892705
Epoch loss: 16.892705
train phase, Epoch 3/20, Loss: 17.160714
val phase, Epoch 3/20, Loss: 16.420020
Val Best Loss: 16.420020
Epoch loss: 16.420020
train phase, Epoch 4/20, Loss: 17.315514
val phase, Epoch 4/20, Loss: 17.072831
Val Best Loss: 16.420020
Epoch loss: 17.072831
train phase, Epoch 5/20, Loss: 16.740038
val phase, Epoch 5/20, Loss: 16.388827
Val Best Loss: 16.388827
Epoch loss: 16.388827
train phase, Epoch 6/20, Loss: 17.026856
val phase, Epoch 6/20, Loss: 16.312849
Val Best Loss: 16.312849
Epoch loss: 16.312849
train phase, Epoch 7/20, Loss: 16.537643
val phase, Epoch 7/20, Loss: 15.879996
Val Best Loss: 15.879996
Epoch loss: 15.879996
train phase, Epoch 8/20, Loss: 16.182949
val phase, Epoch 8/20, Loss: 17.336431
Val Best Loss: 15.879996
Epoch loss: 17.336431
train phase, Epoch 9/20, Loss: 16.128912
val phase, Epoch 9/20, Loss: 15.839313
Val Best Loss: 15.839313
Epoch loss: 15.839313
train phase, Epoch 10/20, Loss: 15.856251
val phase, Epoch 10/20, Loss: 15.921867
Val Best Loss: 15.839313
Epoch loss: 15.921867
train phase, Epoch 11/20, Loss: 15.740892
val phase, Epoch 11/20, Loss: 16.465038
Val Best Loss: 15.839313
Epoch loss: 16.465038
train phase, Epoch 12/20, Loss: 16.077630
val phase, Epoch 12/20, Loss: 16.480370
Val Best Loss: 15.839313
Epoch loss: 16.480370
train phase, Epoch 13/20, Loss: 15.593564
val phase, Epoch 13/20, Loss: 15.970328
Val Best Loss: 15.839313
Epoch loss: 15.970328
train phase, Epoch 14/20, Loss: 15.175045
val phase, Epoch 14/20, Loss: 17.073286
Val Best Loss: 15.839313
Epoch loss: 17.073286
train phase, Epoch 15/20, Loss: 15.190859
val phase, Epoch 15/20, Loss: 16.079164
Val Best Loss: 15.839313
Epoch loss: 16.079164
train phase, Epoch 16/20, Loss: 14.906585
val phase, Epoch 16/20, Loss: 17.374556
Val Best Loss: 15.839313
Epoch loss: 17.374556
train phase, Epoch 17/20, Loss: 14.724853
val phase, Epoch 17/20, Loss: 16.179403
Val Best Loss: 15.839313
Epoch loss: 16.179403
train phase, Epoch 18/20, Loss: 14.710641
val phase, Epoch 18/20, Loss: 15.854697
Val Best Loss: 15.839313
Epoch loss: 15.854697
train phase, Epoch 19/20, Loss: 14.239560
val phase, Epoch 19/20, Loss: 16.084948
Val Best Loss: 15.839313
Epoch loss: 16.084948
train phase, Epoch 20/20, Loss: 13.979339
val phase, Epoch 20/20, Loss: 16.149603
Val Best Loss: 15.839313
Epoch loss: 16.149603
train phase, Epoch 1/20, Loss: 20.094278
val phase, Epoch 1/20, Loss: 18.658085
Val Best Loss: 18.658085
Epoch loss: 18.658085
train phase, Epoch 2/20, Loss: 18.043222
val phase, Epoch 2/20, Loss: 17.264410
Val Best Loss: 17.264410
Epoch loss: 17.264410
train phase, Epoch 3/20, Loss: 17.585231
val phase, Epoch 3/20, Loss: 17.676729
Val Best Loss: 17.264410
Epoch loss: 17.676729
train phase, Epoch 4/20, Loss: 17.133237
val phase, Epoch 4/20, Loss: 16.310722
Val Best Loss: 16.310722
Epoch loss: 16.310722
train phase, Epoch 5/20, Loss: 16.872328
val phase, Epoch 5/20, Loss: 16.010460
Val Best Loss: 16.010460
Epoch loss: 16.010460
train phase, Epoch 6/20, Loss: 16.676583
val phase, Epoch 6/20, Loss: 16.023994
Val Best Loss: 16.010460
Epoch loss: 16.023994
train phase, Epoch 7/20, Loss: 16.402858
val phase, Epoch 7/20, Loss: 16.270958
Val Best Loss: 16.010460
Epoch loss: 16.270958
train phase, Epoch 8/20, Loss: 16.342666
val phase, Epoch 8/20, Loss: 16.510003
Val Best Loss: 16.010460
Epoch loss: 16.510003
train phase, Epoch 9/20, Loss: 16.451813
val phase, Epoch 9/20, Loss: 27.975070
Val Best Loss: 16.010460
Epoch loss: 27.975070
train phase, Epoch 10/20, Loss: 16.275322
val phase, Epoch 10/20, Loss: 16.894878
Val Best Loss: 16.010460
Epoch loss: 16.894878
train phase, Epoch 11/20, Loss: 15.886220
val phase, Epoch 11/20, Loss: 15.968593
Val Best Loss: 15.968593
Epoch loss: 15.968593
train phase, Epoch 12/20, Loss: 15.668974
val phase, Epoch 12/20, Loss: 16.082299
Val Best Loss: 15.968593
Epoch loss: 16.082299
train phase, Epoch 13/20, Loss: 15.503376
val phase, Epoch 13/20, Loss: 15.862025
Val Best Loss: 15.862025
Epoch loss: 15.862025
train phase, Epoch 14/20, Loss: 15.290206
val phase, Epoch 14/20, Loss: 16.006829
Val Best Loss: 15.862025
Epoch loss: 16.006829
train phase, Epoch 15/20, Loss: 15.059874
val phase, Epoch 15/20, Loss: 16.840172
Val Best Loss: 15.862025
Epoch loss: 16.840172
train phase, Epoch 16/20, Loss: 14.758842
val phase, Epoch 16/20, Loss: 16.221781
Val Best Loss: 15.862025
Epoch loss: 16.221781
train phase, Epoch 17/20, Loss: 14.727959
val phase, Epoch 17/20, Loss: 16.644606
Val Best Loss: 15.862025
Epoch loss: 16.644606
train phase, Epoch 18/20, Loss: 14.686500
val phase, Epoch 18/20, Loss: 17.408042
Val Best Loss: 15.862025
Epoch loss: 17.408042
train phase, Epoch 19/20, Loss: 14.233031
val phase, Epoch 19/20, Loss: 17.762808
Val Best Loss: 15.862025
Epoch loss: 17.762808
train phase, Epoch 20/20, Loss: 13.910008
val phase, Epoch 20/20, Loss: 16.864553
Val Best Loss: 15.862025
Epoch loss: 16.864553
train phase, Epoch 1/20, Loss: 19.976034
val phase, Epoch 1/20, Loss: 17.689483
Val Best Loss: 17.689483
Epoch loss: 17.689483
train phase, Epoch 2/20, Loss: 17.921235
val phase, Epoch 2/20, Loss: 16.821225
Val Best Loss: 16.821225
Epoch loss: 16.821225
train phase, Epoch 3/20, Loss: 17.659989
val phase, Epoch 3/20, Loss: 19.417569
Val Best Loss: 16.821225
Epoch loss: 19.417569
train phase, Epoch 4/20, Loss: 17.585521
val phase, Epoch 4/20, Loss: 17.046593
Val Best Loss: 16.821225
Epoch loss: 17.046593
train phase, Epoch 5/20, Loss: 16.702831
val phase, Epoch 5/20, Loss: 16.831498
Val Best Loss: 16.821225
Epoch loss: 16.831498
train phase, Epoch 6/20, Loss: 16.786965
val phase, Epoch 6/20, Loss: 16.672197
Val Best Loss: 16.672197
Epoch loss: 16.672197
train phase, Epoch 7/20, Loss: 16.500979
val phase, Epoch 7/20, Loss: 17.018340
Val Best Loss: 16.672197
Epoch loss: 17.018340
train phase, Epoch 8/20, Loss: 16.703151
val phase, Epoch 8/20, Loss: 18.759793
Val Best Loss: 16.672197
Epoch loss: 18.759793
train phase, Epoch 9/20, Loss: 16.196223
val phase, Epoch 9/20, Loss: 18.631691
Val Best Loss: 16.672197
Epoch loss: 18.631691
train phase, Epoch 10/20, Loss: 16.035548
val phase, Epoch 10/20, Loss: 16.483465
Val Best Loss: 16.483465
Epoch loss: 16.483465
train phase, Epoch 11/20, Loss: 15.779891
val phase, Epoch 11/20, Loss: 16.131992
Val Best Loss: 16.131992
Epoch loss: 16.131992
train phase, Epoch 12/20, Loss: 15.718556
val phase, Epoch 12/20, Loss: 16.053717
Val Best Loss: 16.053717
Epoch loss: 16.053717
train phase, Epoch 13/20, Loss: 15.821661
val phase, Epoch 13/20, Loss: 16.096376
Val Best Loss: 16.053717
Epoch loss: 16.096376
train phase, Epoch 14/20, Loss: 15.376755
val phase, Epoch 14/20, Loss: 15.965646
Val Best Loss: 15.965646
Epoch loss: 15.965646
train phase, Epoch 15/20, Loss: 15.259015
val phase, Epoch 15/20, Loss: 15.742945
Val Best Loss: 15.742945
Epoch loss: 15.742945
train phase, Epoch 16/20, Loss: 15.344254
val phase, Epoch 16/20, Loss: 16.077420
Val Best Loss: 15.742945
Epoch loss: 16.077420
train phase, Epoch 17/20, Loss: 14.909520
val phase, Epoch 17/20, Loss: 16.113255
Val Best Loss: 15.742945
Epoch loss: 16.113255
train phase, Epoch 18/20, Loss: 14.817061
val phase, Epoch 18/20, Loss: 16.341090
Val Best Loss: 15.742945
Epoch loss: 16.341090
train phase, Epoch 19/20, Loss: 14.462360
val phase, Epoch 19/20, Loss: 15.892407
Val Best Loss: 15.742945
Epoch loss: 15.892407
train phase, Epoch 20/20, Loss: 14.198483
val phase, Epoch 20/20, Loss: 16.085446
Val Best Loss: 15.742945
Epoch loss: 16.085446
train phase, Epoch 1/20, Loss: 19.697377
val phase, Epoch 1/20, Loss: 18.508106
Val Best Loss: 18.508106
Epoch loss: 18.508106
train phase, Epoch 2/20, Loss: 17.744661
val phase, Epoch 2/20, Loss: 18.476064
Val Best Loss: 18.476064
Epoch loss: 18.476064
train phase, Epoch 3/20, Loss: 17.163459
val phase, Epoch 3/20, Loss: 16.546048
Val Best Loss: 16.546048
Epoch loss: 16.546048
train phase, Epoch 4/20, Loss: 16.958417
val phase, Epoch 4/20, Loss: 16.169182
Val Best Loss: 16.169182
Epoch loss: 16.169182
train phase, Epoch 5/20, Loss: 16.688324
val phase, Epoch 5/20, Loss: 17.828121
Val Best Loss: 16.169182
Epoch loss: 17.828121
train phase, Epoch 6/20, Loss: 16.268814
val phase, Epoch 6/20, Loss: 16.663861
Val Best Loss: 16.169182
Epoch loss: 16.663861
train phase, Epoch 7/20, Loss: 16.429233
val phase, Epoch 7/20, Loss: 16.135653
Val Best Loss: 16.135653
Epoch loss: 16.135653
train phase, Epoch 8/20, Loss: 16.185116
val phase, Epoch 8/20, Loss: 16.379466
Val Best Loss: 16.135653
Epoch loss: 16.379466
train phase, Epoch 9/20, Loss: 16.150109
val phase, Epoch 9/20, Loss: 16.518061
Val Best Loss: 16.135653
Epoch loss: 16.518061
train phase, Epoch 10/20, Loss: 15.871946
val phase, Epoch 10/20, Loss: 16.584266
Val Best Loss: 16.135653
Epoch loss: 16.584266
train phase, Epoch 11/20, Loss: 15.802697
val phase, Epoch 11/20, Loss: 16.326597
Val Best Loss: 16.135653
Epoch loss: 16.326597
train phase, Epoch 12/20, Loss: 15.581046
val phase, Epoch 12/20, Loss: 16.376038
Val Best Loss: 16.135653
Epoch loss: 16.376038
train phase, Epoch 13/20, Loss: 15.212064
val phase, Epoch 13/20, Loss: 17.300956
Val Best Loss: 16.135653
Epoch loss: 17.300956
train phase, Epoch 14/20, Loss: 15.345713
val phase, Epoch 14/20, Loss: 15.669401
Val Best Loss: 15.669401
Epoch loss: 15.669401
train phase, Epoch 15/20, Loss: 14.964893
val phase, Epoch 15/20, Loss: 16.479521
Val Best Loss: 15.669401
Epoch loss: 16.479521
train phase, Epoch 16/20, Loss: 14.603725
val phase, Epoch 16/20, Loss: 16.262121
Val Best Loss: 15.669401
Epoch loss: 16.262121
train phase, Epoch 17/20, Loss: 14.529666
val phase, Epoch 17/20, Loss: 16.635673
Val Best Loss: 15.669401
Epoch loss: 16.635673
train phase, Epoch 18/20, Loss: 14.409342
val phase, Epoch 18/20, Loss: 16.045967
Val Best Loss: 15.669401
Epoch loss: 16.045967
train phase, Epoch 19/20, Loss: 14.106635
val phase, Epoch 19/20, Loss: 16.195654
Val Best Loss: 15.669401
Epoch loss: 16.195654
train phase, Epoch 20/20, Loss: 13.731264
val phase, Epoch 20/20, Loss: 16.437832
Val Best Loss: 15.669401
Epoch loss: 16.437832
train phase, Epoch 1/20, Loss: 19.948071
val phase, Epoch 1/20, Loss: 18.548076
Val Best Loss: 18.548076
Epoch loss: 18.548076
train phase, Epoch 2/20, Loss: 17.850017
val phase, Epoch 2/20, Loss: 16.467428
Val Best Loss: 16.467428
Epoch loss: 16.467428
train phase, Epoch 3/20, Loss: 17.280550
val phase, Epoch 3/20, Loss: 16.889100
Val Best Loss: 16.467428
Epoch loss: 16.889100
train phase, Epoch 4/20, Loss: 16.695542
val phase, Epoch 4/20, Loss: 16.929464
Val Best Loss: 16.467428
Epoch loss: 16.929464
train phase, Epoch 5/20, Loss: 17.174237
val phase, Epoch 5/20, Loss: 16.829596
Val Best Loss: 16.467428
Epoch loss: 16.829596
train phase, Epoch 6/20, Loss: 16.357210
val phase, Epoch 6/20, Loss: 18.841851
Val Best Loss: 16.467428
Epoch loss: 18.841851
train phase, Epoch 7/20, Loss: 16.313930
val phase, Epoch 7/20, Loss: 16.048936
Val Best Loss: 16.048936
Epoch loss: 16.048936
train phase, Epoch 8/20, Loss: 16.278987
val phase, Epoch 8/20, Loss: 15.938170
Val Best Loss: 15.938170
Epoch loss: 15.938170
train phase, Epoch 9/20, Loss: 16.050340
val phase, Epoch 9/20, Loss: 15.926555
Val Best Loss: 15.926555
Epoch loss: 15.926555
train phase, Epoch 10/20, Loss: 15.928942
val phase, Epoch 10/20, Loss: 16.861191
Val Best Loss: 15.926555
Epoch loss: 16.861191
train phase, Epoch 11/20, Loss: 15.656623
val phase, Epoch 11/20, Loss: 17.955435
Val Best Loss: 15.926555
Epoch loss: 17.955435
train phase, Epoch 12/20, Loss: 15.529314
val phase, Epoch 12/20, Loss: 17.081418
Val Best Loss: 15.926555
Epoch loss: 17.081418
train phase, Epoch 13/20, Loss: 15.572871
val phase, Epoch 13/20, Loss: 16.492177
Val Best Loss: 15.926555
Epoch loss: 16.492177
train phase, Epoch 14/20, Loss: 15.286198
val phase, Epoch 14/20, Loss: 17.137556
Val Best Loss: 15.926555
Epoch loss: 17.137556
train phase, Epoch 15/20, Loss: 15.041280
val phase, Epoch 15/20, Loss: 16.502340
Val Best Loss: 15.926555
Epoch loss: 16.502340
train phase, Epoch 16/20, Loss: 14.888239
val phase, Epoch 16/20, Loss: 17.050372
Val Best Loss: 15.926555
Epoch loss: 17.050372
train phase, Epoch 17/20, Loss: 14.571991
val phase, Epoch 17/20, Loss: 16.610031
Val Best Loss: 15.926555
Epoch loss: 16.610031
train phase, Epoch 18/20, Loss: 14.341043
val phase, Epoch 18/20, Loss: 16.024315
Val Best Loss: 15.926555
Epoch loss: 16.024315
train phase, Epoch 19/20, Loss: 13.815706
val phase, Epoch 19/20, Loss: 16.208733
Val Best Loss: 15.926555
Epoch loss: 16.208733
train phase, Epoch 20/20, Loss: 13.738781
val phase, Epoch 20/20, Loss: 16.398077
Val Best Loss: 15.926555
Epoch loss: 16.398077
[Trial 26] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.174425
val phase, Epoch 1/20, Loss: 17.682992
Val Best Loss: 17.682992
Epoch loss: 17.682992
train phase, Epoch 2/20, Loss: 17.680591
val phase, Epoch 2/20, Loss: 18.355857
Val Best Loss: 17.682992
Epoch loss: 18.355857
train phase, Epoch 3/20, Loss: 17.516968
val phase, Epoch 3/20, Loss: 23.040347
Val Best Loss: 17.682992
Epoch loss: 23.040347
train phase, Epoch 4/20, Loss: 17.379114
val phase, Epoch 4/20, Loss: 17.806013
Val Best Loss: 17.682992
Epoch loss: 17.806013
train phase, Epoch 5/20, Loss: 16.652331
val phase, Epoch 5/20, Loss: 16.928782
Val Best Loss: 16.928782
Epoch loss: 16.928782
train phase, Epoch 6/20, Loss: 16.720888
val phase, Epoch 6/20, Loss: 17.477624
Val Best Loss: 16.928782
Epoch loss: 17.477624
train phase, Epoch 7/20, Loss: 16.404271
val phase, Epoch 7/20, Loss: 17.064114
Val Best Loss: 16.928782
Epoch loss: 17.064114
train phase, Epoch 8/20, Loss: 16.265785
val phase, Epoch 8/20, Loss: 16.104078
Val Best Loss: 16.104078
Epoch loss: 16.104078
train phase, Epoch 9/20, Loss: 16.131261
val phase, Epoch 9/20, Loss: 16.758220
Val Best Loss: 16.104078
Epoch loss: 16.758220
train phase, Epoch 10/20, Loss: 15.828618
val phase, Epoch 10/20, Loss: 16.358312
Val Best Loss: 16.104078
Epoch loss: 16.358312
train phase, Epoch 11/20, Loss: 15.912760
val phase, Epoch 11/20, Loss: 16.501556
Val Best Loss: 16.104078
Epoch loss: 16.501556
train phase, Epoch 12/20, Loss: 15.502891
val phase, Epoch 12/20, Loss: 15.962754
Val Best Loss: 15.962754
Epoch loss: 15.962754
train phase, Epoch 13/20, Loss: 15.489384
val phase, Epoch 13/20, Loss: 15.966386
Val Best Loss: 15.962754
Epoch loss: 15.966386
train phase, Epoch 14/20, Loss: 15.199658
val phase, Epoch 14/20, Loss: 18.688991
Val Best Loss: 15.962754
Epoch loss: 18.688991
train phase, Epoch 15/20, Loss: 15.120816
val phase, Epoch 15/20, Loss: 16.872550
Val Best Loss: 15.962754
Epoch loss: 16.872550
train phase, Epoch 16/20, Loss: 14.906639
val phase, Epoch 16/20, Loss: 16.141033
Val Best Loss: 15.962754
Epoch loss: 16.141033
train phase, Epoch 17/20, Loss: 14.377846
val phase, Epoch 17/20, Loss: 15.914407
Val Best Loss: 15.914407
Epoch loss: 15.914407
train phase, Epoch 18/20, Loss: 14.303369
val phase, Epoch 18/20, Loss: 16.054750
Val Best Loss: 15.914407
Epoch loss: 16.054750
train phase, Epoch 19/20, Loss: 14.113989
val phase, Epoch 19/20, Loss: 16.529999
Val Best Loss: 15.914407
Epoch loss: 16.529999
train phase, Epoch 20/20, Loss: 13.545878
val phase, Epoch 20/20, Loss: 16.225035
Val Best Loss: 15.914407
Epoch loss: 16.225035
[Trial 28] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
[Trial 29] Skipped due to model construction error: Calculated padded input size per channel: (9 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
[Trial 30] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.271328
val phase, Epoch 1/20, Loss: 18.261173
Val Best Loss: 18.261173
Epoch loss: 18.261173
train phase, Epoch 2/20, Loss: 18.031357
val phase, Epoch 2/20, Loss: 16.491116
Val Best Loss: 16.491116
Epoch loss: 16.491116
train phase, Epoch 3/20, Loss: 17.595015
val phase, Epoch 3/20, Loss: 17.858847
Val Best Loss: 16.491116
Epoch loss: 17.858847
train phase, Epoch 4/20, Loss: 17.322328
val phase, Epoch 4/20, Loss: 17.422202
Val Best Loss: 16.491116
Epoch loss: 17.422202
train phase, Epoch 5/20, Loss: 16.988166
val phase, Epoch 5/20, Loss: 17.502621
Val Best Loss: 16.491116
Epoch loss: 17.502621
train phase, Epoch 6/20, Loss: 17.040686
val phase, Epoch 6/20, Loss: 16.259731
Val Best Loss: 16.259731
Epoch loss: 16.259731
train phase, Epoch 7/20, Loss: 16.714345
val phase, Epoch 7/20, Loss: 16.226641
Val Best Loss: 16.226641
Epoch loss: 16.226641
train phase, Epoch 8/20, Loss: 16.523172
val phase, Epoch 8/20, Loss: 17.913007
Val Best Loss: 16.226641
Epoch loss: 17.913007
train phase, Epoch 9/20, Loss: 16.280511
val phase, Epoch 9/20, Loss: 16.466525
Val Best Loss: 16.226641
Epoch loss: 16.466525
train phase, Epoch 10/20, Loss: 15.988504
val phase, Epoch 10/20, Loss: 16.311690
Val Best Loss: 16.226641
Epoch loss: 16.311690
train phase, Epoch 11/20, Loss: 16.080941
val phase, Epoch 11/20, Loss: 16.488282
Val Best Loss: 16.226641
Epoch loss: 16.488282
train phase, Epoch 12/20, Loss: 16.039246
val phase, Epoch 12/20, Loss: 16.252595
Val Best Loss: 16.226641
Epoch loss: 16.252595
train phase, Epoch 13/20, Loss: 15.580317
val phase, Epoch 13/20, Loss: 16.823034
Val Best Loss: 16.226641
Epoch loss: 16.823034
train phase, Epoch 14/20, Loss: 15.697668
val phase, Epoch 14/20, Loss: 16.199246
Val Best Loss: 16.199246
Epoch loss: 16.199246
train phase, Epoch 15/20, Loss: 15.478275
val phase, Epoch 15/20, Loss: 17.769488
Val Best Loss: 16.199246
Epoch loss: 17.769488
train phase, Epoch 16/20, Loss: 15.302256
val phase, Epoch 16/20, Loss: 15.883506
Val Best Loss: 15.883506
Epoch loss: 15.883506
train phase, Epoch 17/20, Loss: 15.186988
val phase, Epoch 17/20, Loss: 16.061291
Val Best Loss: 15.883506
Epoch loss: 16.061291
train phase, Epoch 18/20, Loss: 14.787043
val phase, Epoch 18/20, Loss: 16.099362
Val Best Loss: 15.883506
Epoch loss: 16.099362
train phase, Epoch 19/20, Loss: 14.754015
val phase, Epoch 19/20, Loss: 16.501630
Val Best Loss: 15.883506
Epoch loss: 16.501630
train phase, Epoch 20/20, Loss: 14.618323
val phase, Epoch 20/20, Loss: 17.094204
Val Best Loss: 15.883506
Epoch loss: 17.094204
train phase, Epoch 1/20, Loss: 20.370982
val phase, Epoch 1/20, Loss: 17.188556
Val Best Loss: 17.188556
Epoch loss: 17.188556
train phase, Epoch 2/20, Loss: 18.263329
val phase, Epoch 2/20, Loss: 17.035219
Val Best Loss: 17.035219
Epoch loss: 17.035219
train phase, Epoch 3/20, Loss: 17.671566
val phase, Epoch 3/20, Loss: 16.422610
Val Best Loss: 16.422610
Epoch loss: 16.422610
train phase, Epoch 4/20, Loss: 17.486471
val phase, Epoch 4/20, Loss: 17.051555
Val Best Loss: 16.422610
Epoch loss: 17.051555
train phase, Epoch 5/20, Loss: 17.053251
val phase, Epoch 5/20, Loss: 22.508032
Val Best Loss: 16.422610
Epoch loss: 22.508032
train phase, Epoch 6/20, Loss: 17.077877
val phase, Epoch 6/20, Loss: 16.192055
Val Best Loss: 16.192055
Epoch loss: 16.192055
train phase, Epoch 7/20, Loss: 17.025461
val phase, Epoch 7/20, Loss: 16.345698
Val Best Loss: 16.192055
Epoch loss: 16.345698
train phase, Epoch 8/20, Loss: 16.408920
val phase, Epoch 8/20, Loss: 17.181999
Val Best Loss: 16.192055
Epoch loss: 17.181999
train phase, Epoch 9/20, Loss: 16.204555
val phase, Epoch 9/20, Loss: 16.502565
Val Best Loss: 16.192055
Epoch loss: 16.502565
train phase, Epoch 10/20, Loss: 16.287698
val phase, Epoch 10/20, Loss: 18.485564
Val Best Loss: 16.192055
Epoch loss: 18.485564
train phase, Epoch 11/20, Loss: 16.118167
val phase, Epoch 11/20, Loss: 21.440512
Val Best Loss: 16.192055
Epoch loss: 21.440512
train phase, Epoch 12/20, Loss: 15.897830
val phase, Epoch 12/20, Loss: 15.690998
Val Best Loss: 15.690998
Epoch loss: 15.690998
train phase, Epoch 13/20, Loss: 15.642478
val phase, Epoch 13/20, Loss: 15.854847
Val Best Loss: 15.690998
Epoch loss: 15.854847
train phase, Epoch 14/20, Loss: 15.445409
val phase, Epoch 14/20, Loss: 16.072661
Val Best Loss: 15.690998
Epoch loss: 16.072661
train phase, Epoch 15/20, Loss: 15.312483
val phase, Epoch 15/20, Loss: 16.063390
Val Best Loss: 15.690998
Epoch loss: 16.063390
train phase, Epoch 16/20, Loss: 15.387645
val phase, Epoch 16/20, Loss: 16.058762
Val Best Loss: 15.690998
Epoch loss: 16.058762
train phase, Epoch 17/20, Loss: 14.990634
val phase, Epoch 17/20, Loss: 15.654753
Val Best Loss: 15.654753
Epoch loss: 15.654753
train phase, Epoch 18/20, Loss: 14.929709
val phase, Epoch 18/20, Loss: 15.843309
Val Best Loss: 15.654753
Epoch loss: 15.843309
train phase, Epoch 19/20, Loss: 14.681228
val phase, Epoch 19/20, Loss: 18.889309
Val Best Loss: 15.654753
Epoch loss: 18.889309
train phase, Epoch 20/20, Loss: 14.678571
val phase, Epoch 20/20, Loss: 16.595068
Val Best Loss: 15.654753
Epoch loss: 16.595068
train phase, Epoch 1/20, Loss: 19.898449
val phase, Epoch 1/20, Loss: 17.709546
Val Best Loss: 17.709546
Epoch loss: 17.709546
train phase, Epoch 2/20, Loss: 17.710023
val phase, Epoch 2/20, Loss: 17.665718
Val Best Loss: 17.665718
Epoch loss: 17.665718
train phase, Epoch 3/20, Loss: 17.235307
val phase, Epoch 3/20, Loss: 16.245337
Val Best Loss: 16.245337
Epoch loss: 16.245337
train phase, Epoch 4/20, Loss: 17.237307
val phase, Epoch 4/20, Loss: 16.911368
Val Best Loss: 16.245337
Epoch loss: 16.911368
train phase, Epoch 5/20, Loss: 16.780095
val phase, Epoch 5/20, Loss: 16.573199
Val Best Loss: 16.245337
Epoch loss: 16.573199
train phase, Epoch 6/20, Loss: 16.574203
val phase, Epoch 6/20, Loss: 16.307227
Val Best Loss: 16.245337
Epoch loss: 16.307227
train phase, Epoch 7/20, Loss: 16.506833
val phase, Epoch 7/20, Loss: 15.911066
Val Best Loss: 15.911066
Epoch loss: 15.911066
train phase, Epoch 8/20, Loss: 16.022731
val phase, Epoch 8/20, Loss: 16.152701
Val Best Loss: 15.911066
Epoch loss: 16.152701
train phase, Epoch 9/20, Loss: 15.926280
val phase, Epoch 9/20, Loss: 16.069972
Val Best Loss: 15.911066
Epoch loss: 16.069972
train phase, Epoch 10/20, Loss: 15.909060
val phase, Epoch 10/20, Loss: 17.507837
Val Best Loss: 15.911066
Epoch loss: 17.507837
train phase, Epoch 11/20, Loss: 15.662320
val phase, Epoch 11/20, Loss: 16.134478
Val Best Loss: 15.911066
Epoch loss: 16.134478
train phase, Epoch 12/20, Loss: 15.298006
val phase, Epoch 12/20, Loss: 16.751553
Val Best Loss: 15.911066
Epoch loss: 16.751553
train phase, Epoch 13/20, Loss: 15.532286
val phase, Epoch 13/20, Loss: 16.293137
Val Best Loss: 15.911066
Epoch loss: 16.293137
train phase, Epoch 14/20, Loss: 15.214990
val phase, Epoch 14/20, Loss: 16.977649
Val Best Loss: 15.911066
Epoch loss: 16.977649
train phase, Epoch 15/20, Loss: 14.863590
val phase, Epoch 15/20, Loss: 15.677129
Val Best Loss: 15.677129
Epoch loss: 15.677129
train phase, Epoch 16/20, Loss: 14.550115
val phase, Epoch 16/20, Loss: 16.203371
Val Best Loss: 15.677129
Epoch loss: 16.203371
train phase, Epoch 17/20, Loss: 14.280205
val phase, Epoch 17/20, Loss: 17.093869
Val Best Loss: 15.677129
Epoch loss: 17.093869
train phase, Epoch 18/20, Loss: 14.680886
val phase, Epoch 18/20, Loss: 16.446667
Val Best Loss: 15.677129
Epoch loss: 16.446667
train phase, Epoch 19/20, Loss: 14.039146
val phase, Epoch 19/20, Loss: 17.130223
Val Best Loss: 15.677129
Epoch loss: 17.130223
train phase, Epoch 20/20, Loss: 13.457274
val phase, Epoch 20/20, Loss: 16.905703
Val Best Loss: 15.677129
Epoch loss: 16.905703
train phase, Epoch 1/12, Loss: 20.912947
val phase, Epoch 1/12, Loss: 22.960312
Val Best Loss: 22.960312
Epoch loss: 22.960312
train phase, Epoch 2/12, Loss: 18.481051
val phase, Epoch 2/12, Loss: 18.731792
Val Best Loss: 18.731792
Epoch loss: 18.731792
train phase, Epoch 3/12, Loss: 17.900002
val phase, Epoch 3/12, Loss: 20.643062
Val Best Loss: 18.731792
Epoch loss: 20.643062
train phase, Epoch 4/12, Loss: 17.739452
val phase, Epoch 4/12, Loss: 17.578913
Val Best Loss: 17.578913
Epoch loss: 17.578913
train phase, Epoch 5/12, Loss: 17.256550
val phase, Epoch 5/12, Loss: 17.236447
Val Best Loss: 17.236447
Epoch loss: 17.236447
train phase, Epoch 6/12, Loss: 17.281241
val phase, Epoch 6/12, Loss: 18.479324
Val Best Loss: 17.236447
Epoch loss: 18.479324
train phase, Epoch 7/12, Loss: 16.805608
val phase, Epoch 7/12, Loss: 17.350586
Val Best Loss: 17.236447
Epoch loss: 17.350586
train phase, Epoch 8/12, Loss: 16.837316
val phase, Epoch 8/12, Loss: 17.064814
Val Best Loss: 17.064814
Epoch loss: 17.064814
train phase, Epoch 9/12, Loss: 16.424837
val phase, Epoch 9/12, Loss: 17.518613
Val Best Loss: 17.064814
Epoch loss: 17.518613
train phase, Epoch 10/12, Loss: 16.294262
val phase, Epoch 10/12, Loss: 22.197541
Val Best Loss: 17.064814
Epoch loss: 22.197541
train phase, Epoch 11/12, Loss: 16.164225
val phase, Epoch 11/12, Loss: 17.218345
Val Best Loss: 17.064814
Epoch loss: 17.218345
train phase, Epoch 12/12, Loss: 15.972830
val phase, Epoch 12/12, Loss: 17.326214
Val Best Loss: 17.064814
Epoch loss: 17.326214
[Trial 35] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
[Trial 36] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
[Trial 37] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
[Trial 38] Skipped due to model construction error: Calculated padded input size per channel: (7 x 1). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/12, Loss: 20.768529
val phase, Epoch 1/12, Loss: 35.533502
Val Best Loss: 35.533502
Epoch loss: 35.533502
train phase, Epoch 2/12, Loss: 18.687808
val phase, Epoch 2/12, Loss: 28.628361
Val Best Loss: 28.628361
Epoch loss: 28.628361
train phase, Epoch 3/12, Loss: 17.749101
val phase, Epoch 3/12, Loss: 28.357207
Val Best Loss: 28.357207
Epoch loss: 28.357207
train phase, Epoch 4/12, Loss: 17.586659
val phase, Epoch 4/12, Loss: 38.994968
Val Best Loss: 28.357207
Epoch loss: 38.994968
train phase, Epoch 5/12, Loss: 17.495467
val phase, Epoch 5/12, Loss: 31.650332
Val Best Loss: 28.357207
Epoch loss: 31.650332
train phase, Epoch 6/12, Loss: 17.148331
val phase, Epoch 6/12, Loss: 30.867994
Val Best Loss: 28.357207
Epoch loss: 30.867994
train phase, Epoch 7/12, Loss: 17.003738
val phase, Epoch 7/12, Loss: 41.119380
Val Best Loss: 28.357207
Epoch loss: 41.119380
train phase, Epoch 8/12, Loss: 16.891177
val phase, Epoch 8/12, Loss: 34.094356
Val Best Loss: 28.357207
Epoch loss: 34.094356
train phase, Epoch 9/12, Loss: 16.901392
val phase, Epoch 9/12, Loss: 40.452217
Val Best Loss: 28.357207
Epoch loss: 40.452217
train phase, Epoch 10/12, Loss: 16.555019
val phase, Epoch 10/12, Loss: 39.222150
Val Best Loss: 28.357207
Epoch loss: 39.222150
train phase, Epoch 11/12, Loss: 16.399107
val phase, Epoch 11/12, Loss: 59.172916
Val Best Loss: 28.357207
Epoch loss: 59.172916
train phase, Epoch 12/12, Loss: 16.086759
val phase, Epoch 12/12, Loss: 37.633369
Val Best Loss: 28.357207
Epoch loss: 37.633369
[Trial 40] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.914390
val phase, Epoch 1/20, Loss: 17.103247
Val Best Loss: 17.103247
Epoch loss: 17.103247
train phase, Epoch 2/20, Loss: 17.927724
val phase, Epoch 2/20, Loss: 16.850293
Val Best Loss: 16.850293
Epoch loss: 16.850293
train phase, Epoch 3/20, Loss: 17.906973
val phase, Epoch 3/20, Loss: 16.799930
Val Best Loss: 16.799930
Epoch loss: 16.799930
train phase, Epoch 4/20, Loss: 17.184939
val phase, Epoch 4/20, Loss: 16.639753
Val Best Loss: 16.639753
Epoch loss: 16.639753
train phase, Epoch 5/20, Loss: 17.177004
val phase, Epoch 5/20, Loss: 17.809530
Val Best Loss: 16.639753
Epoch loss: 17.809530
train phase, Epoch 6/20, Loss: 16.750635
val phase, Epoch 6/20, Loss: 17.929312
Val Best Loss: 16.639753
Epoch loss: 17.929312
train phase, Epoch 7/20, Loss: 16.670265
val phase, Epoch 7/20, Loss: 18.095397
Val Best Loss: 16.639753
Epoch loss: 18.095397
train phase, Epoch 8/20, Loss: 16.381876
val phase, Epoch 8/20, Loss: 16.746784
Val Best Loss: 16.639753
Epoch loss: 16.746784
train phase, Epoch 9/20, Loss: 16.286060
val phase, Epoch 9/20, Loss: 15.871999
Val Best Loss: 15.871999
Epoch loss: 15.871999
train phase, Epoch 10/20, Loss: 16.153765
val phase, Epoch 10/20, Loss: 15.997858
Val Best Loss: 15.871999
Epoch loss: 15.997858
train phase, Epoch 11/20, Loss: 15.974054
val phase, Epoch 11/20, Loss: 16.160001
Val Best Loss: 15.871999
Epoch loss: 16.160001
train phase, Epoch 12/20, Loss: 15.791260
val phase, Epoch 12/20, Loss: 19.059979
Val Best Loss: 15.871999
Epoch loss: 19.059979
train phase, Epoch 13/20, Loss: 16.010626
val phase, Epoch 13/20, Loss: 16.065743
Val Best Loss: 15.871999
Epoch loss: 16.065743
train phase, Epoch 14/20, Loss: 15.418619
val phase, Epoch 14/20, Loss: 16.231494
Val Best Loss: 15.871999
Epoch loss: 16.231494
train phase, Epoch 15/20, Loss: 15.386281
val phase, Epoch 15/20, Loss: 16.269587
Val Best Loss: 15.871999
Epoch loss: 16.269587
train phase, Epoch 16/20, Loss: 15.443615
val phase, Epoch 16/20, Loss: 21.513191
Val Best Loss: 15.871999
Epoch loss: 21.513191
train phase, Epoch 17/20, Loss: 15.550248
val phase, Epoch 17/20, Loss: 15.993402
Val Best Loss: 15.871999
Epoch loss: 15.993402
train phase, Epoch 18/20, Loss: 14.968819
val phase, Epoch 18/20, Loss: 18.635328
Val Best Loss: 15.871999
Epoch loss: 18.635328
train phase, Epoch 19/20, Loss: 14.601554
val phase, Epoch 19/20, Loss: 16.307558
Val Best Loss: 15.871999
Epoch loss: 16.307558
train phase, Epoch 20/20, Loss: 14.443533
val phase, Epoch 20/20, Loss: 15.947829
Val Best Loss: 15.871999
Epoch loss: 15.947829
train phase, Epoch 1/20, Loss: 20.246617
val phase, Epoch 1/20, Loss: 21.948224
Val Best Loss: 21.948224
Epoch loss: 21.948224
train phase, Epoch 2/20, Loss: 18.568169
val phase, Epoch 2/20, Loss: 18.239774
Val Best Loss: 18.239774
Epoch loss: 18.239774
train phase, Epoch 3/20, Loss: 17.663640
val phase, Epoch 3/20, Loss: 16.569625
Val Best Loss: 16.569625
Epoch loss: 16.569625
train phase, Epoch 4/20, Loss: 17.047651
val phase, Epoch 4/20, Loss: 16.625239
Val Best Loss: 16.569625
Epoch loss: 16.625239
train phase, Epoch 5/20, Loss: 17.135796
val phase, Epoch 5/20, Loss: 16.233691
Val Best Loss: 16.233691
Epoch loss: 16.233691
train phase, Epoch 6/20, Loss: 16.906686
val phase, Epoch 6/20, Loss: 16.767032
Val Best Loss: 16.233691
Epoch loss: 16.767032
train phase, Epoch 7/20, Loss: 16.667654
val phase, Epoch 7/20, Loss: 16.141230
Val Best Loss: 16.141230
Epoch loss: 16.141230
train phase, Epoch 8/20, Loss: 16.559727
val phase, Epoch 8/20, Loss: 16.085279
Val Best Loss: 16.085279
Epoch loss: 16.085279
train phase, Epoch 9/20, Loss: 16.192129
val phase, Epoch 9/20, Loss: 16.037741
Val Best Loss: 16.037741
Epoch loss: 16.037741
train phase, Epoch 10/20, Loss: 16.138133
val phase, Epoch 10/20, Loss: 16.439260
Val Best Loss: 16.037741
Epoch loss: 16.439260
train phase, Epoch 11/20, Loss: 16.198567
val phase, Epoch 11/20, Loss: 17.088307
Val Best Loss: 16.037741
Epoch loss: 17.088307
train phase, Epoch 12/20, Loss: 15.975507
val phase, Epoch 12/20, Loss: 16.155225
Val Best Loss: 16.037741
Epoch loss: 16.155225
train phase, Epoch 13/20, Loss: 15.739412
val phase, Epoch 13/20, Loss: 15.655784
Val Best Loss: 15.655784
Epoch loss: 15.655784
train phase, Epoch 14/20, Loss: 15.677713
val phase, Epoch 14/20, Loss: 15.974164
Val Best Loss: 15.655784
Epoch loss: 15.974164
train phase, Epoch 15/20, Loss: 15.559382
val phase, Epoch 15/20, Loss: 16.133796
Val Best Loss: 15.655784
Epoch loss: 16.133796
train phase, Epoch 16/20, Loss: 15.405956
val phase, Epoch 16/20, Loss: 15.840733
Val Best Loss: 15.655784
Epoch loss: 15.840733
train phase, Epoch 17/20, Loss: 14.919116
val phase, Epoch 17/20, Loss: 16.207368
Val Best Loss: 15.655784
Epoch loss: 16.207368
train phase, Epoch 18/20, Loss: 15.103753
val phase, Epoch 18/20, Loss: 15.781798
Val Best Loss: 15.655784
Epoch loss: 15.781798
train phase, Epoch 19/20, Loss: 14.785954
val phase, Epoch 19/20, Loss: 15.925176
Val Best Loss: 15.655784
Epoch loss: 15.925176
train phase, Epoch 20/20, Loss: 14.513626
val phase, Epoch 20/20, Loss: 16.014750
Val Best Loss: 15.655784
Epoch loss: 16.014750
train phase, Epoch 1/20, Loss: 20.673568
val phase, Epoch 1/20, Loss: 18.630756
Val Best Loss: 18.630756
Epoch loss: 18.630756
train phase, Epoch 2/20, Loss: 17.998537
val phase, Epoch 2/20, Loss: 16.878962
Val Best Loss: 16.878962
Epoch loss: 16.878962
train phase, Epoch 3/20, Loss: 17.518705
val phase, Epoch 3/20, Loss: 16.576151
Val Best Loss: 16.576151
Epoch loss: 16.576151
train phase, Epoch 4/20, Loss: 17.381187
val phase, Epoch 4/20, Loss: 21.304686
Val Best Loss: 16.576151
Epoch loss: 21.304686
train phase, Epoch 5/20, Loss: 16.864177
val phase, Epoch 5/20, Loss: 16.833526
Val Best Loss: 16.576151
Epoch loss: 16.833526
train phase, Epoch 6/20, Loss: 16.736262
val phase, Epoch 6/20, Loss: 17.049298
Val Best Loss: 16.576151
Epoch loss: 17.049298
train phase, Epoch 7/20, Loss: 16.678164
val phase, Epoch 7/20, Loss: 16.207643
Val Best Loss: 16.207643
Epoch loss: 16.207643
train phase, Epoch 8/20, Loss: 16.510268
val phase, Epoch 8/20, Loss: 16.283694
Val Best Loss: 16.207643
Epoch loss: 16.283694
train phase, Epoch 9/20, Loss: 16.428284
val phase, Epoch 9/20, Loss: 16.798062
Val Best Loss: 16.207643
Epoch loss: 16.798062
train phase, Epoch 10/20, Loss: 16.101019
val phase, Epoch 10/20, Loss: 16.645161
Val Best Loss: 16.207643
Epoch loss: 16.645161
train phase, Epoch 11/20, Loss: 16.240774
val phase, Epoch 11/20, Loss: 16.379854
Val Best Loss: 16.207643
Epoch loss: 16.379854
train phase, Epoch 12/20, Loss: 15.832723
val phase, Epoch 12/20, Loss: 19.704176
Val Best Loss: 16.207643
Epoch loss: 19.704176
train phase, Epoch 13/20, Loss: 15.749394
val phase, Epoch 13/20, Loss: 17.121471
Val Best Loss: 16.207643
Epoch loss: 17.121471
train phase, Epoch 14/20, Loss: 15.548793
val phase, Epoch 14/20, Loss: 16.370823
Val Best Loss: 16.207643
Epoch loss: 16.370823
train phase, Epoch 15/20, Loss: 15.582654
val phase, Epoch 15/20, Loss: 15.824893
Val Best Loss: 15.824893
Epoch loss: 15.824893
train phase, Epoch 16/20, Loss: 15.103998
val phase, Epoch 16/20, Loss: 16.235070
Val Best Loss: 15.824893
Epoch loss: 16.235070
train phase, Epoch 17/20, Loss: 14.771902
val phase, Epoch 17/20, Loss: 16.400545
Val Best Loss: 15.824893
Epoch loss: 16.400545
train phase, Epoch 18/20, Loss: 14.850072
val phase, Epoch 18/20, Loss: 16.522313
Val Best Loss: 15.824893
Epoch loss: 16.522313
train phase, Epoch 19/20, Loss: 14.376598
val phase, Epoch 19/20, Loss: 16.242471
Val Best Loss: 15.824893
Epoch loss: 16.242471
train phase, Epoch 20/20, Loss: 14.222883
val phase, Epoch 20/20, Loss: 17.736745
Val Best Loss: 15.824893
Epoch loss: 17.736745
train phase, Epoch 1/25, Loss: 21.758516
val phase, Epoch 1/25, Loss: 17.700575
Val Best Loss: 17.700575
Epoch loss: 17.700575
train phase, Epoch 2/25, Loss: 19.210689
val phase, Epoch 2/25, Loss: 17.496869
Val Best Loss: 17.496869
Epoch loss: 17.496869
train phase, Epoch 3/25, Loss: 18.725761
val phase, Epoch 3/25, Loss: 18.235528
Val Best Loss: 17.496869
Epoch loss: 18.235528
train phase, Epoch 4/25, Loss: 18.362145
val phase, Epoch 4/25, Loss: 17.661573
Val Best Loss: 17.496869
Epoch loss: 17.661573
train phase, Epoch 5/25, Loss: 17.782145
val phase, Epoch 5/25, Loss: 16.867656
Val Best Loss: 16.867656
Epoch loss: 16.867656
train phase, Epoch 6/25, Loss: 17.814381
val phase, Epoch 6/25, Loss: 17.195268
Val Best Loss: 16.867656
Epoch loss: 17.195268
train phase, Epoch 7/25, Loss: 17.430775
val phase, Epoch 7/25, Loss: 19.426709
Val Best Loss: 16.867656
Epoch loss: 19.426709
train phase, Epoch 8/25, Loss: 17.403717
val phase, Epoch 8/25, Loss: 17.963080
Val Best Loss: 16.867656
Epoch loss: 17.963080
train phase, Epoch 9/25, Loss: 17.097728
val phase, Epoch 9/25, Loss: 16.932423
Val Best Loss: 16.867656
Epoch loss: 16.932423
train phase, Epoch 10/25, Loss: 16.918721
val phase, Epoch 10/25, Loss: 18.463034
Val Best Loss: 16.867656
Epoch loss: 18.463034
train phase, Epoch 11/25, Loss: 16.823360
val phase, Epoch 11/25, Loss: 17.911715
Val Best Loss: 16.867656
Epoch loss: 17.911715
train phase, Epoch 12/25, Loss: 16.723470
val phase, Epoch 12/25, Loss: 16.585628
Val Best Loss: 16.585628
Epoch loss: 16.585628
train phase, Epoch 13/25, Loss: 16.546887
val phase, Epoch 13/25, Loss: 16.665932
Val Best Loss: 16.585628
Epoch loss: 16.665932
train phase, Epoch 14/25, Loss: 16.412382
val phase, Epoch 14/25, Loss: 16.567326
Val Best Loss: 16.567326
Epoch loss: 16.567326
train phase, Epoch 15/25, Loss: 16.170794
val phase, Epoch 15/25, Loss: 16.891981
Val Best Loss: 16.567326
Epoch loss: 16.891981
train phase, Epoch 16/25, Loss: 16.016085
val phase, Epoch 16/25, Loss: 16.425349
Val Best Loss: 16.425349
Epoch loss: 16.425349
train phase, Epoch 17/25, Loss: 15.787032
val phase, Epoch 17/25, Loss: 16.636620
Val Best Loss: 16.425349
Epoch loss: 16.636620
train phase, Epoch 18/25, Loss: 15.642919
val phase, Epoch 18/25, Loss: 16.802672
Val Best Loss: 16.425349
Epoch loss: 16.802672
train phase, Epoch 19/25, Loss: 15.484609
val phase, Epoch 19/25, Loss: 17.181825
Val Best Loss: 16.425349
Epoch loss: 17.181825
train phase, Epoch 20/25, Loss: 15.170805
val phase, Epoch 20/25, Loss: 16.678495
Val Best Loss: 16.425349
Epoch loss: 16.678495
train phase, Epoch 21/25, Loss: 15.153138
val phase, Epoch 21/25, Loss: 19.305785
Val Best Loss: 16.425349
Epoch loss: 19.305785
train phase, Epoch 22/25, Loss: 14.764519
val phase, Epoch 22/25, Loss: 16.641471
Val Best Loss: 16.425349
Epoch loss: 16.641471
train phase, Epoch 23/25, Loss: 14.678511
val phase, Epoch 23/25, Loss: 18.085001
Val Best Loss: 16.425349
Epoch loss: 18.085001
train phase, Epoch 24/25, Loss: 14.192497
val phase, Epoch 24/25, Loss: 16.403172
Val Best Loss: 16.403172
Epoch loss: 16.403172
train phase, Epoch 25/25, Loss: 13.752515
val phase, Epoch 25/25, Loss: 17.922428
Val Best Loss: 16.403172
Epoch loss: 17.922428
train phase, Epoch 1/30, Loss: 20.267561
val phase, Epoch 1/30, Loss: 18.780051
Val Best Loss: 18.780051
Epoch loss: 18.780051
train phase, Epoch 2/30, Loss: 17.937304
val phase, Epoch 2/30, Loss: 17.515669
Val Best Loss: 17.515669
Epoch loss: 17.515669
train phase, Epoch 3/30, Loss: 17.391816
val phase, Epoch 3/30, Loss: 16.784801
Val Best Loss: 16.784801
Epoch loss: 16.784801
train phase, Epoch 4/30, Loss: 17.318250
val phase, Epoch 4/30, Loss: 16.915623
Val Best Loss: 16.784801
Epoch loss: 16.915623
train phase, Epoch 5/30, Loss: 17.041686
val phase, Epoch 5/30, Loss: 16.777241
Val Best Loss: 16.777241
Epoch loss: 16.777241
train phase, Epoch 6/30, Loss: 17.021216
val phase, Epoch 6/30, Loss: 16.918465
Val Best Loss: 16.777241
Epoch loss: 16.918465
train phase, Epoch 7/30, Loss: 16.386322
val phase, Epoch 7/30, Loss: 16.657892
Val Best Loss: 16.657892
Epoch loss: 16.657892
train phase, Epoch 8/30, Loss: 16.532398
val phase, Epoch 8/30, Loss: 16.892051
Val Best Loss: 16.657892
Epoch loss: 16.892051
train phase, Epoch 9/30, Loss: 16.206893
val phase, Epoch 9/30, Loss: 16.281325
Val Best Loss: 16.281325
Epoch loss: 16.281325
train phase, Epoch 10/30, Loss: 16.272654
val phase, Epoch 10/30, Loss: 16.385775
Val Best Loss: 16.281325
Epoch loss: 16.385775
train phase, Epoch 11/30, Loss: 15.737774
val phase, Epoch 11/30, Loss: 16.211804
Val Best Loss: 16.211804
Epoch loss: 16.211804
train phase, Epoch 12/30, Loss: 15.795924
val phase, Epoch 12/30, Loss: 15.668359
Val Best Loss: 15.668359
Epoch loss: 15.668359
train phase, Epoch 13/30, Loss: 15.727128
val phase, Epoch 13/30, Loss: 16.354403
Val Best Loss: 15.668359
Epoch loss: 16.354403
train phase, Epoch 14/30, Loss: 15.359307
val phase, Epoch 14/30, Loss: 17.915615
Val Best Loss: 15.668359
Epoch loss: 17.915615
train phase, Epoch 15/30, Loss: 15.226293
val phase, Epoch 15/30, Loss: 18.009138
Val Best Loss: 15.668359
Epoch loss: 18.009138
train phase, Epoch 16/30, Loss: 15.085518
val phase, Epoch 16/30, Loss: 17.034538
Val Best Loss: 15.668359
Epoch loss: 17.034538
train phase, Epoch 17/30, Loss: 14.733324
val phase, Epoch 17/30, Loss: 16.069426
Val Best Loss: 15.668359
Epoch loss: 16.069426
train phase, Epoch 18/30, Loss: 14.885348
val phase, Epoch 18/30, Loss: 16.210083
Val Best Loss: 15.668359
Epoch loss: 16.210083
train phase, Epoch 19/30, Loss: 14.655477
val phase, Epoch 19/30, Loss: 16.425077
Val Best Loss: 15.668359
Epoch loss: 16.425077
train phase, Epoch 20/30, Loss: 14.020325
val phase, Epoch 20/30, Loss: 16.294461
Val Best Loss: 15.668359
Epoch loss: 16.294461
train phase, Epoch 21/30, Loss: 13.789254
val phase, Epoch 21/30, Loss: 17.362168
Val Best Loss: 15.668359
Epoch loss: 17.362168
train phase, Epoch 22/30, Loss: 13.705006
val phase, Epoch 22/30, Loss: 16.534756
Val Best Loss: 15.668359
Epoch loss: 16.534756
train phase, Epoch 23/30, Loss: 13.345239
val phase, Epoch 23/30, Loss: 18.096997
Val Best Loss: 15.668359
Epoch loss: 18.096997
train phase, Epoch 24/30, Loss: 12.994777
val phase, Epoch 24/30, Loss: 17.216892
Val Best Loss: 15.668359
Epoch loss: 17.216892
train phase, Epoch 25/30, Loss: 12.157565
val phase, Epoch 25/30, Loss: 17.068567
Val Best Loss: 15.668359
Epoch loss: 17.068567
train phase, Epoch 26/30, Loss: 12.131937
val phase, Epoch 26/30, Loss: 16.960102
Val Best Loss: 15.668359
Epoch loss: 16.960102
train phase, Epoch 27/30, Loss: 11.726728
val phase, Epoch 27/30, Loss: 18.155379
Val Best Loss: 15.668359
Epoch loss: 18.155379
train phase, Epoch 28/30, Loss: 11.098018
val phase, Epoch 28/30, Loss: 18.361632
Val Best Loss: 15.668359
Epoch loss: 18.361632
train phase, Epoch 29/30, Loss: 10.880120
val phase, Epoch 29/30, Loss: 17.679112
Val Best Loss: 15.668359
Epoch loss: 17.679112
train phase, Epoch 30/30, Loss: 10.417036
val phase, Epoch 30/30, Loss: 17.476189
Val Best Loss: 15.668359
Epoch loss: 17.476189
train phase, Epoch 1/30, Loss: 32.983551
val phase, Epoch 1/30, Loss: 33.403698
Val Best Loss: 33.403698
Epoch loss: 33.403698
train phase, Epoch 2/30, Loss: nan
val phase, Epoch 2/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 3/30, Loss: nan
val phase, Epoch 3/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 4/30, Loss: nan
val phase, Epoch 4/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 5/30, Loss: nan
val phase, Epoch 5/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 6/30, Loss: nan
val phase, Epoch 6/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 7/30, Loss: nan
val phase, Epoch 7/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 8/30, Loss: nan
val phase, Epoch 8/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 9/30, Loss: nan
val phase, Epoch 9/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 10/30, Loss: nan
val phase, Epoch 10/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 11/30, Loss: nan
val phase, Epoch 11/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 12/30, Loss: nan
val phase, Epoch 12/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 13/30, Loss: nan
val phase, Epoch 13/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 14/30, Loss: nan
val phase, Epoch 14/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 15/30, Loss: nan
val phase, Epoch 15/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 16/30, Loss: nan
val phase, Epoch 16/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 17/30, Loss: nan
val phase, Epoch 17/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 18/30, Loss: nan
val phase, Epoch 18/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 19/30, Loss: nan
val phase, Epoch 19/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 20/30, Loss: nan
val phase, Epoch 20/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 21/30, Loss: nan
val phase, Epoch 21/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 22/30, Loss: nan
val phase, Epoch 22/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 23/30, Loss: nan
val phase, Epoch 23/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 24/30, Loss: nan
val phase, Epoch 24/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 25/30, Loss: nan
val phase, Epoch 25/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 26/30, Loss: nan
val phase, Epoch 26/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 27/30, Loss: nan
val phase, Epoch 27/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 28/30, Loss: nan
val phase, Epoch 28/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 29/30, Loss: nan
val phase, Epoch 29/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 30/30, Loss: nan
val phase, Epoch 30/30, Loss: nan
Val Best Loss: 33.403698
Epoch loss: nan
train phase, Epoch 1/30, Loss: 21.139089
val phase, Epoch 1/30, Loss: 17.625884
Val Best Loss: 17.625884
Epoch loss: 17.625884
train phase, Epoch 2/30, Loss: 18.485613
val phase, Epoch 2/30, Loss: 17.126574
Val Best Loss: 17.126574
Epoch loss: 17.126574
train phase, Epoch 3/30, Loss: 17.931610
val phase, Epoch 3/30, Loss: 16.680634
Val Best Loss: 16.680634
Epoch loss: 16.680634
train phase, Epoch 4/30, Loss: 17.520480
val phase, Epoch 4/30, Loss: 16.699346
Val Best Loss: 16.680634
Epoch loss: 16.699346
train phase, Epoch 5/30, Loss: 16.929973
val phase, Epoch 5/30, Loss: 16.530055
Val Best Loss: 16.530055
Epoch loss: 16.530055
train phase, Epoch 6/30, Loss: 16.964713
val phase, Epoch 6/30, Loss: 16.714335
Val Best Loss: 16.530055
Epoch loss: 16.714335
train phase, Epoch 7/30, Loss: 16.540638
val phase, Epoch 7/30, Loss: 18.890764
Val Best Loss: 16.530055
Epoch loss: 18.890764
train phase, Epoch 8/30, Loss: 16.866845
val phase, Epoch 8/30, Loss: 16.525650
Val Best Loss: 16.525650
Epoch loss: 16.525650
train phase, Epoch 9/30, Loss: 16.287523
val phase, Epoch 9/30, Loss: 18.242879
Val Best Loss: 16.525650
Epoch loss: 18.242879
train phase, Epoch 10/30, Loss: 16.592041
val phase, Epoch 10/30, Loss: 16.034189
Val Best Loss: 16.034189
Epoch loss: 16.034189
train phase, Epoch 11/30, Loss: 16.166130
val phase, Epoch 11/30, Loss: 15.829669
Val Best Loss: 15.829669
Epoch loss: 15.829669
train phase, Epoch 12/30, Loss: 15.852700
val phase, Epoch 12/30, Loss: 15.888153
Val Best Loss: 15.829669
Epoch loss: 15.888153
train phase, Epoch 13/30, Loss: 15.960558
val phase, Epoch 13/30, Loss: 16.300500
Val Best Loss: 15.829669
Epoch loss: 16.300500
train phase, Epoch 14/30, Loss: 15.790436
val phase, Epoch 14/30, Loss: 16.263926
Val Best Loss: 15.829669
Epoch loss: 16.263926
train phase, Epoch 15/30, Loss: 15.755578
val phase, Epoch 15/30, Loss: 16.752465
Val Best Loss: 15.829669
Epoch loss: 16.752465
train phase, Epoch 16/30, Loss: 15.238545
val phase, Epoch 16/30, Loss: 16.583034
Val Best Loss: 15.829669
Epoch loss: 16.583034
train phase, Epoch 17/30, Loss: 15.334911
val phase, Epoch 17/30, Loss: 17.348860
Val Best Loss: 15.829669
Epoch loss: 17.348860
train phase, Epoch 18/30, Loss: 15.049684
val phase, Epoch 18/30, Loss: 15.961840
Val Best Loss: 15.829669
Epoch loss: 15.961840
train phase, Epoch 19/30, Loss: 14.782909
val phase, Epoch 19/30, Loss: 15.982527
Val Best Loss: 15.829669
Epoch loss: 15.982527
train phase, Epoch 20/30, Loss: 14.456108
val phase, Epoch 20/30, Loss: 16.363969
Val Best Loss: 15.829669
Epoch loss: 16.363969
train phase, Epoch 21/30, Loss: 14.261352
val phase, Epoch 21/30, Loss: 17.241298
Val Best Loss: 15.829669
Epoch loss: 17.241298
train phase, Epoch 22/30, Loss: 14.112339
val phase, Epoch 22/30, Loss: 15.687432
Val Best Loss: 15.687432
Epoch loss: 15.687432
train phase, Epoch 23/30, Loss: 13.566269
val phase, Epoch 23/30, Loss: 17.689239
Val Best Loss: 15.687432
Epoch loss: 17.689239
train phase, Epoch 24/30, Loss: 13.527866
val phase, Epoch 24/30, Loss: 17.069486
Val Best Loss: 15.687432
Epoch loss: 17.069486
train phase, Epoch 25/30, Loss: 13.237003
val phase, Epoch 25/30, Loss: 16.863359
Val Best Loss: 15.687432
Epoch loss: 16.863359
train phase, Epoch 26/30, Loss: 12.727682
val phase, Epoch 26/30, Loss: 17.167296
Val Best Loss: 15.687432
Epoch loss: 17.167296
train phase, Epoch 27/30, Loss: 12.610508
val phase, Epoch 27/30, Loss: 17.194500
Val Best Loss: 15.687432
Epoch loss: 17.194500
train phase, Epoch 28/30, Loss: 12.430381
val phase, Epoch 28/30, Loss: 17.240513
Val Best Loss: 15.687432
Epoch loss: 17.240513
train phase, Epoch 29/30, Loss: 12.110859
val phase, Epoch 29/30, Loss: 16.830605
Val Best Loss: 15.687432
Epoch loss: 16.830605
train phase, Epoch 30/30, Loss: 11.787549
val phase, Epoch 30/30, Loss: 17.006036
Val Best Loss: 15.687432
Epoch loss: 17.006036
train phase, Epoch 1/30, Loss: 19.967700
val phase, Epoch 1/30, Loss: 18.563344
Val Best Loss: 18.563344
Epoch loss: 18.563344
train phase, Epoch 2/30, Loss: 17.684472
val phase, Epoch 2/30, Loss: 17.458763
Val Best Loss: 17.458763
Epoch loss: 17.458763
train phase, Epoch 3/30, Loss: 17.355671
val phase, Epoch 3/30, Loss: 17.750876
Val Best Loss: 17.458763
Epoch loss: 17.750876
train phase, Epoch 4/30, Loss: 17.098962
val phase, Epoch 4/30, Loss: 17.149708
Val Best Loss: 17.149708
Epoch loss: 17.149708
train phase, Epoch 5/30, Loss: 16.854181
val phase, Epoch 5/30, Loss: 17.286916
Val Best Loss: 17.149708
Epoch loss: 17.286916
train phase, Epoch 6/30, Loss: 16.775627
val phase, Epoch 6/30, Loss: 16.672408
Val Best Loss: 16.672408
Epoch loss: 16.672408
train phase, Epoch 7/30, Loss: 16.382741
val phase, Epoch 7/30, Loss: 16.519678
Val Best Loss: 16.519678
Epoch loss: 16.519678
train phase, Epoch 8/30, Loss: 16.174175
val phase, Epoch 8/30, Loss: 16.554722
Val Best Loss: 16.519678
Epoch loss: 16.554722
train phase, Epoch 9/30, Loss: 15.947267
val phase, Epoch 9/30, Loss: 16.134961
Val Best Loss: 16.134961
Epoch loss: 16.134961
train phase, Epoch 10/30, Loss: 15.651562
val phase, Epoch 10/30, Loss: 16.863843
Val Best Loss: 16.134961
Epoch loss: 16.863843
train phase, Epoch 11/30, Loss: 15.746457
val phase, Epoch 11/30, Loss: 16.958258
Val Best Loss: 16.134961
Epoch loss: 16.958258
train phase, Epoch 12/30, Loss: 15.521188
val phase, Epoch 12/30, Loss: 17.479300
Val Best Loss: 16.134961
Epoch loss: 17.479300
train phase, Epoch 13/30, Loss: 15.236263
val phase, Epoch 13/30, Loss: 16.106363
Val Best Loss: 16.106363
Epoch loss: 16.106363
train phase, Epoch 14/30, Loss: 15.057415
val phase, Epoch 14/30, Loss: 17.239502
Val Best Loss: 16.106363
Epoch loss: 17.239502
train phase, Epoch 15/30, Loss: 14.921200
val phase, Epoch 15/30, Loss: 16.728913
Val Best Loss: 16.106363
Epoch loss: 16.728913
train phase, Epoch 16/30, Loss: 14.636283
val phase, Epoch 16/30, Loss: 16.208182
Val Best Loss: 16.106363
Epoch loss: 16.208182
train phase, Epoch 17/30, Loss: 14.383438
val phase, Epoch 17/30, Loss: 16.565899
Val Best Loss: 16.106363
Epoch loss: 16.565899
train phase, Epoch 18/30, Loss: 14.237992
val phase, Epoch 18/30, Loss: 16.982577
Val Best Loss: 16.106363
Epoch loss: 16.982577
train phase, Epoch 19/30, Loss: 13.965718
val phase, Epoch 19/30, Loss: 16.567640
Val Best Loss: 16.106363
Epoch loss: 16.567640
train phase, Epoch 20/30, Loss: 13.408484
val phase, Epoch 20/30, Loss: 18.936084
Val Best Loss: 16.106363
Epoch loss: 18.936084
train phase, Epoch 21/30, Loss: 13.232593
val phase, Epoch 21/30, Loss: 17.289344
Val Best Loss: 16.106363
Epoch loss: 17.289344
train phase, Epoch 22/30, Loss: 12.816769
val phase, Epoch 22/30, Loss: 17.182884
Val Best Loss: 16.106363
Epoch loss: 17.182884
train phase, Epoch 23/30, Loss: 12.463538
val phase, Epoch 23/30, Loss: 16.753118
Val Best Loss: 16.106363
Epoch loss: 16.753118
train phase, Epoch 24/30, Loss: 11.828443
val phase, Epoch 24/30, Loss: 17.274322
Val Best Loss: 16.106363
Epoch loss: 17.274322
train phase, Epoch 25/30, Loss: 11.480176
val phase, Epoch 25/30, Loss: 17.106832
Val Best Loss: 16.106363
Epoch loss: 17.106832
train phase, Epoch 26/30, Loss: 10.961212
val phase, Epoch 26/30, Loss: 17.895559
Val Best Loss: 16.106363
Epoch loss: 17.895559
train phase, Epoch 27/30, Loss: 10.700894
val phase, Epoch 27/30, Loss: 18.867316
Val Best Loss: 16.106363
Epoch loss: 18.867316
train phase, Epoch 28/30, Loss: 9.980296
val phase, Epoch 28/30, Loss: 18.210954
Val Best Loss: 16.106363
Epoch loss: 18.210954
train phase, Epoch 29/30, Loss: 9.437406
val phase, Epoch 29/30, Loss: 18.019727
Val Best Loss: 16.106363
Epoch loss: 18.019727
train phase, Epoch 30/30, Loss: 9.135764
val phase, Epoch 30/30, Loss: 21.267306
Val Best Loss: 16.106363
Epoch loss: 21.267306
[Trial 49] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
[Trial 50] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 20.216841
val phase, Epoch 1/30, Loss: 17.747311
Val Best Loss: 17.747311
Epoch loss: 17.747311
train phase, Epoch 2/30, Loss: 18.098626
val phase, Epoch 2/30, Loss: 16.797000
Val Best Loss: 16.797000
Epoch loss: 16.797000
train phase, Epoch 3/30, Loss: 17.915221
val phase, Epoch 3/30, Loss: 17.235163
Val Best Loss: 16.797000
Epoch loss: 17.235163
train phase, Epoch 4/30, Loss: 17.309019
val phase, Epoch 4/30, Loss: 18.548053
Val Best Loss: 16.797000
Epoch loss: 18.548053
train phase, Epoch 5/30, Loss: 16.982125
val phase, Epoch 5/30, Loss: 18.662454
Val Best Loss: 16.797000
Epoch loss: 18.662454
train phase, Epoch 6/30, Loss: 17.179894
val phase, Epoch 6/30, Loss: 16.594806
Val Best Loss: 16.594806
Epoch loss: 16.594806
train phase, Epoch 7/30, Loss: 16.861046
val phase, Epoch 7/30, Loss: 18.497895
Val Best Loss: 16.594806
Epoch loss: 18.497895
train phase, Epoch 8/30, Loss: 16.973209
val phase, Epoch 8/30, Loss: 16.735874
Val Best Loss: 16.594806
Epoch loss: 16.735874
train phase, Epoch 9/30, Loss: 16.409406
val phase, Epoch 9/30, Loss: 16.574017
Val Best Loss: 16.574017
Epoch loss: 16.574017
train phase, Epoch 10/30, Loss: 16.750576
val phase, Epoch 10/30, Loss: 16.342693
Val Best Loss: 16.342693
Epoch loss: 16.342693
train phase, Epoch 11/30, Loss: 16.502536
val phase, Epoch 11/30, Loss: 16.239362
Val Best Loss: 16.239362
Epoch loss: 16.239362
train phase, Epoch 12/30, Loss: 16.072379
val phase, Epoch 12/30, Loss: 17.737247
Val Best Loss: 16.239362
Epoch loss: 17.737247
train phase, Epoch 13/30, Loss: 16.084194
val phase, Epoch 13/30, Loss: 16.798512
Val Best Loss: 16.239362
Epoch loss: 16.798512
train phase, Epoch 14/30, Loss: 15.465930
val phase, Epoch 14/30, Loss: 16.185697
Val Best Loss: 16.185697
Epoch loss: 16.185697
train phase, Epoch 15/30, Loss: 15.642433
val phase, Epoch 15/30, Loss: 16.302638
Val Best Loss: 16.185697
Epoch loss: 16.302638
train phase, Epoch 16/30, Loss: 15.573367
val phase, Epoch 16/30, Loss: 16.681848
Val Best Loss: 16.185697
Epoch loss: 16.681848
train phase, Epoch 17/30, Loss: 15.180924
val phase, Epoch 17/30, Loss: 17.654588
Val Best Loss: 16.185697
Epoch loss: 17.654588
train phase, Epoch 18/30, Loss: 15.037692
val phase, Epoch 18/30, Loss: 16.243776
Val Best Loss: 16.185697
Epoch loss: 16.243776
train phase, Epoch 19/30, Loss: 15.065795
val phase, Epoch 19/30, Loss: 17.377217
Val Best Loss: 16.185697
Epoch loss: 17.377217
train phase, Epoch 20/30, Loss: 14.528776
val phase, Epoch 20/30, Loss: 16.056624
Val Best Loss: 16.056624
Epoch loss: 16.056624
train phase, Epoch 21/30, Loss: 14.303786
val phase, Epoch 21/30, Loss: 17.694730
Val Best Loss: 16.056624
Epoch loss: 17.694730
train phase, Epoch 22/30, Loss: 14.106276
val phase, Epoch 22/30, Loss: 17.126637
Val Best Loss: 16.056624
Epoch loss: 17.126637
train phase, Epoch 23/30, Loss: 14.141623
val phase, Epoch 23/30, Loss: 17.492022
Val Best Loss: 16.056624
Epoch loss: 17.492022
train phase, Epoch 24/30, Loss: 13.581882
val phase, Epoch 24/30, Loss: 17.026264
Val Best Loss: 16.056624
Epoch loss: 17.026264
train phase, Epoch 25/30, Loss: 13.441932
val phase, Epoch 25/30, Loss: 16.964513
Val Best Loss: 16.056624
Epoch loss: 16.964513
train phase, Epoch 26/30, Loss: 12.703406
val phase, Epoch 26/30, Loss: 18.294011
Val Best Loss: 16.056624
Epoch loss: 18.294011
train phase, Epoch 27/30, Loss: 12.728554
val phase, Epoch 27/30, Loss: 18.414702
Val Best Loss: 16.056624
Epoch loss: 18.414702
train phase, Epoch 28/30, Loss: 12.951236
val phase, Epoch 28/30, Loss: 16.626026
Val Best Loss: 16.056624
Epoch loss: 16.626026
train phase, Epoch 29/30, Loss: 12.244620
val phase, Epoch 29/30, Loss: 18.086347
Val Best Loss: 16.056624
Epoch loss: 18.086347
train phase, Epoch 30/30, Loss: 11.373954
val phase, Epoch 30/30, Loss: 17.454920
Val Best Loss: 16.056624
Epoch loss: 17.454920
train phase, Epoch 1/30, Loss: 20.826879
val phase, Epoch 1/30, Loss: 18.692453
Val Best Loss: 18.692453
Epoch loss: 18.692453
train phase, Epoch 2/30, Loss: 18.128460
val phase, Epoch 2/30, Loss: 17.677950
Val Best Loss: 17.677950
Epoch loss: 17.677950
train phase, Epoch 3/30, Loss: 17.967178
val phase, Epoch 3/30, Loss: 16.165606
Val Best Loss: 16.165606
Epoch loss: 16.165606
train phase, Epoch 4/30, Loss: 17.179116
val phase, Epoch 4/30, Loss: 17.131061
Val Best Loss: 16.165606
Epoch loss: 17.131061
train phase, Epoch 5/30, Loss: 17.002499
val phase, Epoch 5/30, Loss: 17.385741
Val Best Loss: 16.165606
Epoch loss: 17.385741
train phase, Epoch 6/30, Loss: 16.995765
val phase, Epoch 6/30, Loss: 16.480660
Val Best Loss: 16.165606
Epoch loss: 16.480660
train phase, Epoch 7/30, Loss: 16.595420
val phase, Epoch 7/30, Loss: 16.217780
Val Best Loss: 16.165606
Epoch loss: 16.217780
train phase, Epoch 8/30, Loss: 16.387992
val phase, Epoch 8/30, Loss: 17.068185
Val Best Loss: 16.165606
Epoch loss: 17.068185
train phase, Epoch 9/30, Loss: 16.378952
val phase, Epoch 9/30, Loss: 16.198518
Val Best Loss: 16.165606
Epoch loss: 16.198518
train phase, Epoch 10/30, Loss: 16.087985
val phase, Epoch 10/30, Loss: 16.325227
Val Best Loss: 16.165606
Epoch loss: 16.325227
train phase, Epoch 11/30, Loss: 16.403193
val phase, Epoch 11/30, Loss: 16.262037
Val Best Loss: 16.165606
Epoch loss: 16.262037
train phase, Epoch 12/30, Loss: 16.051918
val phase, Epoch 12/30, Loss: 16.492370
Val Best Loss: 16.165606
Epoch loss: 16.492370
train phase, Epoch 13/30, Loss: 16.029001
val phase, Epoch 13/30, Loss: 16.429713
Val Best Loss: 16.165606
Epoch loss: 16.429713
train phase, Epoch 14/30, Loss: 15.552595
val phase, Epoch 14/30, Loss: 16.045489
Val Best Loss: 16.045489
Epoch loss: 16.045489
train phase, Epoch 15/30, Loss: 15.588733
val phase, Epoch 15/30, Loss: 15.959239
Val Best Loss: 15.959239
Epoch loss: 15.959239
train phase, Epoch 16/30, Loss: 15.263272
val phase, Epoch 16/30, Loss: 17.116222
Val Best Loss: 15.959239
Epoch loss: 17.116222
train phase, Epoch 17/30, Loss: 15.117314
val phase, Epoch 17/30, Loss: 15.972403
Val Best Loss: 15.959239
Epoch loss: 15.972403
train phase, Epoch 18/30, Loss: 14.877396
val phase, Epoch 18/30, Loss: 15.826334
Val Best Loss: 15.826334
Epoch loss: 15.826334
train phase, Epoch 19/30, Loss: 14.545541
val phase, Epoch 19/30, Loss: 16.745232
Val Best Loss: 15.826334
Epoch loss: 16.745232
train phase, Epoch 20/30, Loss: 14.370892
val phase, Epoch 20/30, Loss: 16.877709
Val Best Loss: 15.826334
Epoch loss: 16.877709
train phase, Epoch 21/30, Loss: 14.208171
val phase, Epoch 21/30, Loss: 17.020495
Val Best Loss: 15.826334
Epoch loss: 17.020495
train phase, Epoch 22/30, Loss: 14.203876
val phase, Epoch 22/30, Loss: 16.869141
Val Best Loss: 15.826334
Epoch loss: 16.869141
train phase, Epoch 23/30, Loss: 13.667091
val phase, Epoch 23/30, Loss: 17.612642
Val Best Loss: 15.826334
Epoch loss: 17.612642
train phase, Epoch 24/30, Loss: 13.609089
val phase, Epoch 24/30, Loss: 16.267800
Val Best Loss: 15.826334
Epoch loss: 16.267800
train phase, Epoch 25/30, Loss: 13.152922
val phase, Epoch 25/30, Loss: 17.401552
Val Best Loss: 15.826334
Epoch loss: 17.401552
train phase, Epoch 26/30, Loss: 12.626795
val phase, Epoch 26/30, Loss: 16.853203
Val Best Loss: 15.826334
Epoch loss: 16.853203
train phase, Epoch 27/30, Loss: 12.485438
val phase, Epoch 27/30, Loss: 17.089957
Val Best Loss: 15.826334
Epoch loss: 17.089957
train phase, Epoch 28/30, Loss: 12.068528
val phase, Epoch 28/30, Loss: 20.462948
Val Best Loss: 15.826334
Epoch loss: 20.462948
train phase, Epoch 29/30, Loss: 11.616368
val phase, Epoch 29/30, Loss: 17.299793
Val Best Loss: 15.826334
Epoch loss: 17.299793
train phase, Epoch 30/30, Loss: 11.262102
val phase, Epoch 30/30, Loss: 18.078691
Val Best Loss: 15.826334
Epoch loss: 18.078691
train phase, Epoch 1/30, Loss: 20.035144
val phase, Epoch 1/30, Loss: 17.597929
Val Best Loss: 17.597929
Epoch loss: 17.597929
train phase, Epoch 2/30, Loss: 17.977477
val phase, Epoch 2/30, Loss: 16.536655
Val Best Loss: 16.536655
Epoch loss: 16.536655
train phase, Epoch 3/30, Loss: 17.591691
val phase, Epoch 3/30, Loss: 16.710435
Val Best Loss: 16.536655
Epoch loss: 16.710435
train phase, Epoch 4/30, Loss: 17.583192
val phase, Epoch 4/30, Loss: 16.300202
Val Best Loss: 16.300202
Epoch loss: 16.300202
train phase, Epoch 5/30, Loss: 17.186615
val phase, Epoch 5/30, Loss: 16.838414
Val Best Loss: 16.300202
Epoch loss: 16.838414
train phase, Epoch 6/30, Loss: 16.633732
val phase, Epoch 6/30, Loss: 16.800649
Val Best Loss: 16.300202
Epoch loss: 16.800649
train phase, Epoch 7/30, Loss: 16.579801
val phase, Epoch 7/30, Loss: 16.261384
Val Best Loss: 16.261384
Epoch loss: 16.261384
train phase, Epoch 8/30, Loss: 16.701686
val phase, Epoch 8/30, Loss: 16.971780
Val Best Loss: 16.261384
Epoch loss: 16.971780
train phase, Epoch 9/30, Loss: 16.390563
val phase, Epoch 9/30, Loss: 19.409488
Val Best Loss: 16.261384
Epoch loss: 19.409488
train phase, Epoch 10/30, Loss: 16.265408
val phase, Epoch 10/30, Loss: 16.500270
Val Best Loss: 16.261384
Epoch loss: 16.500270
train phase, Epoch 11/30, Loss: 15.772571
val phase, Epoch 11/30, Loss: 16.268617
Val Best Loss: 16.261384
Epoch loss: 16.268617
train phase, Epoch 12/30, Loss: 15.787182
val phase, Epoch 12/30, Loss: 16.504633
Val Best Loss: 16.261384
Epoch loss: 16.504633
train phase, Epoch 13/30, Loss: 15.552614
val phase, Epoch 13/30, Loss: 16.000087
Val Best Loss: 16.000087
Epoch loss: 16.000087
train phase, Epoch 14/30, Loss: 15.436826
val phase, Epoch 14/30, Loss: 16.611815
Val Best Loss: 16.000087
Epoch loss: 16.611815
train phase, Epoch 15/30, Loss: 15.326099
val phase, Epoch 15/30, Loss: 15.830991
Val Best Loss: 15.830991
Epoch loss: 15.830991
train phase, Epoch 16/30, Loss: 15.093938
val phase, Epoch 16/30, Loss: 15.894777
Val Best Loss: 15.830991
Epoch loss: 15.894777
train phase, Epoch 17/30, Loss: 14.912212
val phase, Epoch 17/30, Loss: 16.068157
Val Best Loss: 15.830991
Epoch loss: 16.068157
train phase, Epoch 18/30, Loss: 14.764497
val phase, Epoch 18/30, Loss: 15.814153
Val Best Loss: 15.814153
Epoch loss: 15.814153
train phase, Epoch 19/30, Loss: 14.462414
val phase, Epoch 19/30, Loss: 16.957609
Val Best Loss: 15.814153
Epoch loss: 16.957609
train phase, Epoch 20/30, Loss: 14.105843
val phase, Epoch 20/30, Loss: 16.651463
Val Best Loss: 15.814153
Epoch loss: 16.651463
train phase, Epoch 21/30, Loss: 13.841210
val phase, Epoch 21/30, Loss: 16.118613
Val Best Loss: 15.814153
Epoch loss: 16.118613
train phase, Epoch 22/30, Loss: 13.666263
val phase, Epoch 22/30, Loss: 16.741799
Val Best Loss: 15.814153
Epoch loss: 16.741799
train phase, Epoch 23/30, Loss: 13.161236
val phase, Epoch 23/30, Loss: 16.928204
Val Best Loss: 15.814153
Epoch loss: 16.928204
train phase, Epoch 24/30, Loss: 12.980579
val phase, Epoch 24/30, Loss: 16.635731
Val Best Loss: 15.814153
Epoch loss: 16.635731
train phase, Epoch 25/30, Loss: 12.367553
val phase, Epoch 25/30, Loss: 16.804337
Val Best Loss: 15.814153
Epoch loss: 16.804337
train phase, Epoch 26/30, Loss: 12.332457
val phase, Epoch 26/30, Loss: 17.944543
Val Best Loss: 15.814153
Epoch loss: 17.944543
train phase, Epoch 27/30, Loss: 11.854284
val phase, Epoch 27/30, Loss: 17.337609
Val Best Loss: 15.814153
Epoch loss: 17.337609
train phase, Epoch 28/30, Loss: 11.304564
val phase, Epoch 28/30, Loss: 18.329995
Val Best Loss: 15.814153
Epoch loss: 18.329995
train phase, Epoch 29/30, Loss: 10.901916
val phase, Epoch 29/30, Loss: 17.740511
Val Best Loss: 15.814153
Epoch loss: 17.740511
train phase, Epoch 30/30, Loss: 10.517248
val phase, Epoch 30/30, Loss: 17.832524
Val Best Loss: 15.814153
Epoch loss: 17.832524
train phase, Epoch 1/30, Loss: 20.974129
val phase, Epoch 1/30, Loss: 17.900032
Val Best Loss: 17.900032
Epoch loss: 17.900032
train phase, Epoch 2/30, Loss: 17.316216
val phase, Epoch 2/30, Loss: 16.749296
Val Best Loss: 16.749296
Epoch loss: 16.749296
train phase, Epoch 3/30, Loss: 16.959832
val phase, Epoch 3/30, Loss: 16.674182
Val Best Loss: 16.674182
Epoch loss: 16.674182
train phase, Epoch 4/30, Loss: 16.617965
val phase, Epoch 4/30, Loss: 17.666480
Val Best Loss: 16.674182
Epoch loss: 17.666480
train phase, Epoch 5/30, Loss: 16.423394
val phase, Epoch 5/30, Loss: 16.020883
Val Best Loss: 16.020883
Epoch loss: 16.020883
train phase, Epoch 6/30, Loss: 16.137817
val phase, Epoch 6/30, Loss: 15.911643
Val Best Loss: 15.911643
Epoch loss: 15.911643
train phase, Epoch 7/30, Loss: 15.799572
val phase, Epoch 7/30, Loss: 16.952886
Val Best Loss: 15.911643
Epoch loss: 16.952886
train phase, Epoch 8/30, Loss: 15.694417
val phase, Epoch 8/30, Loss: 16.181773
Val Best Loss: 15.911643
Epoch loss: 16.181773
train phase, Epoch 9/30, Loss: 15.356412
val phase, Epoch 9/30, Loss: 15.956366
Val Best Loss: 15.911643
Epoch loss: 15.956366
train phase, Epoch 10/30, Loss: 15.305156
val phase, Epoch 10/30, Loss: 15.934612
Val Best Loss: 15.911643
Epoch loss: 15.934612
train phase, Epoch 11/30, Loss: 14.737986
val phase, Epoch 11/30, Loss: 16.487836
Val Best Loss: 15.911643
Epoch loss: 16.487836
train phase, Epoch 12/30, Loss: 14.664646
val phase, Epoch 12/30, Loss: 16.301806
Val Best Loss: 15.911643
Epoch loss: 16.301806
train phase, Epoch 13/30, Loss: 14.258583
val phase, Epoch 13/30, Loss: 16.483146
Val Best Loss: 15.911643
Epoch loss: 16.483146
train phase, Epoch 14/30, Loss: 13.790754
val phase, Epoch 14/30, Loss: 16.199576
Val Best Loss: 15.911643
Epoch loss: 16.199576
train phase, Epoch 15/30, Loss: 13.417196
val phase, Epoch 15/30, Loss: 16.712716
Val Best Loss: 15.911643
Epoch loss: 16.712716
train phase, Epoch 16/30, Loss: 13.082979
val phase, Epoch 16/30, Loss: 18.441099
Val Best Loss: 15.911643
Epoch loss: 18.441099
train phase, Epoch 17/30, Loss: 12.702909
val phase, Epoch 17/30, Loss: 16.904219
Val Best Loss: 15.911643
Epoch loss: 16.904219
train phase, Epoch 18/30, Loss: 12.200229
val phase, Epoch 18/30, Loss: 17.376509
Val Best Loss: 15.911643
Epoch loss: 17.376509
train phase, Epoch 19/30, Loss: 11.679190
val phase, Epoch 19/30, Loss: 17.357610
Val Best Loss: 15.911643
Epoch loss: 17.357610
train phase, Epoch 20/30, Loss: 11.128373
val phase, Epoch 20/30, Loss: 18.507749
Val Best Loss: 15.911643
Epoch loss: 18.507749
train phase, Epoch 21/30, Loss: 10.722558
val phase, Epoch 21/30, Loss: 18.386324
Val Best Loss: 15.911643
Epoch loss: 18.386324
train phase, Epoch 22/30, Loss: 10.503619
val phase, Epoch 22/30, Loss: 19.060022
Val Best Loss: 15.911643
Epoch loss: 19.060022
train phase, Epoch 23/30, Loss: 9.726741
val phase, Epoch 23/30, Loss: 19.706100
Val Best Loss: 15.911643
Epoch loss: 19.706100
train phase, Epoch 24/30, Loss: 9.036797
val phase, Epoch 24/30, Loss: 21.092737
Val Best Loss: 15.911643
Epoch loss: 21.092737
train phase, Epoch 25/30, Loss: 8.628907
val phase, Epoch 25/30, Loss: 19.576468
Val Best Loss: 15.911643
Epoch loss: 19.576468
train phase, Epoch 26/30, Loss: 8.193344
val phase, Epoch 26/30, Loss: 18.499995
Val Best Loss: 15.911643
Epoch loss: 18.499995
train phase, Epoch 27/30, Loss: 7.741456
val phase, Epoch 27/30, Loss: 19.591279
Val Best Loss: 15.911643
Epoch loss: 19.591279
train phase, Epoch 28/30, Loss: 7.298304
val phase, Epoch 28/30, Loss: 20.550022
Val Best Loss: 15.911643
Epoch loss: 20.550022
train phase, Epoch 29/30, Loss: 6.784436
val phase, Epoch 29/30, Loss: 19.223499
Val Best Loss: 15.911643
Epoch loss: 19.223499
train phase, Epoch 30/30, Loss: 6.327483
val phase, Epoch 30/30, Loss: 19.317640
Val Best Loss: 15.911643
Epoch loss: 19.317640
train phase, Epoch 1/5, Loss: 20.659340
val phase, Epoch 1/5, Loss: 18.461084
Val Best Loss: 18.461084
Epoch loss: 18.461084
train phase, Epoch 2/5, Loss: 18.382820
val phase, Epoch 2/5, Loss: 18.297525
Val Best Loss: 18.297525
Epoch loss: 18.297525
train phase, Epoch 3/5, Loss: 17.687794
val phase, Epoch 3/5, Loss: 16.768148
Val Best Loss: 16.768148
Epoch loss: 16.768148
train phase, Epoch 4/5, Loss: 17.808576
val phase, Epoch 4/5, Loss: 18.155220
Val Best Loss: 16.768148
Epoch loss: 18.155220
train phase, Epoch 5/5, Loss: 17.519589
val phase, Epoch 5/5, Loss: 16.205300
Val Best Loss: 16.205300
Epoch loss: 16.205300
train phase, Epoch 1/25, Loss: 20.327544
val phase, Epoch 1/25, Loss: 26.106235
Val Best Loss: 26.106235
Epoch loss: 26.106235
train phase, Epoch 2/25, Loss: 17.773405
val phase, Epoch 2/25, Loss: 28.601145
Val Best Loss: 26.106235
Epoch loss: 28.601145
train phase, Epoch 3/25, Loss: 16.986744
val phase, Epoch 3/25, Loss: 33.655094
Val Best Loss: 26.106235
Epoch loss: 33.655094
train phase, Epoch 4/25, Loss: 16.826846
val phase, Epoch 4/25, Loss: 35.100887
Val Best Loss: 26.106235
Epoch loss: 35.100887
train phase, Epoch 5/25, Loss: 16.927093
val phase, Epoch 5/25, Loss: 42.522533
Val Best Loss: 26.106235
Epoch loss: 42.522533
train phase, Epoch 6/25, Loss: 16.257586
val phase, Epoch 6/25, Loss: 35.391346
Val Best Loss: 26.106235
Epoch loss: 35.391346
train phase, Epoch 7/25, Loss: 16.599695
val phase, Epoch 7/25, Loss: 40.539465
Val Best Loss: 26.106235
Epoch loss: 40.539465
train phase, Epoch 8/25, Loss: 16.144398
val phase, Epoch 8/25, Loss: 37.259974
Val Best Loss: 26.106235
Epoch loss: 37.259974
train phase, Epoch 9/25, Loss: 16.022625
val phase, Epoch 9/25, Loss: 39.454295
Val Best Loss: 26.106235
Epoch loss: 39.454295
train phase, Epoch 10/25, Loss: 15.825282
val phase, Epoch 10/25, Loss: 30.367561
Val Best Loss: 26.106235
Epoch loss: 30.367561
train phase, Epoch 11/25, Loss: 15.527336
val phase, Epoch 11/25, Loss: 51.397129
Val Best Loss: 26.106235
Epoch loss: 51.397129
train phase, Epoch 12/25, Loss: 15.523513
val phase, Epoch 12/25, Loss: 47.729414
Val Best Loss: 26.106235
Epoch loss: 47.729414
train phase, Epoch 13/25, Loss: 15.304495
val phase, Epoch 13/25, Loss: 41.785091
Val Best Loss: 26.106235
Epoch loss: 41.785091
train phase, Epoch 14/25, Loss: 15.210483
val phase, Epoch 14/25, Loss: 38.526132
Val Best Loss: 26.106235
Epoch loss: 38.526132
train phase, Epoch 15/25, Loss: 14.870124
val phase, Epoch 15/25, Loss: 41.991565
Val Best Loss: 26.106235
Epoch loss: 41.991565
train phase, Epoch 16/25, Loss: 14.643128
val phase, Epoch 16/25, Loss: 50.083356
Val Best Loss: 26.106235
Epoch loss: 50.083356
train phase, Epoch 17/25, Loss: 14.224226
val phase, Epoch 17/25, Loss: 58.089267
Val Best Loss: 26.106235
Epoch loss: 58.089267
train phase, Epoch 18/25, Loss: 13.979649
val phase, Epoch 18/25, Loss: 64.318250
Val Best Loss: 26.106235
Epoch loss: 64.318250
train phase, Epoch 19/25, Loss: 13.958212
val phase, Epoch 19/25, Loss: 67.887406
Val Best Loss: 26.106235
Epoch loss: 67.887406
train phase, Epoch 20/25, Loss: 13.524765
val phase, Epoch 20/25, Loss: 59.089059
Val Best Loss: 26.106235
Epoch loss: 59.089059
train phase, Epoch 21/25, Loss: 13.283227
val phase, Epoch 21/25, Loss: 51.890885
Val Best Loss: 26.106235
Epoch loss: 51.890885
train phase, Epoch 22/25, Loss: 13.023580
val phase, Epoch 22/25, Loss: 84.421161
Val Best Loss: 26.106235
Epoch loss: 84.421161
train phase, Epoch 23/25, Loss: 12.294617
val phase, Epoch 23/25, Loss: 83.348982
Val Best Loss: 26.106235
Epoch loss: 83.348982
train phase, Epoch 24/25, Loss: 12.436742
val phase, Epoch 24/25, Loss: 103.131041
Val Best Loss: 26.106235
Epoch loss: 103.131041
train phase, Epoch 25/25, Loss: 11.725832
val phase, Epoch 25/25, Loss: 84.338265
Val Best Loss: 26.106235
Epoch loss: 84.338265
train phase, Epoch 1/15, Loss: 22.257016
val phase, Epoch 1/15, Loss: 18.980924
Val Best Loss: 18.980924
Epoch loss: 18.980924
train phase, Epoch 2/15, Loss: 18.265323
val phase, Epoch 2/15, Loss: 19.070640
Val Best Loss: 18.980924
Epoch loss: 19.070640
train phase, Epoch 3/15, Loss: 17.826696
val phase, Epoch 3/15, Loss: 17.359078
Val Best Loss: 17.359078
Epoch loss: 17.359078
train phase, Epoch 4/15, Loss: 17.413626
val phase, Epoch 4/15, Loss: 17.993889
Val Best Loss: 17.359078
Epoch loss: 17.993889
train phase, Epoch 5/15, Loss: 17.645374
val phase, Epoch 5/15, Loss: 17.356773
Val Best Loss: 17.356773
Epoch loss: 17.356773
train phase, Epoch 6/15, Loss: 16.959912
val phase, Epoch 6/15, Loss: 18.474792
Val Best Loss: 17.356773
Epoch loss: 18.474792
train phase, Epoch 7/15, Loss: 16.910976
val phase, Epoch 7/15, Loss: 16.305023
Val Best Loss: 16.305023
Epoch loss: 16.305023
train phase, Epoch 8/15, Loss: 17.003970
val phase, Epoch 8/15, Loss: 16.861129
Val Best Loss: 16.305023
Epoch loss: 16.861129
train phase, Epoch 9/15, Loss: 16.500845
val phase, Epoch 9/15, Loss: 16.512563
Val Best Loss: 16.305023
Epoch loss: 16.512563
train phase, Epoch 10/15, Loss: 16.588288
val phase, Epoch 10/15, Loss: 16.260814
Val Best Loss: 16.260814
Epoch loss: 16.260814
train phase, Epoch 11/15, Loss: 16.381332
val phase, Epoch 11/15, Loss: 16.418609
Val Best Loss: 16.260814
Epoch loss: 16.418609
train phase, Epoch 12/15, Loss: 16.336311
val phase, Epoch 12/15, Loss: 17.489724
Val Best Loss: 16.260814
Epoch loss: 17.489724
train phase, Epoch 13/15, Loss: 16.026095
val phase, Epoch 13/15, Loss: 17.055415
Val Best Loss: 16.260814
Epoch loss: 17.055415
train phase, Epoch 14/15, Loss: 15.656462
val phase, Epoch 14/15, Loss: 17.748779
Val Best Loss: 16.260814
Epoch loss: 17.748779
train phase, Epoch 15/15, Loss: 15.593172
val phase, Epoch 15/15, Loss: 19.768551
Val Best Loss: 16.260814
Epoch loss: 19.768551
train phase, Epoch 1/30, Loss: 19.830724
val phase, Epoch 1/30, Loss: 17.211196
Val Best Loss: 17.211196
Epoch loss: 17.211196
train phase, Epoch 2/30, Loss: 17.824161
val phase, Epoch 2/30, Loss: 16.883171
Val Best Loss: 16.883171
Epoch loss: 16.883171
train phase, Epoch 3/30, Loss: 17.197189
val phase, Epoch 3/30, Loss: 17.871278
Val Best Loss: 16.883171
Epoch loss: 17.871278
train phase, Epoch 4/30, Loss: 17.131450
val phase, Epoch 4/30, Loss: 17.862054
Val Best Loss: 16.883171
Epoch loss: 17.862054
train phase, Epoch 5/30, Loss: 16.778683
val phase, Epoch 5/30, Loss: 16.812877
Val Best Loss: 16.812877
Epoch loss: 16.812877
train phase, Epoch 6/30, Loss: 16.695657
val phase, Epoch 6/30, Loss: 17.271107
Val Best Loss: 16.812877
Epoch loss: 17.271107
train phase, Epoch 7/30, Loss: 16.217265
val phase, Epoch 7/30, Loss: 16.063066
Val Best Loss: 16.063066
Epoch loss: 16.063066
train phase, Epoch 8/30, Loss: 16.228184
val phase, Epoch 8/30, Loss: 16.862171
Val Best Loss: 16.063066
Epoch loss: 16.862171
train phase, Epoch 9/30, Loss: 16.047831
val phase, Epoch 9/30, Loss: 16.580642
Val Best Loss: 16.063066
Epoch loss: 16.580642
train phase, Epoch 10/30, Loss: 15.750922
val phase, Epoch 10/30, Loss: 16.850076
Val Best Loss: 16.063066
Epoch loss: 16.850076
train phase, Epoch 11/30, Loss: 15.750752
val phase, Epoch 11/30, Loss: 17.485935
Val Best Loss: 16.063066
Epoch loss: 17.485935
train phase, Epoch 12/30, Loss: 15.501043
val phase, Epoch 12/30, Loss: 15.943744
Val Best Loss: 15.943744
Epoch loss: 15.943744
train phase, Epoch 13/30, Loss: 15.376833
val phase, Epoch 13/30, Loss: 16.227435
Val Best Loss: 15.943744
Epoch loss: 16.227435
train phase, Epoch 14/30, Loss: 14.913235
val phase, Epoch 14/30, Loss: 15.751132
Val Best Loss: 15.751132
Epoch loss: 15.751132
train phase, Epoch 15/30, Loss: 15.214152
val phase, Epoch 15/30, Loss: 16.011701
Val Best Loss: 15.751132
Epoch loss: 16.011701
train phase, Epoch 16/30, Loss: 14.524127
val phase, Epoch 16/30, Loss: 15.590756
Val Best Loss: 15.590756
Epoch loss: 15.590756
train phase, Epoch 17/30, Loss: 14.058612
val phase, Epoch 17/30, Loss: 16.218831
Val Best Loss: 15.590756
Epoch loss: 16.218831
train phase, Epoch 18/30, Loss: 14.076709
val phase, Epoch 18/30, Loss: 16.648393
Val Best Loss: 15.590756
Epoch loss: 16.648393
train phase, Epoch 19/30, Loss: 13.742911
val phase, Epoch 19/30, Loss: 16.583302
Val Best Loss: 15.590756
Epoch loss: 16.583302
train phase, Epoch 20/30, Loss: 13.411142
val phase, Epoch 20/30, Loss: 16.225446
Val Best Loss: 15.590756
Epoch loss: 16.225446
train phase, Epoch 21/30, Loss: 12.865262
val phase, Epoch 21/30, Loss: 18.018056
Val Best Loss: 15.590756
Epoch loss: 18.018056
train phase, Epoch 22/30, Loss: 12.688021
val phase, Epoch 22/30, Loss: 21.312731
Val Best Loss: 15.590756
Epoch loss: 21.312731
train phase, Epoch 23/30, Loss: 12.011836
val phase, Epoch 23/30, Loss: 16.881805
Val Best Loss: 15.590756
Epoch loss: 16.881805
train phase, Epoch 24/30, Loss: 11.825384
val phase, Epoch 24/30, Loss: 17.168632
Val Best Loss: 15.590756
Epoch loss: 17.168632
train phase, Epoch 25/30, Loss: 11.261713
val phase, Epoch 25/30, Loss: 17.345325
Val Best Loss: 15.590756
Epoch loss: 17.345325
train phase, Epoch 26/30, Loss: 10.743430
val phase, Epoch 26/30, Loss: 17.883797
Val Best Loss: 15.590756
Epoch loss: 17.883797
train phase, Epoch 27/30, Loss: 10.309143
val phase, Epoch 27/30, Loss: 18.130531
Val Best Loss: 15.590756
Epoch loss: 18.130531
train phase, Epoch 28/30, Loss: 9.729493
val phase, Epoch 28/30, Loss: 18.701535
Val Best Loss: 15.590756
Epoch loss: 18.701535
train phase, Epoch 29/30, Loss: 9.349292
val phase, Epoch 29/30, Loss: 20.970373
Val Best Loss: 15.590756
Epoch loss: 20.970373
train phase, Epoch 30/30, Loss: 9.045521
val phase, Epoch 30/30, Loss: 19.774141
Val Best Loss: 15.590756
Epoch loss: 19.774141
[Trial 59] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
[Trial 60] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 20.202918
val phase, Epoch 1/30, Loss: 17.038057
Val Best Loss: 17.038057
Epoch loss: 17.038057
train phase, Epoch 2/30, Loss: 17.590675
val phase, Epoch 2/30, Loss: 16.379095
Val Best Loss: 16.379095
Epoch loss: 16.379095
train phase, Epoch 3/30, Loss: 17.152384
val phase, Epoch 3/30, Loss: 16.302053
Val Best Loss: 16.302053
Epoch loss: 16.302053
train phase, Epoch 4/30, Loss: 16.889415
val phase, Epoch 4/30, Loss: 17.967543
Val Best Loss: 16.302053
Epoch loss: 17.967543
train phase, Epoch 5/30, Loss: 16.783172
val phase, Epoch 5/30, Loss: 16.379421
Val Best Loss: 16.302053
Epoch loss: 16.379421
train phase, Epoch 6/30, Loss: 16.379745
val phase, Epoch 6/30, Loss: 16.536928
Val Best Loss: 16.302053
Epoch loss: 16.536928
train phase, Epoch 7/30, Loss: 16.214207
val phase, Epoch 7/30, Loss: 16.280529
Val Best Loss: 16.280529
Epoch loss: 16.280529
train phase, Epoch 8/30, Loss: 15.908083
val phase, Epoch 8/30, Loss: 20.292873
Val Best Loss: 16.280529
Epoch loss: 20.292873
train phase, Epoch 9/30, Loss: 16.035212
val phase, Epoch 9/30, Loss: 17.063830
Val Best Loss: 16.280529
Epoch loss: 17.063830
train phase, Epoch 10/30, Loss: 15.730367
val phase, Epoch 10/30, Loss: 16.221422
Val Best Loss: 16.221422
Epoch loss: 16.221422
train phase, Epoch 11/30, Loss: 15.423155
val phase, Epoch 11/30, Loss: 16.765759
Val Best Loss: 16.221422
Epoch loss: 16.765759
train phase, Epoch 12/30, Loss: 15.393742
val phase, Epoch 12/30, Loss: 16.157631
Val Best Loss: 16.157631
Epoch loss: 16.157631
train phase, Epoch 13/30, Loss: 15.164047
val phase, Epoch 13/30, Loss: 16.352863
Val Best Loss: 16.157631
Epoch loss: 16.352863
train phase, Epoch 14/30, Loss: 14.860285
val phase, Epoch 14/30, Loss: 16.857082
Val Best Loss: 16.157631
Epoch loss: 16.857082
train phase, Epoch 15/30, Loss: 14.683511
val phase, Epoch 15/30, Loss: 16.049790
Val Best Loss: 16.049790
Epoch loss: 16.049790
train phase, Epoch 16/30, Loss: 14.615476
val phase, Epoch 16/30, Loss: 16.149895
Val Best Loss: 16.049790
Epoch loss: 16.149895
train phase, Epoch 17/30, Loss: 14.057246
val phase, Epoch 17/30, Loss: 16.425188
Val Best Loss: 16.049790
Epoch loss: 16.425188
train phase, Epoch 18/30, Loss: 13.892547
val phase, Epoch 18/30, Loss: 16.404720
Val Best Loss: 16.049790
Epoch loss: 16.404720
train phase, Epoch 19/30, Loss: 13.550847
val phase, Epoch 19/30, Loss: 18.519176
Val Best Loss: 16.049790
Epoch loss: 18.519176
train phase, Epoch 20/30, Loss: 13.216762
val phase, Epoch 20/30, Loss: 17.081958
Val Best Loss: 16.049790
Epoch loss: 17.081958
train phase, Epoch 21/30, Loss: 12.884513
val phase, Epoch 21/30, Loss: 16.997674
Val Best Loss: 16.049790
Epoch loss: 16.997674
train phase, Epoch 22/30, Loss: 12.475877
val phase, Epoch 22/30, Loss: 17.545946
Val Best Loss: 16.049790
Epoch loss: 17.545946
train phase, Epoch 23/30, Loss: 12.107284
val phase, Epoch 23/30, Loss: 17.642754
Val Best Loss: 16.049790
Epoch loss: 17.642754
train phase, Epoch 24/30, Loss: 11.723346
val phase, Epoch 24/30, Loss: 20.033153
Val Best Loss: 16.049790
Epoch loss: 20.033153
train phase, Epoch 25/30, Loss: 11.184573
val phase, Epoch 25/30, Loss: 18.005084
Val Best Loss: 16.049790
Epoch loss: 18.005084
train phase, Epoch 26/30, Loss: 10.529838
val phase, Epoch 26/30, Loss: 18.441047
Val Best Loss: 16.049790
Epoch loss: 18.441047
train phase, Epoch 27/30, Loss: 10.305686
val phase, Epoch 27/30, Loss: 18.168986
Val Best Loss: 16.049790
Epoch loss: 18.168986
train phase, Epoch 28/30, Loss: 9.775325
val phase, Epoch 28/30, Loss: 18.743992
Val Best Loss: 16.049790
Epoch loss: 18.743992
train phase, Epoch 29/30, Loss: 9.308618
val phase, Epoch 29/30, Loss: 18.756425
Val Best Loss: 16.049790
Epoch loss: 18.756425
train phase, Epoch 30/30, Loss: 8.558462
val phase, Epoch 30/30, Loss: 18.691054
Val Best Loss: 16.049790
Epoch loss: 18.691054
train phase, Epoch 1/30, Loss: 20.170531
val phase, Epoch 1/30, Loss: 18.062146
Val Best Loss: 18.062146
Epoch loss: 18.062146
train phase, Epoch 2/30, Loss: 18.134796
val phase, Epoch 2/30, Loss: 21.111743
Val Best Loss: 18.062146
Epoch loss: 21.111743
train phase, Epoch 3/30, Loss: 17.653233
val phase, Epoch 3/30, Loss: 16.933495
Val Best Loss: 16.933495
Epoch loss: 16.933495
train phase, Epoch 4/30, Loss: 17.403296
val phase, Epoch 4/30, Loss: 17.469166
Val Best Loss: 16.933495
Epoch loss: 17.469166
train phase, Epoch 5/30, Loss: 17.261587
val phase, Epoch 5/30, Loss: 16.242241
Val Best Loss: 16.242241
Epoch loss: 16.242241
train phase, Epoch 6/30, Loss: 16.828413
val phase, Epoch 6/30, Loss: 16.128457
Val Best Loss: 16.128457
Epoch loss: 16.128457
train phase, Epoch 7/30, Loss: 16.653263
val phase, Epoch 7/30, Loss: 17.227806
Val Best Loss: 16.128457
Epoch loss: 17.227806
train phase, Epoch 8/30, Loss: 16.397248
val phase, Epoch 8/30, Loss: 16.105978
Val Best Loss: 16.105978
Epoch loss: 16.105978
train phase, Epoch 9/30, Loss: 16.261391
val phase, Epoch 9/30, Loss: 16.670986
Val Best Loss: 16.105978
Epoch loss: 16.670986
train phase, Epoch 10/30, Loss: 16.464266
val phase, Epoch 10/30, Loss: 16.973077
Val Best Loss: 16.105978
Epoch loss: 16.973077
train phase, Epoch 11/30, Loss: 16.026185
val phase, Epoch 11/30, Loss: 16.731563
Val Best Loss: 16.105978
Epoch loss: 16.731563
train phase, Epoch 12/30, Loss: 15.875180
val phase, Epoch 12/30, Loss: 16.355402
Val Best Loss: 16.105978
Epoch loss: 16.355402
train phase, Epoch 13/30, Loss: 15.609451
val phase, Epoch 13/30, Loss: 16.801490
Val Best Loss: 16.105978
Epoch loss: 16.801490
train phase, Epoch 14/30, Loss: 15.807178
val phase, Epoch 14/30, Loss: 18.341621
Val Best Loss: 16.105978
Epoch loss: 18.341621
train phase, Epoch 15/30, Loss: 15.324193
val phase, Epoch 15/30, Loss: 15.950633
Val Best Loss: 15.950633
Epoch loss: 15.950633
train phase, Epoch 16/30, Loss: 15.143311
val phase, Epoch 16/30, Loss: 17.449117
Val Best Loss: 15.950633
Epoch loss: 17.449117
train phase, Epoch 17/30, Loss: 14.859042
val phase, Epoch 17/30, Loss: 16.563854
Val Best Loss: 15.950633
Epoch loss: 16.563854
train phase, Epoch 18/30, Loss: 14.678648
val phase, Epoch 18/30, Loss: 15.749580
Val Best Loss: 15.749580
Epoch loss: 15.749580
train phase, Epoch 19/30, Loss: 14.441238
val phase, Epoch 19/30, Loss: 16.283205
Val Best Loss: 15.749580
Epoch loss: 16.283205
train phase, Epoch 20/30, Loss: 14.108260
val phase, Epoch 20/30, Loss: 16.036182
Val Best Loss: 15.749580
Epoch loss: 16.036182
train phase, Epoch 21/30, Loss: 13.909150
val phase, Epoch 21/30, Loss: 16.185711
Val Best Loss: 15.749580
Epoch loss: 16.185711
train phase, Epoch 22/30, Loss: 13.639508
val phase, Epoch 22/30, Loss: 18.326462
Val Best Loss: 15.749580
Epoch loss: 18.326462
train phase, Epoch 23/30, Loss: 13.483275
val phase, Epoch 23/30, Loss: 18.154429
Val Best Loss: 15.749580
Epoch loss: 18.154429
train phase, Epoch 24/30, Loss: 13.001528
val phase, Epoch 24/30, Loss: 16.632826
Val Best Loss: 15.749580
Epoch loss: 16.632826
train phase, Epoch 25/30, Loss: 12.975743
val phase, Epoch 25/30, Loss: 17.467115
Val Best Loss: 15.749580
Epoch loss: 17.467115
train phase, Epoch 26/30, Loss: 12.157917
val phase, Epoch 26/30, Loss: 17.620072
Val Best Loss: 15.749580
Epoch loss: 17.620072
train phase, Epoch 27/30, Loss: 11.989063
val phase, Epoch 27/30, Loss: 20.921452
Val Best Loss: 15.749580
Epoch loss: 20.921452
train phase, Epoch 28/30, Loss: 11.550847
val phase, Epoch 28/30, Loss: 18.168947
Val Best Loss: 15.749580
Epoch loss: 18.168947
train phase, Epoch 29/30, Loss: 10.967211
val phase, Epoch 29/30, Loss: 17.599984
Val Best Loss: 15.749580
Epoch loss: 17.599984
train phase, Epoch 30/30, Loss: 10.351256
val phase, Epoch 30/30, Loss: 19.966833
Val Best Loss: 15.749580
Epoch loss: 19.966833
train phase, Epoch 1/30, Loss: 33.243641
val phase, Epoch 1/30, Loss: 18.078985
Val Best Loss: 18.078985
Epoch loss: 18.078985
train phase, Epoch 2/30, Loss: 17.729702
val phase, Epoch 2/30, Loss: 17.307477
Val Best Loss: 17.307477
Epoch loss: 17.307477
train phase, Epoch 3/30, Loss: 17.082223
val phase, Epoch 3/30, Loss: 16.950735
Val Best Loss: 16.950735
Epoch loss: 16.950735
train phase, Epoch 4/30, Loss: 16.655356
val phase, Epoch 4/30, Loss: 17.069514
Val Best Loss: 16.950735
Epoch loss: 17.069514
train phase, Epoch 5/30, Loss: 16.285865
val phase, Epoch 5/30, Loss: 17.041939
Val Best Loss: 16.950735
Epoch loss: 17.041939
train phase, Epoch 6/30, Loss: 16.062625
val phase, Epoch 6/30, Loss: 16.495003
Val Best Loss: 16.495003
Epoch loss: 16.495003
train phase, Epoch 7/30, Loss: 15.723729
val phase, Epoch 7/30, Loss: 16.446183
Val Best Loss: 16.446183
Epoch loss: 16.446183
train phase, Epoch 8/30, Loss: 15.432637
val phase, Epoch 8/30, Loss: 19.551277
Val Best Loss: 16.446183
Epoch loss: 19.551277
train phase, Epoch 9/30, Loss: 15.025095
val phase, Epoch 9/30, Loss: 17.069019
Val Best Loss: 16.446183
Epoch loss: 17.069019
train phase, Epoch 10/30, Loss: 14.818594
val phase, Epoch 10/30, Loss: 16.588551
Val Best Loss: 16.446183
Epoch loss: 16.588551
train phase, Epoch 11/30, Loss: 14.490915
val phase, Epoch 11/30, Loss: 16.511756
Val Best Loss: 16.446183
Epoch loss: 16.511756
train phase, Epoch 12/30, Loss: 14.068256
val phase, Epoch 12/30, Loss: 16.833829
Val Best Loss: 16.446183
Epoch loss: 16.833829
train phase, Epoch 13/30, Loss: 13.840863
val phase, Epoch 13/30, Loss: 16.780326
Val Best Loss: 16.446183
Epoch loss: 16.780326
train phase, Epoch 14/30, Loss: 13.380607
val phase, Epoch 14/30, Loss: 16.781411
Val Best Loss: 16.446183
Epoch loss: 16.781411
train phase, Epoch 15/30, Loss: 12.933548
val phase, Epoch 15/30, Loss: 17.270837
Val Best Loss: 16.446183
Epoch loss: 17.270837
train phase, Epoch 16/30, Loss: 12.577591
val phase, Epoch 16/30, Loss: 16.895580
Val Best Loss: 16.446183
Epoch loss: 16.895580
train phase, Epoch 17/30, Loss: 12.236222
val phase, Epoch 17/30, Loss: 16.922095
Val Best Loss: 16.446183
Epoch loss: 16.922095
train phase, Epoch 18/30, Loss: 11.772219
val phase, Epoch 18/30, Loss: 17.204519
Val Best Loss: 16.446183
Epoch loss: 17.204519
train phase, Epoch 19/30, Loss: 11.348720
val phase, Epoch 19/30, Loss: 17.522666
Val Best Loss: 16.446183
Epoch loss: 17.522666
train phase, Epoch 20/30, Loss: 10.821020
val phase, Epoch 20/30, Loss: 17.700707
Val Best Loss: 16.446183
Epoch loss: 17.700707
train phase, Epoch 21/30, Loss: 10.476613
val phase, Epoch 21/30, Loss: 18.527278
Val Best Loss: 16.446183
Epoch loss: 18.527278
train phase, Epoch 22/30, Loss: 10.121012
val phase, Epoch 22/30, Loss: 18.213322
Val Best Loss: 16.446183
Epoch loss: 18.213322
train phase, Epoch 23/30, Loss: 9.543947
val phase, Epoch 23/30, Loss: 20.085286
Val Best Loss: 16.446183
Epoch loss: 20.085286
train phase, Epoch 24/30, Loss: 9.159932
val phase, Epoch 24/30, Loss: 18.905810
Val Best Loss: 16.446183
Epoch loss: 18.905810
train phase, Epoch 25/30, Loss: 8.858172
val phase, Epoch 25/30, Loss: 18.629990
Val Best Loss: 16.446183
Epoch loss: 18.629990
train phase, Epoch 26/30, Loss: 8.369068
val phase, Epoch 26/30, Loss: 18.827517
Val Best Loss: 16.446183
Epoch loss: 18.827517
train phase, Epoch 27/30, Loss: 8.155270
val phase, Epoch 27/30, Loss: 18.917520
Val Best Loss: 16.446183
Epoch loss: 18.917520
train phase, Epoch 28/30, Loss: 7.625058
val phase, Epoch 28/30, Loss: 19.349625
Val Best Loss: 16.446183
Epoch loss: 19.349625
train phase, Epoch 29/30, Loss: 7.296248
val phase, Epoch 29/30, Loss: 20.001213
Val Best Loss: 16.446183
Epoch loss: 20.001213
train phase, Epoch 30/30, Loss: 6.966058
val phase, Epoch 30/30, Loss: 20.702849
Val Best Loss: 16.446183
Epoch loss: 20.702849
train phase, Epoch 1/30, Loss: 19.762318
val phase, Epoch 1/30, Loss: 18.362690
Val Best Loss: 18.362690
Epoch loss: 18.362690
train phase, Epoch 2/30, Loss: 17.744598
val phase, Epoch 2/30, Loss: 17.507029
Val Best Loss: 17.507029
Epoch loss: 17.507029
train phase, Epoch 3/30, Loss: 17.182587
val phase, Epoch 3/30, Loss: 17.197080
Val Best Loss: 17.197080
Epoch loss: 17.197080
train phase, Epoch 4/30, Loss: 17.019512
val phase, Epoch 4/30, Loss: 17.069366
Val Best Loss: 17.069366
Epoch loss: 17.069366
train phase, Epoch 5/30, Loss: 16.768041
val phase, Epoch 5/30, Loss: 17.588331
Val Best Loss: 17.069366
Epoch loss: 17.588331
train phase, Epoch 6/30, Loss: 16.982210
val phase, Epoch 6/30, Loss: 16.730775
Val Best Loss: 16.730775
Epoch loss: 16.730775
train phase, Epoch 7/30, Loss: 16.409179
val phase, Epoch 7/30, Loss: 16.306361
Val Best Loss: 16.306361
Epoch loss: 16.306361
train phase, Epoch 8/30, Loss: 16.410087
val phase, Epoch 8/30, Loss: 16.218508
Val Best Loss: 16.218508
Epoch loss: 16.218508
train phase, Epoch 9/30, Loss: 16.065386
val phase, Epoch 9/30, Loss: 16.363439
Val Best Loss: 16.218508
Epoch loss: 16.363439
train phase, Epoch 10/30, Loss: 16.076805
val phase, Epoch 10/30, Loss: 15.896436
Val Best Loss: 15.896436
Epoch loss: 15.896436
train phase, Epoch 11/30, Loss: 15.846102
val phase, Epoch 11/30, Loss: 16.039143
Val Best Loss: 15.896436
Epoch loss: 16.039143
train phase, Epoch 12/30, Loss: 15.647971
val phase, Epoch 12/30, Loss: 16.676165
Val Best Loss: 15.896436
Epoch loss: 16.676165
train phase, Epoch 13/30, Loss: 15.426925
val phase, Epoch 13/30, Loss: 16.341915
Val Best Loss: 15.896436
Epoch loss: 16.341915
train phase, Epoch 14/30, Loss: 15.314679
val phase, Epoch 14/30, Loss: 16.094509
Val Best Loss: 15.896436
Epoch loss: 16.094509
train phase, Epoch 15/30, Loss: 15.479209
val phase, Epoch 15/30, Loss: 15.802991
Val Best Loss: 15.802991
Epoch loss: 15.802991
train phase, Epoch 16/30, Loss: 14.994457
val phase, Epoch 16/30, Loss: 15.907101
Val Best Loss: 15.802991
Epoch loss: 15.907101
train phase, Epoch 17/30, Loss: 14.555543
val phase, Epoch 17/30, Loss: 16.308995
Val Best Loss: 15.802991
Epoch loss: 16.308995
train phase, Epoch 18/30, Loss: 14.468798
val phase, Epoch 18/30, Loss: 17.785562
Val Best Loss: 15.802991
Epoch loss: 17.785562
train phase, Epoch 19/30, Loss: 14.322647
val phase, Epoch 19/30, Loss: 16.341654
Val Best Loss: 15.802991
Epoch loss: 16.341654
train phase, Epoch 20/30, Loss: 13.803047
val phase, Epoch 20/30, Loss: 16.381682
Val Best Loss: 15.802991
Epoch loss: 16.381682
train phase, Epoch 21/30, Loss: 13.626818
val phase, Epoch 21/30, Loss: 16.964575
Val Best Loss: 15.802991
Epoch loss: 16.964575
train phase, Epoch 22/30, Loss: 13.147596
val phase, Epoch 22/30, Loss: 17.151968
Val Best Loss: 15.802991
Epoch loss: 17.151968
train phase, Epoch 23/30, Loss: 13.137678
val phase, Epoch 23/30, Loss: 16.798915
Val Best Loss: 15.802991
Epoch loss: 16.798915
train phase, Epoch 24/30, Loss: 12.244759
val phase, Epoch 24/30, Loss: 16.804998
Val Best Loss: 15.802991
Epoch loss: 16.804998
train phase, Epoch 25/30, Loss: 11.822891
val phase, Epoch 25/30, Loss: 17.022864
Val Best Loss: 15.802991
Epoch loss: 17.022864
train phase, Epoch 26/30, Loss: 11.581107
val phase, Epoch 26/30, Loss: 17.582722
Val Best Loss: 15.802991
Epoch loss: 17.582722
train phase, Epoch 27/30, Loss: 10.984176
val phase, Epoch 27/30, Loss: 18.494629
Val Best Loss: 15.802991
Epoch loss: 18.494629
train phase, Epoch 28/30, Loss: 10.843313
val phase, Epoch 28/30, Loss: 22.316660
Val Best Loss: 15.802991
Epoch loss: 22.316660
train phase, Epoch 29/30, Loss: 10.697755
val phase, Epoch 29/30, Loss: 17.615913
Val Best Loss: 15.802991
Epoch loss: 17.615913
train phase, Epoch 30/30, Loss: 9.790999
val phase, Epoch 30/30, Loss: 20.589958
Val Best Loss: 15.802991
Epoch loss: 20.589958
train phase, Epoch 1/10, Loss: 20.061626
val phase, Epoch 1/10, Loss: 18.320939
Val Best Loss: 18.320939
Epoch loss: 18.320939
train phase, Epoch 2/10, Loss: 17.785692
val phase, Epoch 2/10, Loss: 16.552116
Val Best Loss: 16.552116
Epoch loss: 16.552116
train phase, Epoch 3/10, Loss: 17.285480
val phase, Epoch 3/10, Loss: 16.626613
Val Best Loss: 16.552116
Epoch loss: 16.626613
train phase, Epoch 4/10, Loss: 17.281414
val phase, Epoch 4/10, Loss: 16.620043
Val Best Loss: 16.552116
Epoch loss: 16.620043
train phase, Epoch 5/10, Loss: 16.967076
val phase, Epoch 5/10, Loss: 16.440683
Val Best Loss: 16.440683
Epoch loss: 16.440683
train phase, Epoch 6/10, Loss: 16.622820
val phase, Epoch 6/10, Loss: 16.340815
Val Best Loss: 16.340815
Epoch loss: 16.340815
train phase, Epoch 7/10, Loss: 16.674322
val phase, Epoch 7/10, Loss: 16.139572
Val Best Loss: 16.139572
Epoch loss: 16.139572
train phase, Epoch 8/10, Loss: 16.373051
val phase, Epoch 8/10, Loss: 17.310354
Val Best Loss: 16.139572
Epoch loss: 17.310354
train phase, Epoch 9/10, Loss: 16.221661
val phase, Epoch 9/10, Loss: 16.960018
Val Best Loss: 16.139572
Epoch loss: 16.960018
train phase, Epoch 10/10, Loss: 16.046911
val phase, Epoch 10/10, Loss: 16.118643
Val Best Loss: 16.118643
Epoch loss: 16.118643
train phase, Epoch 1/20, Loss: 21.452152
val phase, Epoch 1/20, Loss: 17.780766
Val Best Loss: 17.780766
Epoch loss: 17.780766
train phase, Epoch 2/20, Loss: 18.154191
val phase, Epoch 2/20, Loss: 19.126782
Val Best Loss: 17.780766
Epoch loss: 19.126782
train phase, Epoch 3/20, Loss: 17.687543
val phase, Epoch 3/20, Loss: 18.168589
Val Best Loss: 17.780766
Epoch loss: 18.168589
train phase, Epoch 4/20, Loss: 17.978083
val phase, Epoch 4/20, Loss: 17.126870
Val Best Loss: 17.126870
Epoch loss: 17.126870
train phase, Epoch 5/20, Loss: 17.434878
val phase, Epoch 5/20, Loss: 17.150936
Val Best Loss: 17.126870
Epoch loss: 17.150936
train phase, Epoch 6/20, Loss: 17.104959
val phase, Epoch 6/20, Loss: 17.185673
Val Best Loss: 17.126870
Epoch loss: 17.185673
train phase, Epoch 7/20, Loss: 16.817497
val phase, Epoch 7/20, Loss: 17.318342
Val Best Loss: 17.126870
Epoch loss: 17.318342
train phase, Epoch 8/20, Loss: 16.831170
val phase, Epoch 8/20, Loss: 17.799713
Val Best Loss: 17.126870
Epoch loss: 17.799713
train phase, Epoch 9/20, Loss: 16.957706
val phase, Epoch 9/20, Loss: 16.371290
Val Best Loss: 16.371290
Epoch loss: 16.371290
train phase, Epoch 10/20, Loss: 16.607838
val phase, Epoch 10/20, Loss: 16.482448
Val Best Loss: 16.371290
Epoch loss: 16.482448
train phase, Epoch 11/20, Loss: 16.104182
val phase, Epoch 11/20, Loss: 16.262245
Val Best Loss: 16.262245
Epoch loss: 16.262245
train phase, Epoch 12/20, Loss: 16.096897
val phase, Epoch 12/20, Loss: 16.375750
Val Best Loss: 16.262245
Epoch loss: 16.375750
train phase, Epoch 13/20, Loss: 15.926916
val phase, Epoch 13/20, Loss: 16.722996
Val Best Loss: 16.262245
Epoch loss: 16.722996
train phase, Epoch 14/20, Loss: 15.788348
val phase, Epoch 14/20, Loss: 17.392655
Val Best Loss: 16.262245
Epoch loss: 17.392655
train phase, Epoch 15/20, Loss: 15.295365
val phase, Epoch 15/20, Loss: 16.927248
Val Best Loss: 16.262245
Epoch loss: 16.927248
train phase, Epoch 16/20, Loss: 15.324991
val phase, Epoch 16/20, Loss: 17.047507
Val Best Loss: 16.262245
Epoch loss: 17.047507
train phase, Epoch 17/20, Loss: 15.389827
val phase, Epoch 17/20, Loss: 17.000803
Val Best Loss: 16.262245
Epoch loss: 17.000803
train phase, Epoch 18/20, Loss: 14.924634
val phase, Epoch 18/20, Loss: 16.524845
Val Best Loss: 16.262245
Epoch loss: 16.524845
train phase, Epoch 19/20, Loss: 14.716689
val phase, Epoch 19/20, Loss: 18.003919
Val Best Loss: 16.262245
Epoch loss: 18.003919
train phase, Epoch 20/20, Loss: 14.344770
val phase, Epoch 20/20, Loss: 16.486658
Val Best Loss: 16.262245
Epoch loss: 16.486658
train phase, Epoch 1/30, Loss: 32.001763
val phase, Epoch 1/30, Loss: 19.932066
Val Best Loss: 19.932066
Epoch loss: 19.932066
train phase, Epoch 2/30, Loss: 19.441342
val phase, Epoch 2/30, Loss: 18.872395
Val Best Loss: 18.872395
Epoch loss: 18.872395
train phase, Epoch 3/30, Loss: 19.117540
val phase, Epoch 3/30, Loss: 18.376967
Val Best Loss: 18.376967
Epoch loss: 18.376967
train phase, Epoch 4/30, Loss: 18.721847
val phase, Epoch 4/30, Loss: 18.689977
Val Best Loss: 18.376967
Epoch loss: 18.689977
train phase, Epoch 5/30, Loss: 19.193535
val phase, Epoch 5/30, Loss: 18.314895
Val Best Loss: 18.314895
Epoch loss: 18.314895
train phase, Epoch 6/30, Loss: 19.090397
val phase, Epoch 6/30, Loss: 18.121001
Val Best Loss: 18.121001
Epoch loss: 18.121001
train phase, Epoch 7/30, Loss: 18.999020
val phase, Epoch 7/30, Loss: 18.471408
Val Best Loss: 18.121001
Epoch loss: 18.471408
train phase, Epoch 8/30, Loss: 18.754713
val phase, Epoch 8/30, Loss: 21.273724
Val Best Loss: 18.121001
Epoch loss: 21.273724
train phase, Epoch 9/30, Loss: 18.838141
val phase, Epoch 9/30, Loss: 18.036878
Val Best Loss: 18.036878
Epoch loss: 18.036878
train phase, Epoch 10/30, Loss: 18.572006
val phase, Epoch 10/30, Loss: 19.344458
Val Best Loss: 18.036878
Epoch loss: 19.344458
train phase, Epoch 11/30, Loss: 18.695066
val phase, Epoch 11/30, Loss: 18.895453
Val Best Loss: 18.036878
Epoch loss: 18.895453
train phase, Epoch 12/30, Loss: 18.960850
val phase, Epoch 12/30, Loss: 18.202007
Val Best Loss: 18.036878
Epoch loss: 18.202007
train phase, Epoch 13/30, Loss: 18.938029
val phase, Epoch 13/30, Loss: 17.878737
Val Best Loss: 17.878737
Epoch loss: 17.878737
train phase, Epoch 14/30, Loss: 18.304723
val phase, Epoch 14/30, Loss: 17.736823
Val Best Loss: 17.736823
Epoch loss: 17.736823
train phase, Epoch 15/30, Loss: 18.504954
val phase, Epoch 15/30, Loss: 18.283901
Val Best Loss: 17.736823
Epoch loss: 18.283901
train phase, Epoch 16/30, Loss: 18.747271
val phase, Epoch 16/30, Loss: 19.093497
Val Best Loss: 17.736823
Epoch loss: 19.093497
train phase, Epoch 17/30, Loss: 18.492459
val phase, Epoch 17/30, Loss: 18.057959
Val Best Loss: 17.736823
Epoch loss: 18.057959
train phase, Epoch 18/30, Loss: 18.498037
val phase, Epoch 18/30, Loss: 18.134146
Val Best Loss: 17.736823
Epoch loss: 18.134146
train phase, Epoch 19/30, Loss: 18.482052
val phase, Epoch 19/30, Loss: 17.687870
Val Best Loss: 17.687870
Epoch loss: 17.687870
train phase, Epoch 20/30, Loss: 18.412521
val phase, Epoch 20/30, Loss: 19.606651
Val Best Loss: 17.687870
Epoch loss: 19.606651
train phase, Epoch 21/30, Loss: 18.443777
val phase, Epoch 21/30, Loss: 18.594903
Val Best Loss: 17.687870
Epoch loss: 18.594903
train phase, Epoch 22/30, Loss: 18.477088
val phase, Epoch 22/30, Loss: 17.915698
Val Best Loss: 17.687870
Epoch loss: 17.915698
train phase, Epoch 23/30, Loss: 18.813553
val phase, Epoch 23/30, Loss: 18.240532
Val Best Loss: 17.687870
Epoch loss: 18.240532
train phase, Epoch 24/30, Loss: 18.607775
val phase, Epoch 24/30, Loss: 19.743483
Val Best Loss: 17.687870
Epoch loss: 19.743483
train phase, Epoch 25/30, Loss: 18.370081
val phase, Epoch 25/30, Loss: 18.069285
Val Best Loss: 17.687870
Epoch loss: 18.069285
train phase, Epoch 26/30, Loss: 18.380430
val phase, Epoch 26/30, Loss: 18.121287
Val Best Loss: 17.687870
Epoch loss: 18.121287
train phase, Epoch 27/30, Loss: 18.219526
val phase, Epoch 27/30, Loss: 18.965523
Val Best Loss: 17.687870
Epoch loss: 18.965523
train phase, Epoch 28/30, Loss: 18.341268
val phase, Epoch 28/30, Loss: 18.568648
Val Best Loss: 17.687870
Epoch loss: 18.568648
train phase, Epoch 29/30, Loss: 18.382635
val phase, Epoch 29/30, Loss: 17.947975
Val Best Loss: 17.687870
Epoch loss: 17.947975
train phase, Epoch 30/30, Loss: 18.883673
val phase, Epoch 30/30, Loss: 19.535649
Val Best Loss: 17.687870
Epoch loss: 19.535649
train phase, Epoch 1/20, Loss: 19.986749
val phase, Epoch 1/20, Loss: 17.183348
Val Best Loss: 17.183348
Epoch loss: 17.183348
train phase, Epoch 2/20, Loss: 17.758070
val phase, Epoch 2/20, Loss: 17.084288
Val Best Loss: 17.084288
Epoch loss: 17.084288
train phase, Epoch 3/20, Loss: 17.132791
val phase, Epoch 3/20, Loss: 16.706469
Val Best Loss: 16.706469
Epoch loss: 16.706469
train phase, Epoch 4/20, Loss: 17.042592
val phase, Epoch 4/20, Loss: 18.017618
Val Best Loss: 16.706469
Epoch loss: 18.017618
train phase, Epoch 5/20, Loss: 17.158023
val phase, Epoch 5/20, Loss: 17.010110
Val Best Loss: 16.706469
Epoch loss: 17.010110
train phase, Epoch 6/20, Loss: 16.380016
val phase, Epoch 6/20, Loss: 16.918421
Val Best Loss: 16.706469
Epoch loss: 16.918421
train phase, Epoch 7/20, Loss: 16.587875
val phase, Epoch 7/20, Loss: 17.457695
Val Best Loss: 16.706469
Epoch loss: 17.457695
train phase, Epoch 8/20, Loss: 16.210467
val phase, Epoch 8/20, Loss: 16.616752
Val Best Loss: 16.616752
Epoch loss: 16.616752
train phase, Epoch 9/20, Loss: 16.122416
val phase, Epoch 9/20, Loss: 16.129329
Val Best Loss: 16.129329
Epoch loss: 16.129329
train phase, Epoch 10/20, Loss: 15.922656
val phase, Epoch 10/20, Loss: 16.546539
Val Best Loss: 16.129329
Epoch loss: 16.546539
train phase, Epoch 11/20, Loss: 15.740402
val phase, Epoch 11/20, Loss: 17.456714
Val Best Loss: 16.129329
Epoch loss: 17.456714
train phase, Epoch 12/20, Loss: 15.943054
val phase, Epoch 12/20, Loss: 16.474393
Val Best Loss: 16.129329
Epoch loss: 16.474393
train phase, Epoch 13/20, Loss: 15.366824
val phase, Epoch 13/20, Loss: 15.923360
Val Best Loss: 15.923360
Epoch loss: 15.923360
train phase, Epoch 14/20, Loss: 15.136895
val phase, Epoch 14/20, Loss: 18.274124
Val Best Loss: 15.923360
Epoch loss: 18.274124
train phase, Epoch 15/20, Loss: 15.150520
val phase, Epoch 15/20, Loss: 15.813006
Val Best Loss: 15.813006
Epoch loss: 15.813006
train phase, Epoch 16/20, Loss: 14.977106
val phase, Epoch 16/20, Loss: 16.803256
Val Best Loss: 15.813006
Epoch loss: 16.803256
train phase, Epoch 17/20, Loss: 14.762344
val phase, Epoch 17/20, Loss: 16.216797
Val Best Loss: 15.813006
Epoch loss: 16.216797
train phase, Epoch 18/20, Loss: 14.493075
val phase, Epoch 18/20, Loss: 16.369481
Val Best Loss: 15.813006
Epoch loss: 16.369481
train phase, Epoch 19/20, Loss: 14.681150
val phase, Epoch 19/20, Loss: 16.086557
Val Best Loss: 15.813006
Epoch loss: 16.086557
train phase, Epoch 20/20, Loss: 14.262048
val phase, Epoch 20/20, Loss: 16.144142
Val Best Loss: 15.813006
Epoch loss: 16.144142
[Trial 69] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 23.830562
val phase, Epoch 1/20, Loss: 21.728631
Val Best Loss: 21.728631
Epoch loss: 21.728631
train phase, Epoch 2/20, Loss: 19.348398
val phase, Epoch 2/20, Loss: 17.992729
Val Best Loss: 17.992729
Epoch loss: 17.992729
train phase, Epoch 3/20, Loss: 18.398406
val phase, Epoch 3/20, Loss: 17.624587
Val Best Loss: 17.624587
Epoch loss: 17.624587
train phase, Epoch 4/20, Loss: 18.209897
val phase, Epoch 4/20, Loss: 17.259657
Val Best Loss: 17.259657
Epoch loss: 17.259657
train phase, Epoch 5/20, Loss: 17.896723
val phase, Epoch 5/20, Loss: 18.477215
Val Best Loss: 17.259657
Epoch loss: 18.477215
train phase, Epoch 6/20, Loss: 17.486047
val phase, Epoch 6/20, Loss: 21.124287
Val Best Loss: 17.259657
Epoch loss: 21.124287
train phase, Epoch 7/20, Loss: 17.671217
val phase, Epoch 7/20, Loss: 17.265372
Val Best Loss: 17.259657
Epoch loss: 17.265372
train phase, Epoch 8/20, Loss: 17.298944
val phase, Epoch 8/20, Loss: 17.198426
Val Best Loss: 17.198426
Epoch loss: 17.198426
train phase, Epoch 9/20, Loss: 23629.929117
val phase, Epoch 9/20, Loss: 39.528600
Val Best Loss: 17.198426
Epoch loss: 39.528600
train phase, Epoch 10/20, Loss: 34.709775
val phase, Epoch 10/20, Loss: 34.169662
Val Best Loss: 17.198426
Epoch loss: 34.169662
train phase, Epoch 11/20, Loss: 31.751641
val phase, Epoch 11/20, Loss: 37.437252
Val Best Loss: 17.198426
Epoch loss: 37.437252
train phase, Epoch 12/20, Loss: 30.859519
val phase, Epoch 12/20, Loss: 32.239343
Val Best Loss: 17.198426
Epoch loss: 32.239343
train phase, Epoch 13/20, Loss: 29.776082
val phase, Epoch 13/20, Loss: 30.207649
Val Best Loss: 17.198426
Epoch loss: 30.207649
train phase, Epoch 14/20, Loss: 28.808922
val phase, Epoch 14/20, Loss: 29.522452
Val Best Loss: 17.198426
Epoch loss: 29.522452
train phase, Epoch 15/20, Loss: 28.178638
val phase, Epoch 15/20, Loss: 28.523713
Val Best Loss: 17.198426
Epoch loss: 28.523713
train phase, Epoch 16/20, Loss: 27.208469
val phase, Epoch 16/20, Loss: 27.729591
Val Best Loss: 17.198426
Epoch loss: 27.729591
train phase, Epoch 17/20, Loss: 26.450428
val phase, Epoch 17/20, Loss: 26.686606
Val Best Loss: 17.198426
Epoch loss: 26.686606
train phase, Epoch 18/20, Loss: 25.798811
val phase, Epoch 18/20, Loss: 26.106039
Val Best Loss: 17.198426
Epoch loss: 26.106039
train phase, Epoch 19/20, Loss: 25.431935
val phase, Epoch 19/20, Loss: 25.999878
Val Best Loss: 17.198426
Epoch loss: 25.999878
train phase, Epoch 20/20, Loss: 25.004183
val phase, Epoch 20/20, Loss: 25.415391
Val Best Loss: 17.198426
Epoch loss: 25.415391
train phase, Epoch 1/20, Loss: 20.188222
val phase, Epoch 1/20, Loss: 17.044821
Val Best Loss: 17.044821
Epoch loss: 17.044821
train phase, Epoch 2/20, Loss: 18.087487
val phase, Epoch 2/20, Loss: 16.958366
Val Best Loss: 16.958366
Epoch loss: 16.958366
train phase, Epoch 3/20, Loss: 17.365266
val phase, Epoch 3/20, Loss: 17.466481
Val Best Loss: 16.958366
Epoch loss: 17.466481
train phase, Epoch 4/20, Loss: 16.958145
val phase, Epoch 4/20, Loss: 16.679493
Val Best Loss: 16.679493
Epoch loss: 16.679493
train phase, Epoch 5/20, Loss: 16.788928
val phase, Epoch 5/20, Loss: 16.655005
Val Best Loss: 16.655005
Epoch loss: 16.655005
train phase, Epoch 6/20, Loss: 16.497425
val phase, Epoch 6/20, Loss: 17.268925
Val Best Loss: 16.655005
Epoch loss: 17.268925
train phase, Epoch 7/20, Loss: 16.371726
val phase, Epoch 7/20, Loss: 16.599750
Val Best Loss: 16.599750
Epoch loss: 16.599750
train phase, Epoch 8/20, Loss: 16.305630
val phase, Epoch 8/20, Loss: 15.900910
Val Best Loss: 15.900910
Epoch loss: 15.900910
train phase, Epoch 9/20, Loss: 15.949955
val phase, Epoch 9/20, Loss: 17.051304
Val Best Loss: 15.900910
Epoch loss: 17.051304
train phase, Epoch 10/20, Loss: 16.184735
val phase, Epoch 10/20, Loss: 18.052535
Val Best Loss: 15.900910
Epoch loss: 18.052535
train phase, Epoch 11/20, Loss: 15.957433
val phase, Epoch 11/20, Loss: 17.166477
Val Best Loss: 15.900910
Epoch loss: 17.166477
train phase, Epoch 12/20, Loss: 15.692038
val phase, Epoch 12/20, Loss: 16.793488
Val Best Loss: 15.900910
Epoch loss: 16.793488
train phase, Epoch 13/20, Loss: 15.588793
val phase, Epoch 13/20, Loss: 15.842961
Val Best Loss: 15.842961
Epoch loss: 15.842961
train phase, Epoch 14/20, Loss: 15.336822
val phase, Epoch 14/20, Loss: 16.659022
Val Best Loss: 15.842961
Epoch loss: 16.659022
train phase, Epoch 15/20, Loss: 14.954028
val phase, Epoch 15/20, Loss: 17.133036
Val Best Loss: 15.842961
Epoch loss: 17.133036
train phase, Epoch 16/20, Loss: 14.941766
val phase, Epoch 16/20, Loss: 16.949187
Val Best Loss: 15.842961
Epoch loss: 16.949187
train phase, Epoch 17/20, Loss: 14.616150
val phase, Epoch 17/20, Loss: 17.257917
Val Best Loss: 15.842961
Epoch loss: 17.257917
train phase, Epoch 18/20, Loss: 14.351990
val phase, Epoch 18/20, Loss: 18.318532
Val Best Loss: 15.842961
Epoch loss: 18.318532
train phase, Epoch 19/20, Loss: 14.254828
val phase, Epoch 19/20, Loss: 17.638055
Val Best Loss: 15.842961
Epoch loss: 17.638055
train phase, Epoch 20/20, Loss: 13.931960
val phase, Epoch 20/20, Loss: 16.636672
Val Best Loss: 15.842961
Epoch loss: 16.636672
train phase, Epoch 1/20, Loss: 19.843733
val phase, Epoch 1/20, Loss: 17.874147
Val Best Loss: 17.874147
Epoch loss: 17.874147
train phase, Epoch 2/20, Loss: 17.843762
val phase, Epoch 2/20, Loss: 18.535692
Val Best Loss: 17.874147
Epoch loss: 18.535692
train phase, Epoch 3/20, Loss: 17.143741
val phase, Epoch 3/20, Loss: 17.987575
Val Best Loss: 17.874147
Epoch loss: 17.987575
train phase, Epoch 4/20, Loss: 17.276400
val phase, Epoch 4/20, Loss: 19.019177
Val Best Loss: 17.874147
Epoch loss: 19.019177
train phase, Epoch 5/20, Loss: 16.775163
val phase, Epoch 5/20, Loss: 17.983943
Val Best Loss: 17.874147
Epoch loss: 17.983943
train phase, Epoch 6/20, Loss: 16.595980
val phase, Epoch 6/20, Loss: 16.192799
Val Best Loss: 16.192799
Epoch loss: 16.192799
train phase, Epoch 7/20, Loss: 16.492724
val phase, Epoch 7/20, Loss: 16.237425
Val Best Loss: 16.192799
Epoch loss: 16.237425
train phase, Epoch 8/20, Loss: 16.451423
val phase, Epoch 8/20, Loss: 16.384376
Val Best Loss: 16.192799
Epoch loss: 16.384376
train phase, Epoch 9/20, Loss: 16.469011
val phase, Epoch 9/20, Loss: 17.276246
Val Best Loss: 16.192799
Epoch loss: 17.276246
train phase, Epoch 10/20, Loss: 16.310214
val phase, Epoch 10/20, Loss: 16.969168
Val Best Loss: 16.192799
Epoch loss: 16.969168
train phase, Epoch 11/20, Loss: 15.800749
val phase, Epoch 11/20, Loss: 16.071621
Val Best Loss: 16.071621
Epoch loss: 16.071621
train phase, Epoch 12/20, Loss: 16.073269
val phase, Epoch 12/20, Loss: 16.044245
Val Best Loss: 16.044245
Epoch loss: 16.044245
train phase, Epoch 13/20, Loss: 15.374018
val phase, Epoch 13/20, Loss: 22.048514
Val Best Loss: 16.044245
Epoch loss: 22.048514
train phase, Epoch 14/20, Loss: 15.667873
val phase, Epoch 14/20, Loss: 15.847032
Val Best Loss: 15.847032
Epoch loss: 15.847032
train phase, Epoch 15/20, Loss: 15.763780
val phase, Epoch 15/20, Loss: 16.267598
Val Best Loss: 15.847032
Epoch loss: 16.267598
train phase, Epoch 16/20, Loss: 14.960380
val phase, Epoch 16/20, Loss: 15.885876
Val Best Loss: 15.847032
Epoch loss: 15.885876
train phase, Epoch 17/20, Loss: 14.687047
val phase, Epoch 17/20, Loss: 16.564604
Val Best Loss: 15.847032
Epoch loss: 16.564604
train phase, Epoch 18/20, Loss: 14.574968
val phase, Epoch 18/20, Loss: 15.978879
Val Best Loss: 15.847032
Epoch loss: 15.978879
train phase, Epoch 19/20, Loss: 14.353764
val phase, Epoch 19/20, Loss: 16.434299
Val Best Loss: 15.847032
Epoch loss: 16.434299
train phase, Epoch 20/20, Loss: 14.200290
val phase, Epoch 20/20, Loss: 17.470335
Val Best Loss: 15.847032
Epoch loss: 17.470335
train phase, Epoch 1/20, Loss: 20.431562
val phase, Epoch 1/20, Loss: 18.180832
Val Best Loss: 18.180832
Epoch loss: 18.180832
train phase, Epoch 2/20, Loss: 18.158513
val phase, Epoch 2/20, Loss: 16.601155
Val Best Loss: 16.601155
Epoch loss: 16.601155
train phase, Epoch 3/20, Loss: 17.811521
val phase, Epoch 3/20, Loss: 18.159622
Val Best Loss: 16.601155
Epoch loss: 18.159622
train phase, Epoch 4/20, Loss: 17.275547
val phase, Epoch 4/20, Loss: 16.235774
Val Best Loss: 16.235774
Epoch loss: 16.235774
train phase, Epoch 5/20, Loss: 17.373675
val phase, Epoch 5/20, Loss: 20.868462
Val Best Loss: 16.235774
Epoch loss: 20.868462
train phase, Epoch 6/20, Loss: 17.074552
val phase, Epoch 6/20, Loss: 17.149151
Val Best Loss: 16.235774
Epoch loss: 17.149151
train phase, Epoch 7/20, Loss: 16.780788
val phase, Epoch 7/20, Loss: 16.630258
Val Best Loss: 16.235774
Epoch loss: 16.630258
train phase, Epoch 8/20, Loss: 16.410331
val phase, Epoch 8/20, Loss: 16.459393
Val Best Loss: 16.235774
Epoch loss: 16.459393
train phase, Epoch 9/20, Loss: 16.412982
val phase, Epoch 9/20, Loss: 16.010912
Val Best Loss: 16.010912
Epoch loss: 16.010912
train phase, Epoch 10/20, Loss: 16.671728
val phase, Epoch 10/20, Loss: 15.927406
Val Best Loss: 15.927406
Epoch loss: 15.927406
train phase, Epoch 11/20, Loss: 15.976729
val phase, Epoch 11/20, Loss: 22.477766
Val Best Loss: 15.927406
Epoch loss: 22.477766
train phase, Epoch 12/20, Loss: 16.107605
val phase, Epoch 12/20, Loss: 18.780194
Val Best Loss: 15.927406
Epoch loss: 18.780194
train phase, Epoch 13/20, Loss: 15.785047
val phase, Epoch 13/20, Loss: 16.141692
Val Best Loss: 15.927406
Epoch loss: 16.141692
train phase, Epoch 14/20, Loss: 15.576214
val phase, Epoch 14/20, Loss: 16.343511
Val Best Loss: 15.927406
Epoch loss: 16.343511
train phase, Epoch 15/20, Loss: 15.245798
val phase, Epoch 15/20, Loss: 16.686711
Val Best Loss: 15.927406
Epoch loss: 16.686711
train phase, Epoch 16/20, Loss: 15.064768
val phase, Epoch 16/20, Loss: 16.027582
Val Best Loss: 15.927406
Epoch loss: 16.027582
train phase, Epoch 17/20, Loss: 14.835184
val phase, Epoch 17/20, Loss: 16.611932
Val Best Loss: 15.927406
Epoch loss: 16.611932
train phase, Epoch 18/20, Loss: 14.697333
val phase, Epoch 18/20, Loss: 16.554950
Val Best Loss: 15.927406
Epoch loss: 16.554950
train phase, Epoch 19/20, Loss: 14.368593
val phase, Epoch 19/20, Loss: 17.176223
Val Best Loss: 15.927406
Epoch loss: 17.176223
train phase, Epoch 20/20, Loss: 14.235524
val phase, Epoch 20/20, Loss: 16.286180
Val Best Loss: 15.927406
Epoch loss: 16.286180
[Trial 74] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/12, Loss: 20.111280
val phase, Epoch 1/12, Loss: 17.395150
Val Best Loss: 17.395150
Epoch loss: 17.395150
train phase, Epoch 2/12, Loss: 17.802072
val phase, Epoch 2/12, Loss: 16.544249
Val Best Loss: 16.544249
Epoch loss: 16.544249
train phase, Epoch 3/12, Loss: 17.139764
val phase, Epoch 3/12, Loss: 16.722471
Val Best Loss: 16.544249
Epoch loss: 16.722471
train phase, Epoch 4/12, Loss: 16.852577
val phase, Epoch 4/12, Loss: 18.190864
Val Best Loss: 16.544249
Epoch loss: 18.190864
train phase, Epoch 5/12, Loss: 16.867678
val phase, Epoch 5/12, Loss: 16.109754
Val Best Loss: 16.109754
Epoch loss: 16.109754
train phase, Epoch 6/12, Loss: 16.642469
val phase, Epoch 6/12, Loss: 16.092921
Val Best Loss: 16.092921
Epoch loss: 16.092921
train phase, Epoch 7/12, Loss: 16.515510
val phase, Epoch 7/12, Loss: 17.179423
Val Best Loss: 16.092921
Epoch loss: 17.179423
train phase, Epoch 8/12, Loss: 16.400697
val phase, Epoch 8/12, Loss: 16.135964
Val Best Loss: 16.092921
Epoch loss: 16.135964
train phase, Epoch 9/12, Loss: 16.048565
val phase, Epoch 9/12, Loss: 16.451314
Val Best Loss: 16.092921
Epoch loss: 16.451314
train phase, Epoch 10/12, Loss: 15.881368
val phase, Epoch 10/12, Loss: 19.466632
Val Best Loss: 16.092921
Epoch loss: 19.466632
train phase, Epoch 11/12, Loss: 15.928693
val phase, Epoch 11/12, Loss: 15.873254
Val Best Loss: 15.873254
Epoch loss: 15.873254
train phase, Epoch 12/12, Loss: 15.635906
val phase, Epoch 12/12, Loss: 16.598413
Val Best Loss: 15.873254
Epoch loss: 16.598413
[Trial 76] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/25, Loss: 20.615010
val phase, Epoch 1/25, Loss: 18.268621
Val Best Loss: 18.268621
Epoch loss: 18.268621
train phase, Epoch 2/25, Loss: 18.804818
val phase, Epoch 2/25, Loss: 18.201670
Val Best Loss: 18.201670
Epoch loss: 18.201670
train phase, Epoch 3/25, Loss: 17.922033
val phase, Epoch 3/25, Loss: 18.312108
Val Best Loss: 18.201670
Epoch loss: 18.312108
train phase, Epoch 4/25, Loss: 18.049016
val phase, Epoch 4/25, Loss: 16.892595
Val Best Loss: 16.892595
Epoch loss: 16.892595
train phase, Epoch 5/25, Loss: 17.713119
val phase, Epoch 5/25, Loss: 18.211494
Val Best Loss: 16.892595
Epoch loss: 18.211494
train phase, Epoch 6/25, Loss: 17.712660
val phase, Epoch 6/25, Loss: 19.780391
Val Best Loss: 16.892595
Epoch loss: 19.780391
train phase, Epoch 7/25, Loss: 17.234913
val phase, Epoch 7/25, Loss: 16.647088
Val Best Loss: 16.647088
Epoch loss: 16.647088
train phase, Epoch 8/25, Loss: 16.989303
val phase, Epoch 8/25, Loss: 17.142214
Val Best Loss: 16.647088
Epoch loss: 17.142214
train phase, Epoch 9/25, Loss: 17.010908
val phase, Epoch 9/25, Loss: 17.863175
Val Best Loss: 16.647088
Epoch loss: 17.863175
train phase, Epoch 10/25, Loss: 16.769536
val phase, Epoch 10/25, Loss: 16.659971
Val Best Loss: 16.647088
Epoch loss: 16.659971
train phase, Epoch 11/25, Loss: 16.476032
val phase, Epoch 11/25, Loss: 17.033229
Val Best Loss: 16.647088
Epoch loss: 17.033229
train phase, Epoch 12/25, Loss: 16.200644
val phase, Epoch 12/25, Loss: 18.047200
Val Best Loss: 16.647088
Epoch loss: 18.047200
train phase, Epoch 13/25, Loss: 15.987638
val phase, Epoch 13/25, Loss: 16.402790
Val Best Loss: 16.402790
Epoch loss: 16.402790
train phase, Epoch 14/25, Loss: 15.870553
val phase, Epoch 14/25, Loss: 15.995636
Val Best Loss: 15.995636
Epoch loss: 15.995636
train phase, Epoch 15/25, Loss: 15.784841
val phase, Epoch 15/25, Loss: 15.942019
Val Best Loss: 15.942019
Epoch loss: 15.942019
train phase, Epoch 16/25, Loss: 15.337376
val phase, Epoch 16/25, Loss: 16.288630
Val Best Loss: 15.942019
Epoch loss: 16.288630
train phase, Epoch 17/25, Loss: 15.396896
val phase, Epoch 17/25, Loss: 16.382432
Val Best Loss: 15.942019
Epoch loss: 16.382432
train phase, Epoch 18/25, Loss: 14.984667
val phase, Epoch 18/25, Loss: 16.634020
Val Best Loss: 15.942019
Epoch loss: 16.634020
train phase, Epoch 19/25, Loss: 14.984348
val phase, Epoch 19/25, Loss: 16.800653
Val Best Loss: 15.942019
Epoch loss: 16.800653
train phase, Epoch 20/25, Loss: 14.506137
val phase, Epoch 20/25, Loss: 16.811689
Val Best Loss: 15.942019
Epoch loss: 16.811689
train phase, Epoch 21/25, Loss: 14.145368
val phase, Epoch 21/25, Loss: 16.249328
Val Best Loss: 15.942019
Epoch loss: 16.249328
train phase, Epoch 22/25, Loss: 14.034742
val phase, Epoch 22/25, Loss: 16.832354
Val Best Loss: 15.942019
Epoch loss: 16.832354
train phase, Epoch 23/25, Loss: 13.965494
val phase, Epoch 23/25, Loss: 17.661547
Val Best Loss: 15.942019
Epoch loss: 17.661547
train phase, Epoch 24/25, Loss: 13.442944
val phase, Epoch 24/25, Loss: 16.618708
Val Best Loss: 15.942019
Epoch loss: 16.618708
train phase, Epoch 25/25, Loss: 12.774261
val phase, Epoch 25/25, Loss: 16.670324
Val Best Loss: 15.942019
Epoch loss: 16.670324
train phase, Epoch 1/5, Loss: 20.093910
val phase, Epoch 1/5, Loss: 31.268125
Val Best Loss: 31.268125
Epoch loss: 31.268125
train phase, Epoch 2/5, Loss: 17.846601
val phase, Epoch 2/5, Loss: 36.768526
Val Best Loss: 31.268125
Epoch loss: 36.768526
train phase, Epoch 3/5, Loss: 17.448472
val phase, Epoch 3/5, Loss: 37.672858
Val Best Loss: 31.268125
Epoch loss: 37.672858
train phase, Epoch 4/5, Loss: 16.955101
val phase, Epoch 4/5, Loss: 61.320032
Val Best Loss: 31.268125
Epoch loss: 61.320032
train phase, Epoch 5/5, Loss: 16.951653
val phase, Epoch 5/5, Loss: 40.729779
Val Best Loss: 31.268125
Epoch loss: 40.729779
train phase, Epoch 1/10, Loss: nan
val phase, Epoch 1/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/10, Loss: nan
val phase, Epoch 2/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/10, Loss: nan
val phase, Epoch 3/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/10, Loss: nan
val phase, Epoch 4/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/10, Loss: nan
val phase, Epoch 5/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/10, Loss: nan
val phase, Epoch 6/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/10, Loss: nan
val phase, Epoch 7/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/10, Loss: nan
val phase, Epoch 8/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/10, Loss: nan
val phase, Epoch 9/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/10, Loss: nan
val phase, Epoch 10/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
[Trial 80] Skipped due to model construction error: Calculated padded input size per channel: (7 x 1). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 19.888638
val phase, Epoch 1/30, Loss: 16.947721
Val Best Loss: 16.947721
Epoch loss: 16.947721
train phase, Epoch 2/30, Loss: 18.458779
val phase, Epoch 2/30, Loss: 16.617773
Val Best Loss: 16.617773
Epoch loss: 16.617773
train phase, Epoch 3/30, Loss: 17.565217
val phase, Epoch 3/30, Loss: 18.780569
Val Best Loss: 16.617773
Epoch loss: 18.780569
train phase, Epoch 4/30, Loss: 17.236765
val phase, Epoch 4/30, Loss: 17.921275
Val Best Loss: 16.617773
Epoch loss: 17.921275
train phase, Epoch 5/30, Loss: 17.016009
val phase, Epoch 5/30, Loss: 16.640672
Val Best Loss: 16.617773
Epoch loss: 16.640672
train phase, Epoch 6/30, Loss: 17.048030
val phase, Epoch 6/30, Loss: 17.095171
Val Best Loss: 16.617773
Epoch loss: 17.095171
train phase, Epoch 7/30, Loss: 16.735228
val phase, Epoch 7/30, Loss: 16.153822
Val Best Loss: 16.153822
Epoch loss: 16.153822
train phase, Epoch 8/30, Loss: 16.353949
val phase, Epoch 8/30, Loss: 20.230872
Val Best Loss: 16.153822
Epoch loss: 20.230872
train phase, Epoch 9/30, Loss: 16.681832
val phase, Epoch 9/30, Loss: 16.025973
Val Best Loss: 16.025973
Epoch loss: 16.025973
train phase, Epoch 10/30, Loss: 16.283471
val phase, Epoch 10/30, Loss: 16.410013
Val Best Loss: 16.025973
Epoch loss: 16.410013
train phase, Epoch 11/30, Loss: 16.093442
val phase, Epoch 11/30, Loss: 16.459019
Val Best Loss: 16.025973
Epoch loss: 16.459019
train phase, Epoch 12/30, Loss: 15.973859
val phase, Epoch 12/30, Loss: 16.815781
Val Best Loss: 16.025973
Epoch loss: 16.815781
train phase, Epoch 13/30, Loss: 15.761432
val phase, Epoch 13/30, Loss: 16.049077
Val Best Loss: 16.025973
Epoch loss: 16.049077
train phase, Epoch 14/30, Loss: 15.789344
val phase, Epoch 14/30, Loss: 16.462753
Val Best Loss: 16.025973
Epoch loss: 16.462753
train phase, Epoch 15/30, Loss: 15.614399
val phase, Epoch 15/30, Loss: 17.530741
Val Best Loss: 16.025973
Epoch loss: 17.530741
train phase, Epoch 16/30, Loss: 15.255130
val phase, Epoch 16/30, Loss: 16.262204
Val Best Loss: 16.025973
Epoch loss: 16.262204
train phase, Epoch 17/30, Loss: 15.520286
val phase, Epoch 17/30, Loss: 16.401853
Val Best Loss: 16.025973
Epoch loss: 16.401853
train phase, Epoch 18/30, Loss: 14.927141
val phase, Epoch 18/30, Loss: 15.921823
Val Best Loss: 15.921823
Epoch loss: 15.921823
train phase, Epoch 19/30, Loss: 14.664073
val phase, Epoch 19/30, Loss: 16.844134
Val Best Loss: 15.921823
Epoch loss: 16.844134
train phase, Epoch 20/30, Loss: 14.698367
val phase, Epoch 20/30, Loss: 16.004055
Val Best Loss: 15.921823
Epoch loss: 16.004055
train phase, Epoch 21/30, Loss: 14.475792
val phase, Epoch 21/30, Loss: 16.357000
Val Best Loss: 15.921823
Epoch loss: 16.357000
train phase, Epoch 22/30, Loss: 13.957135
val phase, Epoch 22/30, Loss: 18.092815
Val Best Loss: 15.921823
Epoch loss: 18.092815
train phase, Epoch 23/30, Loss: 13.839974
val phase, Epoch 23/30, Loss: 16.995980
Val Best Loss: 15.921823
Epoch loss: 16.995980
train phase, Epoch 24/30, Loss: 13.535355
val phase, Epoch 24/30, Loss: 16.945679
Val Best Loss: 15.921823
Epoch loss: 16.945679
train phase, Epoch 25/30, Loss: 13.221803
val phase, Epoch 25/30, Loss: 17.548957
Val Best Loss: 15.921823
Epoch loss: 17.548957
train phase, Epoch 26/30, Loss: 12.784637
val phase, Epoch 26/30, Loss: 17.084844
Val Best Loss: 15.921823
Epoch loss: 17.084844
train phase, Epoch 27/30, Loss: 12.111738
val phase, Epoch 27/30, Loss: 18.128394
Val Best Loss: 15.921823
Epoch loss: 18.128394
train phase, Epoch 28/30, Loss: 11.899651
val phase, Epoch 28/30, Loss: 17.418485
Val Best Loss: 15.921823
Epoch loss: 17.418485
train phase, Epoch 29/30, Loss: 11.656815
val phase, Epoch 29/30, Loss: 18.139077
Val Best Loss: 15.921823
Epoch loss: 18.139077
train phase, Epoch 30/30, Loss: 11.149942
val phase, Epoch 30/30, Loss: 18.363383
Val Best Loss: 15.921823
Epoch loss: 18.363383
train phase, Epoch 1/30, Loss: 19.775009
val phase, Epoch 1/30, Loss: 17.193720
Val Best Loss: 17.193720
Epoch loss: 17.193720
train phase, Epoch 2/30, Loss: 18.256727
val phase, Epoch 2/30, Loss: 16.330545
Val Best Loss: 16.330545
Epoch loss: 16.330545
train phase, Epoch 3/30, Loss: 17.579766
val phase, Epoch 3/30, Loss: 16.305054
Val Best Loss: 16.305054
Epoch loss: 16.305054
train phase, Epoch 4/30, Loss: 17.249654
val phase, Epoch 4/30, Loss: 19.040338
Val Best Loss: 16.305054
Epoch loss: 19.040338
train phase, Epoch 5/30, Loss: 16.883851
val phase, Epoch 5/30, Loss: 16.818311
Val Best Loss: 16.305054
Epoch loss: 16.818311
train phase, Epoch 6/30, Loss: 16.532789
val phase, Epoch 6/30, Loss: 17.312476
Val Best Loss: 16.305054
Epoch loss: 17.312476
train phase, Epoch 7/30, Loss: 16.801082
val phase, Epoch 7/30, Loss: 16.463008
Val Best Loss: 16.305054
Epoch loss: 16.463008
train phase, Epoch 8/30, Loss: 16.381534
val phase, Epoch 8/30, Loss: 17.353457
Val Best Loss: 16.305054
Epoch loss: 17.353457
train phase, Epoch 9/30, Loss: 16.239008
val phase, Epoch 9/30, Loss: 17.062420
Val Best Loss: 16.305054
Epoch loss: 17.062420
train phase, Epoch 10/30, Loss: 16.193162
val phase, Epoch 10/30, Loss: 16.452993
Val Best Loss: 16.305054
Epoch loss: 16.452993
train phase, Epoch 11/30, Loss: 16.075515
val phase, Epoch 11/30, Loss: 16.565213
Val Best Loss: 16.305054
Epoch loss: 16.565213
train phase, Epoch 12/30, Loss: 15.905084
val phase, Epoch 12/30, Loss: 16.752938
Val Best Loss: 16.305054
Epoch loss: 16.752938
train phase, Epoch 13/30, Loss: 15.673085
val phase, Epoch 13/30, Loss: 17.670640
Val Best Loss: 16.305054
Epoch loss: 17.670640
train phase, Epoch 14/30, Loss: 15.380056
val phase, Epoch 14/30, Loss: 16.076102
Val Best Loss: 16.076102
Epoch loss: 16.076102
train phase, Epoch 15/30, Loss: 15.473036
val phase, Epoch 15/30, Loss: 16.371535
Val Best Loss: 16.076102
Epoch loss: 16.371535
train phase, Epoch 16/30, Loss: 15.152565
val phase, Epoch 16/30, Loss: 16.539673
Val Best Loss: 16.076102
Epoch loss: 16.539673
train phase, Epoch 17/30, Loss: 15.166536
val phase, Epoch 17/30, Loss: 16.772201
Val Best Loss: 16.076102
Epoch loss: 16.772201
train phase, Epoch 18/30, Loss: 14.822576
val phase, Epoch 18/30, Loss: 16.453191
Val Best Loss: 16.076102
Epoch loss: 16.453191
train phase, Epoch 19/30, Loss: 14.572139
val phase, Epoch 19/30, Loss: 16.266230
Val Best Loss: 16.076102
Epoch loss: 16.266230
train phase, Epoch 20/30, Loss: 14.262019
val phase, Epoch 20/30, Loss: 16.219422
Val Best Loss: 16.076102
Epoch loss: 16.219422
train phase, Epoch 21/30, Loss: 14.229870
val phase, Epoch 21/30, Loss: 16.562208
Val Best Loss: 16.076102
Epoch loss: 16.562208
train phase, Epoch 22/30, Loss: 14.038734
val phase, Epoch 22/30, Loss: 16.587473
Val Best Loss: 16.076102
Epoch loss: 16.587473
train phase, Epoch 23/30, Loss: 13.760123
val phase, Epoch 23/30, Loss: 16.551559
Val Best Loss: 16.076102
Epoch loss: 16.551559
train phase, Epoch 24/30, Loss: 13.001633
val phase, Epoch 24/30, Loss: 16.544575
Val Best Loss: 16.076102
Epoch loss: 16.544575
train phase, Epoch 25/30, Loss: 12.860045
val phase, Epoch 25/30, Loss: 16.927612
Val Best Loss: 16.076102
Epoch loss: 16.927612
train phase, Epoch 26/30, Loss: 12.589092
val phase, Epoch 26/30, Loss: 16.740070
Val Best Loss: 16.076102
Epoch loss: 16.740070
train phase, Epoch 27/30, Loss: 11.973395
val phase, Epoch 27/30, Loss: 17.909506
Val Best Loss: 16.076102
Epoch loss: 17.909506
train phase, Epoch 28/30, Loss: 11.724125
val phase, Epoch 28/30, Loss: 17.502721
Val Best Loss: 16.076102
Epoch loss: 17.502721
train phase, Epoch 29/30, Loss: 11.059484
val phase, Epoch 29/30, Loss: 19.708095
Val Best Loss: 16.076102
Epoch loss: 19.708095
train phase, Epoch 30/30, Loss: 10.770635
val phase, Epoch 30/30, Loss: 18.241675
Val Best Loss: 16.076102
Epoch loss: 18.241675
train phase, Epoch 1/30, Loss: 20.415308
val phase, Epoch 1/30, Loss: 17.114583
Val Best Loss: 17.114583
Epoch loss: 17.114583
train phase, Epoch 2/30, Loss: 17.759317
val phase, Epoch 2/30, Loss: 16.956017
Val Best Loss: 16.956017
Epoch loss: 16.956017
train phase, Epoch 3/30, Loss: 18.023636
val phase, Epoch 3/30, Loss: 16.741296
Val Best Loss: 16.741296
Epoch loss: 16.741296
train phase, Epoch 4/30, Loss: 17.403538
val phase, Epoch 4/30, Loss: 16.679385
Val Best Loss: 16.679385
Epoch loss: 16.679385
train phase, Epoch 5/30, Loss: 17.020003
val phase, Epoch 5/30, Loss: 16.078683
Val Best Loss: 16.078683
Epoch loss: 16.078683
train phase, Epoch 6/30, Loss: 16.949444
val phase, Epoch 6/30, Loss: 18.879206
Val Best Loss: 16.078683
Epoch loss: 18.879206
train phase, Epoch 7/30, Loss: 16.702618
val phase, Epoch 7/30, Loss: 16.443671
Val Best Loss: 16.078683
Epoch loss: 16.443671
train phase, Epoch 8/30, Loss: 16.613924
val phase, Epoch 8/30, Loss: 16.091867
Val Best Loss: 16.078683
Epoch loss: 16.091867
train phase, Epoch 9/30, Loss: 16.607609
val phase, Epoch 9/30, Loss: 17.536382
Val Best Loss: 16.078683
Epoch loss: 17.536382
train phase, Epoch 10/30, Loss: 16.175594
val phase, Epoch 10/30, Loss: 15.892373
Val Best Loss: 15.892373
Epoch loss: 15.892373
train phase, Epoch 11/30, Loss: 16.209714
val phase, Epoch 11/30, Loss: 16.088151
Val Best Loss: 15.892373
Epoch loss: 16.088151
train phase, Epoch 12/30, Loss: 16.103859
val phase, Epoch 12/30, Loss: 16.081765
Val Best Loss: 15.892373
Epoch loss: 16.081765
train phase, Epoch 13/30, Loss: 15.753110
val phase, Epoch 13/30, Loss: 15.876026
Val Best Loss: 15.876026
Epoch loss: 15.876026
train phase, Epoch 14/30, Loss: 15.977524
val phase, Epoch 14/30, Loss: 16.776705
Val Best Loss: 15.876026
Epoch loss: 16.776705
train phase, Epoch 15/30, Loss: 15.390463
val phase, Epoch 15/30, Loss: 16.451477
Val Best Loss: 15.876026
Epoch loss: 16.451477
train phase, Epoch 16/30, Loss: 15.500600
val phase, Epoch 16/30, Loss: 15.861731
Val Best Loss: 15.861731
Epoch loss: 15.861731
train phase, Epoch 17/30, Loss: 15.082324
val phase, Epoch 17/30, Loss: 16.306735
Val Best Loss: 15.861731
Epoch loss: 16.306735
train phase, Epoch 18/30, Loss: 15.022563
val phase, Epoch 18/30, Loss: 16.420303
Val Best Loss: 15.861731
Epoch loss: 16.420303
train phase, Epoch 19/30, Loss: 14.903110
val phase, Epoch 19/30, Loss: 16.399477
Val Best Loss: 15.861731
Epoch loss: 16.399477
train phase, Epoch 20/30, Loss: 14.678923
val phase, Epoch 20/30, Loss: 15.935457
Val Best Loss: 15.861731
Epoch loss: 15.935457
train phase, Epoch 21/30, Loss: 14.396424
val phase, Epoch 21/30, Loss: 16.866457
Val Best Loss: 15.861731
Epoch loss: 16.866457
train phase, Epoch 22/30, Loss: 14.406126
val phase, Epoch 22/30, Loss: 16.942233
Val Best Loss: 15.861731
Epoch loss: 16.942233
train phase, Epoch 23/30, Loss: 13.972854
val phase, Epoch 23/30, Loss: 16.545095
Val Best Loss: 15.861731
Epoch loss: 16.545095
train phase, Epoch 24/30, Loss: 13.964394
val phase, Epoch 24/30, Loss: 16.862938
Val Best Loss: 15.861731
Epoch loss: 16.862938
train phase, Epoch 25/30, Loss: 13.485021
val phase, Epoch 25/30, Loss: 18.225239
Val Best Loss: 15.861731
Epoch loss: 18.225239
train phase, Epoch 26/30, Loss: 13.125309
val phase, Epoch 26/30, Loss: 16.832677
Val Best Loss: 15.861731
Epoch loss: 16.832677
train phase, Epoch 27/30, Loss: 12.773447
val phase, Epoch 27/30, Loss: 17.390922
Val Best Loss: 15.861731
Epoch loss: 17.390922
train phase, Epoch 28/30, Loss: 12.190486
val phase, Epoch 28/30, Loss: 17.402430
Val Best Loss: 15.861731
Epoch loss: 17.402430
train phase, Epoch 29/30, Loss: 11.969584
val phase, Epoch 29/30, Loss: 17.705359
Val Best Loss: 15.861731
Epoch loss: 17.705359
train phase, Epoch 30/30, Loss: 11.780023
val phase, Epoch 30/30, Loss: 18.011830
Val Best Loss: 15.861731
Epoch loss: 18.011830
train phase, Epoch 1/30, Loss: 20.153475
val phase, Epoch 1/30, Loss: 16.989926
Val Best Loss: 16.989926
Epoch loss: 16.989926
train phase, Epoch 2/30, Loss: 17.741944
val phase, Epoch 2/30, Loss: 18.577527
Val Best Loss: 16.989926
Epoch loss: 18.577527
train phase, Epoch 3/30, Loss: 17.566122
val phase, Epoch 3/30, Loss: 19.380620
Val Best Loss: 16.989926
Epoch loss: 19.380620
train phase, Epoch 4/30, Loss: 17.089031
val phase, Epoch 4/30, Loss: 17.252993
Val Best Loss: 16.989926
Epoch loss: 17.252993
train phase, Epoch 5/30, Loss: 16.927174
val phase, Epoch 5/30, Loss: 16.768106
Val Best Loss: 16.768106
Epoch loss: 16.768106
train phase, Epoch 6/30, Loss: 17.059540
val phase, Epoch 6/30, Loss: 17.021263
Val Best Loss: 16.768106
Epoch loss: 17.021263
train phase, Epoch 7/30, Loss: 16.507487
val phase, Epoch 7/30, Loss: 16.535045
Val Best Loss: 16.535045
Epoch loss: 16.535045
train phase, Epoch 8/30, Loss: 16.634260
val phase, Epoch 8/30, Loss: 16.537150
Val Best Loss: 16.535045
Epoch loss: 16.537150
train phase, Epoch 9/30, Loss: 16.066267
val phase, Epoch 9/30, Loss: 17.831881
Val Best Loss: 16.535045
Epoch loss: 17.831881
train phase, Epoch 10/30, Loss: 16.317864
val phase, Epoch 10/30, Loss: 15.875542
Val Best Loss: 15.875542
Epoch loss: 15.875542
train phase, Epoch 11/30, Loss: 15.870151
val phase, Epoch 11/30, Loss: 18.512410
Val Best Loss: 15.875542
Epoch loss: 18.512410
train phase, Epoch 12/30, Loss: 15.896549
val phase, Epoch 12/30, Loss: 15.852817
Val Best Loss: 15.852817
Epoch loss: 15.852817
train phase, Epoch 13/30, Loss: 15.615469
val phase, Epoch 13/30, Loss: 16.395939
Val Best Loss: 15.852817
Epoch loss: 16.395939
train phase, Epoch 14/30, Loss: 15.371149
val phase, Epoch 14/30, Loss: 16.027277
Val Best Loss: 15.852817
Epoch loss: 16.027277
train phase, Epoch 15/30, Loss: 15.310177
val phase, Epoch 15/30, Loss: 16.519245
Val Best Loss: 15.852817
Epoch loss: 16.519245
train phase, Epoch 16/30, Loss: 15.188846
val phase, Epoch 16/30, Loss: 17.127490
Val Best Loss: 15.852817
Epoch loss: 17.127490
train phase, Epoch 17/30, Loss: 15.018616
val phase, Epoch 17/30, Loss: 15.932921
Val Best Loss: 15.852817
Epoch loss: 15.932921
train phase, Epoch 18/30, Loss: 14.466548
val phase, Epoch 18/30, Loss: 16.294190
Val Best Loss: 15.852817
Epoch loss: 16.294190
train phase, Epoch 19/30, Loss: 14.504122
val phase, Epoch 19/30, Loss: 17.296969
Val Best Loss: 15.852817
Epoch loss: 17.296969
train phase, Epoch 20/30, Loss: 13.976247
val phase, Epoch 20/30, Loss: 15.912563
Val Best Loss: 15.852817
Epoch loss: 15.912563
train phase, Epoch 21/30, Loss: 13.663450
val phase, Epoch 21/30, Loss: 16.407364
Val Best Loss: 15.852817
Epoch loss: 16.407364
train phase, Epoch 22/30, Loss: 13.352498
val phase, Epoch 22/30, Loss: 16.346883
Val Best Loss: 15.852817
Epoch loss: 16.346883
train phase, Epoch 23/30, Loss: 12.926047
val phase, Epoch 23/30, Loss: 16.225908
Val Best Loss: 15.852817
Epoch loss: 16.225908
train phase, Epoch 24/30, Loss: 12.631926
val phase, Epoch 24/30, Loss: 19.181125
Val Best Loss: 15.852817
Epoch loss: 19.181125
train phase, Epoch 25/30, Loss: 12.172435
val phase, Epoch 25/30, Loss: 22.529675
Val Best Loss: 15.852817
Epoch loss: 22.529675
train phase, Epoch 26/30, Loss: 11.708538
val phase, Epoch 26/30, Loss: 17.319165
Val Best Loss: 15.852817
Epoch loss: 17.319165
train phase, Epoch 27/30, Loss: 11.223937
val phase, Epoch 27/30, Loss: 18.062532
Val Best Loss: 15.852817
Epoch loss: 18.062532
train phase, Epoch 28/30, Loss: 10.803519
val phase, Epoch 28/30, Loss: 18.024372
Val Best Loss: 15.852817
Epoch loss: 18.024372
train phase, Epoch 29/30, Loss: 10.381249
val phase, Epoch 29/30, Loss: 18.186395
Val Best Loss: 15.852817
Epoch loss: 18.186395
train phase, Epoch 30/30, Loss: 9.678280
val phase, Epoch 30/30, Loss: 18.170228
Val Best Loss: 15.852817
Epoch loss: 18.170228
train phase, Epoch 1/20, Loss: 21.040834
val phase, Epoch 1/20, Loss: 19.026865
Val Best Loss: 19.026865
Epoch loss: 19.026865
train phase, Epoch 2/20, Loss: 18.768262
val phase, Epoch 2/20, Loss: 17.517589
Val Best Loss: 17.517589
Epoch loss: 17.517589
train phase, Epoch 3/20, Loss: 18.304314
val phase, Epoch 3/20, Loss: 17.191822
Val Best Loss: 17.191822
Epoch loss: 17.191822
train phase, Epoch 4/20, Loss: 17.988569
val phase, Epoch 4/20, Loss: 16.936745
Val Best Loss: 16.936745
Epoch loss: 16.936745
train phase, Epoch 5/20, Loss: 18.034016
val phase, Epoch 5/20, Loss: 17.507729
Val Best Loss: 16.936745
Epoch loss: 17.507729
train phase, Epoch 6/20, Loss: 17.335671
val phase, Epoch 6/20, Loss: 18.619698
Val Best Loss: 16.936745
Epoch loss: 18.619698
train phase, Epoch 7/20, Loss: 17.208473
val phase, Epoch 7/20, Loss: 17.090994
Val Best Loss: 16.936745
Epoch loss: 17.090994
train phase, Epoch 8/20, Loss: 16.955722
val phase, Epoch 8/20, Loss: 17.008597
Val Best Loss: 16.936745
Epoch loss: 17.008597
train phase, Epoch 9/20, Loss: 16.797324
val phase, Epoch 9/20, Loss: 18.133718
Val Best Loss: 16.936745
Epoch loss: 18.133718
train phase, Epoch 10/20, Loss: 16.586653
val phase, Epoch 10/20, Loss: 16.554367
Val Best Loss: 16.554367
Epoch loss: 16.554367
train phase, Epoch 11/20, Loss: 16.356002
val phase, Epoch 11/20, Loss: 17.327930
Val Best Loss: 16.554367
Epoch loss: 17.327930
train phase, Epoch 12/20, Loss: 16.136155
val phase, Epoch 12/20, Loss: 17.024834
Val Best Loss: 16.554367
Epoch loss: 17.024834
train phase, Epoch 13/20, Loss: 16.005492
val phase, Epoch 13/20, Loss: 17.016106
Val Best Loss: 16.554367
Epoch loss: 17.016106
train phase, Epoch 14/20, Loss: 15.821953
val phase, Epoch 14/20, Loss: 16.225511
Val Best Loss: 16.225511
Epoch loss: 16.225511
train phase, Epoch 15/20, Loss: 15.425084
val phase, Epoch 15/20, Loss: 16.672913
Val Best Loss: 16.225511
Epoch loss: 16.672913
train phase, Epoch 16/20, Loss: 15.202264
val phase, Epoch 16/20, Loss: 17.089700
Val Best Loss: 16.225511
Epoch loss: 17.089700
train phase, Epoch 17/20, Loss: 15.045821
val phase, Epoch 17/20, Loss: 16.559614
Val Best Loss: 16.225511
Epoch loss: 16.559614
train phase, Epoch 18/20, Loss: 14.745163
val phase, Epoch 18/20, Loss: 17.442836
Val Best Loss: 16.225511
Epoch loss: 17.442836
train phase, Epoch 19/20, Loss: 14.542930
val phase, Epoch 19/20, Loss: 16.974691
Val Best Loss: 16.225511
Epoch loss: 16.974691
train phase, Epoch 20/20, Loss: 14.307576
val phase, Epoch 20/20, Loss: 16.747660
Val Best Loss: 16.225511
Epoch loss: 16.747660
train phase, Epoch 1/30, Loss: 20.055138
val phase, Epoch 1/30, Loss: 18.593288
Val Best Loss: 18.593288
Epoch loss: 18.593288
train phase, Epoch 2/30, Loss: 18.366303
val phase, Epoch 2/30, Loss: 17.689097
Val Best Loss: 17.689097
Epoch loss: 17.689097
train phase, Epoch 3/30, Loss: 17.585797
val phase, Epoch 3/30, Loss: 16.547501
Val Best Loss: 16.547501
Epoch loss: 16.547501
train phase, Epoch 4/30, Loss: 16.927234
val phase, Epoch 4/30, Loss: 16.855740
Val Best Loss: 16.547501
Epoch loss: 16.855740
train phase, Epoch 5/30, Loss: 16.768784
val phase, Epoch 5/30, Loss: 15.932035
Val Best Loss: 15.932035
Epoch loss: 15.932035
train phase, Epoch 6/30, Loss: 16.771235
val phase, Epoch 6/30, Loss: 18.132130
Val Best Loss: 15.932035
Epoch loss: 18.132130
train phase, Epoch 7/30, Loss: 16.566142
val phase, Epoch 7/30, Loss: 16.147898
Val Best Loss: 15.932035
Epoch loss: 16.147898
train phase, Epoch 8/30, Loss: 16.220172
val phase, Epoch 8/30, Loss: 16.094996
Val Best Loss: 15.932035
Epoch loss: 16.094996
train phase, Epoch 9/30, Loss: 16.384530
val phase, Epoch 9/30, Loss: 15.539556
Val Best Loss: 15.539556
Epoch loss: 15.539556
train phase, Epoch 10/30, Loss: 15.885683
val phase, Epoch 10/30, Loss: 16.325935
Val Best Loss: 15.539556
Epoch loss: 16.325935
train phase, Epoch 11/30, Loss: 15.842239
val phase, Epoch 11/30, Loss: 16.714303
Val Best Loss: 15.539556
Epoch loss: 16.714303
train phase, Epoch 12/30, Loss: 15.673865
val phase, Epoch 12/30, Loss: 16.056359
Val Best Loss: 15.539556
Epoch loss: 16.056359
train phase, Epoch 13/30, Loss: 15.580435
val phase, Epoch 13/30, Loss: 16.633583
Val Best Loss: 15.539556
Epoch loss: 16.633583
train phase, Epoch 14/30, Loss: 15.248456
val phase, Epoch 14/30, Loss: 15.963152
Val Best Loss: 15.539556
Epoch loss: 15.963152
train phase, Epoch 15/30, Loss: 15.254288
val phase, Epoch 15/30, Loss: 15.875590
Val Best Loss: 15.539556
Epoch loss: 15.875590
train phase, Epoch 16/30, Loss: 14.897675
val phase, Epoch 16/30, Loss: 16.163807
Val Best Loss: 15.539556
Epoch loss: 16.163807
train phase, Epoch 17/30, Loss: 14.600528
val phase, Epoch 17/30, Loss: 17.367508
Val Best Loss: 15.539556
Epoch loss: 17.367508
train phase, Epoch 18/30, Loss: 14.315253
val phase, Epoch 18/30, Loss: 15.886729
Val Best Loss: 15.539556
Epoch loss: 15.886729
train phase, Epoch 19/30, Loss: 14.324425
val phase, Epoch 19/30, Loss: 16.935155
Val Best Loss: 15.539556
Epoch loss: 16.935155
train phase, Epoch 20/30, Loss: 14.031336
val phase, Epoch 20/30, Loss: 16.430175
Val Best Loss: 15.539556
Epoch loss: 16.430175
train phase, Epoch 21/30, Loss: 13.748729
val phase, Epoch 21/30, Loss: 16.291370
Val Best Loss: 15.539556
Epoch loss: 16.291370
train phase, Epoch 22/30, Loss: 13.400283
val phase, Epoch 22/30, Loss: 16.873480
Val Best Loss: 15.539556
Epoch loss: 16.873480
train phase, Epoch 23/30, Loss: 13.136649
val phase, Epoch 23/30, Loss: 17.183194
Val Best Loss: 15.539556
Epoch loss: 17.183194
train phase, Epoch 24/30, Loss: 12.898868
val phase, Epoch 24/30, Loss: 18.295054
Val Best Loss: 15.539556
Epoch loss: 18.295054
train phase, Epoch 25/30, Loss: 12.520280
val phase, Epoch 25/30, Loss: 17.704500
Val Best Loss: 15.539556
Epoch loss: 17.704500
train phase, Epoch 26/30, Loss: 12.227672
val phase, Epoch 26/30, Loss: 17.861405
Val Best Loss: 15.539556
Epoch loss: 17.861405
train phase, Epoch 27/30, Loss: 11.691911
val phase, Epoch 27/30, Loss: 17.938675
Val Best Loss: 15.539556
Epoch loss: 17.938675
train phase, Epoch 28/30, Loss: 11.569928
val phase, Epoch 28/30, Loss: 17.216745
Val Best Loss: 15.539556
Epoch loss: 17.216745
train phase, Epoch 29/30, Loss: 10.864761
val phase, Epoch 29/30, Loss: 18.008173
Val Best Loss: 15.539556
Epoch loss: 18.008173
train phase, Epoch 30/30, Loss: 10.705986
val phase, Epoch 30/30, Loss: 19.332906
Val Best Loss: 15.539556
Epoch loss: 19.332906
[Trial 87] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/20, Loss: 20.162039
val phase, Epoch 1/20, Loss: 17.659702
Val Best Loss: 17.659702
Epoch loss: 17.659702
train phase, Epoch 2/20, Loss: 17.548748
val phase, Epoch 2/20, Loss: 19.025920
Val Best Loss: 17.659702
Epoch loss: 19.025920
train phase, Epoch 3/20, Loss: 17.313943
val phase, Epoch 3/20, Loss: 18.172475
Val Best Loss: 17.659702
Epoch loss: 18.172475
train phase, Epoch 4/20, Loss: 17.075490
val phase, Epoch 4/20, Loss: 17.383349
Val Best Loss: 17.383349
Epoch loss: 17.383349
train phase, Epoch 5/20, Loss: 16.505981
val phase, Epoch 5/20, Loss: 16.153340
Val Best Loss: 16.153340
Epoch loss: 16.153340
train phase, Epoch 6/20, Loss: 16.305477
val phase, Epoch 6/20, Loss: 17.658628
Val Best Loss: 16.153340
Epoch loss: 17.658628
train phase, Epoch 7/20, Loss: 16.585106
val phase, Epoch 7/20, Loss: 16.371849
Val Best Loss: 16.153340
Epoch loss: 16.371849
train phase, Epoch 8/20, Loss: 16.113195
val phase, Epoch 8/20, Loss: 16.258571
Val Best Loss: 16.153340
Epoch loss: 16.258571
train phase, Epoch 9/20, Loss: 16.034598
val phase, Epoch 9/20, Loss: 16.319222
Val Best Loss: 16.153340
Epoch loss: 16.319222
train phase, Epoch 10/20, Loss: 16.050639
val phase, Epoch 10/20, Loss: 16.436800
Val Best Loss: 16.153340
Epoch loss: 16.436800
train phase, Epoch 11/20, Loss: 15.653615
val phase, Epoch 11/20, Loss: 15.914634
Val Best Loss: 15.914634
Epoch loss: 15.914634
train phase, Epoch 12/20, Loss: 15.646626
val phase, Epoch 12/20, Loss: 16.753375
Val Best Loss: 15.914634
Epoch loss: 16.753375
train phase, Epoch 13/20, Loss: 15.291644
val phase, Epoch 13/20, Loss: 16.402100
Val Best Loss: 15.914634
Epoch loss: 16.402100
train phase, Epoch 14/20, Loss: 15.017781
val phase, Epoch 14/20, Loss: 15.792033
Val Best Loss: 15.792033
Epoch loss: 15.792033
train phase, Epoch 15/20, Loss: 15.289428
val phase, Epoch 15/20, Loss: 15.843777
Val Best Loss: 15.792033
Epoch loss: 15.843777
train phase, Epoch 16/20, Loss: 14.736716
val phase, Epoch 16/20, Loss: 16.396789
Val Best Loss: 15.792033
Epoch loss: 16.396789
train phase, Epoch 17/20, Loss: 14.533807
val phase, Epoch 17/20, Loss: 20.677072
Val Best Loss: 15.792033
Epoch loss: 20.677072
train phase, Epoch 18/20, Loss: 14.755893
val phase, Epoch 18/20, Loss: 17.329986
Val Best Loss: 15.792033
Epoch loss: 17.329986
train phase, Epoch 19/20, Loss: 14.240217
val phase, Epoch 19/20, Loss: 16.754887
Val Best Loss: 15.792033
Epoch loss: 16.754887
train phase, Epoch 20/20, Loss: 13.928674
val phase, Epoch 20/20, Loss: 16.817567
Val Best Loss: 15.792033
Epoch loss: 16.817567
[Trial 89] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/15, Loss: 30.186887
val phase, Epoch 1/15, Loss: 19.192429
Val Best Loss: 19.192429
Epoch loss: 19.192429
train phase, Epoch 2/15, Loss: 19.085411
val phase, Epoch 2/15, Loss: 18.981984
Val Best Loss: 18.981984
Epoch loss: 18.981984
train phase, Epoch 3/15, Loss: 18.472883
val phase, Epoch 3/15, Loss: 18.138937
Val Best Loss: 18.138937
Epoch loss: 18.138937
train phase, Epoch 4/15, Loss: 18.306383
val phase, Epoch 4/15, Loss: 19.888248
Val Best Loss: 18.138937
Epoch loss: 19.888248
train phase, Epoch 5/15, Loss: 18.188842
val phase, Epoch 5/15, Loss: 17.525645
Val Best Loss: 17.525645
Epoch loss: 17.525645
train phase, Epoch 6/15, Loss: 17.926793
val phase, Epoch 6/15, Loss: 17.555357
Val Best Loss: 17.525645
Epoch loss: 17.555357
train phase, Epoch 7/15, Loss: 18.086992
val phase, Epoch 7/15, Loss: 17.793855
Val Best Loss: 17.525645
Epoch loss: 17.793855
train phase, Epoch 8/15, Loss: 17.877196
val phase, Epoch 8/15, Loss: 17.036703
Val Best Loss: 17.036703
Epoch loss: 17.036703
train phase, Epoch 9/15, Loss: 17.499061
val phase, Epoch 9/15, Loss: 17.412421
Val Best Loss: 17.036703
Epoch loss: 17.412421
train phase, Epoch 10/15, Loss: 17.584565
val phase, Epoch 10/15, Loss: 17.697999
Val Best Loss: 17.036703
Epoch loss: 17.697999
train phase, Epoch 11/15, Loss: 17.594316
val phase, Epoch 11/15, Loss: 17.767941
Val Best Loss: 17.036703
Epoch loss: 17.767941
train phase, Epoch 12/15, Loss: 17.716886
val phase, Epoch 12/15, Loss: 17.811225
Val Best Loss: 17.036703
Epoch loss: 17.811225
train phase, Epoch 13/15, Loss: 17.561223
val phase, Epoch 13/15, Loss: 17.338134
Val Best Loss: 17.036703
Epoch loss: 17.338134
train phase, Epoch 14/15, Loss: 17.102227
val phase, Epoch 14/15, Loss: 17.463333
Val Best Loss: 17.036703
Epoch loss: 17.463333
train phase, Epoch 15/15, Loss: 17.211023
val phase, Epoch 15/15, Loss: 17.154236
Val Best Loss: 17.036703
Epoch loss: 17.154236
train phase, Epoch 1/30, Loss: 20.262103
val phase, Epoch 1/30, Loss: 18.326686
Val Best Loss: 18.326686
Epoch loss: 18.326686
train phase, Epoch 2/30, Loss: 18.450200
val phase, Epoch 2/30, Loss: 16.979214
Val Best Loss: 16.979214
Epoch loss: 16.979214
train phase, Epoch 3/30, Loss: 17.354060
val phase, Epoch 3/30, Loss: 17.086110
Val Best Loss: 16.979214
Epoch loss: 17.086110
train phase, Epoch 4/30, Loss: 17.480163
val phase, Epoch 4/30, Loss: 17.877623
Val Best Loss: 16.979214
Epoch loss: 17.877623
train phase, Epoch 5/30, Loss: 16.840996
val phase, Epoch 5/30, Loss: 17.747820
Val Best Loss: 16.979214
Epoch loss: 17.747820
train phase, Epoch 6/30, Loss: 17.131146
val phase, Epoch 6/30, Loss: 19.466555
Val Best Loss: 16.979214
Epoch loss: 19.466555
train phase, Epoch 7/30, Loss: 16.548797
val phase, Epoch 7/30, Loss: 17.628685
Val Best Loss: 16.979214
Epoch loss: 17.628685
train phase, Epoch 8/30, Loss: 16.597604
val phase, Epoch 8/30, Loss: 18.178528
Val Best Loss: 16.979214
Epoch loss: 18.178528
train phase, Epoch 9/30, Loss: 16.200812
val phase, Epoch 9/30, Loss: 19.737694
Val Best Loss: 16.979214
Epoch loss: 19.737694
train phase, Epoch 10/30, Loss: 16.370221
val phase, Epoch 10/30, Loss: 16.620604
Val Best Loss: 16.620604
Epoch loss: 16.620604
train phase, Epoch 11/30, Loss: 15.868386
val phase, Epoch 11/30, Loss: 16.539455
Val Best Loss: 16.539455
Epoch loss: 16.539455
train phase, Epoch 12/30, Loss: 15.829484
val phase, Epoch 12/30, Loss: 16.331298
Val Best Loss: 16.331298
Epoch loss: 16.331298
train phase, Epoch 13/30, Loss: 15.766429
val phase, Epoch 13/30, Loss: 16.871584
Val Best Loss: 16.331298
Epoch loss: 16.871584
train phase, Epoch 14/30, Loss: 15.360891
val phase, Epoch 14/30, Loss: 16.133090
Val Best Loss: 16.133090
Epoch loss: 16.133090
train phase, Epoch 15/30, Loss: 15.228601
val phase, Epoch 15/30, Loss: 16.369963
Val Best Loss: 16.133090
Epoch loss: 16.369963
train phase, Epoch 16/30, Loss: 15.139910
val phase, Epoch 16/30, Loss: 16.761869
Val Best Loss: 16.133090
Epoch loss: 16.761869
train phase, Epoch 17/30, Loss: 14.838002
val phase, Epoch 17/30, Loss: 17.177553
Val Best Loss: 16.133090
Epoch loss: 17.177553
train phase, Epoch 18/30, Loss: 14.710807
val phase, Epoch 18/30, Loss: 17.359402
Val Best Loss: 16.133090
Epoch loss: 17.359402
train phase, Epoch 19/30, Loss: 14.347371
val phase, Epoch 19/30, Loss: 16.580175
Val Best Loss: 16.133090
Epoch loss: 16.580175
train phase, Epoch 20/30, Loss: 14.026142
val phase, Epoch 20/30, Loss: 17.268848
Val Best Loss: 16.133090
Epoch loss: 17.268848
train phase, Epoch 21/30, Loss: 13.940613
val phase, Epoch 21/30, Loss: 16.657136
Val Best Loss: 16.133090
Epoch loss: 16.657136
train phase, Epoch 22/30, Loss: 13.569363
val phase, Epoch 22/30, Loss: 17.042955
Val Best Loss: 16.133090
Epoch loss: 17.042955
train phase, Epoch 23/30, Loss: 13.153224
val phase, Epoch 23/30, Loss: 17.718700
Val Best Loss: 16.133090
Epoch loss: 17.718700
train phase, Epoch 24/30, Loss: 12.846847
val phase, Epoch 24/30, Loss: 17.611368
Val Best Loss: 16.133090
Epoch loss: 17.611368
train phase, Epoch 25/30, Loss: 12.376037
val phase, Epoch 25/30, Loss: 17.522887
Val Best Loss: 16.133090
Epoch loss: 17.522887
train phase, Epoch 26/30, Loss: 12.039484
val phase, Epoch 26/30, Loss: 18.073368
Val Best Loss: 16.133090
Epoch loss: 18.073368
train phase, Epoch 27/30, Loss: 11.491259
val phase, Epoch 27/30, Loss: 18.500364
Val Best Loss: 16.133090
Epoch loss: 18.500364
train phase, Epoch 28/30, Loss: 11.032123
val phase, Epoch 28/30, Loss: 18.360785
Val Best Loss: 16.133090
Epoch loss: 18.360785
train phase, Epoch 29/30, Loss: 10.741975
val phase, Epoch 29/30, Loss: 18.721951
Val Best Loss: 16.133090
Epoch loss: 18.721951
train phase, Epoch 30/30, Loss: 10.406819
val phase, Epoch 30/30, Loss: 19.194203
Val Best Loss: 16.133090
Epoch loss: 19.194203
train phase, Epoch 1/30, Loss: 22.405709
val phase, Epoch 1/30, Loss: 17.341869
Val Best Loss: 17.341869
Epoch loss: 17.341869
train phase, Epoch 2/30, Loss: 18.041708
val phase, Epoch 2/30, Loss: 16.716798
Val Best Loss: 16.716798
Epoch loss: 16.716798
train phase, Epoch 3/30, Loss: 17.792512
val phase, Epoch 3/30, Loss: 16.462200
Val Best Loss: 16.462200
Epoch loss: 16.462200
train phase, Epoch 4/30, Loss: 17.474746
val phase, Epoch 4/30, Loss: 16.675691
Val Best Loss: 16.462200
Epoch loss: 16.675691
train phase, Epoch 5/30, Loss: 16.875867
val phase, Epoch 5/30, Loss: 16.462082
Val Best Loss: 16.462082
Epoch loss: 16.462082
train phase, Epoch 6/30, Loss: 16.990148
val phase, Epoch 6/30, Loss: 16.287447
Val Best Loss: 16.287447
Epoch loss: 16.287447
train phase, Epoch 7/30, Loss: 16.748172
val phase, Epoch 7/30, Loss: 16.444003
Val Best Loss: 16.287447
Epoch loss: 16.444003
train phase, Epoch 8/30, Loss: 16.541133
val phase, Epoch 8/30, Loss: 17.617237
Val Best Loss: 16.287447
Epoch loss: 17.617237
train phase, Epoch 9/30, Loss: 16.289396
val phase, Epoch 9/30, Loss: 16.640660
Val Best Loss: 16.287447
Epoch loss: 16.640660
train phase, Epoch 10/30, Loss: 16.266040
val phase, Epoch 10/30, Loss: 16.188323
Val Best Loss: 16.188323
Epoch loss: 16.188323
train phase, Epoch 11/30, Loss: 16.045670
val phase, Epoch 11/30, Loss: 18.392385
Val Best Loss: 16.188323
Epoch loss: 18.392385
train phase, Epoch 12/30, Loss: 15.997415
val phase, Epoch 12/30, Loss: 16.455703
Val Best Loss: 16.188323
Epoch loss: 16.455703
train phase, Epoch 13/30, Loss: 15.810053
val phase, Epoch 13/30, Loss: 17.844360
Val Best Loss: 16.188323
Epoch loss: 17.844360
train phase, Epoch 14/30, Loss: 15.424845
val phase, Epoch 14/30, Loss: 15.988279
Val Best Loss: 15.988279
Epoch loss: 15.988279
train phase, Epoch 15/30, Loss: 15.595579
val phase, Epoch 15/30, Loss: 15.856691
Val Best Loss: 15.856691
Epoch loss: 15.856691
train phase, Epoch 16/30, Loss: 15.478893
val phase, Epoch 16/30, Loss: 16.373373
Val Best Loss: 15.856691
Epoch loss: 16.373373
train phase, Epoch 17/30, Loss: 15.212581
val phase, Epoch 17/30, Loss: 16.515995
Val Best Loss: 15.856691
Epoch loss: 16.515995
train phase, Epoch 18/30, Loss: 15.151001
val phase, Epoch 18/30, Loss: 16.728999
Val Best Loss: 15.856691
Epoch loss: 16.728999
train phase, Epoch 19/30, Loss: 14.883291
val phase, Epoch 19/30, Loss: 16.451346
Val Best Loss: 15.856691
Epoch loss: 16.451346
train phase, Epoch 20/30, Loss: 14.548669
val phase, Epoch 20/30, Loss: 16.585474
Val Best Loss: 15.856691
Epoch loss: 16.585474
train phase, Epoch 21/30, Loss: 14.505652
val phase, Epoch 21/30, Loss: 16.232512
Val Best Loss: 15.856691
Epoch loss: 16.232512
train phase, Epoch 22/30, Loss: 14.154609
val phase, Epoch 22/30, Loss: 16.716218
Val Best Loss: 15.856691
Epoch loss: 16.716218
train phase, Epoch 23/30, Loss: 13.766619
val phase, Epoch 23/30, Loss: 17.075894
Val Best Loss: 15.856691
Epoch loss: 17.075894
train phase, Epoch 24/30, Loss: 13.467304
val phase, Epoch 24/30, Loss: 17.407364
Val Best Loss: 15.856691
Epoch loss: 17.407364
train phase, Epoch 25/30, Loss: 13.386095
val phase, Epoch 25/30, Loss: 19.474933
Val Best Loss: 15.856691
Epoch loss: 19.474933
train phase, Epoch 26/30, Loss: 13.083230
val phase, Epoch 26/30, Loss: 17.516260
Val Best Loss: 15.856691
Epoch loss: 17.516260
train phase, Epoch 27/30, Loss: 12.752415
val phase, Epoch 27/30, Loss: 18.053736
Val Best Loss: 15.856691
Epoch loss: 18.053736
train phase, Epoch 28/30, Loss: 12.089567
val phase, Epoch 28/30, Loss: 17.192491
Val Best Loss: 15.856691
Epoch loss: 17.192491
train phase, Epoch 29/30, Loss: 12.130253
val phase, Epoch 29/30, Loss: 17.234521
Val Best Loss: 15.856691
Epoch loss: 17.234521
train phase, Epoch 30/30, Loss: 11.714218
val phase, Epoch 30/30, Loss: 18.007340
Val Best Loss: 15.856691
Epoch loss: 18.007340
train phase, Epoch 1/30, Loss: 20.207367
val phase, Epoch 1/30, Loss: 21.339167
Val Best Loss: 21.339167
Epoch loss: 21.339167
train phase, Epoch 2/30, Loss: 18.148673
val phase, Epoch 2/30, Loss: 18.030456
Val Best Loss: 18.030456
Epoch loss: 18.030456
train phase, Epoch 3/30, Loss: 17.476273
val phase, Epoch 3/30, Loss: 16.766291
Val Best Loss: 16.766291
Epoch loss: 16.766291
train phase, Epoch 4/30, Loss: 17.247658
val phase, Epoch 4/30, Loss: 16.351159
Val Best Loss: 16.351159
Epoch loss: 16.351159
train phase, Epoch 5/30, Loss: 16.781914
val phase, Epoch 5/30, Loss: 18.349601
Val Best Loss: 16.351159
Epoch loss: 18.349601
train phase, Epoch 6/30, Loss: 16.815931
val phase, Epoch 6/30, Loss: 16.439599
Val Best Loss: 16.351159
Epoch loss: 16.439599
train phase, Epoch 7/30, Loss: 16.760270
val phase, Epoch 7/30, Loss: 16.200634
Val Best Loss: 16.200634
Epoch loss: 16.200634
train phase, Epoch 8/30, Loss: 16.830678
val phase, Epoch 8/30, Loss: 17.816662
Val Best Loss: 16.200634
Epoch loss: 17.816662
train phase, Epoch 9/30, Loss: 16.213102
val phase, Epoch 9/30, Loss: 16.087150
Val Best Loss: 16.087150
Epoch loss: 16.087150
train phase, Epoch 10/30, Loss: 16.048355
val phase, Epoch 10/30, Loss: 16.588403
Val Best Loss: 16.087150
Epoch loss: 16.588403
train phase, Epoch 11/30, Loss: 16.020519
val phase, Epoch 11/30, Loss: 17.457521
Val Best Loss: 16.087150
Epoch loss: 17.457521
train phase, Epoch 12/30, Loss: 15.796545
val phase, Epoch 12/30, Loss: 16.084897
Val Best Loss: 16.084897
Epoch loss: 16.084897
train phase, Epoch 13/30, Loss: 15.716507
val phase, Epoch 13/30, Loss: 16.178652
Val Best Loss: 16.084897
Epoch loss: 16.178652
train phase, Epoch 14/30, Loss: 15.441742
val phase, Epoch 14/30, Loss: 15.921866
Val Best Loss: 15.921866
Epoch loss: 15.921866
train phase, Epoch 15/30, Loss: 15.254582
val phase, Epoch 15/30, Loss: 15.826744
Val Best Loss: 15.826744
Epoch loss: 15.826744
train phase, Epoch 16/30, Loss: 15.111656
val phase, Epoch 16/30, Loss: 15.606622
Val Best Loss: 15.606622
Epoch loss: 15.606622
train phase, Epoch 17/30, Loss: 14.930088
val phase, Epoch 17/30, Loss: 16.383075
Val Best Loss: 15.606622
Epoch loss: 16.383075
train phase, Epoch 18/30, Loss: 14.633801
val phase, Epoch 18/30, Loss: 20.588051
Val Best Loss: 15.606622
Epoch loss: 20.588051
train phase, Epoch 19/30, Loss: 14.801125
val phase, Epoch 19/30, Loss: 17.185100
Val Best Loss: 15.606622
Epoch loss: 17.185100
train phase, Epoch 20/30, Loss: 14.168118
val phase, Epoch 20/30, Loss: 17.304632
Val Best Loss: 15.606622
Epoch loss: 17.304632
train phase, Epoch 21/30, Loss: 14.023631
val phase, Epoch 21/30, Loss: 16.190585
Val Best Loss: 15.606622
Epoch loss: 16.190585
train phase, Epoch 22/30, Loss: 13.583767
val phase, Epoch 22/30, Loss: 18.071627
Val Best Loss: 15.606622
Epoch loss: 18.071627
train phase, Epoch 23/30, Loss: 13.365254
val phase, Epoch 23/30, Loss: 16.388713
Val Best Loss: 15.606622
Epoch loss: 16.388713
train phase, Epoch 24/30, Loss: 12.966904
val phase, Epoch 24/30, Loss: 17.512125
Val Best Loss: 15.606622
Epoch loss: 17.512125
train phase, Epoch 25/30, Loss: 12.722773
val phase, Epoch 25/30, Loss: 20.707908
Val Best Loss: 15.606622
Epoch loss: 20.707908
train phase, Epoch 26/30, Loss: 12.369685
val phase, Epoch 26/30, Loss: 17.818259
Val Best Loss: 15.606622
Epoch loss: 17.818259
train phase, Epoch 27/30, Loss: 11.684672
val phase, Epoch 27/30, Loss: 17.829647
Val Best Loss: 15.606622
Epoch loss: 17.829647
train phase, Epoch 28/30, Loss: 11.311386
val phase, Epoch 28/30, Loss: 18.525925
Val Best Loss: 15.606622
Epoch loss: 18.525925
train phase, Epoch 29/30, Loss: 11.021535
val phase, Epoch 29/30, Loss: 17.812078
Val Best Loss: 15.606622
Epoch loss: 17.812078
train phase, Epoch 30/30, Loss: 10.250712
val phase, Epoch 30/30, Loss: 18.327415
Val Best Loss: 15.606622
Epoch loss: 18.327415
train phase, Epoch 1/30, Loss: 19.488385
val phase, Epoch 1/30, Loss: 17.047426
Val Best Loss: 17.047426
Epoch loss: 17.047426
train phase, Epoch 2/30, Loss: 17.727107
val phase, Epoch 2/30, Loss: 17.245997
Val Best Loss: 17.047426
Epoch loss: 17.245997
train phase, Epoch 3/30, Loss: 17.712600
val phase, Epoch 3/30, Loss: 17.017402
Val Best Loss: 17.017402
Epoch loss: 17.017402
train phase, Epoch 4/30, Loss: 17.298197
val phase, Epoch 4/30, Loss: 16.510963
Val Best Loss: 16.510963
Epoch loss: 16.510963
train phase, Epoch 5/30, Loss: 16.964237
val phase, Epoch 5/30, Loss: 16.582603
Val Best Loss: 16.510963
Epoch loss: 16.582603
train phase, Epoch 6/30, Loss: 16.542488
val phase, Epoch 6/30, Loss: 16.199570
Val Best Loss: 16.199570
Epoch loss: 16.199570
train phase, Epoch 7/30, Loss: 16.481723
val phase, Epoch 7/30, Loss: 16.603919
Val Best Loss: 16.199570
Epoch loss: 16.603919
train phase, Epoch 8/30, Loss: 16.459344
val phase, Epoch 8/30, Loss: 16.453050
Val Best Loss: 16.199570
Epoch loss: 16.453050
train phase, Epoch 9/30, Loss: 16.234810
val phase, Epoch 9/30, Loss: 16.275880
Val Best Loss: 16.199570
Epoch loss: 16.275880
train phase, Epoch 10/30, Loss: 16.184421
val phase, Epoch 10/30, Loss: 16.071258
Val Best Loss: 16.071258
Epoch loss: 16.071258
train phase, Epoch 11/30, Loss: 16.137337
val phase, Epoch 11/30, Loss: 16.192784
Val Best Loss: 16.071258
Epoch loss: 16.192784
train phase, Epoch 12/30, Loss: 15.727008
val phase, Epoch 12/30, Loss: 16.357872
Val Best Loss: 16.071258
Epoch loss: 16.357872
train phase, Epoch 13/30, Loss: 15.756652
val phase, Epoch 13/30, Loss: 16.950911
Val Best Loss: 16.071258
Epoch loss: 16.950911
train phase, Epoch 14/30, Loss: 15.609050
val phase, Epoch 14/30, Loss: 16.801021
Val Best Loss: 16.071258
Epoch loss: 16.801021
train phase, Epoch 15/30, Loss: 15.533417
val phase, Epoch 15/30, Loss: 18.517678
Val Best Loss: 16.071258
Epoch loss: 18.517678
train phase, Epoch 16/30, Loss: 15.049950
val phase, Epoch 16/30, Loss: 17.077411
Val Best Loss: 16.071258
Epoch loss: 17.077411
train phase, Epoch 17/30, Loss: 14.921584
val phase, Epoch 17/30, Loss: 16.181503
Val Best Loss: 16.071258
Epoch loss: 16.181503
train phase, Epoch 18/30, Loss: 14.687302
val phase, Epoch 18/30, Loss: 16.298631
Val Best Loss: 16.071258
Epoch loss: 16.298631
train phase, Epoch 19/30, Loss: 14.541966
val phase, Epoch 19/30, Loss: 16.806930
Val Best Loss: 16.071258
Epoch loss: 16.806930
train phase, Epoch 20/30, Loss: 14.403473
val phase, Epoch 20/30, Loss: 16.418703
Val Best Loss: 16.071258
Epoch loss: 16.418703
train phase, Epoch 21/30, Loss: 14.194946
val phase, Epoch 21/30, Loss: 17.083060
Val Best Loss: 16.071258
Epoch loss: 17.083060
train phase, Epoch 22/30, Loss: 13.720347
val phase, Epoch 22/30, Loss: 16.918018
Val Best Loss: 16.071258
Epoch loss: 16.918018
train phase, Epoch 23/30, Loss: 13.538234
val phase, Epoch 23/30, Loss: 16.265994
Val Best Loss: 16.071258
Epoch loss: 16.265994
train phase, Epoch 24/30, Loss: 12.990816
val phase, Epoch 24/30, Loss: 17.979523
Val Best Loss: 16.071258
Epoch loss: 17.979523
train phase, Epoch 25/30, Loss: 12.946670
val phase, Epoch 25/30, Loss: 18.696764
Val Best Loss: 16.071258
Epoch loss: 18.696764
train phase, Epoch 26/30, Loss: 12.238231
val phase, Epoch 26/30, Loss: 18.555592
Val Best Loss: 16.071258
Epoch loss: 18.555592
train phase, Epoch 27/30, Loss: 11.993738
val phase, Epoch 27/30, Loss: 19.167602
Val Best Loss: 16.071258
Epoch loss: 19.167602
train phase, Epoch 28/30, Loss: 11.379064
val phase, Epoch 28/30, Loss: 17.141658
Val Best Loss: 16.071258
Epoch loss: 17.141658
train phase, Epoch 29/30, Loss: 10.889884
val phase, Epoch 29/30, Loss: 17.296033
Val Best Loss: 16.071258
Epoch loss: 17.296033
train phase, Epoch 30/30, Loss: 10.569768
val phase, Epoch 30/30, Loss: 18.840179
Val Best Loss: 16.071258
Epoch loss: 18.840179
train phase, Epoch 1/30, Loss: 20.430550
val phase, Epoch 1/30, Loss: 18.003662
Val Best Loss: 18.003662
Epoch loss: 18.003662
train phase, Epoch 2/30, Loss: 18.034323
val phase, Epoch 2/30, Loss: 19.629624
Val Best Loss: 18.003662
Epoch loss: 19.629624
train phase, Epoch 3/30, Loss: 18.167374
val phase, Epoch 3/30, Loss: 16.774519
Val Best Loss: 16.774519
Epoch loss: 16.774519
train phase, Epoch 4/30, Loss: 17.084649
val phase, Epoch 4/30, Loss: 19.247390
Val Best Loss: 16.774519
Epoch loss: 19.247390
train phase, Epoch 5/30, Loss: 16.869284
val phase, Epoch 5/30, Loss: 16.901075
Val Best Loss: 16.774519
Epoch loss: 16.901075
train phase, Epoch 6/30, Loss: 16.643882
val phase, Epoch 6/30, Loss: 16.048565
Val Best Loss: 16.048565
Epoch loss: 16.048565
train phase, Epoch 7/30, Loss: 16.495328
val phase, Epoch 7/30, Loss: 16.155875
Val Best Loss: 16.048565
Epoch loss: 16.155875
train phase, Epoch 8/30, Loss: 16.243809
val phase, Epoch 8/30, Loss: 16.204604
Val Best Loss: 16.048565
Epoch loss: 16.204604
train phase, Epoch 9/30, Loss: 16.256543
val phase, Epoch 9/30, Loss: 16.079398
Val Best Loss: 16.048565
Epoch loss: 16.079398
train phase, Epoch 10/30, Loss: 15.837969
val phase, Epoch 10/30, Loss: 16.003797
Val Best Loss: 16.003797
Epoch loss: 16.003797
train phase, Epoch 11/30, Loss: 16.111925
val phase, Epoch 11/30, Loss: 16.390773
Val Best Loss: 16.003797
Epoch loss: 16.390773
train phase, Epoch 12/30, Loss: 15.744483
val phase, Epoch 12/30, Loss: 17.376927
Val Best Loss: 16.003797
Epoch loss: 17.376927
train phase, Epoch 13/30, Loss: 15.715790
val phase, Epoch 13/30, Loss: 16.300457
Val Best Loss: 16.003797
Epoch loss: 16.300457
train phase, Epoch 14/30, Loss: 15.499981
val phase, Epoch 14/30, Loss: 15.898211
Val Best Loss: 15.898211
Epoch loss: 15.898211
train phase, Epoch 15/30, Loss: 15.081357
val phase, Epoch 15/30, Loss: 16.727481
Val Best Loss: 15.898211
Epoch loss: 16.727481
train phase, Epoch 16/30, Loss: 15.050579
val phase, Epoch 16/30, Loss: 16.097482
Val Best Loss: 15.898211
Epoch loss: 16.097482
train phase, Epoch 17/30, Loss: 14.756908
val phase, Epoch 17/30, Loss: 16.179958
Val Best Loss: 15.898211
Epoch loss: 16.179958
train phase, Epoch 18/30, Loss: 14.560742
val phase, Epoch 18/30, Loss: 16.011393
Val Best Loss: 15.898211
Epoch loss: 16.011393
train phase, Epoch 19/30, Loss: 14.322607
val phase, Epoch 19/30, Loss: 17.054728
Val Best Loss: 15.898211
Epoch loss: 17.054728
train phase, Epoch 20/30, Loss: 14.056160
val phase, Epoch 20/30, Loss: 16.345460
Val Best Loss: 15.898211
Epoch loss: 16.345460
train phase, Epoch 21/30, Loss: 13.891798
val phase, Epoch 21/30, Loss: 17.172532
Val Best Loss: 15.898211
Epoch loss: 17.172532
train phase, Epoch 22/30, Loss: 13.567822
val phase, Epoch 22/30, Loss: 16.628138
Val Best Loss: 15.898211
Epoch loss: 16.628138
train phase, Epoch 23/30, Loss: 13.307315
val phase, Epoch 23/30, Loss: 16.874743
Val Best Loss: 15.898211
Epoch loss: 16.874743
train phase, Epoch 24/30, Loss: 12.831081
val phase, Epoch 24/30, Loss: 16.902761
Val Best Loss: 15.898211
Epoch loss: 16.902761
train phase, Epoch 25/30, Loss: 12.500362
val phase, Epoch 25/30, Loss: 17.045467
Val Best Loss: 15.898211
Epoch loss: 17.045467
train phase, Epoch 26/30, Loss: 12.070237
val phase, Epoch 26/30, Loss: 18.758828
Val Best Loss: 15.898211
Epoch loss: 18.758828
train phase, Epoch 27/30, Loss: 11.903758
val phase, Epoch 27/30, Loss: 18.080249
Val Best Loss: 15.898211
Epoch loss: 18.080249
train phase, Epoch 28/30, Loss: 11.481153
val phase, Epoch 28/30, Loss: 17.166287
Val Best Loss: 15.898211
Epoch loss: 17.166287
train phase, Epoch 29/30, Loss: 10.882280
val phase, Epoch 29/30, Loss: 20.301243
Val Best Loss: 15.898211
Epoch loss: 20.301243
train phase, Epoch 30/30, Loss: 10.622766
val phase, Epoch 30/30, Loss: 19.077257
Val Best Loss: 15.898211
Epoch loss: 19.077257
train phase, Epoch 1/12, Loss: 19.847729
val phase, Epoch 1/12, Loss: 37.724665
Val Best Loss: 37.724665
Epoch loss: 37.724665
train phase, Epoch 2/12, Loss: 17.876708
val phase, Epoch 2/12, Loss: 34.569137
Val Best Loss: 34.569137
Epoch loss: 34.569137
train phase, Epoch 3/12, Loss: 17.652924
val phase, Epoch 3/12, Loss: 38.066632
Val Best Loss: 34.569137
Epoch loss: 38.066632
train phase, Epoch 4/12, Loss: 17.434132
val phase, Epoch 4/12, Loss: 35.799015
Val Best Loss: 34.569137
Epoch loss: 35.799015
train phase, Epoch 5/12, Loss: 17.292187
val phase, Epoch 5/12, Loss: 43.649551
Val Best Loss: 34.569137
Epoch loss: 43.649551
train phase, Epoch 6/12, Loss: 16.955004
val phase, Epoch 6/12, Loss: 64.259886
Val Best Loss: 34.569137
Epoch loss: 64.259886
train phase, Epoch 7/12, Loss: 16.769517
val phase, Epoch 7/12, Loss: 45.537507
Val Best Loss: 34.569137
Epoch loss: 45.537507
train phase, Epoch 8/12, Loss: 16.293568
val phase, Epoch 8/12, Loss: 53.452196
Val Best Loss: 34.569137
Epoch loss: 53.452196
train phase, Epoch 9/12, Loss: 16.372070
val phase, Epoch 9/12, Loss: 40.453939
Val Best Loss: 34.569137
Epoch loss: 40.453939
train phase, Epoch 10/12, Loss: 16.168391
val phase, Epoch 10/12, Loss: 68.980628
Val Best Loss: 34.569137
Epoch loss: 68.980628
train phase, Epoch 11/12, Loss: 15.997876
val phase, Epoch 11/12, Loss: 45.276716
Val Best Loss: 34.569137
Epoch loss: 45.276716
train phase, Epoch 12/12, Loss: 15.838761
val phase, Epoch 12/12, Loss: 53.436683
Val Best Loss: 34.569137
Epoch loss: 53.436683
train phase, Epoch 1/20, Loss: 22.247104
val phase, Epoch 1/20, Loss: 18.464931
Val Best Loss: 18.464931
Epoch loss: 18.464931
train phase, Epoch 2/20, Loss: 18.040286
val phase, Epoch 2/20, Loss: 18.406876
Val Best Loss: 18.406876
Epoch loss: 18.406876
train phase, Epoch 3/20, Loss: 17.782379
val phase, Epoch 3/20, Loss: 18.120961
Val Best Loss: 18.120961
Epoch loss: 18.120961
train phase, Epoch 4/20, Loss: 17.334618
val phase, Epoch 4/20, Loss: 17.490763
Val Best Loss: 17.490763
Epoch loss: 17.490763
train phase, Epoch 5/20, Loss: 17.232358
val phase, Epoch 5/20, Loss: 17.442329
Val Best Loss: 17.442329
Epoch loss: 17.442329
train phase, Epoch 6/20, Loss: 16.984616
val phase, Epoch 6/20, Loss: 17.126910
Val Best Loss: 17.126910
Epoch loss: 17.126910
train phase, Epoch 7/20, Loss: 16.753098
val phase, Epoch 7/20, Loss: 18.226783
Val Best Loss: 17.126910
Epoch loss: 18.226783
train phase, Epoch 8/20, Loss: 16.573538
val phase, Epoch 8/20, Loss: 17.309325
Val Best Loss: 17.126910
Epoch loss: 17.309325
train phase, Epoch 9/20, Loss: 16.284558
val phase, Epoch 9/20, Loss: 17.156401
Val Best Loss: 17.126910
Epoch loss: 17.156401
train phase, Epoch 10/20, Loss: 16.207024
val phase, Epoch 10/20, Loss: 18.229423
Val Best Loss: 17.126910
Epoch loss: 18.229423
train phase, Epoch 11/20, Loss: 15.988033
val phase, Epoch 11/20, Loss: 17.183054
Val Best Loss: 17.126910
Epoch loss: 17.183054
train phase, Epoch 12/20, Loss: 15.799354
val phase, Epoch 12/20, Loss: 17.022791
Val Best Loss: 17.022791
Epoch loss: 17.022791
train phase, Epoch 13/20, Loss: 15.576261
val phase, Epoch 13/20, Loss: 18.151576
Val Best Loss: 17.022791
Epoch loss: 18.151576
train phase, Epoch 14/20, Loss: 15.582914
val phase, Epoch 14/20, Loss: 17.967385
Val Best Loss: 17.022791
Epoch loss: 17.967385
train phase, Epoch 15/20, Loss: 15.137119
val phase, Epoch 15/20, Loss: 17.223345
Val Best Loss: 17.022791
Epoch loss: 17.223345
train phase, Epoch 16/20, Loss: 14.760870
val phase, Epoch 16/20, Loss: 19.021745
Val Best Loss: 17.022791
Epoch loss: 19.021745
train phase, Epoch 17/20, Loss: 15.071320
val phase, Epoch 17/20, Loss: 17.133689
Val Best Loss: 17.022791
Epoch loss: 17.133689
train phase, Epoch 18/20, Loss: 14.604001
val phase, Epoch 18/20, Loss: 17.452496
Val Best Loss: 17.022791
Epoch loss: 17.452496
train phase, Epoch 19/20, Loss: 14.432478
val phase, Epoch 19/20, Loss: 17.704532
Val Best Loss: 17.022791
Epoch loss: 17.704532
train phase, Epoch 20/20, Loss: 14.146744
val phase, Epoch 20/20, Loss: 17.576737
Val Best Loss: 17.022791
Epoch loss: 17.576737
[Trial 98] Skipped due to model construction error: Calculated padded input size per channel: (7 x 1). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/5, Loss: 20.608286
val phase, Epoch 1/5, Loss: 17.227630
Val Best Loss: 17.227630
Epoch loss: 17.227630
train phase, Epoch 2/5, Loss: 17.715776
val phase, Epoch 2/5, Loss: 17.302755
Val Best Loss: 17.227630
Epoch loss: 17.302755
train phase, Epoch 3/5, Loss: 17.110780
val phase, Epoch 3/5, Loss: 16.999559
Val Best Loss: 16.999559
Epoch loss: 16.999559
train phase, Epoch 4/5, Loss: 16.593803
val phase, Epoch 4/5, Loss: 16.855519
Val Best Loss: 16.855519
Epoch loss: 16.855519
train phase, Epoch 5/5, Loss: 16.431284
val phase, Epoch 5/5, Loss: 16.640695
Val Best Loss: 16.640695
Epoch loss: 16.640695
[Trial 100] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/30, Loss: 20.104292
val phase, Epoch 1/30, Loss: 20.458976
Val Best Loss: 20.458976
Epoch loss: 20.458976
train phase, Epoch 2/30, Loss: 18.489320
val phase, Epoch 2/30, Loss: 22.070195
Val Best Loss: 20.458976
Epoch loss: 22.070195
train phase, Epoch 3/30, Loss: 17.720671
val phase, Epoch 3/30, Loss: 18.635350
Val Best Loss: 18.635350
Epoch loss: 18.635350
train phase, Epoch 4/30, Loss: 17.071918
val phase, Epoch 4/30, Loss: 17.647544
Val Best Loss: 17.647544
Epoch loss: 17.647544
train phase, Epoch 5/30, Loss: 16.801362
val phase, Epoch 5/30, Loss: 17.158866
Val Best Loss: 17.158866
Epoch loss: 17.158866
train phase, Epoch 6/30, Loss: 16.796133
val phase, Epoch 6/30, Loss: 16.693259
Val Best Loss: 16.693259
Epoch loss: 16.693259
train phase, Epoch 7/30, Loss: 16.422150
val phase, Epoch 7/30, Loss: 16.019354
Val Best Loss: 16.019354
Epoch loss: 16.019354
train phase, Epoch 8/30, Loss: 16.401129
val phase, Epoch 8/30, Loss: 16.231272
Val Best Loss: 16.019354
Epoch loss: 16.231272
train phase, Epoch 9/30, Loss: 16.142431
val phase, Epoch 9/30, Loss: 16.771408
Val Best Loss: 16.019354
Epoch loss: 16.771408
train phase, Epoch 10/30, Loss: 16.093906
val phase, Epoch 10/30, Loss: 16.625986
Val Best Loss: 16.019354
Epoch loss: 16.625986
train phase, Epoch 11/30, Loss: 15.950874
val phase, Epoch 11/30, Loss: 16.170930
Val Best Loss: 16.019354
Epoch loss: 16.170930
train phase, Epoch 12/30, Loss: 15.868202
val phase, Epoch 12/30, Loss: 16.797517
Val Best Loss: 16.019354
Epoch loss: 16.797517
train phase, Epoch 13/30, Loss: 15.484869
val phase, Epoch 13/30, Loss: 16.640407
Val Best Loss: 16.019354
Epoch loss: 16.640407
train phase, Epoch 14/30, Loss: 15.325999
val phase, Epoch 14/30, Loss: 20.014863
Val Best Loss: 16.019354
Epoch loss: 20.014863
train phase, Epoch 15/30, Loss: 15.177811
val phase, Epoch 15/30, Loss: 16.023176
Val Best Loss: 16.019354
Epoch loss: 16.023176
train phase, Epoch 16/30, Loss: 15.232568
val phase, Epoch 16/30, Loss: 15.980900
Val Best Loss: 15.980900
Epoch loss: 15.980900
train phase, Epoch 17/30, Loss: 14.827630
val phase, Epoch 17/30, Loss: 16.600896
Val Best Loss: 15.980900
Epoch loss: 16.600896
train phase, Epoch 18/30, Loss: 14.773172
val phase, Epoch 18/30, Loss: 16.765970
Val Best Loss: 15.980900
Epoch loss: 16.765970
train phase, Epoch 19/30, Loss: 14.507971
val phase, Epoch 19/30, Loss: 16.361050
Val Best Loss: 15.980900
Epoch loss: 16.361050
train phase, Epoch 20/30, Loss: 14.327082
val phase, Epoch 20/30, Loss: 16.137794
Val Best Loss: 15.980900
Epoch loss: 16.137794
train phase, Epoch 21/30, Loss: 13.923501
val phase, Epoch 21/30, Loss: 18.000986
Val Best Loss: 15.980900
Epoch loss: 18.000986
train phase, Epoch 22/30, Loss: 13.621793
val phase, Epoch 22/30, Loss: 17.080241
Val Best Loss: 15.980900
Epoch loss: 17.080241
train phase, Epoch 23/30, Loss: 13.552911
val phase, Epoch 23/30, Loss: 17.160619
Val Best Loss: 15.980900
Epoch loss: 17.160619
train phase, Epoch 24/30, Loss: 12.962879
val phase, Epoch 24/30, Loss: 16.796526
Val Best Loss: 15.980900
Epoch loss: 16.796526
train phase, Epoch 25/30, Loss: 12.730468
val phase, Epoch 25/30, Loss: 16.861617
Val Best Loss: 15.980900
Epoch loss: 16.861617
train phase, Epoch 26/30, Loss: 12.185564
val phase, Epoch 26/30, Loss: 17.145033
Val Best Loss: 15.980900
Epoch loss: 17.145033
train phase, Epoch 27/30, Loss: 12.237030
val phase, Epoch 27/30, Loss: 17.445689
Val Best Loss: 15.980900
Epoch loss: 17.445689
train phase, Epoch 28/30, Loss: 11.413613
val phase, Epoch 28/30, Loss: 17.508649
Val Best Loss: 15.980900
Epoch loss: 17.508649
train phase, Epoch 29/30, Loss: 11.114459
val phase, Epoch 29/30, Loss: 17.804042
Val Best Loss: 15.980900
Epoch loss: 17.804042
train phase, Epoch 30/30, Loss: 10.773524
val phase, Epoch 30/30, Loss: 17.630153
Val Best Loss: 15.980900
Epoch loss: 17.630153
train phase, Epoch 1/30, Loss: 20.603165
val phase, Epoch 1/30, Loss: 17.410071
Val Best Loss: 17.410071
Epoch loss: 17.410071
train phase, Epoch 2/30, Loss: 18.103458
val phase, Epoch 2/30, Loss: 16.722887
Val Best Loss: 16.722887
Epoch loss: 16.722887
train phase, Epoch 3/30, Loss: 18.036052
val phase, Epoch 3/30, Loss: 17.569250
Val Best Loss: 16.722887
Epoch loss: 17.569250
train phase, Epoch 4/30, Loss: 17.335027
val phase, Epoch 4/30, Loss: 17.705616
Val Best Loss: 16.722887
Epoch loss: 17.705616
train phase, Epoch 5/30, Loss: 17.109377
val phase, Epoch 5/30, Loss: 16.429944
Val Best Loss: 16.429944
Epoch loss: 16.429944
train phase, Epoch 6/30, Loss: 16.922088
val phase, Epoch 6/30, Loss: 17.715683
Val Best Loss: 16.429944
Epoch loss: 17.715683
train phase, Epoch 7/30, Loss: 16.602020
val phase, Epoch 7/30, Loss: 16.886622
Val Best Loss: 16.429944
Epoch loss: 16.886622
train phase, Epoch 8/30, Loss: 16.673623
val phase, Epoch 8/30, Loss: 16.593874
Val Best Loss: 16.429944
Epoch loss: 16.593874
train phase, Epoch 9/30, Loss: 16.160709
val phase, Epoch 9/30, Loss: 16.086892
Val Best Loss: 16.086892
Epoch loss: 16.086892
train phase, Epoch 10/30, Loss: 16.004919
val phase, Epoch 10/30, Loss: 16.904626
Val Best Loss: 16.086892
Epoch loss: 16.904626
train phase, Epoch 11/30, Loss: 16.323270
val phase, Epoch 11/30, Loss: 15.939545
Val Best Loss: 15.939545
Epoch loss: 15.939545
train phase, Epoch 12/30, Loss: 15.734662
val phase, Epoch 12/30, Loss: 16.786888
Val Best Loss: 15.939545
Epoch loss: 16.786888
train phase, Epoch 13/30, Loss: 15.485840
val phase, Epoch 13/30, Loss: 15.980966
Val Best Loss: 15.939545
Epoch loss: 15.980966
train phase, Epoch 14/30, Loss: 15.312583
val phase, Epoch 14/30, Loss: 16.743586
Val Best Loss: 15.939545
Epoch loss: 16.743586
train phase, Epoch 15/30, Loss: 15.220479
val phase, Epoch 15/30, Loss: 16.091981
Val Best Loss: 15.939545
Epoch loss: 16.091981
train phase, Epoch 16/30, Loss: 15.168388
val phase, Epoch 16/30, Loss: 15.966196
Val Best Loss: 15.939545
Epoch loss: 15.966196
train phase, Epoch 17/30, Loss: 15.150014
val phase, Epoch 17/30, Loss: 16.534759
Val Best Loss: 15.939545
Epoch loss: 16.534759
train phase, Epoch 18/30, Loss: 14.707189
val phase, Epoch 18/30, Loss: 15.921017
Val Best Loss: 15.921017
Epoch loss: 15.921017
train phase, Epoch 19/30, Loss: 14.410698
val phase, Epoch 19/30, Loss: 16.990959
Val Best Loss: 15.921017
Epoch loss: 16.990959
train phase, Epoch 20/30, Loss: 14.303853
val phase, Epoch 20/30, Loss: 16.397499
Val Best Loss: 15.921017
Epoch loss: 16.397499
train phase, Epoch 21/30, Loss: 13.901712
val phase, Epoch 21/30, Loss: 17.759695
Val Best Loss: 15.921017
Epoch loss: 17.759695
train phase, Epoch 22/30, Loss: 13.853695
val phase, Epoch 22/30, Loss: 16.446865
Val Best Loss: 15.921017
Epoch loss: 16.446865
train phase, Epoch 23/30, Loss: 13.297669
val phase, Epoch 23/30, Loss: 17.252815
Val Best Loss: 15.921017
Epoch loss: 17.252815
train phase, Epoch 24/30, Loss: 13.542990
val phase, Epoch 24/30, Loss: 17.773450
Val Best Loss: 15.921017
Epoch loss: 17.773450
train phase, Epoch 25/30, Loss: 12.764927
val phase, Epoch 25/30, Loss: 17.248795
Val Best Loss: 15.921017
Epoch loss: 17.248795
train phase, Epoch 26/30, Loss: 12.412733
val phase, Epoch 26/30, Loss: 17.673507
Val Best Loss: 15.921017
Epoch loss: 17.673507
train phase, Epoch 27/30, Loss: 12.078636
val phase, Epoch 27/30, Loss: 17.506953
Val Best Loss: 15.921017
Epoch loss: 17.506953
train phase, Epoch 28/30, Loss: 11.905496
val phase, Epoch 28/30, Loss: 18.109218
Val Best Loss: 15.921017
Epoch loss: 18.109218
train phase, Epoch 29/30, Loss: 11.331291
val phase, Epoch 29/30, Loss: 18.343117
Val Best Loss: 15.921017
Epoch loss: 18.343117
train phase, Epoch 30/30, Loss: 10.946440
val phase, Epoch 30/30, Loss: 18.645320
Val Best Loss: 15.921017
Epoch loss: 18.645320
train phase, Epoch 1/30, Loss: 20.333635
val phase, Epoch 1/30, Loss: 16.801219
Val Best Loss: 16.801219
Epoch loss: 16.801219
train phase, Epoch 2/30, Loss: 17.952784
val phase, Epoch 2/30, Loss: 17.172321
Val Best Loss: 16.801219
Epoch loss: 17.172321
train phase, Epoch 3/30, Loss: 17.550437
val phase, Epoch 3/30, Loss: 17.196544
Val Best Loss: 16.801219
Epoch loss: 17.196544
train phase, Epoch 4/30, Loss: 17.295326
val phase, Epoch 4/30, Loss: 18.623211
Val Best Loss: 16.801219
Epoch loss: 18.623211
train phase, Epoch 5/30, Loss: 17.399660
val phase, Epoch 5/30, Loss: 17.855218
Val Best Loss: 16.801219
Epoch loss: 17.855218
train phase, Epoch 6/30, Loss: 16.665077
val phase, Epoch 6/30, Loss: 19.526117
Val Best Loss: 16.801219
Epoch loss: 19.526117
train phase, Epoch 7/30, Loss: 16.543275
val phase, Epoch 7/30, Loss: 16.720649
Val Best Loss: 16.720649
Epoch loss: 16.720649
train phase, Epoch 8/30, Loss: 16.704532
val phase, Epoch 8/30, Loss: 16.246223
Val Best Loss: 16.246223
Epoch loss: 16.246223
train phase, Epoch 9/30, Loss: 16.232205
val phase, Epoch 9/30, Loss: 16.669015
Val Best Loss: 16.246223
Epoch loss: 16.669015
train phase, Epoch 10/30, Loss: 16.134372
val phase, Epoch 10/30, Loss: 17.529704
Val Best Loss: 16.246223
Epoch loss: 17.529704
train phase, Epoch 11/30, Loss: 16.092237
val phase, Epoch 11/30, Loss: 16.126967
Val Best Loss: 16.126967
Epoch loss: 16.126967
train phase, Epoch 12/30, Loss: 15.816747
val phase, Epoch 12/30, Loss: 17.944039
Val Best Loss: 16.126967
Epoch loss: 17.944039
train phase, Epoch 13/30, Loss: 15.806097
val phase, Epoch 13/30, Loss: 16.510760
Val Best Loss: 16.126967
Epoch loss: 16.510760
train phase, Epoch 14/30, Loss: 15.695147
val phase, Epoch 14/30, Loss: 17.098305
Val Best Loss: 16.126967
Epoch loss: 17.098305
train phase, Epoch 15/30, Loss: 15.596684
val phase, Epoch 15/30, Loss: 16.622036
Val Best Loss: 16.126967
Epoch loss: 16.622036
train phase, Epoch 16/30, Loss: 15.154480
val phase, Epoch 16/30, Loss: 16.007201
Val Best Loss: 16.007201
Epoch loss: 16.007201
train phase, Epoch 17/30, Loss: 15.259631
val phase, Epoch 17/30, Loss: 16.067082
Val Best Loss: 16.007201
Epoch loss: 16.067082
train phase, Epoch 18/30, Loss: 14.977471
val phase, Epoch 18/30, Loss: 18.190674
Val Best Loss: 16.007201
Epoch loss: 18.190674
train phase, Epoch 19/30, Loss: 14.606878
val phase, Epoch 19/30, Loss: 16.173853
Val Best Loss: 16.007201
Epoch loss: 16.173853
train phase, Epoch 20/30, Loss: 14.426610
val phase, Epoch 20/30, Loss: 16.337898
Val Best Loss: 16.007201
Epoch loss: 16.337898
train phase, Epoch 21/30, Loss: 14.573031
val phase, Epoch 21/30, Loss: 17.380560
Val Best Loss: 16.007201
Epoch loss: 17.380560
train phase, Epoch 22/30, Loss: 13.909521
val phase, Epoch 22/30, Loss: 17.249718
Val Best Loss: 16.007201
Epoch loss: 17.249718
train phase, Epoch 23/30, Loss: 13.584833
val phase, Epoch 23/30, Loss: 17.322939
Val Best Loss: 16.007201
Epoch loss: 17.322939
train phase, Epoch 24/30, Loss: 13.280224
val phase, Epoch 24/30, Loss: 17.105943
Val Best Loss: 16.007201
Epoch loss: 17.105943
train phase, Epoch 25/30, Loss: 13.294305
val phase, Epoch 25/30, Loss: 17.036885
Val Best Loss: 16.007201
Epoch loss: 17.036885
train phase, Epoch 26/30, Loss: 12.635054
val phase, Epoch 26/30, Loss: 19.200582
Val Best Loss: 16.007201
Epoch loss: 19.200582
train phase, Epoch 27/30, Loss: 12.342648
val phase, Epoch 27/30, Loss: 17.848491
Val Best Loss: 16.007201
Epoch loss: 17.848491
train phase, Epoch 28/30, Loss: 11.704556
val phase, Epoch 28/30, Loss: 19.627064
Val Best Loss: 16.007201
Epoch loss: 19.627064
train phase, Epoch 29/30, Loss: 11.416243
val phase, Epoch 29/30, Loss: 21.115421
Val Best Loss: 16.007201
Epoch loss: 21.115421
train phase, Epoch 30/30, Loss: 10.953372
val phase, Epoch 30/30, Loss: 18.881868
Val Best Loss: 16.007201
Epoch loss: 18.881868
train phase, Epoch 1/20, Loss: 20.213046
val phase, Epoch 1/20, Loss: 17.775085
Val Best Loss: 17.775085
Epoch loss: 17.775085
train phase, Epoch 2/20, Loss: 17.956086
val phase, Epoch 2/20, Loss: 16.841588
Val Best Loss: 16.841588
Epoch loss: 16.841588
train phase, Epoch 3/20, Loss: 18.110486
val phase, Epoch 3/20, Loss: 20.988595
Val Best Loss: 16.841588
Epoch loss: 20.988595
train phase, Epoch 4/20, Loss: 17.450786
val phase, Epoch 4/20, Loss: 16.676633
Val Best Loss: 16.676633
Epoch loss: 16.676633
train phase, Epoch 5/20, Loss: 17.264758
val phase, Epoch 5/20, Loss: 18.306261
Val Best Loss: 16.676633
Epoch loss: 18.306261
train phase, Epoch 6/20, Loss: 16.701674
val phase, Epoch 6/20, Loss: 16.781357
Val Best Loss: 16.676633
Epoch loss: 16.781357
train phase, Epoch 7/20, Loss: 16.512618
val phase, Epoch 7/20, Loss: 16.392875
Val Best Loss: 16.392875
Epoch loss: 16.392875
train phase, Epoch 8/20, Loss: 16.293178
val phase, Epoch 8/20, Loss: 16.127112
Val Best Loss: 16.127112
Epoch loss: 16.127112
train phase, Epoch 9/20, Loss: 16.031534
val phase, Epoch 9/20, Loss: 15.999277
Val Best Loss: 15.999277
Epoch loss: 15.999277
train phase, Epoch 10/20, Loss: 15.880305
val phase, Epoch 10/20, Loss: 17.707388
Val Best Loss: 15.999277
Epoch loss: 17.707388
train phase, Epoch 11/20, Loss: 15.993000
val phase, Epoch 11/20, Loss: 16.276926
Val Best Loss: 15.999277
Epoch loss: 16.276926
train phase, Epoch 12/20, Loss: 15.635486
val phase, Epoch 12/20, Loss: 15.770042
Val Best Loss: 15.770042
Epoch loss: 15.770042
train phase, Epoch 13/20, Loss: 15.478158
val phase, Epoch 13/20, Loss: 16.366524
Val Best Loss: 15.770042
Epoch loss: 16.366524
train phase, Epoch 14/20, Loss: 15.441464
val phase, Epoch 14/20, Loss: 15.744006
Val Best Loss: 15.744006
Epoch loss: 15.744006
train phase, Epoch 15/20, Loss: 15.099897
val phase, Epoch 15/20, Loss: 17.687574
Val Best Loss: 15.744006
Epoch loss: 17.687574
train phase, Epoch 16/20, Loss: 14.900825
val phase, Epoch 16/20, Loss: 15.937636
Val Best Loss: 15.744006
Epoch loss: 15.937636
train phase, Epoch 17/20, Loss: 14.696610
val phase, Epoch 17/20, Loss: 15.681315
Val Best Loss: 15.681315
Epoch loss: 15.681315
train phase, Epoch 18/20, Loss: 14.600346
val phase, Epoch 18/20, Loss: 15.935570
Val Best Loss: 15.681315
Epoch loss: 15.935570
train phase, Epoch 19/20, Loss: 14.234950
val phase, Epoch 19/20, Loss: 17.471870
Val Best Loss: 15.681315
Epoch loss: 17.471870
train phase, Epoch 20/20, Loss: 13.722015
val phase, Epoch 20/20, Loss: 16.278055
Val Best Loss: 15.681315
Epoch loss: 16.278055
train phase, Epoch 1/20, Loss: 19.669638
val phase, Epoch 1/20, Loss: 18.061619
Val Best Loss: 18.061619
Epoch loss: 18.061619
train phase, Epoch 2/20, Loss: 17.621559
val phase, Epoch 2/20, Loss: 16.998519
Val Best Loss: 16.998519
Epoch loss: 16.998519
train phase, Epoch 3/20, Loss: 17.405780
val phase, Epoch 3/20, Loss: 19.496116
Val Best Loss: 16.998519
Epoch loss: 19.496116
train phase, Epoch 4/20, Loss: 17.031655
val phase, Epoch 4/20, Loss: 16.581408
Val Best Loss: 16.581408
Epoch loss: 16.581408
train phase, Epoch 5/20, Loss: 16.912702
val phase, Epoch 5/20, Loss: 16.314148
Val Best Loss: 16.314148
Epoch loss: 16.314148
train phase, Epoch 6/20, Loss: 16.423940
val phase, Epoch 6/20, Loss: 17.575766
Val Best Loss: 16.314148
Epoch loss: 17.575766
train phase, Epoch 7/20, Loss: 16.543082
val phase, Epoch 7/20, Loss: 17.348517
Val Best Loss: 16.314148
Epoch loss: 17.348517
train phase, Epoch 8/20, Loss: 16.352051
val phase, Epoch 8/20, Loss: 16.364838
Val Best Loss: 16.314148
Epoch loss: 16.364838
train phase, Epoch 9/20, Loss: 15.921829
val phase, Epoch 9/20, Loss: 15.922245
Val Best Loss: 15.922245
Epoch loss: 15.922245
train phase, Epoch 10/20, Loss: 15.652070
val phase, Epoch 10/20, Loss: 16.308580
Val Best Loss: 15.922245
Epoch loss: 16.308580
train phase, Epoch 11/20, Loss: 15.669459
val phase, Epoch 11/20, Loss: 18.054123
Val Best Loss: 15.922245
Epoch loss: 18.054123
train phase, Epoch 12/20, Loss: 15.399454
val phase, Epoch 12/20, Loss: 16.273507
Val Best Loss: 15.922245
Epoch loss: 16.273507
train phase, Epoch 13/20, Loss: 15.150470
val phase, Epoch 13/20, Loss: 16.234766
Val Best Loss: 15.922245
Epoch loss: 16.234766
train phase, Epoch 14/20, Loss: 14.989473
val phase, Epoch 14/20, Loss: 16.300109
Val Best Loss: 15.922245
Epoch loss: 16.300109
train phase, Epoch 15/20, Loss: 14.813515
val phase, Epoch 15/20, Loss: 16.631669
Val Best Loss: 15.922245
Epoch loss: 16.631669
train phase, Epoch 16/20, Loss: 14.608045
val phase, Epoch 16/20, Loss: 16.782004
Val Best Loss: 15.922245
Epoch loss: 16.782004
train phase, Epoch 17/20, Loss: 14.305080
val phase, Epoch 17/20, Loss: 16.784892
Val Best Loss: 15.922245
Epoch loss: 16.784892
train phase, Epoch 18/20, Loss: 14.073711
val phase, Epoch 18/20, Loss: 16.583811
Val Best Loss: 15.922245
Epoch loss: 16.583811
train phase, Epoch 19/20, Loss: 13.994029
val phase, Epoch 19/20, Loss: 16.530757
Val Best Loss: 15.922245
Epoch loss: 16.530757
train phase, Epoch 20/20, Loss: 13.430196
val phase, Epoch 20/20, Loss: 16.633141
Val Best Loss: 15.922245
Epoch loss: 16.633141
train phase, Epoch 1/20, Loss: 20.336846
val phase, Epoch 1/20, Loss: 22.634089
Val Best Loss: 22.634089
Epoch loss: 22.634089
train phase, Epoch 2/20, Loss: 18.886956
val phase, Epoch 2/20, Loss: 18.417843
Val Best Loss: 18.417843
Epoch loss: 18.417843
train phase, Epoch 3/20, Loss: 18.285887
val phase, Epoch 3/20, Loss: 19.861546
Val Best Loss: 18.417843
Epoch loss: 19.861546
train phase, Epoch 4/20, Loss: 17.840109
val phase, Epoch 4/20, Loss: 18.923199
Val Best Loss: 18.417843
Epoch loss: 18.923199
train phase, Epoch 5/20, Loss: 17.565910
val phase, Epoch 5/20, Loss: 19.330720
Val Best Loss: 18.417843
Epoch loss: 19.330720
train phase, Epoch 6/20, Loss: 17.365844
val phase, Epoch 6/20, Loss: 16.928741
Val Best Loss: 16.928741
Epoch loss: 16.928741
train phase, Epoch 7/20, Loss: 17.153889
val phase, Epoch 7/20, Loss: 16.659000
Val Best Loss: 16.659000
Epoch loss: 16.659000
train phase, Epoch 8/20, Loss: 16.922023
val phase, Epoch 8/20, Loss: 17.588113
Val Best Loss: 16.659000
Epoch loss: 17.588113
train phase, Epoch 9/20, Loss: 16.685035
val phase, Epoch 9/20, Loss: 16.651564
Val Best Loss: 16.651564
Epoch loss: 16.651564
train phase, Epoch 10/20, Loss: 16.437073
val phase, Epoch 10/20, Loss: 16.367671
Val Best Loss: 16.367671
Epoch loss: 16.367671
train phase, Epoch 11/20, Loss: 16.280465
val phase, Epoch 11/20, Loss: 16.801162
Val Best Loss: 16.367671
Epoch loss: 16.801162
train phase, Epoch 12/20, Loss: 16.240564
val phase, Epoch 12/20, Loss: 17.256940
Val Best Loss: 16.367671
Epoch loss: 17.256940
train phase, Epoch 13/20, Loss: 16.080607
val phase, Epoch 13/20, Loss: 16.660993
Val Best Loss: 16.367671
Epoch loss: 16.660993
train phase, Epoch 14/20, Loss: 15.750927
val phase, Epoch 14/20, Loss: 17.288256
Val Best Loss: 16.367671
Epoch loss: 17.288256
train phase, Epoch 15/20, Loss: 15.769743
val phase, Epoch 15/20, Loss: 16.399164
Val Best Loss: 16.367671
Epoch loss: 16.399164
train phase, Epoch 16/20, Loss: 15.359169
val phase, Epoch 16/20, Loss: 16.642923
Val Best Loss: 16.367671
Epoch loss: 16.642923
train phase, Epoch 17/20, Loss: 15.105452
val phase, Epoch 17/20, Loss: 16.559831
Val Best Loss: 16.367671
Epoch loss: 16.559831
train phase, Epoch 18/20, Loss: 15.123624
val phase, Epoch 18/20, Loss: 17.298502
Val Best Loss: 16.367671
Epoch loss: 17.298502
train phase, Epoch 19/20, Loss: 14.657991
val phase, Epoch 19/20, Loss: 16.634929
Val Best Loss: 16.367671
Epoch loss: 16.634929
train phase, Epoch 20/20, Loss: 14.590561
val phase, Epoch 20/20, Loss: 16.972084
Val Best Loss: 16.367671
Epoch loss: 16.972084
train phase, Epoch 1/20, Loss: 19.650420
val phase, Epoch 1/20, Loss: 17.453675
Val Best Loss: 17.453675
Epoch loss: 17.453675
train phase, Epoch 2/20, Loss: 17.681926
val phase, Epoch 2/20, Loss: 16.458928
Val Best Loss: 16.458928
Epoch loss: 16.458928
train phase, Epoch 3/20, Loss: 17.230876
val phase, Epoch 3/20, Loss: 17.596748
Val Best Loss: 16.458928
Epoch loss: 17.596748
train phase, Epoch 4/20, Loss: 16.943963
val phase, Epoch 4/20, Loss: 16.182533
Val Best Loss: 16.182533
Epoch loss: 16.182533
train phase, Epoch 5/20, Loss: 16.594695
val phase, Epoch 5/20, Loss: 19.157682
Val Best Loss: 16.182533
Epoch loss: 19.157682
train phase, Epoch 6/20, Loss: 16.802477
val phase, Epoch 6/20, Loss: 19.451121
Val Best Loss: 16.182533
Epoch loss: 19.451121
train phase, Epoch 7/20, Loss: 16.454324
val phase, Epoch 7/20, Loss: 16.042237
Val Best Loss: 16.042237
Epoch loss: 16.042237
train phase, Epoch 8/20, Loss: 16.400034
val phase, Epoch 8/20, Loss: 15.967080
Val Best Loss: 15.967080
Epoch loss: 15.967080
train phase, Epoch 9/20, Loss: 16.100967
val phase, Epoch 9/20, Loss: 16.171325
Val Best Loss: 15.967080
Epoch loss: 16.171325
train phase, Epoch 10/20, Loss: 16.026898
val phase, Epoch 10/20, Loss: 16.037792
Val Best Loss: 15.967080
Epoch loss: 16.037792
train phase, Epoch 11/20, Loss: 15.930232
val phase, Epoch 11/20, Loss: 15.854158
Val Best Loss: 15.854158
Epoch loss: 15.854158
train phase, Epoch 12/20, Loss: 15.417515
val phase, Epoch 12/20, Loss: 16.421952
Val Best Loss: 15.854158
Epoch loss: 16.421952
train phase, Epoch 13/20, Loss: 15.557429
val phase, Epoch 13/20, Loss: 19.229232
Val Best Loss: 15.854158
Epoch loss: 19.229232
train phase, Epoch 14/20, Loss: 15.409416
val phase, Epoch 14/20, Loss: 16.516059
Val Best Loss: 15.854158
Epoch loss: 16.516059
train phase, Epoch 15/20, Loss: 14.974347
val phase, Epoch 15/20, Loss: 16.379487
Val Best Loss: 15.854158
Epoch loss: 16.379487
train phase, Epoch 16/20, Loss: 14.815242
val phase, Epoch 16/20, Loss: 15.959511
Val Best Loss: 15.854158
Epoch loss: 15.959511
train phase, Epoch 17/20, Loss: 14.617038
val phase, Epoch 17/20, Loss: 15.738331
Val Best Loss: 15.738331
Epoch loss: 15.738331
train phase, Epoch 18/20, Loss: 14.449300
val phase, Epoch 18/20, Loss: 17.135988
Val Best Loss: 15.738331
Epoch loss: 17.135988
train phase, Epoch 19/20, Loss: 14.086463
val phase, Epoch 19/20, Loss: 15.947408
Val Best Loss: 15.738331
Epoch loss: 15.947408
train phase, Epoch 20/20, Loss: 13.959552
val phase, Epoch 20/20, Loss: 16.158461
Val Best Loss: 15.738331
Epoch loss: 16.158461
train phase, Epoch 1/20, Loss: 20.169542
val phase, Epoch 1/20, Loss: 17.113679
Val Best Loss: 17.113679
Epoch loss: 17.113679
train phase, Epoch 2/20, Loss: 17.579690
val phase, Epoch 2/20, Loss: 17.256410
Val Best Loss: 17.113679
Epoch loss: 17.256410
train phase, Epoch 3/20, Loss: 17.616387
val phase, Epoch 3/20, Loss: 16.713456
Val Best Loss: 16.713456
Epoch loss: 16.713456
train phase, Epoch 4/20, Loss: 16.823456
val phase, Epoch 4/20, Loss: 16.360691
Val Best Loss: 16.360691
Epoch loss: 16.360691
train phase, Epoch 5/20, Loss: 16.970100
val phase, Epoch 5/20, Loss: 16.439166
Val Best Loss: 16.360691
Epoch loss: 16.439166
train phase, Epoch 6/20, Loss: 16.539312
val phase, Epoch 6/20, Loss: 16.412795
Val Best Loss: 16.360691
Epoch loss: 16.412795
train phase, Epoch 7/20, Loss: 16.574489
val phase, Epoch 7/20, Loss: 16.298208
Val Best Loss: 16.298208
Epoch loss: 16.298208
train phase, Epoch 8/20, Loss: 16.678920
val phase, Epoch 8/20, Loss: 16.714689
Val Best Loss: 16.298208
Epoch loss: 16.714689
train phase, Epoch 9/20, Loss: 16.205500
val phase, Epoch 9/20, Loss: 16.080412
Val Best Loss: 16.080412
Epoch loss: 16.080412
train phase, Epoch 10/20, Loss: 16.150593
val phase, Epoch 10/20, Loss: 17.767431
Val Best Loss: 16.080412
Epoch loss: 17.767431
train phase, Epoch 11/20, Loss: 16.046586
val phase, Epoch 11/20, Loss: 16.527050
Val Best Loss: 16.080412
Epoch loss: 16.527050
train phase, Epoch 12/20, Loss: 15.871676
val phase, Epoch 12/20, Loss: 16.172845
Val Best Loss: 16.080412
Epoch loss: 16.172845
train phase, Epoch 13/20, Loss: 15.505962
val phase, Epoch 13/20, Loss: 16.095557
Val Best Loss: 16.080412
Epoch loss: 16.095557
train phase, Epoch 14/20, Loss: 15.575452
val phase, Epoch 14/20, Loss: 16.134272
Val Best Loss: 16.080412
Epoch loss: 16.134272
train phase, Epoch 15/20, Loss: 15.455799
val phase, Epoch 15/20, Loss: 16.614979
Val Best Loss: 16.080412
Epoch loss: 16.614979
train phase, Epoch 16/20, Loss: 15.325724
val phase, Epoch 16/20, Loss: 15.690085
Val Best Loss: 15.690085
Epoch loss: 15.690085
train phase, Epoch 17/20, Loss: 14.979056
val phase, Epoch 17/20, Loss: 15.786367
Val Best Loss: 15.690085
Epoch loss: 15.786367
train phase, Epoch 18/20, Loss: 14.806503
val phase, Epoch 18/20, Loss: 17.105632
Val Best Loss: 15.690085
Epoch loss: 17.105632
train phase, Epoch 19/20, Loss: 14.727231
val phase, Epoch 19/20, Loss: 16.314734
Val Best Loss: 15.690085
Epoch loss: 16.314734
train phase, Epoch 20/20, Loss: 14.252871
val phase, Epoch 20/20, Loss: 15.996250
Val Best Loss: 15.690085
Epoch loss: 15.996250
train phase, Epoch 1/20, Loss: 19.732617
val phase, Epoch 1/20, Loss: 18.903895
Val Best Loss: 18.903895
Epoch loss: 18.903895
train phase, Epoch 2/20, Loss: 17.630985
val phase, Epoch 2/20, Loss: 16.796643
Val Best Loss: 16.796643
Epoch loss: 16.796643
train phase, Epoch 3/20, Loss: 17.092372
val phase, Epoch 3/20, Loss: 16.705940
Val Best Loss: 16.705940
Epoch loss: 16.705940
train phase, Epoch 4/20, Loss: 17.049458
val phase, Epoch 4/20, Loss: 16.426403
Val Best Loss: 16.426403
Epoch loss: 16.426403
train phase, Epoch 5/20, Loss: 16.822944
val phase, Epoch 5/20, Loss: 15.985350
Val Best Loss: 15.985350
Epoch loss: 15.985350
train phase, Epoch 6/20, Loss: 16.692641
val phase, Epoch 6/20, Loss: 16.411163
Val Best Loss: 15.985350
Epoch loss: 16.411163
train phase, Epoch 7/20, Loss: 16.497129
val phase, Epoch 7/20, Loss: 16.021339
Val Best Loss: 15.985350
Epoch loss: 16.021339
train phase, Epoch 8/20, Loss: 16.305739
val phase, Epoch 8/20, Loss: 16.045551
Val Best Loss: 15.985350
Epoch loss: 16.045551
train phase, Epoch 9/20, Loss: 15.879984
val phase, Epoch 9/20, Loss: 15.995519
Val Best Loss: 15.985350
Epoch loss: 15.995519
train phase, Epoch 10/20, Loss: 15.864044
val phase, Epoch 10/20, Loss: 17.575401
Val Best Loss: 15.985350
Epoch loss: 17.575401
train phase, Epoch 11/20, Loss: 15.659159
val phase, Epoch 11/20, Loss: 16.472668
Val Best Loss: 15.985350
Epoch loss: 16.472668
train phase, Epoch 12/20, Loss: 15.555036
val phase, Epoch 12/20, Loss: 15.941972
Val Best Loss: 15.941972
Epoch loss: 15.941972
train phase, Epoch 13/20, Loss: 15.293085
val phase, Epoch 13/20, Loss: 15.909591
Val Best Loss: 15.909591
Epoch loss: 15.909591
train phase, Epoch 14/20, Loss: 15.112904
val phase, Epoch 14/20, Loss: 16.119353
Val Best Loss: 15.909591
Epoch loss: 16.119353
train phase, Epoch 15/20, Loss: 15.197091
val phase, Epoch 15/20, Loss: 16.495021
Val Best Loss: 15.909591
Epoch loss: 16.495021
train phase, Epoch 16/20, Loss: 14.701488
val phase, Epoch 16/20, Loss: 16.464820
Val Best Loss: 15.909591
Epoch loss: 16.464820
train phase, Epoch 17/20, Loss: 14.437398
val phase, Epoch 17/20, Loss: 16.566861
Val Best Loss: 15.909591
Epoch loss: 16.566861
train phase, Epoch 18/20, Loss: 14.322573
val phase, Epoch 18/20, Loss: 16.818959
Val Best Loss: 15.909591
Epoch loss: 16.818959
train phase, Epoch 19/20, Loss: 14.174861
val phase, Epoch 19/20, Loss: 17.538779
Val Best Loss: 15.909591
Epoch loss: 17.538779
train phase, Epoch 20/20, Loss: 13.664687
val phase, Epoch 20/20, Loss: 16.348910
Val Best Loss: 15.909591
Epoch loss: 16.348910
[Trial 110] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.873837
val phase, Epoch 1/20, Loss: 17.983646
Val Best Loss: 17.983646
Epoch loss: 17.983646
train phase, Epoch 2/20, Loss: 17.824504
val phase, Epoch 2/20, Loss: 18.627074
Val Best Loss: 17.983646
Epoch loss: 18.627074
train phase, Epoch 3/20, Loss: 17.584830
val phase, Epoch 3/20, Loss: 17.607497
Val Best Loss: 17.607497
Epoch loss: 17.607497
train phase, Epoch 4/20, Loss: 17.251750
val phase, Epoch 4/20, Loss: 19.911510
Val Best Loss: 17.607497
Epoch loss: 19.911510
train phase, Epoch 5/20, Loss: 16.751834
val phase, Epoch 5/20, Loss: 19.473846
Val Best Loss: 17.607497
Epoch loss: 19.473846
train phase, Epoch 6/20, Loss: 16.867539
val phase, Epoch 6/20, Loss: 16.634306
Val Best Loss: 16.634306
Epoch loss: 16.634306
train phase, Epoch 7/20, Loss: 16.466613
val phase, Epoch 7/20, Loss: 16.542327
Val Best Loss: 16.542327
Epoch loss: 16.542327
train phase, Epoch 8/20, Loss: 16.315247
val phase, Epoch 8/20, Loss: 17.917958
Val Best Loss: 16.542327
Epoch loss: 17.917958
train phase, Epoch 9/20, Loss: 16.183028
val phase, Epoch 9/20, Loss: 17.881896
Val Best Loss: 16.542327
Epoch loss: 17.881896
train phase, Epoch 10/20, Loss: 16.119624
val phase, Epoch 10/20, Loss: 15.921373
Val Best Loss: 15.921373
Epoch loss: 15.921373
train phase, Epoch 11/20, Loss: 15.920195
val phase, Epoch 11/20, Loss: 16.150982
Val Best Loss: 15.921373
Epoch loss: 16.150982
train phase, Epoch 12/20, Loss: 15.772994
val phase, Epoch 12/20, Loss: 16.534103
Val Best Loss: 15.921373
Epoch loss: 16.534103
train phase, Epoch 13/20, Loss: 15.468792
val phase, Epoch 13/20, Loss: 15.669377
Val Best Loss: 15.669377
Epoch loss: 15.669377
train phase, Epoch 14/20, Loss: 15.532392
val phase, Epoch 14/20, Loss: 16.455118
Val Best Loss: 15.669377
Epoch loss: 16.455118
train phase, Epoch 15/20, Loss: 15.206042
val phase, Epoch 15/20, Loss: 16.140219
Val Best Loss: 15.669377
Epoch loss: 16.140219
train phase, Epoch 16/20, Loss: 14.954486
val phase, Epoch 16/20, Loss: 15.840833
Val Best Loss: 15.669377
Epoch loss: 15.840833
train phase, Epoch 17/20, Loss: 14.709385
val phase, Epoch 17/20, Loss: 15.740719
Val Best Loss: 15.669377
Epoch loss: 15.740719
train phase, Epoch 18/20, Loss: 14.529398
val phase, Epoch 18/20, Loss: 17.775485
Val Best Loss: 15.669377
Epoch loss: 17.775485
train phase, Epoch 19/20, Loss: 14.473429
val phase, Epoch 19/20, Loss: 16.377233
Val Best Loss: 15.669377
Epoch loss: 16.377233
train phase, Epoch 20/20, Loss: 14.022124
val phase, Epoch 20/20, Loss: 17.800574
Val Best Loss: 15.669377
Epoch loss: 17.800574
train phase, Epoch 1/20, Loss: 20.328972
val phase, Epoch 1/20, Loss: 18.215987
Val Best Loss: 18.215987
Epoch loss: 18.215987
train phase, Epoch 2/20, Loss: 17.674698
val phase, Epoch 2/20, Loss: 26.622950
Val Best Loss: 18.215987
Epoch loss: 26.622950
train phase, Epoch 3/20, Loss: 17.533230
val phase, Epoch 3/20, Loss: 16.988491
Val Best Loss: 16.988491
Epoch loss: 16.988491
train phase, Epoch 4/20, Loss: 17.050603
val phase, Epoch 4/20, Loss: 16.808626
Val Best Loss: 16.808626
Epoch loss: 16.808626
train phase, Epoch 5/20, Loss: 16.874226
val phase, Epoch 5/20, Loss: 16.115562
Val Best Loss: 16.115562
Epoch loss: 16.115562
train phase, Epoch 6/20, Loss: 16.461028
val phase, Epoch 6/20, Loss: 16.247104
Val Best Loss: 16.115562
Epoch loss: 16.247104
train phase, Epoch 7/20, Loss: 16.481888
val phase, Epoch 7/20, Loss: 16.601474
Val Best Loss: 16.115562
Epoch loss: 16.601474
train phase, Epoch 8/20, Loss: 16.351891
val phase, Epoch 8/20, Loss: 18.778623
Val Best Loss: 16.115562
Epoch loss: 18.778623
train phase, Epoch 9/20, Loss: 16.024778
val phase, Epoch 9/20, Loss: 15.695303
Val Best Loss: 15.695303
Epoch loss: 15.695303
train phase, Epoch 10/20, Loss: 15.710555
val phase, Epoch 10/20, Loss: 17.296782
Val Best Loss: 15.695303
Epoch loss: 17.296782
train phase, Epoch 11/20, Loss: 15.786020
val phase, Epoch 11/20, Loss: 16.151308
Val Best Loss: 15.695303
Epoch loss: 16.151308
train phase, Epoch 12/20, Loss: 15.464073
val phase, Epoch 12/20, Loss: 17.107005
Val Best Loss: 15.695303
Epoch loss: 17.107005
train phase, Epoch 13/20, Loss: 15.518462
val phase, Epoch 13/20, Loss: 18.192523
Val Best Loss: 15.695303
Epoch loss: 18.192523
train phase, Epoch 14/20, Loss: 15.407819
val phase, Epoch 14/20, Loss: 16.782056
Val Best Loss: 15.695303
Epoch loss: 16.782056
train phase, Epoch 15/20, Loss: 15.171196
val phase, Epoch 15/20, Loss: 15.895272
Val Best Loss: 15.695303
Epoch loss: 15.895272
train phase, Epoch 16/20, Loss: 14.802280
val phase, Epoch 16/20, Loss: 15.780106
Val Best Loss: 15.695303
Epoch loss: 15.780106
train phase, Epoch 17/20, Loss: 14.595978
val phase, Epoch 17/20, Loss: 20.817630
Val Best Loss: 15.695303
Epoch loss: 20.817630
train phase, Epoch 18/20, Loss: 14.538239
val phase, Epoch 18/20, Loss: 16.773052
Val Best Loss: 15.695303
Epoch loss: 16.773052
train phase, Epoch 19/20, Loss: 14.129418
val phase, Epoch 19/20, Loss: 16.629860
Val Best Loss: 15.695303
Epoch loss: 16.629860
train phase, Epoch 20/20, Loss: 13.997212
val phase, Epoch 20/20, Loss: 16.403240
Val Best Loss: 15.695303
Epoch loss: 16.403240
train phase, Epoch 1/20, Loss: 19.902858
val phase, Epoch 1/20, Loss: 17.164935
Val Best Loss: 17.164935
Epoch loss: 17.164935
train phase, Epoch 2/20, Loss: 17.632437
val phase, Epoch 2/20, Loss: 19.488539
Val Best Loss: 17.164935
Epoch loss: 19.488539
train phase, Epoch 3/20, Loss: 17.344070
val phase, Epoch 3/20, Loss: 17.353066
Val Best Loss: 17.164935
Epoch loss: 17.353066
train phase, Epoch 4/20, Loss: 16.941602
val phase, Epoch 4/20, Loss: 18.280474
Val Best Loss: 17.164935
Epoch loss: 18.280474
train phase, Epoch 5/20, Loss: 16.807725
val phase, Epoch 5/20, Loss: 16.560789
Val Best Loss: 16.560789
Epoch loss: 16.560789
train phase, Epoch 6/20, Loss: 16.478086
val phase, Epoch 6/20, Loss: 15.875800
Val Best Loss: 15.875800
Epoch loss: 15.875800
train phase, Epoch 7/20, Loss: 16.196705
val phase, Epoch 7/20, Loss: 16.463013
Val Best Loss: 15.875800
Epoch loss: 16.463013
train phase, Epoch 8/20, Loss: 16.280206
val phase, Epoch 8/20, Loss: 16.883260
Val Best Loss: 15.875800
Epoch loss: 16.883260
train phase, Epoch 9/20, Loss: 16.029900
val phase, Epoch 9/20, Loss: 15.835630
Val Best Loss: 15.835630
Epoch loss: 15.835630
train phase, Epoch 10/20, Loss: 15.648639
val phase, Epoch 10/20, Loss: 15.996612
Val Best Loss: 15.835630
Epoch loss: 15.996612
train phase, Epoch 11/20, Loss: 15.725301
val phase, Epoch 11/20, Loss: 16.292227
Val Best Loss: 15.835630
Epoch loss: 16.292227
train phase, Epoch 12/20, Loss: 15.462077
val phase, Epoch 12/20, Loss: 16.100195
Val Best Loss: 15.835630
Epoch loss: 16.100195
train phase, Epoch 13/20, Loss: 15.203076
val phase, Epoch 13/20, Loss: 15.644071
Val Best Loss: 15.644071
Epoch loss: 15.644071
train phase, Epoch 14/20, Loss: 15.162881
val phase, Epoch 14/20, Loss: 16.277505
Val Best Loss: 15.644071
Epoch loss: 16.277505
train phase, Epoch 15/20, Loss: 14.752098
val phase, Epoch 15/20, Loss: 15.854498
Val Best Loss: 15.644071
Epoch loss: 15.854498
train phase, Epoch 16/20, Loss: 14.829274
val phase, Epoch 16/20, Loss: 16.357721
Val Best Loss: 15.644071
Epoch loss: 16.357721
train phase, Epoch 17/20, Loss: 14.441306
val phase, Epoch 17/20, Loss: 16.188600
Val Best Loss: 15.644071
Epoch loss: 16.188600
train phase, Epoch 18/20, Loss: 14.038293
val phase, Epoch 18/20, Loss: 16.657797
Val Best Loss: 15.644071
Epoch loss: 16.657797
train phase, Epoch 19/20, Loss: 13.826969
val phase, Epoch 19/20, Loss: 16.992571
Val Best Loss: 15.644071
Epoch loss: 16.992571
train phase, Epoch 20/20, Loss: 13.559074
val phase, Epoch 20/20, Loss: 16.776299
Val Best Loss: 15.644071
Epoch loss: 16.776299
train phase, Epoch 1/20, Loss: 20.480444
val phase, Epoch 1/20, Loss: 17.622036
Val Best Loss: 17.622036
Epoch loss: 17.622036
train phase, Epoch 2/20, Loss: 17.446266
val phase, Epoch 2/20, Loss: 21.471963
Val Best Loss: 17.622036
Epoch loss: 21.471963
train phase, Epoch 3/20, Loss: 17.261923
val phase, Epoch 3/20, Loss: 17.142605
Val Best Loss: 17.142605
Epoch loss: 17.142605
train phase, Epoch 4/20, Loss: 17.069588
val phase, Epoch 4/20, Loss: 16.389457
Val Best Loss: 16.389457
Epoch loss: 16.389457
train phase, Epoch 5/20, Loss: 16.939369
val phase, Epoch 5/20, Loss: 16.543591
Val Best Loss: 16.389457
Epoch loss: 16.543591
train phase, Epoch 6/20, Loss: 16.676033
val phase, Epoch 6/20, Loss: 16.444513
Val Best Loss: 16.389457
Epoch loss: 16.444513
train phase, Epoch 7/20, Loss: 16.370419
val phase, Epoch 7/20, Loss: 16.094666
Val Best Loss: 16.094666
Epoch loss: 16.094666
train phase, Epoch 8/20, Loss: 16.212469
val phase, Epoch 8/20, Loss: 16.988904
Val Best Loss: 16.094666
Epoch loss: 16.988904
train phase, Epoch 9/20, Loss: 16.204711
val phase, Epoch 9/20, Loss: 16.178796
Val Best Loss: 16.094666
Epoch loss: 16.178796
train phase, Epoch 10/20, Loss: 16.008655
val phase, Epoch 10/20, Loss: 15.807968
Val Best Loss: 15.807968
Epoch loss: 15.807968
train phase, Epoch 11/20, Loss: 15.595247
val phase, Epoch 11/20, Loss: 16.038992
Val Best Loss: 15.807968
Epoch loss: 16.038992
train phase, Epoch 12/20, Loss: 15.425330
val phase, Epoch 12/20, Loss: 16.453774
Val Best Loss: 15.807968
Epoch loss: 16.453774
train phase, Epoch 13/20, Loss: 15.424619
val phase, Epoch 13/20, Loss: 17.766652
Val Best Loss: 15.807968
Epoch loss: 17.766652
train phase, Epoch 14/20, Loss: 15.164711
val phase, Epoch 14/20, Loss: 15.748205
Val Best Loss: 15.748205
Epoch loss: 15.748205
train phase, Epoch 15/20, Loss: 14.788476
val phase, Epoch 15/20, Loss: 15.820218
Val Best Loss: 15.748205
Epoch loss: 15.820218
train phase, Epoch 16/20, Loss: 14.855852
val phase, Epoch 16/20, Loss: 15.613626
Val Best Loss: 15.613626
Epoch loss: 15.613626
train phase, Epoch 17/20, Loss: 14.374961
val phase, Epoch 17/20, Loss: 16.893617
Val Best Loss: 15.613626
Epoch loss: 16.893617
train phase, Epoch 18/20, Loss: 14.275713
val phase, Epoch 18/20, Loss: 17.271633
Val Best Loss: 15.613626
Epoch loss: 17.271633
train phase, Epoch 19/20, Loss: 14.103902
val phase, Epoch 19/20, Loss: 16.729251
Val Best Loss: 15.613626
Epoch loss: 16.729251
train phase, Epoch 20/20, Loss: 13.554776
val phase, Epoch 20/20, Loss: 17.092921
Val Best Loss: 15.613626
Epoch loss: 17.092921
train phase, Epoch 1/20, Loss: 19.914955
val phase, Epoch 1/20, Loss: 17.628704
Val Best Loss: 17.628704
Epoch loss: 17.628704
train phase, Epoch 2/20, Loss: 17.569832
val phase, Epoch 2/20, Loss: 16.471309
Val Best Loss: 16.471309
Epoch loss: 16.471309
train phase, Epoch 3/20, Loss: 16.960212
val phase, Epoch 3/20, Loss: 16.628834
Val Best Loss: 16.471309
Epoch loss: 16.628834
train phase, Epoch 4/20, Loss: 16.881797
val phase, Epoch 4/20, Loss: 16.682091
Val Best Loss: 16.471309
Epoch loss: 16.682091
train phase, Epoch 5/20, Loss: 16.739596
val phase, Epoch 5/20, Loss: 17.096364
Val Best Loss: 16.471309
Epoch loss: 17.096364
train phase, Epoch 6/20, Loss: 16.398057
val phase, Epoch 6/20, Loss: 17.827382
Val Best Loss: 16.471309
Epoch loss: 17.827382
train phase, Epoch 7/20, Loss: 16.162142
val phase, Epoch 7/20, Loss: 17.586387
Val Best Loss: 16.471309
Epoch loss: 17.586387
train phase, Epoch 8/20, Loss: 16.192883
val phase, Epoch 8/20, Loss: 16.341599
Val Best Loss: 16.341599
Epoch loss: 16.341599
train phase, Epoch 9/20, Loss: 15.751810
val phase, Epoch 9/20, Loss: 16.836165
Val Best Loss: 16.341599
Epoch loss: 16.836165
train phase, Epoch 10/20, Loss: 15.830597
val phase, Epoch 10/20, Loss: 16.207985
Val Best Loss: 16.207985
Epoch loss: 16.207985
train phase, Epoch 11/20, Loss: 15.465042
val phase, Epoch 11/20, Loss: 16.092463
Val Best Loss: 16.092463
Epoch loss: 16.092463
train phase, Epoch 12/20, Loss: 15.414999
val phase, Epoch 12/20, Loss: 16.492659
Val Best Loss: 16.092463
Epoch loss: 16.492659
train phase, Epoch 13/20, Loss: 15.069034
val phase, Epoch 13/20, Loss: 18.469294
Val Best Loss: 16.092463
Epoch loss: 18.469294
train phase, Epoch 14/20, Loss: 15.122299
val phase, Epoch 14/20, Loss: 18.523147
Val Best Loss: 16.092463
Epoch loss: 18.523147
train phase, Epoch 15/20, Loss: 14.812261
val phase, Epoch 15/20, Loss: 16.028941
Val Best Loss: 16.028941
Epoch loss: 16.028941
train phase, Epoch 16/20, Loss: 14.454184
val phase, Epoch 16/20, Loss: 19.641573
Val Best Loss: 16.028941
Epoch loss: 19.641573
train phase, Epoch 17/20, Loss: 14.080678
val phase, Epoch 17/20, Loss: 16.116974
Val Best Loss: 16.028941
Epoch loss: 16.116974
train phase, Epoch 18/20, Loss: 13.842423
val phase, Epoch 18/20, Loss: 16.178056
Val Best Loss: 16.028941
Epoch loss: 16.178056
train phase, Epoch 19/20, Loss: 13.550147
val phase, Epoch 19/20, Loss: 16.764279
Val Best Loss: 16.028941
Epoch loss: 16.764279
train phase, Epoch 20/20, Loss: 13.172733
val phase, Epoch 20/20, Loss: 16.612101
Val Best Loss: 16.028941
Epoch loss: 16.612101
train phase, Epoch 1/20, Loss: 20.042668
val phase, Epoch 1/20, Loss: 16.946398
Val Best Loss: 16.946398
Epoch loss: 16.946398
train phase, Epoch 2/20, Loss: 17.769727
val phase, Epoch 2/20, Loss: 17.117275
Val Best Loss: 16.946398
Epoch loss: 17.117275
train phase, Epoch 3/20, Loss: 17.436609
val phase, Epoch 3/20, Loss: 19.766467
Val Best Loss: 16.946398
Epoch loss: 19.766467
train phase, Epoch 4/20, Loss: 16.870780
val phase, Epoch 4/20, Loss: 16.348992
Val Best Loss: 16.348992
Epoch loss: 16.348992
train phase, Epoch 5/20, Loss: 16.581896
val phase, Epoch 5/20, Loss: 16.288435
Val Best Loss: 16.288435
Epoch loss: 16.288435
train phase, Epoch 6/20, Loss: 16.424497
val phase, Epoch 6/20, Loss: 16.118405
Val Best Loss: 16.118405
Epoch loss: 16.118405
train phase, Epoch 7/20, Loss: 16.462824
val phase, Epoch 7/20, Loss: 16.147424
Val Best Loss: 16.118405
Epoch loss: 16.147424
train phase, Epoch 8/20, Loss: 16.289749
val phase, Epoch 8/20, Loss: 16.452223
Val Best Loss: 16.118405
Epoch loss: 16.452223
train phase, Epoch 9/20, Loss: 15.984517
val phase, Epoch 9/20, Loss: 16.551619
Val Best Loss: 16.118405
Epoch loss: 16.551619
train phase, Epoch 10/20, Loss: 15.888573
val phase, Epoch 10/20, Loss: 16.696691
Val Best Loss: 16.118405
Epoch loss: 16.696691
train phase, Epoch 11/20, Loss: 15.856011
val phase, Epoch 11/20, Loss: 16.394547
Val Best Loss: 16.118405
Epoch loss: 16.394547
train phase, Epoch 12/20, Loss: 15.517077
val phase, Epoch 12/20, Loss: 15.881885
Val Best Loss: 15.881885
Epoch loss: 15.881885
train phase, Epoch 13/20, Loss: 15.298738
val phase, Epoch 13/20, Loss: 16.369554
Val Best Loss: 15.881885
Epoch loss: 16.369554
train phase, Epoch 14/20, Loss: 15.188022
val phase, Epoch 14/20, Loss: 16.543410
Val Best Loss: 15.881885
Epoch loss: 16.543410
train phase, Epoch 15/20, Loss: 14.897155
val phase, Epoch 15/20, Loss: 16.837252
Val Best Loss: 15.881885
Epoch loss: 16.837252
train phase, Epoch 16/20, Loss: 14.534565
val phase, Epoch 16/20, Loss: 16.599185
Val Best Loss: 15.881885
Epoch loss: 16.599185
train phase, Epoch 17/20, Loss: 14.467230
val phase, Epoch 17/20, Loss: 16.968844
Val Best Loss: 15.881885
Epoch loss: 16.968844
train phase, Epoch 18/20, Loss: 14.085866
val phase, Epoch 18/20, Loss: 16.619657
Val Best Loss: 15.881885
Epoch loss: 16.619657
train phase, Epoch 19/20, Loss: 13.757868
val phase, Epoch 19/20, Loss: 17.293417
Val Best Loss: 15.881885
Epoch loss: 17.293417
train phase, Epoch 20/20, Loss: 13.458220
val phase, Epoch 20/20, Loss: 16.256241
Val Best Loss: 15.881885
Epoch loss: 16.256241
train phase, Epoch 1/20, Loss: 20.294872
val phase, Epoch 1/20, Loss: 17.682942
Val Best Loss: 17.682942
Epoch loss: 17.682942
train phase, Epoch 2/20, Loss: 18.066106
val phase, Epoch 2/20, Loss: 17.591843
Val Best Loss: 17.591843
Epoch loss: 17.591843
train phase, Epoch 3/20, Loss: 17.533011
val phase, Epoch 3/20, Loss: 17.291628
Val Best Loss: 17.291628
Epoch loss: 17.291628
train phase, Epoch 4/20, Loss: 17.204442
val phase, Epoch 4/20, Loss: 17.980207
Val Best Loss: 17.291628
Epoch loss: 17.980207
train phase, Epoch 5/20, Loss: 17.066434
val phase, Epoch 5/20, Loss: 16.689028
Val Best Loss: 16.689028
Epoch loss: 16.689028
train phase, Epoch 6/20, Loss: 17.075844
val phase, Epoch 6/20, Loss: 16.573988
Val Best Loss: 16.573988
Epoch loss: 16.573988
train phase, Epoch 7/20, Loss: 16.751112
val phase, Epoch 7/20, Loss: 17.564648
Val Best Loss: 16.573988
Epoch loss: 17.564648
train phase, Epoch 8/20, Loss: 16.895531
val phase, Epoch 8/20, Loss: 16.747655
Val Best Loss: 16.573988
Epoch loss: 16.747655
train phase, Epoch 9/20, Loss: 16.337570
val phase, Epoch 9/20, Loss: 16.271566
Val Best Loss: 16.271566
Epoch loss: 16.271566
train phase, Epoch 10/20, Loss: 16.385567
val phase, Epoch 10/20, Loss: 16.239196
Val Best Loss: 16.239196
Epoch loss: 16.239196
train phase, Epoch 11/20, Loss: 16.264539
val phase, Epoch 11/20, Loss: 16.580275
Val Best Loss: 16.239196
Epoch loss: 16.580275
train phase, Epoch 12/20, Loss: 16.105834
val phase, Epoch 12/20, Loss: 18.786161
Val Best Loss: 16.239196
Epoch loss: 18.786161
train phase, Epoch 13/20, Loss: 15.937005
val phase, Epoch 13/20, Loss: 17.719897
Val Best Loss: 16.239196
Epoch loss: 17.719897
train phase, Epoch 14/20, Loss: 15.891804
val phase, Epoch 14/20, Loss: 16.391755
Val Best Loss: 16.239196
Epoch loss: 16.391755
train phase, Epoch 15/20, Loss: 15.754833
val phase, Epoch 15/20, Loss: 16.410629
Val Best Loss: 16.239196
Epoch loss: 16.410629
train phase, Epoch 16/20, Loss: 15.476367
val phase, Epoch 16/20, Loss: 16.388264
Val Best Loss: 16.239196
Epoch loss: 16.388264
train phase, Epoch 17/20, Loss: 15.392366
val phase, Epoch 17/20, Loss: 16.986628
Val Best Loss: 16.239196
Epoch loss: 16.986628
train phase, Epoch 18/20, Loss: 15.493552
val phase, Epoch 18/20, Loss: 17.318744
Val Best Loss: 16.239196
Epoch loss: 17.318744
train phase, Epoch 19/20, Loss: 15.204894
val phase, Epoch 19/20, Loss: 16.114962
Val Best Loss: 16.114962
Epoch loss: 16.114962
train phase, Epoch 20/20, Loss: 14.900192
val phase, Epoch 20/20, Loss: 16.432070
Val Best Loss: 16.114962
Epoch loss: 16.432070
train phase, Epoch 1/20, Loss: 19.863266
val phase, Epoch 1/20, Loss: 17.424698
Val Best Loss: 17.424698
Epoch loss: 17.424698
train phase, Epoch 2/20, Loss: 17.840924
val phase, Epoch 2/20, Loss: 17.876529
Val Best Loss: 17.424698
Epoch loss: 17.876529
train phase, Epoch 3/20, Loss: 17.605770
val phase, Epoch 3/20, Loss: 18.253510
Val Best Loss: 17.424698
Epoch loss: 18.253510
train phase, Epoch 4/20, Loss: 17.280932
val phase, Epoch 4/20, Loss: 19.358829
Val Best Loss: 17.424698
Epoch loss: 19.358829
train phase, Epoch 5/20, Loss: 16.905566
val phase, Epoch 5/20, Loss: 17.421931
Val Best Loss: 17.421931
Epoch loss: 17.421931
train phase, Epoch 6/20, Loss: 16.576582
val phase, Epoch 6/20, Loss: 16.659105
Val Best Loss: 16.659105
Epoch loss: 16.659105
train phase, Epoch 7/20, Loss: 16.819822
val phase, Epoch 7/20, Loss: 16.177696
Val Best Loss: 16.177696
Epoch loss: 16.177696
train phase, Epoch 8/20, Loss: 16.333215
val phase, Epoch 8/20, Loss: 16.548841
Val Best Loss: 16.177696
Epoch loss: 16.548841
train phase, Epoch 9/20, Loss: 16.478728
val phase, Epoch 9/20, Loss: 16.592592
Val Best Loss: 16.177696
Epoch loss: 16.592592
train phase, Epoch 10/20, Loss: 16.116079
val phase, Epoch 10/20, Loss: 17.641419
Val Best Loss: 16.177696
Epoch loss: 17.641419
train phase, Epoch 11/20, Loss: 16.052906
val phase, Epoch 11/20, Loss: 16.046671
Val Best Loss: 16.046671
Epoch loss: 16.046671
train phase, Epoch 12/20, Loss: 15.800083
val phase, Epoch 12/20, Loss: 16.191987
Val Best Loss: 16.046671
Epoch loss: 16.191987
train phase, Epoch 13/20, Loss: 15.805118
val phase, Epoch 13/20, Loss: 16.439846
Val Best Loss: 16.046671
Epoch loss: 16.439846
train phase, Epoch 14/20, Loss: 15.457813
val phase, Epoch 14/20, Loss: 17.331204
Val Best Loss: 16.046671
Epoch loss: 17.331204
train phase, Epoch 15/20, Loss: 15.479936
val phase, Epoch 15/20, Loss: 16.118264
Val Best Loss: 16.046671
Epoch loss: 16.118264
train phase, Epoch 16/20, Loss: 15.379675
val phase, Epoch 16/20, Loss: 16.393313
Val Best Loss: 16.046671
Epoch loss: 16.393313
train phase, Epoch 17/20, Loss: 15.112033
val phase, Epoch 17/20, Loss: 16.605821
Val Best Loss: 16.046671
Epoch loss: 16.605821
train phase, Epoch 18/20, Loss: 15.087659
val phase, Epoch 18/20, Loss: 16.917686
Val Best Loss: 16.046671
Epoch loss: 16.917686
train phase, Epoch 19/20, Loss: 15.032675
val phase, Epoch 19/20, Loss: 18.583433
Val Best Loss: 16.046671
Epoch loss: 18.583433
train phase, Epoch 20/20, Loss: 14.870634
val phase, Epoch 20/20, Loss: 16.368259
Val Best Loss: 16.046671
Epoch loss: 16.368259
[Trial 119] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
[Trial 120] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.020654
val phase, Epoch 1/20, Loss: 16.937504
Val Best Loss: 16.937504
Epoch loss: 16.937504
train phase, Epoch 2/20, Loss: 17.389477
val phase, Epoch 2/20, Loss: 18.069303
Val Best Loss: 16.937504
Epoch loss: 18.069303
train phase, Epoch 3/20, Loss: 17.243018
val phase, Epoch 3/20, Loss: 16.795490
Val Best Loss: 16.795490
Epoch loss: 16.795490
train phase, Epoch 4/20, Loss: 16.828409
val phase, Epoch 4/20, Loss: 16.492116
Val Best Loss: 16.492116
Epoch loss: 16.492116
train phase, Epoch 5/20, Loss: 16.609410
val phase, Epoch 5/20, Loss: 17.958336
Val Best Loss: 16.492116
Epoch loss: 17.958336
train phase, Epoch 6/20, Loss: 16.651265
val phase, Epoch 6/20, Loss: 16.355633
Val Best Loss: 16.355633
Epoch loss: 16.355633
train phase, Epoch 7/20, Loss: 16.214777
val phase, Epoch 7/20, Loss: 16.014989
Val Best Loss: 16.014989
Epoch loss: 16.014989
train phase, Epoch 8/20, Loss: 16.141136
val phase, Epoch 8/20, Loss: 16.794596
Val Best Loss: 16.014989
Epoch loss: 16.794596
train phase, Epoch 9/20, Loss: 15.969548
val phase, Epoch 9/20, Loss: 15.795534
Val Best Loss: 15.795534
Epoch loss: 15.795534
train phase, Epoch 10/20, Loss: 15.813604
val phase, Epoch 10/20, Loss: 15.958746
Val Best Loss: 15.795534
Epoch loss: 15.958746
train phase, Epoch 11/20, Loss: 15.556825
val phase, Epoch 11/20, Loss: 15.975416
Val Best Loss: 15.795534
Epoch loss: 15.975416
train phase, Epoch 12/20, Loss: 15.449538
val phase, Epoch 12/20, Loss: 15.858978
Val Best Loss: 15.795534
Epoch loss: 15.858978
train phase, Epoch 13/20, Loss: 15.248080
val phase, Epoch 13/20, Loss: 16.200009
Val Best Loss: 15.795534
Epoch loss: 16.200009
train phase, Epoch 14/20, Loss: 15.124269
val phase, Epoch 14/20, Loss: 16.274444
Val Best Loss: 15.795534
Epoch loss: 16.274444
train phase, Epoch 15/20, Loss: 14.830709
val phase, Epoch 15/20, Loss: 15.821457
Val Best Loss: 15.795534
Epoch loss: 15.821457
train phase, Epoch 16/20, Loss: 14.624082
val phase, Epoch 16/20, Loss: 16.782760
Val Best Loss: 15.795534
Epoch loss: 16.782760
train phase, Epoch 17/20, Loss: 14.513209
val phase, Epoch 17/20, Loss: 15.493945
Val Best Loss: 15.493945
Epoch loss: 15.493945
train phase, Epoch 18/20, Loss: 14.015923
val phase, Epoch 18/20, Loss: 17.195138
Val Best Loss: 15.493945
Epoch loss: 17.195138
train phase, Epoch 19/20, Loss: 13.804476
val phase, Epoch 19/20, Loss: 16.593207
Val Best Loss: 15.493945
Epoch loss: 16.593207
train phase, Epoch 20/20, Loss: 13.511017
val phase, Epoch 20/20, Loss: 16.466320
Val Best Loss: 15.493945
Epoch loss: 16.466320
train phase, Epoch 1/20, Loss: 20.320163
val phase, Epoch 1/20, Loss: 18.140419
Val Best Loss: 18.140419
Epoch loss: 18.140419
train phase, Epoch 2/20, Loss: 17.648361
val phase, Epoch 2/20, Loss: 17.358226
Val Best Loss: 17.358226
Epoch loss: 17.358226
train phase, Epoch 3/20, Loss: 17.494865
val phase, Epoch 3/20, Loss: 17.062267
Val Best Loss: 17.062267
Epoch loss: 17.062267
train phase, Epoch 4/20, Loss: 16.916691
val phase, Epoch 4/20, Loss: 16.694489
Val Best Loss: 16.694489
Epoch loss: 16.694489
train phase, Epoch 5/20, Loss: 16.701584
val phase, Epoch 5/20, Loss: 16.117494
Val Best Loss: 16.117494
Epoch loss: 16.117494
train phase, Epoch 6/20, Loss: 16.430747
val phase, Epoch 6/20, Loss: 17.444773
Val Best Loss: 16.117494
Epoch loss: 17.444773
train phase, Epoch 7/20, Loss: 16.494696
val phase, Epoch 7/20, Loss: 16.939667
Val Best Loss: 16.117494
Epoch loss: 16.939667
train phase, Epoch 8/20, Loss: 16.304313
val phase, Epoch 8/20, Loss: 17.275875
Val Best Loss: 16.117494
Epoch loss: 17.275875
train phase, Epoch 9/20, Loss: 16.119985
val phase, Epoch 9/20, Loss: 16.148401
Val Best Loss: 16.117494
Epoch loss: 16.148401
train phase, Epoch 10/20, Loss: 16.056926
val phase, Epoch 10/20, Loss: 16.225473
Val Best Loss: 16.117494
Epoch loss: 16.225473
train phase, Epoch 11/20, Loss: 15.936684
val phase, Epoch 11/20, Loss: 16.252554
Val Best Loss: 16.117494
Epoch loss: 16.252554
train phase, Epoch 12/20, Loss: 15.621653
val phase, Epoch 12/20, Loss: 17.597668
Val Best Loss: 16.117494
Epoch loss: 17.597668
train phase, Epoch 13/20, Loss: 15.379025
val phase, Epoch 13/20, Loss: 16.148561
Val Best Loss: 16.117494
Epoch loss: 16.148561
train phase, Epoch 14/20, Loss: 15.239625
val phase, Epoch 14/20, Loss: 16.989117
Val Best Loss: 16.117494
Epoch loss: 16.989117
train phase, Epoch 15/20, Loss: 15.096672
val phase, Epoch 15/20, Loss: 15.873172
Val Best Loss: 15.873172
Epoch loss: 15.873172
train phase, Epoch 16/20, Loss: 14.801153
val phase, Epoch 16/20, Loss: 16.331351
Val Best Loss: 15.873172
Epoch loss: 16.331351
train phase, Epoch 17/20, Loss: 14.697087
val phase, Epoch 17/20, Loss: 16.762040
Val Best Loss: 15.873172
Epoch loss: 16.762040
train phase, Epoch 18/20, Loss: 14.429819
val phase, Epoch 18/20, Loss: 15.928248
Val Best Loss: 15.873172
Epoch loss: 15.928248
train phase, Epoch 19/20, Loss: 14.160394
val phase, Epoch 19/20, Loss: 15.943718
Val Best Loss: 15.873172
Epoch loss: 15.943718
train phase, Epoch 20/20, Loss: 13.649225
val phase, Epoch 20/20, Loss: 17.598937
Val Best Loss: 15.873172
Epoch loss: 17.598937
train phase, Epoch 1/20, Loss: 19.836232
val phase, Epoch 1/20, Loss: 17.743761
Val Best Loss: 17.743761
Epoch loss: 17.743761
train phase, Epoch 2/20, Loss: 17.541326
val phase, Epoch 2/20, Loss: 16.974818
Val Best Loss: 16.974818
Epoch loss: 16.974818
train phase, Epoch 3/20, Loss: 17.166590
val phase, Epoch 3/20, Loss: 17.019091
Val Best Loss: 16.974818
Epoch loss: 17.019091
train phase, Epoch 4/20, Loss: 16.895378
val phase, Epoch 4/20, Loss: 17.059275
Val Best Loss: 16.974818
Epoch loss: 17.059275
train phase, Epoch 5/20, Loss: 16.849210
val phase, Epoch 5/20, Loss: 16.606022
Val Best Loss: 16.606022
Epoch loss: 16.606022
train phase, Epoch 6/20, Loss: 16.686708
val phase, Epoch 6/20, Loss: 16.274256
Val Best Loss: 16.274256
Epoch loss: 16.274256
train phase, Epoch 7/20, Loss: 16.563573
val phase, Epoch 7/20, Loss: 16.274373
Val Best Loss: 16.274256
Epoch loss: 16.274373
train phase, Epoch 8/20, Loss: 16.253935
val phase, Epoch 8/20, Loss: 16.299865
Val Best Loss: 16.274256
Epoch loss: 16.299865
train phase, Epoch 9/20, Loss: 16.101588
val phase, Epoch 9/20, Loss: 16.736445
Val Best Loss: 16.274256
Epoch loss: 16.736445
train phase, Epoch 10/20, Loss: 15.955348
val phase, Epoch 10/20, Loss: 16.145333
Val Best Loss: 16.145333
Epoch loss: 16.145333
train phase, Epoch 11/20, Loss: 16.015258
val phase, Epoch 11/20, Loss: 16.088360
Val Best Loss: 16.088360
Epoch loss: 16.088360
train phase, Epoch 12/20, Loss: 15.594852
val phase, Epoch 12/20, Loss: 16.045341
Val Best Loss: 16.045341
Epoch loss: 16.045341
train phase, Epoch 13/20, Loss: 15.450069
val phase, Epoch 13/20, Loss: 16.354469
Val Best Loss: 16.045341
Epoch loss: 16.354469
train phase, Epoch 14/20, Loss: 15.392848
val phase, Epoch 14/20, Loss: 16.025033
Val Best Loss: 16.025033
Epoch loss: 16.025033
train phase, Epoch 15/20, Loss: 15.094436
val phase, Epoch 15/20, Loss: 17.934152
Val Best Loss: 16.025033
Epoch loss: 17.934152
train phase, Epoch 16/20, Loss: 14.916772
val phase, Epoch 16/20, Loss: 16.183934
Val Best Loss: 16.025033
Epoch loss: 16.183934
train phase, Epoch 17/20, Loss: 14.705452
val phase, Epoch 17/20, Loss: 16.141647
Val Best Loss: 16.025033
Epoch loss: 16.141647
train phase, Epoch 18/20, Loss: 14.286538
val phase, Epoch 18/20, Loss: 16.119692
Val Best Loss: 16.025033
Epoch loss: 16.119692
train phase, Epoch 19/20, Loss: 14.049371
val phase, Epoch 19/20, Loss: 16.324957
Val Best Loss: 16.025033
Epoch loss: 16.324957
train phase, Epoch 20/20, Loss: 13.684847
val phase, Epoch 20/20, Loss: 16.138666
Val Best Loss: 16.025033
Epoch loss: 16.138666
train phase, Epoch 1/20, Loss: 20.786615
val phase, Epoch 1/20, Loss: 16.865981
Val Best Loss: 16.865981
Epoch loss: 16.865981
train phase, Epoch 2/20, Loss: 17.472785
val phase, Epoch 2/20, Loss: 17.437204
Val Best Loss: 16.865981
Epoch loss: 17.437204
train phase, Epoch 3/20, Loss: 17.309715
val phase, Epoch 3/20, Loss: 16.802816
Val Best Loss: 16.802816
Epoch loss: 16.802816
train phase, Epoch 4/20, Loss: 16.894965
val phase, Epoch 4/20, Loss: 16.527862
Val Best Loss: 16.527862
Epoch loss: 16.527862
train phase, Epoch 5/20, Loss: 16.687808
val phase, Epoch 5/20, Loss: 16.122467
Val Best Loss: 16.122467
Epoch loss: 16.122467
train phase, Epoch 6/20, Loss: 16.541623
val phase, Epoch 6/20, Loss: 16.662406
Val Best Loss: 16.122467
Epoch loss: 16.662406
train phase, Epoch 7/20, Loss: 16.263718
val phase, Epoch 7/20, Loss: 16.321216
Val Best Loss: 16.122467
Epoch loss: 16.321216
train phase, Epoch 8/20, Loss: 16.193985
val phase, Epoch 8/20, Loss: 17.661577
Val Best Loss: 16.122467
Epoch loss: 17.661577
train phase, Epoch 9/20, Loss: 15.929173
val phase, Epoch 9/20, Loss: 19.379313
Val Best Loss: 16.122467
Epoch loss: 19.379313
train phase, Epoch 10/20, Loss: 15.770948
val phase, Epoch 10/20, Loss: 16.274604
Val Best Loss: 16.122467
Epoch loss: 16.274604
train phase, Epoch 11/20, Loss: 15.492917
val phase, Epoch 11/20, Loss: 16.818624
Val Best Loss: 16.122467
Epoch loss: 16.818624
train phase, Epoch 12/20, Loss: 15.461081
val phase, Epoch 12/20, Loss: 17.247782
Val Best Loss: 16.122467
Epoch loss: 17.247782
train phase, Epoch 13/20, Loss: 15.247235
val phase, Epoch 13/20, Loss: 15.873415
Val Best Loss: 15.873415
Epoch loss: 15.873415
train phase, Epoch 14/20, Loss: 15.118959
val phase, Epoch 14/20, Loss: 16.068685
Val Best Loss: 15.873415
Epoch loss: 16.068685
train phase, Epoch 15/20, Loss: 14.904185
val phase, Epoch 15/20, Loss: 16.842852
Val Best Loss: 15.873415
Epoch loss: 16.842852
train phase, Epoch 16/20, Loss: 14.613871
val phase, Epoch 16/20, Loss: 16.555214
Val Best Loss: 15.873415
Epoch loss: 16.555214
train phase, Epoch 17/20, Loss: 14.236336
val phase, Epoch 17/20, Loss: 16.723242
Val Best Loss: 15.873415
Epoch loss: 16.723242
train phase, Epoch 18/20, Loss: 14.081439
val phase, Epoch 18/20, Loss: 17.470804
Val Best Loss: 15.873415
Epoch loss: 17.470804
train phase, Epoch 19/20, Loss: 13.655554
val phase, Epoch 19/20, Loss: 16.810395
Val Best Loss: 15.873415
Epoch loss: 16.810395
train phase, Epoch 20/20, Loss: 13.551387
val phase, Epoch 20/20, Loss: 17.099348
Val Best Loss: 15.873415
Epoch loss: 17.099348
train phase, Epoch 1/20, Loss: 20.356432
val phase, Epoch 1/20, Loss: 18.967425
Val Best Loss: 18.967425
Epoch loss: 18.967425
train phase, Epoch 2/20, Loss: 17.799588
val phase, Epoch 2/20, Loss: 18.589415
Val Best Loss: 18.589415
Epoch loss: 18.589415
train phase, Epoch 3/20, Loss: 17.290605
val phase, Epoch 3/20, Loss: 20.391134
Val Best Loss: 18.589415
Epoch loss: 20.391134
train phase, Epoch 4/20, Loss: 17.356876
val phase, Epoch 4/20, Loss: 16.708684
Val Best Loss: 16.708684
Epoch loss: 16.708684
train phase, Epoch 5/20, Loss: 16.750957
val phase, Epoch 5/20, Loss: 16.849373
Val Best Loss: 16.708684
Epoch loss: 16.849373
train phase, Epoch 6/20, Loss: 16.731226
val phase, Epoch 6/20, Loss: 16.347339
Val Best Loss: 16.347339
Epoch loss: 16.347339
train phase, Epoch 7/20, Loss: 16.378428
val phase, Epoch 7/20, Loss: 16.547355
Val Best Loss: 16.347339
Epoch loss: 16.547355
train phase, Epoch 8/20, Loss: 16.291088
val phase, Epoch 8/20, Loss: 15.892093
Val Best Loss: 15.892093
Epoch loss: 15.892093
train phase, Epoch 9/20, Loss: 16.020916
val phase, Epoch 9/20, Loss: 18.085612
Val Best Loss: 15.892093
Epoch loss: 18.085612
train phase, Epoch 10/20, Loss: 15.930548
val phase, Epoch 10/20, Loss: 17.210693
Val Best Loss: 15.892093
Epoch loss: 17.210693
train phase, Epoch 11/20, Loss: 15.942466
val phase, Epoch 11/20, Loss: 15.892747
Val Best Loss: 15.892093
Epoch loss: 15.892747
train phase, Epoch 12/20, Loss: 15.672825
val phase, Epoch 12/20, Loss: 20.147155
Val Best Loss: 15.892093
Epoch loss: 20.147155
train phase, Epoch 13/20, Loss: 15.567448
val phase, Epoch 13/20, Loss: 15.805822
Val Best Loss: 15.805822
Epoch loss: 15.805822
train phase, Epoch 14/20, Loss: 15.196011
val phase, Epoch 14/20, Loss: 16.280469
Val Best Loss: 15.805822
Epoch loss: 16.280469
train phase, Epoch 15/20, Loss: 15.141653
val phase, Epoch 15/20, Loss: 16.074352
Val Best Loss: 15.805822
Epoch loss: 16.074352
train phase, Epoch 16/20, Loss: 14.884879
val phase, Epoch 16/20, Loss: 16.141542
Val Best Loss: 15.805822
Epoch loss: 16.141542
train phase, Epoch 17/20, Loss: 14.834452
val phase, Epoch 17/20, Loss: 16.288896
Val Best Loss: 15.805822
Epoch loss: 16.288896
train phase, Epoch 18/20, Loss: 14.557788
val phase, Epoch 18/20, Loss: 19.691039
Val Best Loss: 15.805822
Epoch loss: 19.691039
train phase, Epoch 19/20, Loss: 14.708817
val phase, Epoch 19/20, Loss: 17.162962
Val Best Loss: 15.805822
Epoch loss: 17.162962
train phase, Epoch 20/20, Loss: 13.921427
val phase, Epoch 20/20, Loss: 16.397722
Val Best Loss: 15.805822
Epoch loss: 16.397722
[Trial 126] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/15, Loss: 20.126666
val phase, Epoch 1/15, Loss: 16.848566
Val Best Loss: 16.848566
Epoch loss: 16.848566
train phase, Epoch 2/15, Loss: 18.680544
val phase, Epoch 2/15, Loss: 17.948748
Val Best Loss: 16.848566
Epoch loss: 17.948748
train phase, Epoch 3/15, Loss: 17.684016
val phase, Epoch 3/15, Loss: 16.498714
Val Best Loss: 16.498714
Epoch loss: 16.498714
train phase, Epoch 4/15, Loss: 17.587225
val phase, Epoch 4/15, Loss: 16.837093
Val Best Loss: 16.498714
Epoch loss: 16.837093
train phase, Epoch 5/15, Loss: 17.246016
val phase, Epoch 5/15, Loss: 16.630827
Val Best Loss: 16.498714
Epoch loss: 16.630827
train phase, Epoch 6/15, Loss: 16.968534
val phase, Epoch 6/15, Loss: 18.707604
Val Best Loss: 16.498714
Epoch loss: 18.707604
train phase, Epoch 7/15, Loss: 16.681129
val phase, Epoch 7/15, Loss: 16.592362
Val Best Loss: 16.498714
Epoch loss: 16.592362
train phase, Epoch 8/15, Loss: 16.655174
val phase, Epoch 8/15, Loss: 16.235144
Val Best Loss: 16.235144
Epoch loss: 16.235144
train phase, Epoch 9/15, Loss: 16.313496
val phase, Epoch 9/15, Loss: 16.127682
Val Best Loss: 16.127682
Epoch loss: 16.127682
train phase, Epoch 10/15, Loss: 16.332056
val phase, Epoch 10/15, Loss: 17.945380
Val Best Loss: 16.127682
Epoch loss: 17.945380
train phase, Epoch 11/15, Loss: 16.094530
val phase, Epoch 11/15, Loss: 15.906097
Val Best Loss: 15.906097
Epoch loss: 15.906097
train phase, Epoch 12/15, Loss: 15.907940
val phase, Epoch 12/15, Loss: 15.796618
Val Best Loss: 15.796618
Epoch loss: 15.796618
train phase, Epoch 13/15, Loss: 15.683182
val phase, Epoch 13/15, Loss: 16.201499
Val Best Loss: 15.796618
Epoch loss: 16.201499
train phase, Epoch 14/15, Loss: 15.582406
val phase, Epoch 14/15, Loss: 16.249588
Val Best Loss: 15.796618
Epoch loss: 16.249588
train phase, Epoch 15/15, Loss: 15.273821
val phase, Epoch 15/15, Loss: 15.963222
Val Best Loss: 15.796618
Epoch loss: 15.963222
train phase, Epoch 1/20, Loss: 21.730928
val phase, Epoch 1/20, Loss: 17.534701
Val Best Loss: 17.534701
Epoch loss: 17.534701
train phase, Epoch 2/20, Loss: 17.302942
val phase, Epoch 2/20, Loss: 17.028529
Val Best Loss: 17.028529
Epoch loss: 17.028529
train phase, Epoch 3/20, Loss: 16.916390
val phase, Epoch 3/20, Loss: 17.217336
Val Best Loss: 17.028529
Epoch loss: 17.217336
train phase, Epoch 4/20, Loss: 16.579452
val phase, Epoch 4/20, Loss: 17.098259
Val Best Loss: 17.028529
Epoch loss: 17.098259
train phase, Epoch 5/20, Loss: 16.350544
val phase, Epoch 5/20, Loss: 16.835210
Val Best Loss: 16.835210
Epoch loss: 16.835210
train phase, Epoch 6/20, Loss: 16.047961
val phase, Epoch 6/20, Loss: 17.063390
Val Best Loss: 16.835210
Epoch loss: 17.063390
train phase, Epoch 7/20, Loss: 15.798863
val phase, Epoch 7/20, Loss: 16.931345
Val Best Loss: 16.835210
Epoch loss: 16.931345
train phase, Epoch 8/20, Loss: 15.629976
val phase, Epoch 8/20, Loss: 16.334956
Val Best Loss: 16.334956
Epoch loss: 16.334956
train phase, Epoch 9/20, Loss: 15.278726
val phase, Epoch 9/20, Loss: 16.420293
Val Best Loss: 16.334956
Epoch loss: 16.420293
train phase, Epoch 10/20, Loss: 15.214359
val phase, Epoch 10/20, Loss: 16.487516
Val Best Loss: 16.334956
Epoch loss: 16.487516
train phase, Epoch 11/20, Loss: 14.932312
val phase, Epoch 11/20, Loss: 16.756491
Val Best Loss: 16.334956
Epoch loss: 16.756491
train phase, Epoch 12/20, Loss: 14.506420
val phase, Epoch 12/20, Loss: 16.929291
Val Best Loss: 16.334956
Epoch loss: 16.929291
train phase, Epoch 13/20, Loss: 14.200336
val phase, Epoch 13/20, Loss: 16.800953
Val Best Loss: 16.334956
Epoch loss: 16.800953
train phase, Epoch 14/20, Loss: 13.799685
val phase, Epoch 14/20, Loss: 16.287089
Val Best Loss: 16.287089
Epoch loss: 16.287089
train phase, Epoch 15/20, Loss: 13.636996
val phase, Epoch 15/20, Loss: 16.701215
Val Best Loss: 16.287089
Epoch loss: 16.701215
train phase, Epoch 16/20, Loss: 13.062739
val phase, Epoch 16/20, Loss: 19.006819
Val Best Loss: 16.287089
Epoch loss: 19.006819
train phase, Epoch 17/20, Loss: 12.619189
val phase, Epoch 17/20, Loss: 18.476170
Val Best Loss: 16.287089
Epoch loss: 18.476170
train phase, Epoch 18/20, Loss: 12.234154
val phase, Epoch 18/20, Loss: 18.146818
Val Best Loss: 16.287089
Epoch loss: 18.146818
train phase, Epoch 19/20, Loss: 11.628899
val phase, Epoch 19/20, Loss: 18.053768
Val Best Loss: 16.287089
Epoch loss: 18.053768
train phase, Epoch 20/20, Loss: 11.239167
val phase, Epoch 20/20, Loss: 18.016835
Val Best Loss: 16.287089
Epoch loss: 18.016835
train phase, Epoch 1/12, Loss: 20.331294
val phase, Epoch 1/12, Loss: 18.689460
Val Best Loss: 18.689460
Epoch loss: 18.689460
train phase, Epoch 2/12, Loss: 17.655377
val phase, Epoch 2/12, Loss: 18.968766
Val Best Loss: 18.689460
Epoch loss: 18.968766
train phase, Epoch 3/12, Loss: 17.161341
val phase, Epoch 3/12, Loss: 17.324437
Val Best Loss: 17.324437
Epoch loss: 17.324437
train phase, Epoch 4/12, Loss: 16.818853
val phase, Epoch 4/12, Loss: 16.573925
Val Best Loss: 16.573925
Epoch loss: 16.573925
train phase, Epoch 5/12, Loss: 16.777415
val phase, Epoch 5/12, Loss: 16.403088
Val Best Loss: 16.403088
Epoch loss: 16.403088
train phase, Epoch 6/12, Loss: 16.393667
val phase, Epoch 6/12, Loss: 16.292305
Val Best Loss: 16.292305
Epoch loss: 16.292305
train phase, Epoch 7/12, Loss: 16.282665
val phase, Epoch 7/12, Loss: 16.108190
Val Best Loss: 16.108190
Epoch loss: 16.108190
train phase, Epoch 8/12, Loss: 15.838639
val phase, Epoch 8/12, Loss: 16.043355
Val Best Loss: 16.043355
Epoch loss: 16.043355
train phase, Epoch 9/12, Loss: 15.758407
val phase, Epoch 9/12, Loss: 16.290950
Val Best Loss: 16.043355
Epoch loss: 16.290950
train phase, Epoch 10/12, Loss: 15.830471
val phase, Epoch 10/12, Loss: 17.530700
Val Best Loss: 16.043355
Epoch loss: 17.530700
train phase, Epoch 11/12, Loss: 15.550517
val phase, Epoch 11/12, Loss: 16.406009
Val Best Loss: 16.043355
Epoch loss: 16.406009
train phase, Epoch 12/12, Loss: 15.108120
val phase, Epoch 12/12, Loss: 15.945732
Val Best Loss: 15.945732
Epoch loss: 15.945732
train phase, Epoch 1/20, Loss: 29.157984
val phase, Epoch 1/20, Loss: 25.055688
Val Best Loss: 25.055688
Epoch loss: 25.055688
train phase, Epoch 2/20, Loss: 18.913564
val phase, Epoch 2/20, Loss: 19.483018
Val Best Loss: 19.483018
Epoch loss: 19.483018
train phase, Epoch 3/20, Loss: 18.118629
val phase, Epoch 3/20, Loss: 18.613773
Val Best Loss: 18.613773
Epoch loss: 18.613773
train phase, Epoch 4/20, Loss: 17.927384
val phase, Epoch 4/20, Loss: 19.285608
Val Best Loss: 18.613773
Epoch loss: 19.285608
train phase, Epoch 5/20, Loss: 17.934657
val phase, Epoch 5/20, Loss: 18.135193
Val Best Loss: 18.135193
Epoch loss: 18.135193
train phase, Epoch 6/20, Loss: 18.086298
val phase, Epoch 6/20, Loss: 17.638900
Val Best Loss: 17.638900
Epoch loss: 17.638900
train phase, Epoch 7/20, Loss: 17.577658
val phase, Epoch 7/20, Loss: 16.670751
Val Best Loss: 16.670751
Epoch loss: 16.670751
train phase, Epoch 8/20, Loss: 17.320148
val phase, Epoch 8/20, Loss: 17.093745
Val Best Loss: 16.670751
Epoch loss: 17.093745
train phase, Epoch 9/20, Loss: 16.976463
val phase, Epoch 9/20, Loss: 16.646549
Val Best Loss: 16.646549
Epoch loss: 16.646549
train phase, Epoch 10/20, Loss: 17.099512
val phase, Epoch 10/20, Loss: 16.659950
Val Best Loss: 16.646549
Epoch loss: 16.659950
train phase, Epoch 11/20, Loss: 17.005170
val phase, Epoch 11/20, Loss: 17.854520
Val Best Loss: 16.646549
Epoch loss: 17.854520
train phase, Epoch 12/20, Loss: 16.589957
val phase, Epoch 12/20, Loss: 18.545271
Val Best Loss: 16.646549
Epoch loss: 18.545271
train phase, Epoch 13/20, Loss: 16.681611
val phase, Epoch 13/20, Loss: 17.515442
Val Best Loss: 16.646549
Epoch loss: 17.515442
train phase, Epoch 14/20, Loss: 16.548216
val phase, Epoch 14/20, Loss: 16.776095
Val Best Loss: 16.646549
Epoch loss: 16.776095
train phase, Epoch 15/20, Loss: 16.405673
val phase, Epoch 15/20, Loss: 16.886101
Val Best Loss: 16.646549
Epoch loss: 16.886101
train phase, Epoch 16/20, Loss: 16.470958
val phase, Epoch 16/20, Loss: 16.486674
Val Best Loss: 16.486674
Epoch loss: 16.486674
train phase, Epoch 17/20, Loss: 16.446665
val phase, Epoch 17/20, Loss: 16.614500
Val Best Loss: 16.486674
Epoch loss: 16.614500
train phase, Epoch 18/20, Loss: 16.443541
val phase, Epoch 18/20, Loss: 16.589231
Val Best Loss: 16.486674
Epoch loss: 16.589231
train phase, Epoch 19/20, Loss: 16.288323
val phase, Epoch 19/20, Loss: 16.487861
Val Best Loss: 16.486674
Epoch loss: 16.487861
train phase, Epoch 20/20, Loss: 16.162451
val phase, Epoch 20/20, Loss: 16.847964
Val Best Loss: 16.486674
Epoch loss: 16.847964
train phase, Epoch 1/30, Loss: 20.280862
val phase, Epoch 1/30, Loss: 17.244798
Val Best Loss: 17.244798
Epoch loss: 17.244798
train phase, Epoch 2/30, Loss: 18.377308
val phase, Epoch 2/30, Loss: 16.925506
Val Best Loss: 16.925506
Epoch loss: 16.925506
train phase, Epoch 3/30, Loss: 18.021494
val phase, Epoch 3/30, Loss: 16.923777
Val Best Loss: 16.923777
Epoch loss: 16.923777
train phase, Epoch 4/30, Loss: 17.351932
val phase, Epoch 4/30, Loss: 18.883403
Val Best Loss: 16.923777
Epoch loss: 18.883403
train phase, Epoch 5/30, Loss: 17.234839
val phase, Epoch 5/30, Loss: 18.215082
Val Best Loss: 16.923777
Epoch loss: 18.215082
train phase, Epoch 6/30, Loss: 17.070985
val phase, Epoch 6/30, Loss: 17.568285
Val Best Loss: 16.923777
Epoch loss: 17.568285
train phase, Epoch 7/30, Loss: 17.146834
val phase, Epoch 7/30, Loss: 16.462650
Val Best Loss: 16.462650
Epoch loss: 16.462650
train phase, Epoch 8/30, Loss: 16.664357
val phase, Epoch 8/30, Loss: 16.957318
Val Best Loss: 16.462650
Epoch loss: 16.957318
train phase, Epoch 9/30, Loss: 16.580160
val phase, Epoch 9/30, Loss: 16.387498
Val Best Loss: 16.387498
Epoch loss: 16.387498
train phase, Epoch 10/30, Loss: 16.448283
val phase, Epoch 10/30, Loss: 16.249079
Val Best Loss: 16.249079
Epoch loss: 16.249079
train phase, Epoch 11/30, Loss: 16.535491
val phase, Epoch 11/30, Loss: 16.082927
Val Best Loss: 16.082927
Epoch loss: 16.082927
train phase, Epoch 12/30, Loss: 15.997500
val phase, Epoch 12/30, Loss: 16.060796
Val Best Loss: 16.060796
Epoch loss: 16.060796
train phase, Epoch 13/30, Loss: 15.815707
val phase, Epoch 13/30, Loss: 15.938671
Val Best Loss: 15.938671
Epoch loss: 15.938671
train phase, Epoch 14/30, Loss: 15.750423
val phase, Epoch 14/30, Loss: 16.188394
Val Best Loss: 15.938671
Epoch loss: 16.188394
train phase, Epoch 15/30, Loss: 15.519445
val phase, Epoch 15/30, Loss: 15.770549
Val Best Loss: 15.770549
Epoch loss: 15.770549
train phase, Epoch 16/30, Loss: 15.301457
val phase, Epoch 16/30, Loss: 16.577472
Val Best Loss: 15.770549
Epoch loss: 16.577472
train phase, Epoch 17/30, Loss: 15.365656
val phase, Epoch 17/30, Loss: 16.217500
Val Best Loss: 15.770549
Epoch loss: 16.217500
train phase, Epoch 18/30, Loss: 14.906116
val phase, Epoch 18/30, Loss: 16.580136
Val Best Loss: 15.770549
Epoch loss: 16.580136
train phase, Epoch 19/30, Loss: 14.948820
val phase, Epoch 19/30, Loss: 16.463892
Val Best Loss: 15.770549
Epoch loss: 16.463892
train phase, Epoch 20/30, Loss: 14.546420
val phase, Epoch 20/30, Loss: 17.447668
Val Best Loss: 15.770549
Epoch loss: 17.447668
train phase, Epoch 21/30, Loss: 14.575338
val phase, Epoch 21/30, Loss: 18.684026
Val Best Loss: 15.770549
Epoch loss: 18.684026
train phase, Epoch 22/30, Loss: 14.096789
val phase, Epoch 22/30, Loss: 17.134870
Val Best Loss: 15.770549
Epoch loss: 17.134870
train phase, Epoch 23/30, Loss: 13.941307
val phase, Epoch 23/30, Loss: 16.932492
Val Best Loss: 15.770549
Epoch loss: 16.932492
train phase, Epoch 24/30, Loss: 13.746697
val phase, Epoch 24/30, Loss: 19.169681
Val Best Loss: 15.770549
Epoch loss: 19.169681
train phase, Epoch 25/30, Loss: 13.282218
val phase, Epoch 25/30, Loss: 16.775321
Val Best Loss: 15.770549
Epoch loss: 16.775321
train phase, Epoch 26/30, Loss: 12.994358
val phase, Epoch 26/30, Loss: 17.347444
Val Best Loss: 15.770549
Epoch loss: 17.347444
train phase, Epoch 27/30, Loss: 12.674435
val phase, Epoch 27/30, Loss: 16.801054
Val Best Loss: 15.770549
Epoch loss: 16.801054
train phase, Epoch 28/30, Loss: 12.253514
val phase, Epoch 28/30, Loss: 17.818894
Val Best Loss: 15.770549
Epoch loss: 17.818894
train phase, Epoch 29/30, Loss: 11.979213
val phase, Epoch 29/30, Loss: 22.363300
Val Best Loss: 15.770549
Epoch loss: 22.363300
train phase, Epoch 30/30, Loss: 11.849757
val phase, Epoch 30/30, Loss: 18.272945
Val Best Loss: 15.770549
Epoch loss: 18.272945
train phase, Epoch 1/20, Loss: 20.213685
val phase, Epoch 1/20, Loss: 16.836277
Val Best Loss: 16.836277
Epoch loss: 16.836277
train phase, Epoch 2/20, Loss: 17.536616
val phase, Epoch 2/20, Loss: 16.412575
Val Best Loss: 16.412575
Epoch loss: 16.412575
train phase, Epoch 3/20, Loss: 17.329841
val phase, Epoch 3/20, Loss: 16.822221
Val Best Loss: 16.412575
Epoch loss: 16.822221
train phase, Epoch 4/20, Loss: 17.069627
val phase, Epoch 4/20, Loss: 16.230387
Val Best Loss: 16.230387
Epoch loss: 16.230387
train phase, Epoch 5/20, Loss: 16.887819
val phase, Epoch 5/20, Loss: 16.638586
Val Best Loss: 16.230387
Epoch loss: 16.638586
train phase, Epoch 6/20, Loss: 16.542214
val phase, Epoch 6/20, Loss: 16.210711
Val Best Loss: 16.210711
Epoch loss: 16.210711
train phase, Epoch 7/20, Loss: 16.244233
val phase, Epoch 7/20, Loss: 16.316628
Val Best Loss: 16.210711
Epoch loss: 16.316628
train phase, Epoch 8/20, Loss: 16.184794
val phase, Epoch 8/20, Loss: 16.682286
Val Best Loss: 16.210711
Epoch loss: 16.682286
train phase, Epoch 9/20, Loss: 16.011906
val phase, Epoch 9/20, Loss: 16.175897
Val Best Loss: 16.175897
Epoch loss: 16.175897
train phase, Epoch 10/20, Loss: 15.909318
val phase, Epoch 10/20, Loss: 16.132258
Val Best Loss: 16.132258
Epoch loss: 16.132258
train phase, Epoch 11/20, Loss: 15.775131
val phase, Epoch 11/20, Loss: 16.058643
Val Best Loss: 16.058643
Epoch loss: 16.058643
train phase, Epoch 12/20, Loss: 15.721808
val phase, Epoch 12/20, Loss: 16.074946
Val Best Loss: 16.058643
Epoch loss: 16.074946
train phase, Epoch 13/20, Loss: 15.365193
val phase, Epoch 13/20, Loss: 17.473943
Val Best Loss: 16.058643
Epoch loss: 17.473943
train phase, Epoch 14/20, Loss: 15.392931
val phase, Epoch 14/20, Loss: 16.768743
Val Best Loss: 16.058643
Epoch loss: 16.768743
train phase, Epoch 15/20, Loss: 15.066344
val phase, Epoch 15/20, Loss: 17.421445
Val Best Loss: 16.058643
Epoch loss: 17.421445
train phase, Epoch 16/20, Loss: 14.808362
val phase, Epoch 16/20, Loss: 16.362836
Val Best Loss: 16.058643
Epoch loss: 16.362836
train phase, Epoch 17/20, Loss: 14.528585
val phase, Epoch 17/20, Loss: 15.962368
Val Best Loss: 15.962368
Epoch loss: 15.962368
train phase, Epoch 18/20, Loss: 14.561085
val phase, Epoch 18/20, Loss: 16.141748
Val Best Loss: 15.962368
Epoch loss: 16.141748
train phase, Epoch 19/20, Loss: 14.364046
val phase, Epoch 19/20, Loss: 17.124666
Val Best Loss: 15.962368
Epoch loss: 17.124666
train phase, Epoch 20/20, Loss: 13.873851
val phase, Epoch 20/20, Loss: 15.937781
Val Best Loss: 15.937781
Epoch loss: 15.937781
train phase, Epoch 1/25, Loss: 20.010864
val phase, Epoch 1/25, Loss: 17.301516
Val Best Loss: 17.301516
Epoch loss: 17.301516
train phase, Epoch 2/25, Loss: 17.954184
val phase, Epoch 2/25, Loss: 18.053600
Val Best Loss: 17.301516
Epoch loss: 18.053600
train phase, Epoch 3/25, Loss: 17.666453
val phase, Epoch 3/25, Loss: 20.112933
Val Best Loss: 17.301516
Epoch loss: 20.112933
train phase, Epoch 4/25, Loss: 17.076884
val phase, Epoch 4/25, Loss: 16.281096
Val Best Loss: 16.281096
Epoch loss: 16.281096
train phase, Epoch 5/25, Loss: 17.390646
val phase, Epoch 5/25, Loss: 17.627458
Val Best Loss: 16.281096
Epoch loss: 17.627458
train phase, Epoch 6/25, Loss: 16.846160
val phase, Epoch 6/25, Loss: 18.787560
Val Best Loss: 16.281096
Epoch loss: 18.787560
train phase, Epoch 7/25, Loss: 16.498068
val phase, Epoch 7/25, Loss: 18.291073
Val Best Loss: 16.281096
Epoch loss: 18.291073
train phase, Epoch 8/25, Loss: 16.428775
val phase, Epoch 8/25, Loss: 15.909712
Val Best Loss: 15.909712
Epoch loss: 15.909712
train phase, Epoch 9/25, Loss: 16.252706
val phase, Epoch 9/25, Loss: 16.937356
Val Best Loss: 15.909712
Epoch loss: 16.937356
train phase, Epoch 10/25, Loss: 15.817815
val phase, Epoch 10/25, Loss: 16.515214
Val Best Loss: 15.909712
Epoch loss: 16.515214
train phase, Epoch 11/25, Loss: 15.981263
val phase, Epoch 11/25, Loss: 15.860469
Val Best Loss: 15.860469
Epoch loss: 15.860469
train phase, Epoch 12/25, Loss: 15.902068
val phase, Epoch 12/25, Loss: 16.253159
Val Best Loss: 15.860469
Epoch loss: 16.253159
train phase, Epoch 13/25, Loss: 15.583355
val phase, Epoch 13/25, Loss: 16.113007
Val Best Loss: 15.860469
Epoch loss: 16.113007
train phase, Epoch 14/25, Loss: 15.340079
val phase, Epoch 14/25, Loss: 18.115203
Val Best Loss: 15.860469
Epoch loss: 18.115203
train phase, Epoch 15/25, Loss: 15.053211
val phase, Epoch 15/25, Loss: 15.964940
Val Best Loss: 15.860469
Epoch loss: 15.964940
train phase, Epoch 16/25, Loss: 15.140015
val phase, Epoch 16/25, Loss: 16.359792
Val Best Loss: 15.860469
Epoch loss: 16.359792
train phase, Epoch 17/25, Loss: 14.638463
val phase, Epoch 17/25, Loss: 16.016664
Val Best Loss: 15.860469
Epoch loss: 16.016664
train phase, Epoch 18/25, Loss: 14.303558
val phase, Epoch 18/25, Loss: 17.681743
Val Best Loss: 15.860469
Epoch loss: 17.681743
train phase, Epoch 19/25, Loss: 14.147128
val phase, Epoch 19/25, Loss: 17.345874
Val Best Loss: 15.860469
Epoch loss: 17.345874
train phase, Epoch 20/25, Loss: 13.738054
val phase, Epoch 20/25, Loss: 16.292937
Val Best Loss: 15.860469
Epoch loss: 16.292937
train phase, Epoch 21/25, Loss: 13.596541
val phase, Epoch 21/25, Loss: 17.340867
Val Best Loss: 15.860469
Epoch loss: 17.340867
train phase, Epoch 22/25, Loss: 13.219769
val phase, Epoch 22/25, Loss: 17.093725
Val Best Loss: 15.860469
Epoch loss: 17.093725
train phase, Epoch 23/25, Loss: 12.972018
val phase, Epoch 23/25, Loss: 16.629725
Val Best Loss: 15.860469
Epoch loss: 16.629725
train phase, Epoch 24/25, Loss: 12.362503
val phase, Epoch 24/25, Loss: 17.693077
Val Best Loss: 15.860469
Epoch loss: 17.693077
train phase, Epoch 25/25, Loss: 12.049233
val phase, Epoch 25/25, Loss: 20.877040
Val Best Loss: 15.860469
Epoch loss: 20.877040
train phase, Epoch 1/5, Loss: 20.230600
val phase, Epoch 1/5, Loss: 17.834177
Val Best Loss: 17.834177
Epoch loss: 17.834177
train phase, Epoch 2/5, Loss: 18.626763
val phase, Epoch 2/5, Loss: 21.748128
Val Best Loss: 17.834177
Epoch loss: 21.748128
train phase, Epoch 3/5, Loss: 17.527586
val phase, Epoch 3/5, Loss: 17.873361
Val Best Loss: 17.834177
Epoch loss: 17.873361
train phase, Epoch 4/5, Loss: 17.282312
val phase, Epoch 4/5, Loss: 21.911839
Val Best Loss: 17.834177
Epoch loss: 21.911839
train phase, Epoch 5/5, Loss: 17.409339
val phase, Epoch 5/5, Loss: 17.422970
Val Best Loss: 17.422970
Epoch loss: 17.422970
train phase, Epoch 1/30, Loss: 20.176278
val phase, Epoch 1/30, Loss: 17.977028
Val Best Loss: 17.977028
Epoch loss: 17.977028
train phase, Epoch 2/30, Loss: 18.671815
val phase, Epoch 2/30, Loss: 18.530271
Val Best Loss: 17.977028
Epoch loss: 18.530271
train phase, Epoch 3/30, Loss: 18.208289
val phase, Epoch 3/30, Loss: 22.100126
Val Best Loss: 17.977028
Epoch loss: 22.100126
train phase, Epoch 4/30, Loss: 18.167090
val phase, Epoch 4/30, Loss: 17.244151
Val Best Loss: 17.244151
Epoch loss: 17.244151
train phase, Epoch 5/30, Loss: 17.613184
val phase, Epoch 5/30, Loss: 17.257213
Val Best Loss: 17.244151
Epoch loss: 17.257213
train phase, Epoch 6/30, Loss: 17.500347
val phase, Epoch 6/30, Loss: 19.748194
Val Best Loss: 17.244151
Epoch loss: 19.748194
train phase, Epoch 7/30, Loss: 17.419267
val phase, Epoch 7/30, Loss: 18.334383
Val Best Loss: 17.244151
Epoch loss: 18.334383
train phase, Epoch 8/30, Loss: 16.933402
val phase, Epoch 8/30, Loss: 17.008476
Val Best Loss: 17.008476
Epoch loss: 17.008476
train phase, Epoch 9/30, Loss: 16.903834
val phase, Epoch 9/30, Loss: 19.157621
Val Best Loss: 17.008476
Epoch loss: 19.157621
train phase, Epoch 10/30, Loss: 16.770965
val phase, Epoch 10/30, Loss: 16.812276
Val Best Loss: 16.812276
Epoch loss: 16.812276
train phase, Epoch 11/30, Loss: 16.889319
val phase, Epoch 11/30, Loss: 16.712774
Val Best Loss: 16.712774
Epoch loss: 16.712774
train phase, Epoch 12/30, Loss: 16.315240
val phase, Epoch 12/30, Loss: 17.361494
Val Best Loss: 16.712774
Epoch loss: 17.361494
train phase, Epoch 13/30, Loss: 16.145399
val phase, Epoch 13/30, Loss: 16.806835
Val Best Loss: 16.712774
Epoch loss: 16.806835
train phase, Epoch 14/30, Loss: 16.064705
val phase, Epoch 14/30, Loss: 17.188864
Val Best Loss: 16.712774
Epoch loss: 17.188864
train phase, Epoch 15/30, Loss: 15.665163
val phase, Epoch 15/30, Loss: 16.818801
Val Best Loss: 16.712774
Epoch loss: 16.818801
train phase, Epoch 16/30, Loss: 15.529764
val phase, Epoch 16/30, Loss: 16.344645
Val Best Loss: 16.344645
Epoch loss: 16.344645
train phase, Epoch 17/30, Loss: 15.373253
val phase, Epoch 17/30, Loss: 17.370732
Val Best Loss: 16.344645
Epoch loss: 17.370732
train phase, Epoch 18/30, Loss: 14.964352
val phase, Epoch 18/30, Loss: 18.155314
Val Best Loss: 16.344645
Epoch loss: 18.155314
train phase, Epoch 19/30, Loss: 14.971412
val phase, Epoch 19/30, Loss: 18.872999
Val Best Loss: 16.344645
Epoch loss: 18.872999
train phase, Epoch 20/30, Loss: 14.426560
val phase, Epoch 20/30, Loss: 17.120058
Val Best Loss: 16.344645
Epoch loss: 17.120058
train phase, Epoch 21/30, Loss: 14.165062
val phase, Epoch 21/30, Loss: 17.086407
Val Best Loss: 16.344645
Epoch loss: 17.086407
train phase, Epoch 22/30, Loss: 13.802478
val phase, Epoch 22/30, Loss: 17.392454
Val Best Loss: 16.344645
Epoch loss: 17.392454
train phase, Epoch 23/30, Loss: 13.374311
val phase, Epoch 23/30, Loss: 17.459665
Val Best Loss: 16.344645
Epoch loss: 17.459665
train phase, Epoch 24/30, Loss: 13.082631
val phase, Epoch 24/30, Loss: 17.502266
Val Best Loss: 16.344645
Epoch loss: 17.502266
train phase, Epoch 25/30, Loss: 12.767585
val phase, Epoch 25/30, Loss: 18.914772
Val Best Loss: 16.344645
Epoch loss: 18.914772
train phase, Epoch 26/30, Loss: 12.464578
val phase, Epoch 26/30, Loss: 17.573620
Val Best Loss: 16.344645
Epoch loss: 17.573620
train phase, Epoch 27/30, Loss: 11.864343
val phase, Epoch 27/30, Loss: 17.552383
Val Best Loss: 16.344645
Epoch loss: 17.552383
train phase, Epoch 28/30, Loss: 11.463367
val phase, Epoch 28/30, Loss: 17.889497
Val Best Loss: 16.344645
Epoch loss: 17.889497
train phase, Epoch 29/30, Loss: 11.306695
val phase, Epoch 29/30, Loss: 17.927206
Val Best Loss: 16.344645
Epoch loss: 17.927206
train phase, Epoch 30/30, Loss: 10.885173
val phase, Epoch 30/30, Loss: 17.513156
Val Best Loss: 16.344645
Epoch loss: 17.513156
train phase, Epoch 1/10, Loss: 19.862310
val phase, Epoch 1/10, Loss: 17.672494
Val Best Loss: 17.672494
Epoch loss: 17.672494
train phase, Epoch 2/10, Loss: 18.260913
val phase, Epoch 2/10, Loss: 17.133012
Val Best Loss: 17.133012
Epoch loss: 17.133012
train phase, Epoch 3/10, Loss: 17.596581
val phase, Epoch 3/10, Loss: 16.342885
Val Best Loss: 16.342885
Epoch loss: 16.342885
train phase, Epoch 4/10, Loss: 17.013797
val phase, Epoch 4/10, Loss: 16.803184
Val Best Loss: 16.342885
Epoch loss: 16.803184
train phase, Epoch 5/10, Loss: 16.948976
val phase, Epoch 5/10, Loss: 16.286937
Val Best Loss: 16.286937
Epoch loss: 16.286937
train phase, Epoch 6/10, Loss: 16.396755
val phase, Epoch 6/10, Loss: 16.930328
Val Best Loss: 16.286937
Epoch loss: 16.930328
train phase, Epoch 7/10, Loss: 16.283282
val phase, Epoch 7/10, Loss: 16.049845
Val Best Loss: 16.049845
Epoch loss: 16.049845
train phase, Epoch 8/10, Loss: 16.293796
val phase, Epoch 8/10, Loss: 17.900298
Val Best Loss: 16.049845
Epoch loss: 17.900298
train phase, Epoch 9/10, Loss: 16.174162
val phase, Epoch 9/10, Loss: 18.117081
Val Best Loss: 16.049845
Epoch loss: 18.117081
train phase, Epoch 10/10, Loss: 16.006533
val phase, Epoch 10/10, Loss: 16.940036
Val Best Loss: 16.049845
Epoch loss: 16.940036
[Trial 137] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 34.699302
val phase, Epoch 1/30, Loss: 19.040477
Val Best Loss: 19.040477
Epoch loss: 19.040477
train phase, Epoch 2/30, Loss: 19.573771
val phase, Epoch 2/30, Loss: 17.989011
Val Best Loss: 17.989011
Epoch loss: 17.989011
train phase, Epoch 3/30, Loss: 18.417024
val phase, Epoch 3/30, Loss: 21.917442
Val Best Loss: 17.989011
Epoch loss: 21.917442
train phase, Epoch 4/30, Loss: 18.109731
val phase, Epoch 4/30, Loss: 17.284337
Val Best Loss: 17.284337
Epoch loss: 17.284337
train phase, Epoch 5/30, Loss: 17.418457
val phase, Epoch 5/30, Loss: 18.899347
Val Best Loss: 17.284337
Epoch loss: 18.899347
train phase, Epoch 6/30, Loss: 17.900162
val phase, Epoch 6/30, Loss: 21.833264
Val Best Loss: 17.284337
Epoch loss: 21.833264
train phase, Epoch 7/30, Loss: 17.199804
val phase, Epoch 7/30, Loss: 19.156221
Val Best Loss: 17.284337
Epoch loss: 19.156221
train phase, Epoch 8/30, Loss: 17.425755
val phase, Epoch 8/30, Loss: 16.908200
Val Best Loss: 16.908200
Epoch loss: 16.908200
train phase, Epoch 9/30, Loss: 17.008702
val phase, Epoch 9/30, Loss: 16.422444
Val Best Loss: 16.422444
Epoch loss: 16.422444
train phase, Epoch 10/30, Loss: 16.671745
val phase, Epoch 10/30, Loss: 16.759925
Val Best Loss: 16.422444
Epoch loss: 16.759925
train phase, Epoch 11/30, Loss: 16.635085
val phase, Epoch 11/30, Loss: 21.266454
Val Best Loss: 16.422444
Epoch loss: 21.266454
train phase, Epoch 12/30, Loss: 16.771117
val phase, Epoch 12/30, Loss: 17.054910
Val Best Loss: 16.422444
Epoch loss: 17.054910
train phase, Epoch 13/30, Loss: 16.482352
val phase, Epoch 13/30, Loss: 16.805391
Val Best Loss: 16.422444
Epoch loss: 16.805391
train phase, Epoch 14/30, Loss: 16.469657
val phase, Epoch 14/30, Loss: 16.790905
Val Best Loss: 16.422444
Epoch loss: 16.790905
train phase, Epoch 15/30, Loss: 16.525899
val phase, Epoch 15/30, Loss: 16.657380
Val Best Loss: 16.422444
Epoch loss: 16.657380
train phase, Epoch 16/30, Loss: 16.169622
val phase, Epoch 16/30, Loss: 18.588021
Val Best Loss: 16.422444
Epoch loss: 18.588021
train phase, Epoch 17/30, Loss: 16.649102
val phase, Epoch 17/30, Loss: 16.973182
Val Best Loss: 16.422444
Epoch loss: 16.973182
train phase, Epoch 18/30, Loss: 16.196948
val phase, Epoch 18/30, Loss: 16.998866
Val Best Loss: 16.422444
Epoch loss: 16.998866
train phase, Epoch 19/30, Loss: 16.114511
val phase, Epoch 19/30, Loss: 17.685119
Val Best Loss: 16.422444
Epoch loss: 17.685119
train phase, Epoch 20/30, Loss: 15.926714
val phase, Epoch 20/30, Loss: 16.977842
Val Best Loss: 16.422444
Epoch loss: 16.977842
train phase, Epoch 21/30, Loss: 15.765135
val phase, Epoch 21/30, Loss: 16.795355
Val Best Loss: 16.422444
Epoch loss: 16.795355
train phase, Epoch 22/30, Loss: 15.764623
val phase, Epoch 22/30, Loss: 17.905565
Val Best Loss: 16.422444
Epoch loss: 17.905565
train phase, Epoch 23/30, Loss: 15.751629
val phase, Epoch 23/30, Loss: 16.820798
Val Best Loss: 16.422444
Epoch loss: 16.820798
train phase, Epoch 24/30, Loss: 15.461802
val phase, Epoch 24/30, Loss: 18.799353
Val Best Loss: 16.422444
Epoch loss: 18.799353
train phase, Epoch 25/30, Loss: 15.420403
val phase, Epoch 25/30, Loss: 18.265323
Val Best Loss: 16.422444
Epoch loss: 18.265323
train phase, Epoch 26/30, Loss: 15.102526
val phase, Epoch 26/30, Loss: 19.390565
Val Best Loss: 16.422444
Epoch loss: 19.390565
train phase, Epoch 27/30, Loss: 15.105561
val phase, Epoch 27/30, Loss: 17.533093
Val Best Loss: 16.422444
Epoch loss: 17.533093
train phase, Epoch 28/30, Loss: 14.867705
val phase, Epoch 28/30, Loss: 17.277220
Val Best Loss: 16.422444
Epoch loss: 17.277220
train phase, Epoch 29/30, Loss: 14.452897
val phase, Epoch 29/30, Loss: 17.617816
Val Best Loss: 16.422444
Epoch loss: 17.617816
train phase, Epoch 30/30, Loss: 14.481673
val phase, Epoch 30/30, Loss: 18.681148
Val Best Loss: 16.422444
Epoch loss: 18.681148
train phase, Epoch 1/20, Loss: 22.070188
val phase, Epoch 1/20, Loss: 20.587172
Val Best Loss: 20.587172
Epoch loss: 20.587172
train phase, Epoch 2/20, Loss: 20.072578
val phase, Epoch 2/20, Loss: 19.522433
Val Best Loss: 19.522433
Epoch loss: 19.522433
train phase, Epoch 3/20, Loss: 19.537140
val phase, Epoch 3/20, Loss: 17.385865
Val Best Loss: 17.385865
Epoch loss: 17.385865
train phase, Epoch 4/20, Loss: 18.540296
val phase, Epoch 4/20, Loss: 18.088887
Val Best Loss: 17.385865
Epoch loss: 18.088887
train phase, Epoch 5/20, Loss: 18.929211
val phase, Epoch 5/20, Loss: 18.386598
Val Best Loss: 17.385865
Epoch loss: 18.386598
train phase, Epoch 6/20, Loss: 18.287272
val phase, Epoch 6/20, Loss: 18.545920
Val Best Loss: 17.385865
Epoch loss: 18.545920
train phase, Epoch 7/20, Loss: 18.205189
val phase, Epoch 7/20, Loss: 19.326210
Val Best Loss: 17.385865
Epoch loss: 19.326210
train phase, Epoch 8/20, Loss: 17.818187
val phase, Epoch 8/20, Loss: 16.964770
Val Best Loss: 16.964770
Epoch loss: 16.964770
train phase, Epoch 9/20, Loss: 17.866529
val phase, Epoch 9/20, Loss: 17.008044
Val Best Loss: 16.964770
Epoch loss: 17.008044
train phase, Epoch 10/20, Loss: 17.721922
val phase, Epoch 10/20, Loss: 20.226706
Val Best Loss: 16.964770
Epoch loss: 20.226706
train phase, Epoch 11/20, Loss: 17.636256
val phase, Epoch 11/20, Loss: 17.025178
Val Best Loss: 16.964770
Epoch loss: 17.025178
train phase, Epoch 12/20, Loss: 17.366578
val phase, Epoch 12/20, Loss: 16.641062
Val Best Loss: 16.641062
Epoch loss: 16.641062
train phase, Epoch 13/20, Loss: 17.234668
val phase, Epoch 13/20, Loss: 16.771844
Val Best Loss: 16.641062
Epoch loss: 16.771844
train phase, Epoch 14/20, Loss: 17.227843
val phase, Epoch 14/20, Loss: 17.395507
Val Best Loss: 16.641062
Epoch loss: 17.395507
train phase, Epoch 15/20, Loss: 17.300123
val phase, Epoch 15/20, Loss: 16.784306
Val Best Loss: 16.641062
Epoch loss: 16.784306
train phase, Epoch 16/20, Loss: 17.042848
val phase, Epoch 16/20, Loss: 17.119958
Val Best Loss: 16.641062
Epoch loss: 17.119958
train phase, Epoch 17/20, Loss: 17.085044
val phase, Epoch 17/20, Loss: 16.805121
Val Best Loss: 16.641062
Epoch loss: 16.805121
train phase, Epoch 18/20, Loss: 16.823441
val phase, Epoch 18/20, Loss: 20.281743
Val Best Loss: 16.641062
Epoch loss: 20.281743
train phase, Epoch 19/20, Loss: 16.855882
val phase, Epoch 19/20, Loss: 17.660874
Val Best Loss: 16.641062
Epoch loss: 17.660874
train phase, Epoch 20/20, Loss: 16.894522
val phase, Epoch 20/20, Loss: 16.875027
Val Best Loss: 16.641062
Epoch loss: 16.875027
train phase, Epoch 1/30, Loss: 19.680893
val phase, Epoch 1/30, Loss: 17.423836
Val Best Loss: 17.423836
Epoch loss: 17.423836
train phase, Epoch 2/30, Loss: 18.396388
val phase, Epoch 2/30, Loss: 16.931415
Val Best Loss: 16.931415
Epoch loss: 16.931415
train phase, Epoch 3/30, Loss: 17.561387
val phase, Epoch 3/30, Loss: 17.521896
Val Best Loss: 16.931415
Epoch loss: 17.521896
train phase, Epoch 4/30, Loss: 17.456751
val phase, Epoch 4/30, Loss: 17.799383
Val Best Loss: 16.931415
Epoch loss: 17.799383
train phase, Epoch 5/30, Loss: 17.380817
val phase, Epoch 5/30, Loss: 22.343759
Val Best Loss: 16.931415
Epoch loss: 22.343759
train phase, Epoch 6/30, Loss: 17.184102
val phase, Epoch 6/30, Loss: 16.600470
Val Best Loss: 16.600470
Epoch loss: 16.600470
train phase, Epoch 7/30, Loss: 16.680112
val phase, Epoch 7/30, Loss: 16.065983
Val Best Loss: 16.065983
Epoch loss: 16.065983
train phase, Epoch 8/30, Loss: 16.670262
val phase, Epoch 8/30, Loss: 16.365330
Val Best Loss: 16.065983
Epoch loss: 16.365330
train phase, Epoch 9/30, Loss: 16.200786
val phase, Epoch 9/30, Loss: 16.639776
Val Best Loss: 16.065983
Epoch loss: 16.639776
train phase, Epoch 10/30, Loss: 16.294425
val phase, Epoch 10/30, Loss: 16.727139
Val Best Loss: 16.065983
Epoch loss: 16.727139
train phase, Epoch 11/30, Loss: 15.982631
val phase, Epoch 11/30, Loss: 15.906532
Val Best Loss: 15.906532
Epoch loss: 15.906532
train phase, Epoch 12/30, Loss: 15.954699
val phase, Epoch 12/30, Loss: 17.865747
Val Best Loss: 15.906532
Epoch loss: 17.865747
train phase, Epoch 13/30, Loss: 15.775851
val phase, Epoch 13/30, Loss: 16.297450
Val Best Loss: 15.906532
Epoch loss: 16.297450
train phase, Epoch 14/30, Loss: 15.437376
val phase, Epoch 14/30, Loss: 16.356138
Val Best Loss: 15.906532
Epoch loss: 16.356138
train phase, Epoch 15/30, Loss: 15.283383
val phase, Epoch 15/30, Loss: 16.207452
Val Best Loss: 15.906532
Epoch loss: 16.207452
train phase, Epoch 16/30, Loss: 15.408236
val phase, Epoch 16/30, Loss: 16.331584
Val Best Loss: 15.906532
Epoch loss: 16.331584
train phase, Epoch 17/30, Loss: 15.096545
val phase, Epoch 17/30, Loss: 16.079902
Val Best Loss: 15.906532
Epoch loss: 16.079902
train phase, Epoch 18/30, Loss: 15.035677
val phase, Epoch 18/30, Loss: 16.428074
Val Best Loss: 15.906532
Epoch loss: 16.428074
train phase, Epoch 19/30, Loss: 14.896937
val phase, Epoch 19/30, Loss: 16.468306
Val Best Loss: 15.906532
Epoch loss: 16.468306
train phase, Epoch 20/30, Loss: 14.533933
val phase, Epoch 20/30, Loss: 16.177626
Val Best Loss: 15.906532
Epoch loss: 16.177626
train phase, Epoch 21/30, Loss: 14.392962
val phase, Epoch 21/30, Loss: 17.091777
Val Best Loss: 15.906532
Epoch loss: 17.091777
train phase, Epoch 22/30, Loss: 14.170816
val phase, Epoch 22/30, Loss: 17.041268
Val Best Loss: 15.906532
Epoch loss: 17.041268
train phase, Epoch 23/30, Loss: 13.923323
val phase, Epoch 23/30, Loss: 16.908647
Val Best Loss: 15.906532
Epoch loss: 16.908647
train phase, Epoch 24/30, Loss: 13.910388
val phase, Epoch 24/30, Loss: 16.869475
Val Best Loss: 15.906532
Epoch loss: 16.869475
train phase, Epoch 25/30, Loss: 13.604504
val phase, Epoch 25/30, Loss: 17.206307
Val Best Loss: 15.906532
Epoch loss: 17.206307
train phase, Epoch 26/30, Loss: 13.714178
val phase, Epoch 26/30, Loss: 16.802281
Val Best Loss: 15.906532
Epoch loss: 16.802281
train phase, Epoch 27/30, Loss: 12.909363
val phase, Epoch 27/30, Loss: 16.724568
Val Best Loss: 15.906532
Epoch loss: 16.724568
train phase, Epoch 28/30, Loss: 13.031395
val phase, Epoch 28/30, Loss: 16.869529
Val Best Loss: 15.906532
Epoch loss: 16.869529
train phase, Epoch 29/30, Loss: 12.433186
val phase, Epoch 29/30, Loss: 20.042375
Val Best Loss: 15.906532
Epoch loss: 20.042375
train phase, Epoch 30/30, Loss: 12.274250
val phase, Epoch 30/30, Loss: 17.975364
Val Best Loss: 15.906532
Epoch loss: 17.975364
train phase, Epoch 1/20, Loss: 20.478138
val phase, Epoch 1/20, Loss: 17.434811
Val Best Loss: 17.434811
Epoch loss: 17.434811
train phase, Epoch 2/20, Loss: 17.567085
val phase, Epoch 2/20, Loss: 16.668600
Val Best Loss: 16.668600
Epoch loss: 16.668600
train phase, Epoch 3/20, Loss: 17.197065
val phase, Epoch 3/20, Loss: 17.181352
Val Best Loss: 16.668600
Epoch loss: 17.181352
train phase, Epoch 4/20, Loss: 17.227000
val phase, Epoch 4/20, Loss: 17.234351
Val Best Loss: 16.668600
Epoch loss: 17.234351
train phase, Epoch 5/20, Loss: 16.993855
val phase, Epoch 5/20, Loss: 17.394453
Val Best Loss: 16.668600
Epoch loss: 17.394453
train phase, Epoch 6/20, Loss: 16.833643
val phase, Epoch 6/20, Loss: 16.816921
Val Best Loss: 16.668600
Epoch loss: 16.816921
train phase, Epoch 7/20, Loss: 16.261210
val phase, Epoch 7/20, Loss: 16.149225
Val Best Loss: 16.149225
Epoch loss: 16.149225
train phase, Epoch 8/20, Loss: 16.390870
val phase, Epoch 8/20, Loss: 16.712161
Val Best Loss: 16.149225
Epoch loss: 16.712161
train phase, Epoch 9/20, Loss: 16.057637
val phase, Epoch 9/20, Loss: 16.751701
Val Best Loss: 16.149225
Epoch loss: 16.751701
train phase, Epoch 10/20, Loss: 15.913789
val phase, Epoch 10/20, Loss: 16.603059
Val Best Loss: 16.149225
Epoch loss: 16.603059
train phase, Epoch 11/20, Loss: 15.653639
val phase, Epoch 11/20, Loss: 17.266337
Val Best Loss: 16.149225
Epoch loss: 17.266337
train phase, Epoch 12/20, Loss: 15.593858
val phase, Epoch 12/20, Loss: 16.455244
Val Best Loss: 16.149225
Epoch loss: 16.455244
train phase, Epoch 13/20, Loss: 15.412971
val phase, Epoch 13/20, Loss: 17.101629
Val Best Loss: 16.149225
Epoch loss: 17.101629
train phase, Epoch 14/20, Loss: 15.125159
val phase, Epoch 14/20, Loss: 17.461122
Val Best Loss: 16.149225
Epoch loss: 17.461122
train phase, Epoch 15/20, Loss: 15.083232
val phase, Epoch 15/20, Loss: 16.052637
Val Best Loss: 16.052637
Epoch loss: 16.052637
train phase, Epoch 16/20, Loss: 15.129115
val phase, Epoch 16/20, Loss: 18.241999
Val Best Loss: 16.052637
Epoch loss: 18.241999
train phase, Epoch 17/20, Loss: 14.696281
val phase, Epoch 17/20, Loss: 16.932781
Val Best Loss: 16.052637
Epoch loss: 16.932781
train phase, Epoch 18/20, Loss: 14.618522
val phase, Epoch 18/20, Loss: 16.900586
Val Best Loss: 16.052637
Epoch loss: 16.900586
train phase, Epoch 19/20, Loss: 14.332897
val phase, Epoch 19/20, Loss: 17.099189
Val Best Loss: 16.052637
Epoch loss: 17.099189
train phase, Epoch 20/20, Loss: 13.824880
val phase, Epoch 20/20, Loss: 17.485280
Val Best Loss: 16.052637
Epoch loss: 17.485280
train phase, Epoch 1/20, Loss: 19.844907
val phase, Epoch 1/20, Loss: 19.020169
Val Best Loss: 19.020169
Epoch loss: 19.020169
train phase, Epoch 2/20, Loss: 17.986129
val phase, Epoch 2/20, Loss: 16.948218
Val Best Loss: 16.948218
Epoch loss: 16.948218
train phase, Epoch 3/20, Loss: 17.321411
val phase, Epoch 3/20, Loss: 16.663944
Val Best Loss: 16.663944
Epoch loss: 16.663944
train phase, Epoch 4/20, Loss: 17.309411
val phase, Epoch 4/20, Loss: 16.449514
Val Best Loss: 16.449514
Epoch loss: 16.449514
train phase, Epoch 5/20, Loss: 16.663375
val phase, Epoch 5/20, Loss: 16.521141
Val Best Loss: 16.449514
Epoch loss: 16.521141
train phase, Epoch 6/20, Loss: 16.836346
val phase, Epoch 6/20, Loss: 16.149433
Val Best Loss: 16.149433
Epoch loss: 16.149433
train phase, Epoch 7/20, Loss: 16.473294
val phase, Epoch 7/20, Loss: 16.180631
Val Best Loss: 16.149433
Epoch loss: 16.180631
train phase, Epoch 8/20, Loss: 16.650395
val phase, Epoch 8/20, Loss: 16.483162
Val Best Loss: 16.149433
Epoch loss: 16.483162
train phase, Epoch 9/20, Loss: 16.366827
val phase, Epoch 9/20, Loss: 16.104263
Val Best Loss: 16.104263
Epoch loss: 16.104263
train phase, Epoch 10/20, Loss: 16.182096
val phase, Epoch 10/20, Loss: 15.793755
Val Best Loss: 15.793755
Epoch loss: 15.793755
train phase, Epoch 11/20, Loss: 15.743118
val phase, Epoch 11/20, Loss: 16.196501
Val Best Loss: 15.793755
Epoch loss: 16.196501
train phase, Epoch 12/20, Loss: 15.579269
val phase, Epoch 12/20, Loss: 16.096355
Val Best Loss: 15.793755
Epoch loss: 16.096355
train phase, Epoch 13/20, Loss: 15.742687
val phase, Epoch 13/20, Loss: 16.621504
Val Best Loss: 15.793755
Epoch loss: 16.621504
train phase, Epoch 14/20, Loss: 15.305173
val phase, Epoch 14/20, Loss: 17.553947
Val Best Loss: 15.793755
Epoch loss: 17.553947
train phase, Epoch 15/20, Loss: 15.376418
val phase, Epoch 15/20, Loss: 17.853435
Val Best Loss: 15.793755
Epoch loss: 17.853435
train phase, Epoch 16/20, Loss: 15.073579
val phase, Epoch 16/20, Loss: 15.895642
Val Best Loss: 15.793755
Epoch loss: 15.895642
train phase, Epoch 17/20, Loss: 14.844800
val phase, Epoch 17/20, Loss: 16.134043
Val Best Loss: 15.793755
Epoch loss: 16.134043
train phase, Epoch 18/20, Loss: 14.748726
val phase, Epoch 18/20, Loss: 16.195568
Val Best Loss: 15.793755
Epoch loss: 16.195568
train phase, Epoch 19/20, Loss: 14.728513
val phase, Epoch 19/20, Loss: 15.705954
Val Best Loss: 15.705954
Epoch loss: 15.705954
train phase, Epoch 20/20, Loss: 14.259055
val phase, Epoch 20/20, Loss: 16.518093
Val Best Loss: 15.705954
Epoch loss: 16.518093
train phase, Epoch 1/20, Loss: 20.224606
val phase, Epoch 1/20, Loss: 16.839281
Val Best Loss: 16.839281
Epoch loss: 16.839281
train phase, Epoch 2/20, Loss: 17.975450
val phase, Epoch 2/20, Loss: 16.686802
Val Best Loss: 16.686802
Epoch loss: 16.686802
train phase, Epoch 3/20, Loss: 17.413068
val phase, Epoch 3/20, Loss: 16.977485
Val Best Loss: 16.686802
Epoch loss: 16.977485
train phase, Epoch 4/20, Loss: 17.327889
val phase, Epoch 4/20, Loss: 16.959435
Val Best Loss: 16.686802
Epoch loss: 16.959435
train phase, Epoch 5/20, Loss: 16.980233
val phase, Epoch 5/20, Loss: 17.711285
Val Best Loss: 16.686802
Epoch loss: 17.711285
train phase, Epoch 6/20, Loss: 16.792237
val phase, Epoch 6/20, Loss: 16.415830
Val Best Loss: 16.415830
Epoch loss: 16.415830
train phase, Epoch 7/20, Loss: 16.453968
val phase, Epoch 7/20, Loss: 17.256361
Val Best Loss: 16.415830
Epoch loss: 17.256361
train phase, Epoch 8/20, Loss: 16.290735
val phase, Epoch 8/20, Loss: 16.555274
Val Best Loss: 16.415830
Epoch loss: 16.555274
train phase, Epoch 9/20, Loss: 16.304787
val phase, Epoch 9/20, Loss: 19.740307
Val Best Loss: 16.415830
Epoch loss: 19.740307
train phase, Epoch 10/20, Loss: 16.109816
val phase, Epoch 10/20, Loss: 15.908071
Val Best Loss: 15.908071
Epoch loss: 15.908071
train phase, Epoch 11/20, Loss: 15.761701
val phase, Epoch 11/20, Loss: 16.497282
Val Best Loss: 15.908071
Epoch loss: 16.497282
train phase, Epoch 12/20, Loss: 15.818590
val phase, Epoch 12/20, Loss: 16.250182
Val Best Loss: 15.908071
Epoch loss: 16.250182
train phase, Epoch 13/20, Loss: 15.334018
val phase, Epoch 13/20, Loss: 16.080504
Val Best Loss: 15.908071
Epoch loss: 16.080504
train phase, Epoch 14/20, Loss: 15.409277
val phase, Epoch 14/20, Loss: 16.048867
Val Best Loss: 15.908071
Epoch loss: 16.048867
train phase, Epoch 15/20, Loss: 14.996481
val phase, Epoch 15/20, Loss: 16.561797
Val Best Loss: 15.908071
Epoch loss: 16.561797
train phase, Epoch 16/20, Loss: 14.985204
val phase, Epoch 16/20, Loss: 15.939645
Val Best Loss: 15.908071
Epoch loss: 15.939645
train phase, Epoch 17/20, Loss: 14.493714
val phase, Epoch 17/20, Loss: 16.444881
Val Best Loss: 15.908071
Epoch loss: 16.444881
train phase, Epoch 18/20, Loss: 14.428182
val phase, Epoch 18/20, Loss: 16.412714
Val Best Loss: 15.908071
Epoch loss: 16.412714
train phase, Epoch 19/20, Loss: 13.788193
val phase, Epoch 19/20, Loss: 16.417952
Val Best Loss: 15.908071
Epoch loss: 16.417952
train phase, Epoch 20/20, Loss: 13.925728
val phase, Epoch 20/20, Loss: 16.018344
Val Best Loss: 15.908071
Epoch loss: 16.018344
train phase, Epoch 1/20, Loss: 19.629680
val phase, Epoch 1/20, Loss: 28.891076
Val Best Loss: 28.891076
Epoch loss: 28.891076
train phase, Epoch 2/20, Loss: 17.852944
val phase, Epoch 2/20, Loss: 20.393972
Val Best Loss: 20.393972
Epoch loss: 20.393972
train phase, Epoch 3/20, Loss: 17.549767
val phase, Epoch 3/20, Loss: 16.401503
Val Best Loss: 16.401503
Epoch loss: 16.401503
train phase, Epoch 4/20, Loss: 17.118299
val phase, Epoch 4/20, Loss: 19.001406
Val Best Loss: 16.401503
Epoch loss: 19.001406
train phase, Epoch 5/20, Loss: 16.835929
val phase, Epoch 5/20, Loss: 17.045356
Val Best Loss: 16.401503
Epoch loss: 17.045356
train phase, Epoch 6/20, Loss: 16.570229
val phase, Epoch 6/20, Loss: 16.883796
Val Best Loss: 16.401503
Epoch loss: 16.883796
train phase, Epoch 7/20, Loss: 16.505581
val phase, Epoch 7/20, Loss: 15.952666
Val Best Loss: 15.952666
Epoch loss: 15.952666
train phase, Epoch 8/20, Loss: 16.422938
val phase, Epoch 8/20, Loss: 15.743640
Val Best Loss: 15.743640
Epoch loss: 15.743640
train phase, Epoch 9/20, Loss: 16.169479
val phase, Epoch 9/20, Loss: 16.256587
Val Best Loss: 15.743640
Epoch loss: 16.256587
train phase, Epoch 10/20, Loss: 15.970492
val phase, Epoch 10/20, Loss: 17.087662
Val Best Loss: 15.743640
Epoch loss: 17.087662
train phase, Epoch 11/20, Loss: 15.874693
val phase, Epoch 11/20, Loss: 15.817152
Val Best Loss: 15.743640
Epoch loss: 15.817152
train phase, Epoch 12/20, Loss: 15.614750
val phase, Epoch 12/20, Loss: 16.105136
Val Best Loss: 15.743640
Epoch loss: 16.105136
train phase, Epoch 13/20, Loss: 15.419581
val phase, Epoch 13/20, Loss: 16.029061
Val Best Loss: 15.743640
Epoch loss: 16.029061
train phase, Epoch 14/20, Loss: 15.234135
val phase, Epoch 14/20, Loss: 15.824677
Val Best Loss: 15.743640
Epoch loss: 15.824677
train phase, Epoch 15/20, Loss: 15.080838
val phase, Epoch 15/20, Loss: 16.593589
Val Best Loss: 15.743640
Epoch loss: 16.593589
train phase, Epoch 16/20, Loss: 14.934254
val phase, Epoch 16/20, Loss: 18.003512
Val Best Loss: 15.743640
Epoch loss: 18.003512
train phase, Epoch 17/20, Loss: 14.808087
val phase, Epoch 17/20, Loss: 16.954392
Val Best Loss: 15.743640
Epoch loss: 16.954392
train phase, Epoch 18/20, Loss: 14.205595
val phase, Epoch 18/20, Loss: 16.000907
Val Best Loss: 15.743640
Epoch loss: 16.000907
train phase, Epoch 19/20, Loss: 14.054738
val phase, Epoch 19/20, Loss: 16.438391
Val Best Loss: 15.743640
Epoch loss: 16.438391
train phase, Epoch 20/20, Loss: 13.769135
val phase, Epoch 20/20, Loss: 17.695807
Val Best Loss: 15.743640
Epoch loss: 17.695807
train phase, Epoch 1/20, Loss: 20.094745
val phase, Epoch 1/20, Loss: 17.433911
Val Best Loss: 17.433911
Epoch loss: 17.433911
train phase, Epoch 2/20, Loss: 17.637088
val phase, Epoch 2/20, Loss: 16.783276
Val Best Loss: 16.783276
Epoch loss: 16.783276
train phase, Epoch 3/20, Loss: 17.311744
val phase, Epoch 3/20, Loss: 16.382384
Val Best Loss: 16.382384
Epoch loss: 16.382384
train phase, Epoch 4/20, Loss: 17.022612
val phase, Epoch 4/20, Loss: 17.720029
Val Best Loss: 16.382384
Epoch loss: 17.720029
train phase, Epoch 5/20, Loss: 16.897631
val phase, Epoch 5/20, Loss: 16.272298
Val Best Loss: 16.272298
Epoch loss: 16.272298
train phase, Epoch 6/20, Loss: 16.814723
val phase, Epoch 6/20, Loss: 16.146798
Val Best Loss: 16.146798
Epoch loss: 16.146798
train phase, Epoch 7/20, Loss: 16.494917
val phase, Epoch 7/20, Loss: 15.943931
Val Best Loss: 15.943931
Epoch loss: 15.943931
train phase, Epoch 8/20, Loss: 16.174822
val phase, Epoch 8/20, Loss: 16.045174
Val Best Loss: 15.943931
Epoch loss: 16.045174
train phase, Epoch 9/20, Loss: 16.270292
val phase, Epoch 9/20, Loss: 16.090252
Val Best Loss: 15.943931
Epoch loss: 16.090252
train phase, Epoch 10/20, Loss: 15.793446
val phase, Epoch 10/20, Loss: 16.422201
Val Best Loss: 15.943931
Epoch loss: 16.422201
train phase, Epoch 11/20, Loss: 15.798636
val phase, Epoch 11/20, Loss: 16.920536
Val Best Loss: 15.943931
Epoch loss: 16.920536
train phase, Epoch 12/20, Loss: 15.855609
val phase, Epoch 12/20, Loss: 15.819374
Val Best Loss: 15.819374
Epoch loss: 15.819374
train phase, Epoch 13/20, Loss: 15.857095
val phase, Epoch 13/20, Loss: 16.801469
Val Best Loss: 15.819374
Epoch loss: 16.801469
train phase, Epoch 14/20, Loss: 15.425999
val phase, Epoch 14/20, Loss: 16.036242
Val Best Loss: 15.819374
Epoch loss: 16.036242
train phase, Epoch 15/20, Loss: 15.148857
val phase, Epoch 15/20, Loss: 16.304857
Val Best Loss: 15.819374
Epoch loss: 16.304857
train phase, Epoch 16/20, Loss: 15.056475
val phase, Epoch 16/20, Loss: 15.814670
Val Best Loss: 15.814670
Epoch loss: 15.814670
train phase, Epoch 17/20, Loss: 14.833974
val phase, Epoch 17/20, Loss: 16.245035
Val Best Loss: 15.814670
Epoch loss: 16.245035
train phase, Epoch 18/20, Loss: 14.908479
val phase, Epoch 18/20, Loss: 16.618039
Val Best Loss: 15.814670
Epoch loss: 16.618039
train phase, Epoch 19/20, Loss: 14.297744
val phase, Epoch 19/20, Loss: 16.501667
Val Best Loss: 15.814670
Epoch loss: 16.501667
train phase, Epoch 20/20, Loss: 14.286876
val phase, Epoch 20/20, Loss: 16.946270
Val Best Loss: 15.814670
Epoch loss: 16.946270
[Trial 146] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
[Trial 147] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.814835
val phase, Epoch 1/20, Loss: 17.326727
Val Best Loss: 17.326727
Epoch loss: 17.326727
train phase, Epoch 2/20, Loss: 17.688952
val phase, Epoch 2/20, Loss: 18.455218
Val Best Loss: 17.326727
Epoch loss: 18.455218
train phase, Epoch 3/20, Loss: 17.289020
val phase, Epoch 3/20, Loss: 16.527083
Val Best Loss: 16.527083
Epoch loss: 16.527083
train phase, Epoch 4/20, Loss: 16.897228
val phase, Epoch 4/20, Loss: 16.718110
Val Best Loss: 16.527083
Epoch loss: 16.718110
train phase, Epoch 5/20, Loss: 16.690915
val phase, Epoch 5/20, Loss: 15.773395
Val Best Loss: 15.773395
Epoch loss: 15.773395
train phase, Epoch 6/20, Loss: 16.377736
val phase, Epoch 6/20, Loss: 16.614266
Val Best Loss: 15.773395
Epoch loss: 16.614266
train phase, Epoch 7/20, Loss: 16.315558
val phase, Epoch 7/20, Loss: 16.103290
Val Best Loss: 15.773395
Epoch loss: 16.103290
train phase, Epoch 8/20, Loss: 16.248290
val phase, Epoch 8/20, Loss: 16.749010
Val Best Loss: 15.773395
Epoch loss: 16.749010
train phase, Epoch 9/20, Loss: 16.067296
val phase, Epoch 9/20, Loss: 16.032967
Val Best Loss: 15.773395
Epoch loss: 16.032967
train phase, Epoch 10/20, Loss: 15.879505
val phase, Epoch 10/20, Loss: 15.673532
Val Best Loss: 15.673532
Epoch loss: 15.673532
train phase, Epoch 11/20, Loss: 15.664448
val phase, Epoch 11/20, Loss: 16.559376
Val Best Loss: 15.673532
Epoch loss: 16.559376
train phase, Epoch 12/20, Loss: 15.565038
val phase, Epoch 12/20, Loss: 15.688179
Val Best Loss: 15.673532
Epoch loss: 15.688179
train phase, Epoch 13/20, Loss: 15.103209
val phase, Epoch 13/20, Loss: 16.597411
Val Best Loss: 15.673532
Epoch loss: 16.597411
train phase, Epoch 14/20, Loss: 15.217730
val phase, Epoch 14/20, Loss: 15.745158
Val Best Loss: 15.673532
Epoch loss: 15.745158
train phase, Epoch 15/20, Loss: 14.862500
val phase, Epoch 15/20, Loss: 16.940449
Val Best Loss: 15.673532
Epoch loss: 16.940449
train phase, Epoch 16/20, Loss: 14.712928
val phase, Epoch 16/20, Loss: 16.161576
Val Best Loss: 15.673532
Epoch loss: 16.161576
train phase, Epoch 17/20, Loss: 14.400904
val phase, Epoch 17/20, Loss: 16.128545
Val Best Loss: 15.673532
Epoch loss: 16.128545
train phase, Epoch 18/20, Loss: 14.361151
val phase, Epoch 18/20, Loss: 17.256990
Val Best Loss: 15.673532
Epoch loss: 17.256990
train phase, Epoch 19/20, Loss: 13.837050
val phase, Epoch 19/20, Loss: 16.825861
Val Best Loss: 15.673532
Epoch loss: 16.825861
train phase, Epoch 20/20, Loss: 13.607608
val phase, Epoch 20/20, Loss: 16.703487
Val Best Loss: 15.673532
Epoch loss: 16.703487
train phase, Epoch 1/15, Loss: 19.851934
val phase, Epoch 1/15, Loss: 30.034979
Val Best Loss: 30.034979
Epoch loss: 30.034979
train phase, Epoch 2/15, Loss: 18.108463
val phase, Epoch 2/15, Loss: 29.418719
Val Best Loss: 29.418719
Epoch loss: 29.418719
train phase, Epoch 3/15, Loss: 17.540134
val phase, Epoch 3/15, Loss: 31.443766
Val Best Loss: 29.418719
Epoch loss: 31.443766
train phase, Epoch 4/15, Loss: 17.475330
val phase, Epoch 4/15, Loss: 33.404549
Val Best Loss: 29.418719
Epoch loss: 33.404549
train phase, Epoch 5/15, Loss: 17.211007
val phase, Epoch 5/15, Loss: 36.483533
Val Best Loss: 29.418719
Epoch loss: 36.483533
train phase, Epoch 6/15, Loss: 16.777891
val phase, Epoch 6/15, Loss: 34.901435
Val Best Loss: 29.418719
Epoch loss: 34.901435
train phase, Epoch 7/15, Loss: 16.617850
val phase, Epoch 7/15, Loss: 39.093671
Val Best Loss: 29.418719
Epoch loss: 39.093671
train phase, Epoch 8/15, Loss: 16.445986
val phase, Epoch 8/15, Loss: 35.697786
Val Best Loss: 29.418719
Epoch loss: 35.697786
train phase, Epoch 9/15, Loss: 16.176825
val phase, Epoch 9/15, Loss: 36.762916
Val Best Loss: 29.418719
Epoch loss: 36.762916
train phase, Epoch 10/15, Loss: 16.148928
val phase, Epoch 10/15, Loss: 34.404783
Val Best Loss: 29.418719
Epoch loss: 34.404783
train phase, Epoch 11/15, Loss: 15.835897
val phase, Epoch 11/15, Loss: 29.241729
Val Best Loss: 29.241729
Epoch loss: 29.241729
train phase, Epoch 12/15, Loss: 15.711435
val phase, Epoch 12/15, Loss: 35.245558
Val Best Loss: 29.241729
Epoch loss: 35.245558
train phase, Epoch 13/15, Loss: 15.473741
val phase, Epoch 13/15, Loss: 33.712855
Val Best Loss: 29.241729
Epoch loss: 33.712855
train phase, Epoch 14/15, Loss: 15.139660
val phase, Epoch 14/15, Loss: 37.456908
Val Best Loss: 29.241729
Epoch loss: 37.456908
train phase, Epoch 15/15, Loss: 14.971342
val phase, Epoch 15/15, Loss: 31.166161
Val Best Loss: 29.241729
Epoch loss: 31.166161
train phase, Epoch 1/30, Loss: 20.478659
val phase, Epoch 1/30, Loss: 20.859053
Val Best Loss: 20.859053
Epoch loss: 20.859053
train phase, Epoch 2/30, Loss: 18.637231
val phase, Epoch 2/30, Loss: 18.121824
Val Best Loss: 18.121824
Epoch loss: 18.121824
train phase, Epoch 3/30, Loss: 18.003094
val phase, Epoch 3/30, Loss: 20.355074
Val Best Loss: 18.121824
Epoch loss: 20.355074
train phase, Epoch 4/30, Loss: 17.719504
val phase, Epoch 4/30, Loss: 20.825226
Val Best Loss: 18.121824
Epoch loss: 20.825226
train phase, Epoch 5/30, Loss: 17.500639
val phase, Epoch 5/30, Loss: 18.059685
Val Best Loss: 18.059685
Epoch loss: 18.059685
train phase, Epoch 6/30, Loss: 17.112043
val phase, Epoch 6/30, Loss: 17.233102
Val Best Loss: 17.233102
Epoch loss: 17.233102
train phase, Epoch 7/30, Loss: 16.975814
val phase, Epoch 7/30, Loss: 17.055961
Val Best Loss: 17.055961
Epoch loss: 17.055961
train phase, Epoch 8/30, Loss: 17.035676
val phase, Epoch 8/30, Loss: 17.442386
Val Best Loss: 17.055961
Epoch loss: 17.442386
train phase, Epoch 9/30, Loss: 16.673530
val phase, Epoch 9/30, Loss: 16.969377
Val Best Loss: 16.969377
Epoch loss: 16.969377
train phase, Epoch 10/30, Loss: 16.526373
val phase, Epoch 10/30, Loss: 17.063421
Val Best Loss: 16.969377
Epoch loss: 17.063421
train phase, Epoch 11/30, Loss: 16.201193
val phase, Epoch 11/30, Loss: 17.524182
Val Best Loss: 16.969377
Epoch loss: 17.524182
train phase, Epoch 12/30, Loss: 16.182938
val phase, Epoch 12/30, Loss: 16.586390
Val Best Loss: 16.586390
Epoch loss: 16.586390
train phase, Epoch 13/30, Loss: 15.844316
val phase, Epoch 13/30, Loss: 17.437480
Val Best Loss: 16.586390
Epoch loss: 17.437480
train phase, Epoch 14/30, Loss: 15.778344
val phase, Epoch 14/30, Loss: 16.470525
Val Best Loss: 16.470525
Epoch loss: 16.470525
train phase, Epoch 15/30, Loss: 15.565764
val phase, Epoch 15/30, Loss: 16.723400
Val Best Loss: 16.470525
Epoch loss: 16.723400
train phase, Epoch 16/30, Loss: 15.513896
val phase, Epoch 16/30, Loss: 17.016372
Val Best Loss: 16.470525
Epoch loss: 17.016372
train phase, Epoch 17/30, Loss: 15.521374
val phase, Epoch 17/30, Loss: 16.720099
Val Best Loss: 16.470525
Epoch loss: 16.720099
train phase, Epoch 18/30, Loss: 15.016958
val phase, Epoch 18/30, Loss: 16.744806
Val Best Loss: 16.470525
Epoch loss: 16.744806
train phase, Epoch 19/30, Loss: 14.803490
val phase, Epoch 19/30, Loss: 16.709462
Val Best Loss: 16.470525
Epoch loss: 16.709462
train phase, Epoch 20/30, Loss: 14.562696
val phase, Epoch 20/30, Loss: 17.034664
Val Best Loss: 16.470525
Epoch loss: 17.034664
train phase, Epoch 21/30, Loss: 14.312676
val phase, Epoch 21/30, Loss: 16.726728
Val Best Loss: 16.470525
Epoch loss: 16.726728
train phase, Epoch 22/30, Loss: 14.049510
val phase, Epoch 22/30, Loss: 17.029731
Val Best Loss: 16.470525
Epoch loss: 17.029731
train phase, Epoch 23/30, Loss: 13.818836
val phase, Epoch 23/30, Loss: 17.148469
Val Best Loss: 16.470525
Epoch loss: 17.148469
train phase, Epoch 24/30, Loss: 13.622852
val phase, Epoch 24/30, Loss: 17.661910
Val Best Loss: 16.470525
Epoch loss: 17.661910
train phase, Epoch 25/30, Loss: 13.379813
val phase, Epoch 25/30, Loss: 17.542305
Val Best Loss: 16.470525
Epoch loss: 17.542305
train phase, Epoch 26/30, Loss: 12.770252
val phase, Epoch 26/30, Loss: 19.898764
Val Best Loss: 16.470525
Epoch loss: 19.898764
train phase, Epoch 27/30, Loss: 12.418869
val phase, Epoch 27/30, Loss: 18.233109
Val Best Loss: 16.470525
Epoch loss: 18.233109
train phase, Epoch 28/30, Loss: 12.120258
val phase, Epoch 28/30, Loss: 17.878906
Val Best Loss: 16.470525
Epoch loss: 17.878906
train phase, Epoch 29/30, Loss: 11.926866
val phase, Epoch 29/30, Loss: 17.963860
Val Best Loss: 16.470525
Epoch loss: 17.963860
train phase, Epoch 30/30, Loss: 11.438683
val phase, Epoch 30/30, Loss: 18.550104
Val Best Loss: 16.470525
Epoch loss: 18.550104
train phase, Epoch 1/20, Loss: 19.845883
val phase, Epoch 1/20, Loss: 20.050890
Val Best Loss: 20.050890
Epoch loss: 20.050890
train phase, Epoch 2/20, Loss: 17.953149
val phase, Epoch 2/20, Loss: 17.376667
Val Best Loss: 17.376667
Epoch loss: 17.376667
train phase, Epoch 3/20, Loss: 17.584047
val phase, Epoch 3/20, Loss: 16.127686
Val Best Loss: 16.127686
Epoch loss: 16.127686
train phase, Epoch 4/20, Loss: 17.176595
val phase, Epoch 4/20, Loss: 16.428849
Val Best Loss: 16.127686
Epoch loss: 16.428849
train phase, Epoch 5/20, Loss: 17.186015
val phase, Epoch 5/20, Loss: 25.735923
Val Best Loss: 16.127686
Epoch loss: 25.735923
train phase, Epoch 6/20, Loss: 16.689340
val phase, Epoch 6/20, Loss: 16.234856
Val Best Loss: 16.127686
Epoch loss: 16.234856
train phase, Epoch 7/20, Loss: 16.422823
val phase, Epoch 7/20, Loss: 16.598507
Val Best Loss: 16.127686
Epoch loss: 16.598507
train phase, Epoch 8/20, Loss: 16.215657
val phase, Epoch 8/20, Loss: 15.842125
Val Best Loss: 15.842125
Epoch loss: 15.842125
train phase, Epoch 9/20, Loss: 16.036687
val phase, Epoch 9/20, Loss: 18.450546
Val Best Loss: 15.842125
Epoch loss: 18.450546
train phase, Epoch 10/20, Loss: 16.101908
val phase, Epoch 10/20, Loss: 16.086795
Val Best Loss: 15.842125
Epoch loss: 16.086795
train phase, Epoch 11/20, Loss: 15.937563
val phase, Epoch 11/20, Loss: 15.839675
Val Best Loss: 15.839675
Epoch loss: 15.839675
train phase, Epoch 12/20, Loss: 15.722773
val phase, Epoch 12/20, Loss: 19.219318
Val Best Loss: 15.839675
Epoch loss: 19.219318
train phase, Epoch 13/20, Loss: 15.555698
val phase, Epoch 13/20, Loss: 16.833395
Val Best Loss: 15.839675
Epoch loss: 16.833395
train phase, Epoch 14/20, Loss: 15.341823
val phase, Epoch 14/20, Loss: 17.742073
Val Best Loss: 15.839675
Epoch loss: 17.742073
train phase, Epoch 15/20, Loss: 14.975549
val phase, Epoch 15/20, Loss: 17.183683
Val Best Loss: 15.839675
Epoch loss: 17.183683
train phase, Epoch 16/20, Loss: 15.050784
val phase, Epoch 16/20, Loss: 15.977307
Val Best Loss: 15.839675
Epoch loss: 15.977307
train phase, Epoch 17/20, Loss: 14.604025
val phase, Epoch 17/20, Loss: 16.479336
Val Best Loss: 15.839675
Epoch loss: 16.479336
train phase, Epoch 18/20, Loss: 14.412031
val phase, Epoch 18/20, Loss: 16.515728
Val Best Loss: 15.839675
Epoch loss: 16.515728
train phase, Epoch 19/20, Loss: 14.231752
val phase, Epoch 19/20, Loss: 17.154302
Val Best Loss: 15.839675
Epoch loss: 17.154302
train phase, Epoch 20/20, Loss: 13.834394
val phase, Epoch 20/20, Loss: 16.026117
Val Best Loss: 15.839675
Epoch loss: 16.026117
train phase, Epoch 1/20, Loss: 19.998214
val phase, Epoch 1/20, Loss: 17.166441
Val Best Loss: 17.166441
Epoch loss: 17.166441
train phase, Epoch 2/20, Loss: 18.148870
val phase, Epoch 2/20, Loss: 16.876556
Val Best Loss: 16.876556
Epoch loss: 16.876556
train phase, Epoch 3/20, Loss: 17.024592
val phase, Epoch 3/20, Loss: 16.141614
Val Best Loss: 16.141614
Epoch loss: 16.141614
train phase, Epoch 4/20, Loss: 17.228968
val phase, Epoch 4/20, Loss: 16.212803
Val Best Loss: 16.141614
Epoch loss: 16.212803
train phase, Epoch 5/20, Loss: 16.934152
val phase, Epoch 5/20, Loss: 16.387663
Val Best Loss: 16.141614
Epoch loss: 16.387663
train phase, Epoch 6/20, Loss: 16.488396
val phase, Epoch 6/20, Loss: 16.275058
Val Best Loss: 16.141614
Epoch loss: 16.275058
train phase, Epoch 7/20, Loss: 16.555603
val phase, Epoch 7/20, Loss: 16.227390
Val Best Loss: 16.141614
Epoch loss: 16.227390
train phase, Epoch 8/20, Loss: 16.230940
val phase, Epoch 8/20, Loss: 16.376201
Val Best Loss: 16.141614
Epoch loss: 16.376201
train phase, Epoch 9/20, Loss: 16.181287
val phase, Epoch 9/20, Loss: 15.786350
Val Best Loss: 15.786350
Epoch loss: 15.786350
train phase, Epoch 10/20, Loss: 15.784483
val phase, Epoch 10/20, Loss: 16.543952
Val Best Loss: 15.786350
Epoch loss: 16.543952
train phase, Epoch 11/20, Loss: 15.614218
val phase, Epoch 11/20, Loss: 15.980215
Val Best Loss: 15.786350
Epoch loss: 15.980215
train phase, Epoch 12/20, Loss: 15.573214
val phase, Epoch 12/20, Loss: 16.034305
Val Best Loss: 15.786350
Epoch loss: 16.034305
train phase, Epoch 13/20, Loss: 15.437100
val phase, Epoch 13/20, Loss: 15.750239
Val Best Loss: 15.750239
Epoch loss: 15.750239
train phase, Epoch 14/20, Loss: 15.261500
val phase, Epoch 14/20, Loss: 16.848294
Val Best Loss: 15.750239
Epoch loss: 16.848294
train phase, Epoch 15/20, Loss: 15.097894
val phase, Epoch 15/20, Loss: 18.632734
Val Best Loss: 15.750239
Epoch loss: 18.632734
train phase, Epoch 16/20, Loss: 15.143979
val phase, Epoch 16/20, Loss: 15.735727
Val Best Loss: 15.735727
Epoch loss: 15.735727
train phase, Epoch 17/20, Loss: 14.621072
val phase, Epoch 17/20, Loss: 15.789771
Val Best Loss: 15.735727
Epoch loss: 15.789771
train phase, Epoch 18/20, Loss: 14.534873
val phase, Epoch 18/20, Loss: 17.306490
Val Best Loss: 15.735727
Epoch loss: 17.306490
train phase, Epoch 19/20, Loss: 14.113916
val phase, Epoch 19/20, Loss: 16.232296
Val Best Loss: 15.735727
Epoch loss: 16.232296
train phase, Epoch 20/20, Loss: 13.896054
val phase, Epoch 20/20, Loss: 16.141113
Val Best Loss: 15.735727
Epoch loss: 16.141113
train phase, Epoch 1/20, Loss: 19.801249
val phase, Epoch 1/20, Loss: 18.646784
Val Best Loss: 18.646784
Epoch loss: 18.646784
train phase, Epoch 2/20, Loss: 17.697842
val phase, Epoch 2/20, Loss: 17.367345
Val Best Loss: 17.367345
Epoch loss: 17.367345
train phase, Epoch 3/20, Loss: 17.581801
val phase, Epoch 3/20, Loss: 17.653751
Val Best Loss: 17.367345
Epoch loss: 17.653751
train phase, Epoch 4/20, Loss: 17.013735
val phase, Epoch 4/20, Loss: 16.309876
Val Best Loss: 16.309876
Epoch loss: 16.309876
train phase, Epoch 5/20, Loss: 16.928637
val phase, Epoch 5/20, Loss: 18.045989
Val Best Loss: 16.309876
Epoch loss: 18.045989
train phase, Epoch 6/20, Loss: 16.739507
val phase, Epoch 6/20, Loss: 16.137629
Val Best Loss: 16.137629
Epoch loss: 16.137629
train phase, Epoch 7/20, Loss: 16.246894
val phase, Epoch 7/20, Loss: 17.003291
Val Best Loss: 16.137629
Epoch loss: 17.003291
train phase, Epoch 8/20, Loss: 16.207937
val phase, Epoch 8/20, Loss: 18.961680
Val Best Loss: 16.137629
Epoch loss: 18.961680
train phase, Epoch 9/20, Loss: 16.187658
val phase, Epoch 9/20, Loss: 17.656002
Val Best Loss: 16.137629
Epoch loss: 17.656002
train phase, Epoch 10/20, Loss: 15.830036
val phase, Epoch 10/20, Loss: 16.079802
Val Best Loss: 16.079802
Epoch loss: 16.079802
train phase, Epoch 11/20, Loss: 15.618902
val phase, Epoch 11/20, Loss: 16.840819
Val Best Loss: 16.079802
Epoch loss: 16.840819
train phase, Epoch 12/20, Loss: 15.694091
val phase, Epoch 12/20, Loss: 16.715838
Val Best Loss: 16.079802
Epoch loss: 16.715838
train phase, Epoch 13/20, Loss: 15.314349
val phase, Epoch 13/20, Loss: 16.094760
Val Best Loss: 16.079802
Epoch loss: 16.094760
train phase, Epoch 14/20, Loss: 15.052877
val phase, Epoch 14/20, Loss: 16.543601
Val Best Loss: 16.079802
Epoch loss: 16.543601
train phase, Epoch 15/20, Loss: 14.990056
val phase, Epoch 15/20, Loss: 17.926629
Val Best Loss: 16.079802
Epoch loss: 17.926629
train phase, Epoch 16/20, Loss: 14.877833
val phase, Epoch 16/20, Loss: 16.950681
Val Best Loss: 16.079802
Epoch loss: 16.950681
train phase, Epoch 17/20, Loss: 14.753343
val phase, Epoch 17/20, Loss: 16.536273
Val Best Loss: 16.079802
Epoch loss: 16.536273
train phase, Epoch 18/20, Loss: 14.583949
val phase, Epoch 18/20, Loss: 18.142181
Val Best Loss: 16.079802
Epoch loss: 18.142181
train phase, Epoch 19/20, Loss: 13.832085
val phase, Epoch 19/20, Loss: 17.253597
Val Best Loss: 16.079802
Epoch loss: 17.253597
train phase, Epoch 20/20, Loss: 13.862058
val phase, Epoch 20/20, Loss: 17.002332
Val Best Loss: 16.079802
Epoch loss: 17.002332
train phase, Epoch 1/20, Loss: 19.715843
val phase, Epoch 1/20, Loss: 16.779796
Val Best Loss: 16.779796
Epoch loss: 16.779796
train phase, Epoch 2/20, Loss: 17.770948
val phase, Epoch 2/20, Loss: 16.459847
Val Best Loss: 16.459847
Epoch loss: 16.459847
train phase, Epoch 3/20, Loss: 17.415112
val phase, Epoch 3/20, Loss: 17.698583
Val Best Loss: 16.459847
Epoch loss: 17.698583
train phase, Epoch 4/20, Loss: 17.293099
val phase, Epoch 4/20, Loss: 16.495034
Val Best Loss: 16.459847
Epoch loss: 16.495034
train phase, Epoch 5/20, Loss: 16.867395
val phase, Epoch 5/20, Loss: 16.567213
Val Best Loss: 16.459847
Epoch loss: 16.567213
train phase, Epoch 6/20, Loss: 16.492049
val phase, Epoch 6/20, Loss: 18.288719
Val Best Loss: 16.459847
Epoch loss: 18.288719
train phase, Epoch 7/20, Loss: 16.777762
val phase, Epoch 7/20, Loss: 18.569240
Val Best Loss: 16.459847
Epoch loss: 18.569240
train phase, Epoch 8/20, Loss: 16.415833
val phase, Epoch 8/20, Loss: 16.607508
Val Best Loss: 16.459847
Epoch loss: 16.607508
train phase, Epoch 9/20, Loss: 16.436533
val phase, Epoch 9/20, Loss: 15.896013
Val Best Loss: 15.896013
Epoch loss: 15.896013
train phase, Epoch 10/20, Loss: 15.895370
val phase, Epoch 10/20, Loss: 16.624976
Val Best Loss: 15.896013
Epoch loss: 16.624976
train phase, Epoch 11/20, Loss: 15.642169
val phase, Epoch 11/20, Loss: 15.950427
Val Best Loss: 15.896013
Epoch loss: 15.950427
train phase, Epoch 12/20, Loss: 15.579152
val phase, Epoch 12/20, Loss: 16.641286
Val Best Loss: 15.896013
Epoch loss: 16.641286
train phase, Epoch 13/20, Loss: 15.322176
val phase, Epoch 13/20, Loss: 16.217782
Val Best Loss: 15.896013
Epoch loss: 16.217782
train phase, Epoch 14/20, Loss: 15.140282
val phase, Epoch 14/20, Loss: 15.848061
Val Best Loss: 15.848061
Epoch loss: 15.848061
train phase, Epoch 15/20, Loss: 14.833194
val phase, Epoch 15/20, Loss: 16.576672
Val Best Loss: 15.848061
Epoch loss: 16.576672
train phase, Epoch 16/20, Loss: 14.644726
val phase, Epoch 16/20, Loss: 17.772990
Val Best Loss: 15.848061
Epoch loss: 17.772990
train phase, Epoch 17/20, Loss: 14.260368
val phase, Epoch 17/20, Loss: 16.159547
Val Best Loss: 15.848061
Epoch loss: 16.159547
train phase, Epoch 18/20, Loss: 14.087733
val phase, Epoch 18/20, Loss: 16.896378
Val Best Loss: 15.848061
Epoch loss: 16.896378
train phase, Epoch 19/20, Loss: 13.970928
val phase, Epoch 19/20, Loss: 16.585641
Val Best Loss: 15.848061
Epoch loss: 16.585641
train phase, Epoch 20/20, Loss: 13.455425
val phase, Epoch 20/20, Loss: 18.688078
Val Best Loss: 15.848061
Epoch loss: 18.688078
train phase, Epoch 1/20, Loss: 19.887915
val phase, Epoch 1/20, Loss: 17.703640
Val Best Loss: 17.703640
Epoch loss: 17.703640
train phase, Epoch 2/20, Loss: 18.490774
val phase, Epoch 2/20, Loss: 17.592947
Val Best Loss: 17.592947
Epoch loss: 17.592947
train phase, Epoch 3/20, Loss: 17.645511
val phase, Epoch 3/20, Loss: 19.183730
Val Best Loss: 17.592947
Epoch loss: 19.183730
train phase, Epoch 4/20, Loss: 17.018642
val phase, Epoch 4/20, Loss: 16.678933
Val Best Loss: 16.678933
Epoch loss: 16.678933
train phase, Epoch 5/20, Loss: 16.970957
val phase, Epoch 5/20, Loss: 21.180432
Val Best Loss: 16.678933
Epoch loss: 21.180432
train phase, Epoch 6/20, Loss: 17.120457
val phase, Epoch 6/20, Loss: 16.605942
Val Best Loss: 16.605942
Epoch loss: 16.605942
train phase, Epoch 7/20, Loss: 16.466173
val phase, Epoch 7/20, Loss: 16.062689
Val Best Loss: 16.062689
Epoch loss: 16.062689
train phase, Epoch 8/20, Loss: 16.312923
val phase, Epoch 8/20, Loss: 15.979219
Val Best Loss: 15.979219
Epoch loss: 15.979219
train phase, Epoch 9/20, Loss: 16.121101
val phase, Epoch 9/20, Loss: 21.567065
Val Best Loss: 15.979219
Epoch loss: 21.567065
train phase, Epoch 10/20, Loss: 16.574165
val phase, Epoch 10/20, Loss: 16.192730
Val Best Loss: 15.979219
Epoch loss: 16.192730
train phase, Epoch 11/20, Loss: 15.740107
val phase, Epoch 11/20, Loss: 17.727452
Val Best Loss: 15.979219
Epoch loss: 17.727452
train phase, Epoch 12/20, Loss: 15.828124
val phase, Epoch 12/20, Loss: 18.491382
Val Best Loss: 15.979219
Epoch loss: 18.491382
train phase, Epoch 13/20, Loss: 15.709967
val phase, Epoch 13/20, Loss: 17.767644
Val Best Loss: 15.979219
Epoch loss: 17.767644
train phase, Epoch 14/20, Loss: 15.363039
val phase, Epoch 14/20, Loss: 20.146577
Val Best Loss: 15.979219
Epoch loss: 20.146577
train phase, Epoch 15/20, Loss: 15.440936
val phase, Epoch 15/20, Loss: 17.559279
Val Best Loss: 15.979219
Epoch loss: 17.559279
train phase, Epoch 16/20, Loss: 15.278229
val phase, Epoch 16/20, Loss: 17.143895
Val Best Loss: 15.979219
Epoch loss: 17.143895
train phase, Epoch 17/20, Loss: 15.285616
val phase, Epoch 17/20, Loss: 16.214482
Val Best Loss: 15.979219
Epoch loss: 16.214482
train phase, Epoch 18/20, Loss: 14.878054
val phase, Epoch 18/20, Loss: 16.770309
Val Best Loss: 15.979219
Epoch loss: 16.770309
train phase, Epoch 19/20, Loss: 14.894445
val phase, Epoch 19/20, Loss: 16.345974
Val Best Loss: 15.979219
Epoch loss: 16.345974
train phase, Epoch 20/20, Loss: 14.714038
val phase, Epoch 20/20, Loss: 16.229289
Val Best Loss: 15.979219
Epoch loss: 16.229289
train phase, Epoch 1/20, Loss: 20.608718
val phase, Epoch 1/20, Loss: 17.767951
Val Best Loss: 17.767951
Epoch loss: 17.767951
train phase, Epoch 2/20, Loss: 17.789467
val phase, Epoch 2/20, Loss: 18.098128
Val Best Loss: 17.767951
Epoch loss: 18.098128
train phase, Epoch 3/20, Loss: 17.376287
val phase, Epoch 3/20, Loss: 16.952605
Val Best Loss: 16.952605
Epoch loss: 16.952605
train phase, Epoch 4/20, Loss: 17.343883
val phase, Epoch 4/20, Loss: 17.190823
Val Best Loss: 16.952605
Epoch loss: 17.190823
train phase, Epoch 5/20, Loss: 16.985366
val phase, Epoch 5/20, Loss: 18.288983
Val Best Loss: 16.952605
Epoch loss: 18.288983
train phase, Epoch 6/20, Loss: 16.944421
val phase, Epoch 6/20, Loss: 21.831429
Val Best Loss: 16.952605
Epoch loss: 21.831429
train phase, Epoch 7/20, Loss: 16.641379
val phase, Epoch 7/20, Loss: 16.421883
Val Best Loss: 16.421883
Epoch loss: 16.421883
train phase, Epoch 8/20, Loss: 16.524426
val phase, Epoch 8/20, Loss: 16.253308
Val Best Loss: 16.253308
Epoch loss: 16.253308
train phase, Epoch 9/20, Loss: 16.279435
val phase, Epoch 9/20, Loss: 16.284409
Val Best Loss: 16.253308
Epoch loss: 16.284409
train phase, Epoch 10/20, Loss: 16.124054
val phase, Epoch 10/20, Loss: 16.039650
Val Best Loss: 16.039650
Epoch loss: 16.039650
train phase, Epoch 11/20, Loss: 15.725785
val phase, Epoch 11/20, Loss: 17.112240
Val Best Loss: 16.039650
Epoch loss: 17.112240
train phase, Epoch 12/20, Loss: 16.091727
val phase, Epoch 12/20, Loss: 16.205561
Val Best Loss: 16.039650
Epoch loss: 16.205561
train phase, Epoch 13/20, Loss: 15.496145
val phase, Epoch 13/20, Loss: 16.278661
Val Best Loss: 16.039650
Epoch loss: 16.278661
train phase, Epoch 14/20, Loss: 15.707747
val phase, Epoch 14/20, Loss: 16.170420
Val Best Loss: 16.039650
Epoch loss: 16.170420
train phase, Epoch 15/20, Loss: 15.374534
val phase, Epoch 15/20, Loss: 16.172131
Val Best Loss: 16.039650
Epoch loss: 16.172131
train phase, Epoch 16/20, Loss: 15.279156
val phase, Epoch 16/20, Loss: 15.882591
Val Best Loss: 15.882591
Epoch loss: 15.882591
train phase, Epoch 17/20, Loss: 14.833675
val phase, Epoch 17/20, Loss: 16.826631
Val Best Loss: 15.882591
Epoch loss: 16.826631
train phase, Epoch 18/20, Loss: 14.715656
val phase, Epoch 18/20, Loss: 17.395655
Val Best Loss: 15.882591
Epoch loss: 17.395655
train phase, Epoch 19/20, Loss: 14.480667
val phase, Epoch 19/20, Loss: 16.633962
Val Best Loss: 15.882591
Epoch loss: 16.633962
train phase, Epoch 20/20, Loss: 14.609796
val phase, Epoch 20/20, Loss: 15.919114
Val Best Loss: 15.882591
Epoch loss: 15.919114
train phase, Epoch 1/12, Loss: 27.982278
val phase, Epoch 1/12, Loss: 18.138193
Val Best Loss: 18.138193
Epoch loss: 18.138193
train phase, Epoch 2/12, Loss: 18.337456
val phase, Epoch 2/12, Loss: 17.960846
Val Best Loss: 17.960846
Epoch loss: 17.960846
train phase, Epoch 3/12, Loss: 17.947019
val phase, Epoch 3/12, Loss: 18.389128
Val Best Loss: 17.960846
Epoch loss: 18.389128
train phase, Epoch 4/12, Loss: 17.689175
val phase, Epoch 4/12, Loss: 16.944545
Val Best Loss: 16.944545
Epoch loss: 16.944545
train phase, Epoch 5/12, Loss: 17.246105
val phase, Epoch 5/12, Loss: 16.657314
Val Best Loss: 16.657314
Epoch loss: 16.657314
train phase, Epoch 6/12, Loss: 17.129095
val phase, Epoch 6/12, Loss: 17.259616
Val Best Loss: 16.657314
Epoch loss: 17.259616
train phase, Epoch 7/12, Loss: 16.908371
val phase, Epoch 7/12, Loss: 17.274550
Val Best Loss: 16.657314
Epoch loss: 17.274550
train phase, Epoch 8/12, Loss: 16.819460
val phase, Epoch 8/12, Loss: 16.628723
Val Best Loss: 16.628723
Epoch loss: 16.628723
train phase, Epoch 9/12, Loss: 16.673277
val phase, Epoch 9/12, Loss: 16.328957
Val Best Loss: 16.328957
Epoch loss: 16.328957
train phase, Epoch 10/12, Loss: 16.725526
val phase, Epoch 10/12, Loss: 17.604064
Val Best Loss: 16.328957
Epoch loss: 17.604064
train phase, Epoch 11/12, Loss: 16.618699
val phase, Epoch 11/12, Loss: 16.606627
Val Best Loss: 16.328957
Epoch loss: 16.606627
train phase, Epoch 12/12, Loss: 16.495562
val phase, Epoch 12/12, Loss: 16.508482
Val Best Loss: 16.328957
Epoch loss: 16.508482
train phase, Epoch 1/20, Loss: 20.208099
val phase, Epoch 1/20, Loss: 25.102570
Val Best Loss: 25.102570
Epoch loss: 25.102570
train phase, Epoch 2/20, Loss: 18.332875
val phase, Epoch 2/20, Loss: 16.739353
Val Best Loss: 16.739353
Epoch loss: 16.739353
train phase, Epoch 3/20, Loss: 17.601055
val phase, Epoch 3/20, Loss: 16.618291
Val Best Loss: 16.618291
Epoch loss: 16.618291
train phase, Epoch 4/20, Loss: 17.145428
val phase, Epoch 4/20, Loss: 26.412437
Val Best Loss: 16.618291
Epoch loss: 26.412437
train phase, Epoch 5/20, Loss: 16.984632
val phase, Epoch 5/20, Loss: 16.935136
Val Best Loss: 16.618291
Epoch loss: 16.935136
train phase, Epoch 6/20, Loss: 16.968715
val phase, Epoch 6/20, Loss: 16.385844
Val Best Loss: 16.385844
Epoch loss: 16.385844
train phase, Epoch 7/20, Loss: 16.745565
val phase, Epoch 7/20, Loss: 16.958630
Val Best Loss: 16.385844
Epoch loss: 16.958630
train phase, Epoch 8/20, Loss: 16.716450
val phase, Epoch 8/20, Loss: 16.119697
Val Best Loss: 16.119697
Epoch loss: 16.119697
train phase, Epoch 9/20, Loss: 16.314018
val phase, Epoch 9/20, Loss: 16.492307
Val Best Loss: 16.119697
Epoch loss: 16.492307
train phase, Epoch 10/20, Loss: 16.276798
val phase, Epoch 10/20, Loss: 18.139325
Val Best Loss: 16.119697
Epoch loss: 18.139325
train phase, Epoch 11/20, Loss: 16.058144
val phase, Epoch 11/20, Loss: 16.349394
Val Best Loss: 16.119697
Epoch loss: 16.349394
train phase, Epoch 12/20, Loss: 15.872421
val phase, Epoch 12/20, Loss: 16.376140
Val Best Loss: 16.119697
Epoch loss: 16.376140
train phase, Epoch 13/20, Loss: 15.699513
val phase, Epoch 13/20, Loss: 16.114627
Val Best Loss: 16.114627
Epoch loss: 16.114627
train phase, Epoch 14/20, Loss: 15.797566
val phase, Epoch 14/20, Loss: 16.114229
Val Best Loss: 16.114229
Epoch loss: 16.114229
train phase, Epoch 15/20, Loss: 15.702616
val phase, Epoch 15/20, Loss: 16.451169
Val Best Loss: 16.114229
Epoch loss: 16.451169
train phase, Epoch 16/20, Loss: 15.488926
val phase, Epoch 16/20, Loss: 17.273736
Val Best Loss: 16.114229
Epoch loss: 17.273736
train phase, Epoch 17/20, Loss: 15.235799
val phase, Epoch 17/20, Loss: 16.113201
Val Best Loss: 16.113201
Epoch loss: 16.113201
train phase, Epoch 18/20, Loss: 15.158621
val phase, Epoch 18/20, Loss: 16.471460
Val Best Loss: 16.113201
Epoch loss: 16.471460
train phase, Epoch 19/20, Loss: 14.802467
val phase, Epoch 19/20, Loss: 16.128346
Val Best Loss: 16.113201
Epoch loss: 16.128346
train phase, Epoch 20/20, Loss: 14.642011
val phase, Epoch 20/20, Loss: 16.182360
Val Best Loss: 16.113201
Epoch loss: 16.182360
train phase, Epoch 1/30, Loss: 20.308763
val phase, Epoch 1/30, Loss: 19.841745
Val Best Loss: 19.841745
Epoch loss: 19.841745
train phase, Epoch 2/30, Loss: 18.295545
val phase, Epoch 2/30, Loss: 16.561487
Val Best Loss: 16.561487
Epoch loss: 16.561487
train phase, Epoch 3/30, Loss: 17.195176
val phase, Epoch 3/30, Loss: 17.137875
Val Best Loss: 16.561487
Epoch loss: 17.137875
train phase, Epoch 4/30, Loss: 17.171982
val phase, Epoch 4/30, Loss: 18.628000
Val Best Loss: 16.561487
Epoch loss: 18.628000
train phase, Epoch 5/30, Loss: 16.751278
val phase, Epoch 5/30, Loss: 15.894569
Val Best Loss: 15.894569
Epoch loss: 15.894569
train phase, Epoch 6/30, Loss: 16.365158
val phase, Epoch 6/30, Loss: 15.975184
Val Best Loss: 15.894569
Epoch loss: 15.975184
train phase, Epoch 7/30, Loss: 16.678733
val phase, Epoch 7/30, Loss: 16.015670
Val Best Loss: 15.894569
Epoch loss: 16.015670
train phase, Epoch 8/30, Loss: 16.768681
val phase, Epoch 8/30, Loss: 16.090852
Val Best Loss: 15.894569
Epoch loss: 16.090852
train phase, Epoch 9/30, Loss: 16.098154
val phase, Epoch 9/30, Loss: 15.847722
Val Best Loss: 15.847722
Epoch loss: 15.847722
train phase, Epoch 10/30, Loss: 15.790145
val phase, Epoch 10/30, Loss: 17.157829
Val Best Loss: 15.847722
Epoch loss: 17.157829
train phase, Epoch 11/30, Loss: 15.838794
val phase, Epoch 11/30, Loss: 16.268634
Val Best Loss: 15.847722
Epoch loss: 16.268634
train phase, Epoch 12/30, Loss: 15.684130
val phase, Epoch 12/30, Loss: 15.521300
Val Best Loss: 15.521300
Epoch loss: 15.521300
train phase, Epoch 13/30, Loss: 15.652902
val phase, Epoch 13/30, Loss: 17.275566
Val Best Loss: 15.521300
Epoch loss: 17.275566
train phase, Epoch 14/30, Loss: 15.342785
val phase, Epoch 14/30, Loss: 16.867752
Val Best Loss: 15.521300
Epoch loss: 16.867752
train phase, Epoch 15/30, Loss: 15.207690
val phase, Epoch 15/30, Loss: 16.026326
Val Best Loss: 15.521300
Epoch loss: 16.026326
train phase, Epoch 16/30, Loss: 15.091644
val phase, Epoch 16/30, Loss: 16.400003
Val Best Loss: 15.521300
Epoch loss: 16.400003
train phase, Epoch 17/30, Loss: 15.003301
val phase, Epoch 17/30, Loss: 15.940327
Val Best Loss: 15.521300
Epoch loss: 15.940327
train phase, Epoch 18/30, Loss: 14.422714
val phase, Epoch 18/30, Loss: 16.741590
Val Best Loss: 15.521300
Epoch loss: 16.741590
train phase, Epoch 19/30, Loss: 14.107379
val phase, Epoch 19/30, Loss: 19.288692
Val Best Loss: 15.521300
Epoch loss: 19.288692
train phase, Epoch 20/30, Loss: 14.159492
val phase, Epoch 20/30, Loss: 17.482406
Val Best Loss: 15.521300
Epoch loss: 17.482406
train phase, Epoch 21/30, Loss: 13.841286
val phase, Epoch 21/30, Loss: 17.856708
Val Best Loss: 15.521300
Epoch loss: 17.856708
train phase, Epoch 22/30, Loss: 13.398526
val phase, Epoch 22/30, Loss: 18.043919
Val Best Loss: 15.521300
Epoch loss: 18.043919
train phase, Epoch 23/30, Loss: 12.954140
val phase, Epoch 23/30, Loss: 17.217671
Val Best Loss: 15.521300
Epoch loss: 17.217671
train phase, Epoch 24/30, Loss: 12.687614
val phase, Epoch 24/30, Loss: 17.687776
Val Best Loss: 15.521300
Epoch loss: 17.687776
train phase, Epoch 25/30, Loss: 12.229174
val phase, Epoch 25/30, Loss: 17.221193
Val Best Loss: 15.521300
Epoch loss: 17.221193
train phase, Epoch 26/30, Loss: 11.999158
val phase, Epoch 26/30, Loss: 18.197893
Val Best Loss: 15.521300
Epoch loss: 18.197893
train phase, Epoch 27/30, Loss: 11.414377
val phase, Epoch 27/30, Loss: 18.818932
Val Best Loss: 15.521300
Epoch loss: 18.818932
train phase, Epoch 28/30, Loss: 11.085276
val phase, Epoch 28/30, Loss: 18.037103
Val Best Loss: 15.521300
Epoch loss: 18.037103
train phase, Epoch 29/30, Loss: 10.408213
val phase, Epoch 29/30, Loss: 18.370435
Val Best Loss: 15.521300
Epoch loss: 18.370435
train phase, Epoch 30/30, Loss: 9.904501
val phase, Epoch 30/30, Loss: 19.012120
Val Best Loss: 15.521300
Epoch loss: 19.012120
[Trial 160] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 19.964701
val phase, Epoch 1/30, Loss: 17.100715
Val Best Loss: 17.100715
Epoch loss: 17.100715
train phase, Epoch 2/30, Loss: 17.472336
val phase, Epoch 2/30, Loss: 18.036355
Val Best Loss: 17.100715
Epoch loss: 18.036355
train phase, Epoch 3/30, Loss: 17.582818
val phase, Epoch 3/30, Loss: 16.485232
Val Best Loss: 16.485232
Epoch loss: 16.485232
train phase, Epoch 4/30, Loss: 16.905200
val phase, Epoch 4/30, Loss: 19.184248
Val Best Loss: 16.485232
Epoch loss: 19.184248
train phase, Epoch 5/30, Loss: 17.346651
val phase, Epoch 5/30, Loss: 17.021694
Val Best Loss: 16.485232
Epoch loss: 17.021694
train phase, Epoch 6/30, Loss: 16.568179
val phase, Epoch 6/30, Loss: 17.902243
Val Best Loss: 16.485232
Epoch loss: 17.902243
train phase, Epoch 7/30, Loss: 16.405644
val phase, Epoch 7/30, Loss: 16.187032
Val Best Loss: 16.187032
Epoch loss: 16.187032
train phase, Epoch 8/30, Loss: 16.441649
val phase, Epoch 8/30, Loss: 16.264807
Val Best Loss: 16.187032
Epoch loss: 16.264807
train phase, Epoch 9/30, Loss: 16.111469
val phase, Epoch 9/30, Loss: 15.993642
Val Best Loss: 15.993642
Epoch loss: 15.993642
train phase, Epoch 10/30, Loss: 16.120583
val phase, Epoch 10/30, Loss: 16.187585
Val Best Loss: 15.993642
Epoch loss: 16.187585
train phase, Epoch 11/30, Loss: 15.954335
val phase, Epoch 11/30, Loss: 16.497646
Val Best Loss: 15.993642
Epoch loss: 16.497646
train phase, Epoch 12/30, Loss: 15.608136
val phase, Epoch 12/30, Loss: 15.998704
Val Best Loss: 15.993642
Epoch loss: 15.998704
train phase, Epoch 13/30, Loss: 15.767508
val phase, Epoch 13/30, Loss: 16.421555
Val Best Loss: 15.993642
Epoch loss: 16.421555
train phase, Epoch 14/30, Loss: 15.497792
val phase, Epoch 14/30, Loss: 15.987688
Val Best Loss: 15.987688
Epoch loss: 15.987688
train phase, Epoch 15/30, Loss: 15.237154
val phase, Epoch 15/30, Loss: 16.155807
Val Best Loss: 15.987688
Epoch loss: 16.155807
train phase, Epoch 16/30, Loss: 15.018328
val phase, Epoch 16/30, Loss: 16.069833
Val Best Loss: 15.987688
Epoch loss: 16.069833
train phase, Epoch 17/30, Loss: 14.796958
val phase, Epoch 17/30, Loss: 16.088940
Val Best Loss: 15.987688
Epoch loss: 16.088940
train phase, Epoch 18/30, Loss: 14.516841
val phase, Epoch 18/30, Loss: 16.755060
Val Best Loss: 15.987688
Epoch loss: 16.755060
train phase, Epoch 19/30, Loss: 14.231626
val phase, Epoch 19/30, Loss: 16.174326
Val Best Loss: 15.987688
Epoch loss: 16.174326
train phase, Epoch 20/30, Loss: 13.979228
val phase, Epoch 20/30, Loss: 16.673769
Val Best Loss: 15.987688
Epoch loss: 16.673769
train phase, Epoch 21/30, Loss: 13.722502
val phase, Epoch 21/30, Loss: 16.755366
Val Best Loss: 15.987688
Epoch loss: 16.755366
train phase, Epoch 22/30, Loss: 13.498529
val phase, Epoch 22/30, Loss: 16.915017
Val Best Loss: 15.987688
Epoch loss: 16.915017
train phase, Epoch 23/30, Loss: 12.867522
val phase, Epoch 23/30, Loss: 16.871675
Val Best Loss: 15.987688
Epoch loss: 16.871675
train phase, Epoch 24/30, Loss: 12.594665
val phase, Epoch 24/30, Loss: 17.708057
Val Best Loss: 15.987688
Epoch loss: 17.708057
train phase, Epoch 25/30, Loss: 12.182645
val phase, Epoch 25/30, Loss: 17.331606
Val Best Loss: 15.987688
Epoch loss: 17.331606
train phase, Epoch 26/30, Loss: 11.614573
val phase, Epoch 26/30, Loss: 18.380852
Val Best Loss: 15.987688
Epoch loss: 18.380852
train phase, Epoch 27/30, Loss: 11.625280
val phase, Epoch 27/30, Loss: 18.970729
Val Best Loss: 15.987688
Epoch loss: 18.970729
train phase, Epoch 28/30, Loss: 11.043836
val phase, Epoch 28/30, Loss: 18.939528
Val Best Loss: 15.987688
Epoch loss: 18.939528
train phase, Epoch 29/30, Loss: 10.343793
val phase, Epoch 29/30, Loss: 17.847766
Val Best Loss: 15.987688
Epoch loss: 17.847766
train phase, Epoch 30/30, Loss: 9.947215
val phase, Epoch 30/30, Loss: 18.851866
Val Best Loss: 15.987688
Epoch loss: 18.851866
train phase, Epoch 1/30, Loss: 20.056152
val phase, Epoch 1/30, Loss: 17.408879
Val Best Loss: 17.408879
Epoch loss: 17.408879
train phase, Epoch 2/30, Loss: 17.911387
val phase, Epoch 2/30, Loss: 16.613548
Val Best Loss: 16.613548
Epoch loss: 16.613548
train phase, Epoch 3/30, Loss: 17.679415
val phase, Epoch 3/30, Loss: 16.583675
Val Best Loss: 16.583675
Epoch loss: 16.583675
train phase, Epoch 4/30, Loss: 17.605268
val phase, Epoch 4/30, Loss: 19.614572
Val Best Loss: 16.583675
Epoch loss: 19.614572
train phase, Epoch 5/30, Loss: 17.080065
val phase, Epoch 5/30, Loss: 16.903188
Val Best Loss: 16.583675
Epoch loss: 16.903188
train phase, Epoch 6/30, Loss: 16.728985
val phase, Epoch 6/30, Loss: 16.868899
Val Best Loss: 16.583675
Epoch loss: 16.868899
train phase, Epoch 7/30, Loss: 16.485161
val phase, Epoch 7/30, Loss: 17.714842
Val Best Loss: 16.583675
Epoch loss: 17.714842
train phase, Epoch 8/30, Loss: 16.298850
val phase, Epoch 8/30, Loss: 16.072635
Val Best Loss: 16.072635
Epoch loss: 16.072635
train phase, Epoch 9/30, Loss: 16.277213
val phase, Epoch 9/30, Loss: 16.972534
Val Best Loss: 16.072635
Epoch loss: 16.972534
train phase, Epoch 10/30, Loss: 16.043177
val phase, Epoch 10/30, Loss: 18.579765
Val Best Loss: 16.072635
Epoch loss: 18.579765
train phase, Epoch 11/30, Loss: 15.749030
val phase, Epoch 11/30, Loss: 16.156647
Val Best Loss: 16.072635
Epoch loss: 16.156647
train phase, Epoch 12/30, Loss: 15.674975
val phase, Epoch 12/30, Loss: 16.156164
Val Best Loss: 16.072635
Epoch loss: 16.156164
train phase, Epoch 13/30, Loss: 15.709584
val phase, Epoch 13/30, Loss: 16.272708
Val Best Loss: 16.072635
Epoch loss: 16.272708
train phase, Epoch 14/30, Loss: 15.356157
val phase, Epoch 14/30, Loss: 16.158972
Val Best Loss: 16.072635
Epoch loss: 16.158972
train phase, Epoch 15/30, Loss: 15.341324
val phase, Epoch 15/30, Loss: 16.208425
Val Best Loss: 16.072635
Epoch loss: 16.208425
train phase, Epoch 16/30, Loss: 15.038778
val phase, Epoch 16/30, Loss: 17.191361
Val Best Loss: 16.072635
Epoch loss: 17.191361
train phase, Epoch 17/30, Loss: 15.136466
val phase, Epoch 17/30, Loss: 16.207880
Val Best Loss: 16.072635
Epoch loss: 16.207880
train phase, Epoch 18/30, Loss: 14.758738
val phase, Epoch 18/30, Loss: 18.038565
Val Best Loss: 16.072635
Epoch loss: 18.038565
train phase, Epoch 19/30, Loss: 14.516962
val phase, Epoch 19/30, Loss: 16.936943
Val Best Loss: 16.072635
Epoch loss: 16.936943
train phase, Epoch 20/30, Loss: 14.438765
val phase, Epoch 20/30, Loss: 16.218716
Val Best Loss: 16.072635
Epoch loss: 16.218716
train phase, Epoch 21/30, Loss: 13.972426
val phase, Epoch 21/30, Loss: 17.629497
Val Best Loss: 16.072635
Epoch loss: 17.629497
train phase, Epoch 22/30, Loss: 13.807761
val phase, Epoch 22/30, Loss: 16.359349
Val Best Loss: 16.072635
Epoch loss: 16.359349
train phase, Epoch 23/30, Loss: 13.461534
val phase, Epoch 23/30, Loss: 16.781366
Val Best Loss: 16.072635
Epoch loss: 16.781366
train phase, Epoch 24/30, Loss: 13.303899
val phase, Epoch 24/30, Loss: 17.094099
Val Best Loss: 16.072635
Epoch loss: 17.094099
train phase, Epoch 25/30, Loss: 12.961144
val phase, Epoch 25/30, Loss: 17.348088
Val Best Loss: 16.072635
Epoch loss: 17.348088
train phase, Epoch 26/30, Loss: 12.750430
val phase, Epoch 26/30, Loss: 16.501414
Val Best Loss: 16.072635
Epoch loss: 16.501414
train phase, Epoch 27/30, Loss: 12.470322
val phase, Epoch 27/30, Loss: 17.946902
Val Best Loss: 16.072635
Epoch loss: 17.946902
train phase, Epoch 28/30, Loss: 11.829496
val phase, Epoch 28/30, Loss: 17.085581
Val Best Loss: 16.072635
Epoch loss: 17.085581
train phase, Epoch 29/30, Loss: 11.257132
val phase, Epoch 29/30, Loss: 17.897766
Val Best Loss: 16.072635
Epoch loss: 17.897766
train phase, Epoch 30/30, Loss: 11.095222
val phase, Epoch 30/30, Loss: 17.751708
Val Best Loss: 16.072635
Epoch loss: 17.751708
train phase, Epoch 1/30, Loss: 19.592515
val phase, Epoch 1/30, Loss: 17.218162
Val Best Loss: 17.218162
Epoch loss: 17.218162
train phase, Epoch 2/30, Loss: 17.877798
val phase, Epoch 2/30, Loss: 16.989221
Val Best Loss: 16.989221
Epoch loss: 16.989221
train phase, Epoch 3/30, Loss: 17.386505
val phase, Epoch 3/30, Loss: 16.491845
Val Best Loss: 16.491845
Epoch loss: 16.491845
train phase, Epoch 4/30, Loss: 17.272557
val phase, Epoch 4/30, Loss: 16.454072
Val Best Loss: 16.454072
Epoch loss: 16.454072
train phase, Epoch 5/30, Loss: 16.864513
val phase, Epoch 5/30, Loss: 17.136487
Val Best Loss: 16.454072
Epoch loss: 17.136487
train phase, Epoch 6/30, Loss: 16.503677
val phase, Epoch 6/30, Loss: 16.715877
Val Best Loss: 16.454072
Epoch loss: 16.715877
train phase, Epoch 7/30, Loss: 16.421903
val phase, Epoch 7/30, Loss: 17.004654
Val Best Loss: 16.454072
Epoch loss: 17.004654
train phase, Epoch 8/30, Loss: 16.300799
val phase, Epoch 8/30, Loss: 16.480822
Val Best Loss: 16.454072
Epoch loss: 16.480822
train phase, Epoch 9/30, Loss: 16.071635
val phase, Epoch 9/30, Loss: 16.217486
Val Best Loss: 16.217486
Epoch loss: 16.217486
train phase, Epoch 10/30, Loss: 16.139688
val phase, Epoch 10/30, Loss: 17.005756
Val Best Loss: 16.217486
Epoch loss: 17.005756
train phase, Epoch 11/30, Loss: 16.035011
val phase, Epoch 11/30, Loss: 16.020482
Val Best Loss: 16.020482
Epoch loss: 16.020482
train phase, Epoch 12/30, Loss: 15.747055
val phase, Epoch 12/30, Loss: 15.812187
Val Best Loss: 15.812187
Epoch loss: 15.812187
train phase, Epoch 13/30, Loss: 15.457489
val phase, Epoch 13/30, Loss: 17.261105
Val Best Loss: 15.812187
Epoch loss: 17.261105
train phase, Epoch 14/30, Loss: 15.183129
val phase, Epoch 14/30, Loss: 19.333033
Val Best Loss: 15.812187
Epoch loss: 19.333033
train phase, Epoch 15/30, Loss: 14.989011
val phase, Epoch 15/30, Loss: 16.311533
Val Best Loss: 15.812187
Epoch loss: 16.311533
train phase, Epoch 16/30, Loss: 14.989353
val phase, Epoch 16/30, Loss: 15.884755
Val Best Loss: 15.812187
Epoch loss: 15.884755
train phase, Epoch 17/30, Loss: 14.404989
val phase, Epoch 17/30, Loss: 16.845809
Val Best Loss: 15.812187
Epoch loss: 16.845809
train phase, Epoch 18/30, Loss: 14.548164
val phase, Epoch 18/30, Loss: 18.221750
Val Best Loss: 15.812187
Epoch loss: 18.221750
train phase, Epoch 19/30, Loss: 14.014979
val phase, Epoch 19/30, Loss: 16.252544
Val Best Loss: 15.812187
Epoch loss: 16.252544
train phase, Epoch 20/30, Loss: 14.156614
val phase, Epoch 20/30, Loss: 16.200966
Val Best Loss: 15.812187
Epoch loss: 16.200966
train phase, Epoch 21/30, Loss: 13.514231
val phase, Epoch 21/30, Loss: 16.918368
Val Best Loss: 15.812187
Epoch loss: 16.918368
train phase, Epoch 22/30, Loss: 13.247007
val phase, Epoch 22/30, Loss: 16.620950
Val Best Loss: 15.812187
Epoch loss: 16.620950
train phase, Epoch 23/30, Loss: 12.616473
val phase, Epoch 23/30, Loss: 16.741098
Val Best Loss: 15.812187
Epoch loss: 16.741098
train phase, Epoch 24/30, Loss: 12.452206
val phase, Epoch 24/30, Loss: 16.774049
Val Best Loss: 15.812187
Epoch loss: 16.774049
train phase, Epoch 25/30, Loss: 11.972646
val phase, Epoch 25/30, Loss: 16.679864
Val Best Loss: 15.812187
Epoch loss: 16.679864
train phase, Epoch 26/30, Loss: 11.711612
val phase, Epoch 26/30, Loss: 19.526775
Val Best Loss: 15.812187
Epoch loss: 19.526775
train phase, Epoch 27/30, Loss: 11.030537
val phase, Epoch 27/30, Loss: 17.721622
Val Best Loss: 15.812187
Epoch loss: 17.721622
train phase, Epoch 28/30, Loss: 10.751431
val phase, Epoch 28/30, Loss: 17.482798
Val Best Loss: 15.812187
Epoch loss: 17.482798
train phase, Epoch 29/30, Loss: 10.003619
val phase, Epoch 29/30, Loss: 17.698741
Val Best Loss: 15.812187
Epoch loss: 17.698741
train phase, Epoch 30/30, Loss: 9.498012
val phase, Epoch 30/30, Loss: 18.816315
Val Best Loss: 15.812187
Epoch loss: 18.816315
train phase, Epoch 1/30, Loss: 19.979974
val phase, Epoch 1/30, Loss: 17.431661
Val Best Loss: 17.431661
Epoch loss: 17.431661
train phase, Epoch 2/30, Loss: 18.097534
val phase, Epoch 2/30, Loss: 16.641333
Val Best Loss: 16.641333
Epoch loss: 16.641333
train phase, Epoch 3/30, Loss: 17.509603
val phase, Epoch 3/30, Loss: 17.443539
Val Best Loss: 16.641333
Epoch loss: 17.443539
train phase, Epoch 4/30, Loss: 17.331712
val phase, Epoch 4/30, Loss: 16.500064
Val Best Loss: 16.500064
Epoch loss: 16.500064
train phase, Epoch 5/30, Loss: 17.032394
val phase, Epoch 5/30, Loss: 16.788768
Val Best Loss: 16.500064
Epoch loss: 16.788768
train phase, Epoch 6/30, Loss: 16.537176
val phase, Epoch 6/30, Loss: 15.884406
Val Best Loss: 15.884406
Epoch loss: 15.884406
train phase, Epoch 7/30, Loss: 16.502574
val phase, Epoch 7/30, Loss: 19.935254
Val Best Loss: 15.884406
Epoch loss: 19.935254
train phase, Epoch 8/30, Loss: 16.471680
val phase, Epoch 8/30, Loss: 16.066934
Val Best Loss: 15.884406
Epoch loss: 16.066934
train phase, Epoch 9/30, Loss: 16.135384
val phase, Epoch 9/30, Loss: 16.837741
Val Best Loss: 15.884406
Epoch loss: 16.837741
train phase, Epoch 10/30, Loss: 16.051676
val phase, Epoch 10/30, Loss: 19.065310
Val Best Loss: 15.884406
Epoch loss: 19.065310
train phase, Epoch 11/30, Loss: 16.201670
val phase, Epoch 11/30, Loss: 16.522242
Val Best Loss: 15.884406
Epoch loss: 16.522242
train phase, Epoch 12/30, Loss: 15.766673
val phase, Epoch 12/30, Loss: 16.072180
Val Best Loss: 15.884406
Epoch loss: 16.072180
train phase, Epoch 13/30, Loss: 15.409343
val phase, Epoch 13/30, Loss: 16.484307
Val Best Loss: 15.884406
Epoch loss: 16.484307
train phase, Epoch 14/30, Loss: 15.638473
val phase, Epoch 14/30, Loss: 18.135690
Val Best Loss: 15.884406
Epoch loss: 18.135690
train phase, Epoch 15/30, Loss: 15.286801
val phase, Epoch 15/30, Loss: 16.847604
Val Best Loss: 15.884406
Epoch loss: 16.847604
train phase, Epoch 16/30, Loss: 14.908436
val phase, Epoch 16/30, Loss: 16.301538
Val Best Loss: 15.884406
Epoch loss: 16.301538
train phase, Epoch 17/30, Loss: 14.745190
val phase, Epoch 17/30, Loss: 18.562281
Val Best Loss: 15.884406
Epoch loss: 18.562281
train phase, Epoch 18/30, Loss: 14.854342
val phase, Epoch 18/30, Loss: 16.704483
Val Best Loss: 15.884406
Epoch loss: 16.704483
train phase, Epoch 19/30, Loss: 14.227378
val phase, Epoch 19/30, Loss: 15.912363
Val Best Loss: 15.884406
Epoch loss: 15.912363
train phase, Epoch 20/30, Loss: 14.068179
val phase, Epoch 20/30, Loss: 18.383421
Val Best Loss: 15.884406
Epoch loss: 18.383421
train phase, Epoch 21/30, Loss: 13.721882
val phase, Epoch 21/30, Loss: 16.501636
Val Best Loss: 15.884406
Epoch loss: 16.501636
train phase, Epoch 22/30, Loss: 13.429925
val phase, Epoch 22/30, Loss: 17.104225
Val Best Loss: 15.884406
Epoch loss: 17.104225
train phase, Epoch 23/30, Loss: 13.025934
val phase, Epoch 23/30, Loss: 17.607539
Val Best Loss: 15.884406
Epoch loss: 17.607539
train phase, Epoch 24/30, Loss: 12.614771
val phase, Epoch 24/30, Loss: 18.663728
Val Best Loss: 15.884406
Epoch loss: 18.663728
train phase, Epoch 25/30, Loss: 12.415943
val phase, Epoch 25/30, Loss: 17.156675
Val Best Loss: 15.884406
Epoch loss: 17.156675
train phase, Epoch 26/30, Loss: 11.871222
val phase, Epoch 26/30, Loss: 17.952377
Val Best Loss: 15.884406
Epoch loss: 17.952377
train phase, Epoch 27/30, Loss: 11.316017
val phase, Epoch 27/30, Loss: 17.480095
Val Best Loss: 15.884406
Epoch loss: 17.480095
train phase, Epoch 28/30, Loss: 10.980824
val phase, Epoch 28/30, Loss: 19.556180
Val Best Loss: 15.884406
Epoch loss: 19.556180
train phase, Epoch 29/30, Loss: 10.780412
val phase, Epoch 29/30, Loss: 18.198035
Val Best Loss: 15.884406
Epoch loss: 18.198035
train phase, Epoch 30/30, Loss: 10.015033
val phase, Epoch 30/30, Loss: 19.645258
Val Best Loss: 15.884406
Epoch loss: 19.645258
train phase, Epoch 1/20, Loss: 20.259856
val phase, Epoch 1/20, Loss: 17.094981
Val Best Loss: 17.094981
Epoch loss: 17.094981
train phase, Epoch 2/20, Loss: 17.976465
val phase, Epoch 2/20, Loss: 17.208078
Val Best Loss: 17.094981
Epoch loss: 17.208078
train phase, Epoch 3/20, Loss: 17.530649
val phase, Epoch 3/20, Loss: 20.507377
Val Best Loss: 17.094981
Epoch loss: 20.507377
train phase, Epoch 4/20, Loss: 17.070279
val phase, Epoch 4/20, Loss: 16.424368
Val Best Loss: 16.424368
Epoch loss: 16.424368
train phase, Epoch 5/20, Loss: 17.098585
val phase, Epoch 5/20, Loss: 16.142213
Val Best Loss: 16.142213
Epoch loss: 16.142213
train phase, Epoch 6/20, Loss: 16.864481
val phase, Epoch 6/20, Loss: 16.102706
Val Best Loss: 16.102706
Epoch loss: 16.102706
train phase, Epoch 7/20, Loss: 16.730389
val phase, Epoch 7/20, Loss: 16.035726
Val Best Loss: 16.035726
Epoch loss: 16.035726
train phase, Epoch 8/20, Loss: 16.768443
val phase, Epoch 8/20, Loss: 16.960460
Val Best Loss: 16.035726
Epoch loss: 16.960460
train phase, Epoch 9/20, Loss: 16.286414
val phase, Epoch 9/20, Loss: 16.792332
Val Best Loss: 16.035726
Epoch loss: 16.792332
train phase, Epoch 10/20, Loss: 16.236499
val phase, Epoch 10/20, Loss: 17.719440
Val Best Loss: 16.035726
Epoch loss: 17.719440
train phase, Epoch 11/20, Loss: 15.758823
val phase, Epoch 11/20, Loss: 16.878641
Val Best Loss: 16.035726
Epoch loss: 16.878641
train phase, Epoch 12/20, Loss: 16.040149
val phase, Epoch 12/20, Loss: 15.614431
Val Best Loss: 15.614431
Epoch loss: 15.614431
train phase, Epoch 13/20, Loss: 15.672748
val phase, Epoch 13/20, Loss: 19.974411
Val Best Loss: 15.614431
Epoch loss: 19.974411
train phase, Epoch 14/20, Loss: 15.365607
val phase, Epoch 14/20, Loss: 17.436789
Val Best Loss: 15.614431
Epoch loss: 17.436789
train phase, Epoch 15/20, Loss: 15.478040
val phase, Epoch 15/20, Loss: 15.997992
Val Best Loss: 15.614431
Epoch loss: 15.997992
train phase, Epoch 16/20, Loss: 14.998809
val phase, Epoch 16/20, Loss: 16.588855
Val Best Loss: 15.614431
Epoch loss: 16.588855
train phase, Epoch 17/20, Loss: 14.763380
val phase, Epoch 17/20, Loss: 16.416187
Val Best Loss: 15.614431
Epoch loss: 16.416187
train phase, Epoch 18/20, Loss: 14.731960
val phase, Epoch 18/20, Loss: 17.394478
Val Best Loss: 15.614431
Epoch loss: 17.394478
train phase, Epoch 19/20, Loss: 14.506121
val phase, Epoch 19/20, Loss: 19.174738
Val Best Loss: 15.614431
Epoch loss: 19.174738
train phase, Epoch 20/20, Loss: 14.127699
val phase, Epoch 20/20, Loss: 16.695894
Val Best Loss: 15.614431
Epoch loss: 16.695894
train phase, Epoch 1/25, Loss: 20.942652
val phase, Epoch 1/25, Loss: 18.258426
Val Best Loss: 18.258426
Epoch loss: 18.258426
train phase, Epoch 2/25, Loss: 18.706596
val phase, Epoch 2/25, Loss: 17.700673
Val Best Loss: 17.700673
Epoch loss: 17.700673
train phase, Epoch 3/25, Loss: 18.065795
val phase, Epoch 3/25, Loss: 16.999508
Val Best Loss: 16.999508
Epoch loss: 16.999508
train phase, Epoch 4/25, Loss: 18.105283
val phase, Epoch 4/25, Loss: 17.502572
Val Best Loss: 16.999508
Epoch loss: 17.502572
train phase, Epoch 5/25, Loss: 17.399385
val phase, Epoch 5/25, Loss: 17.285769
Val Best Loss: 16.999508
Epoch loss: 17.285769
train phase, Epoch 6/25, Loss: 17.436133
val phase, Epoch 6/25, Loss: 17.976956
Val Best Loss: 16.999508
Epoch loss: 17.976956
train phase, Epoch 7/25, Loss: 17.271801
val phase, Epoch 7/25, Loss: 17.827182
Val Best Loss: 16.999508
Epoch loss: 17.827182
train phase, Epoch 8/25, Loss: 17.172512
val phase, Epoch 8/25, Loss: 17.262718
Val Best Loss: 16.999508
Epoch loss: 17.262718
train phase, Epoch 9/25, Loss: 16.778810
val phase, Epoch 9/25, Loss: 17.294517
Val Best Loss: 16.999508
Epoch loss: 17.294517
train phase, Epoch 10/25, Loss: 16.505862
val phase, Epoch 10/25, Loss: 18.425065
Val Best Loss: 16.999508
Epoch loss: 18.425065
train phase, Epoch 11/25, Loss: 16.454094
val phase, Epoch 11/25, Loss: 16.781771
Val Best Loss: 16.781771
Epoch loss: 16.781771
train phase, Epoch 12/25, Loss: 16.311715
val phase, Epoch 12/25, Loss: 16.107706
Val Best Loss: 16.107706
Epoch loss: 16.107706
train phase, Epoch 13/25, Loss: 15.959622
val phase, Epoch 13/25, Loss: 16.040524
Val Best Loss: 16.040524
Epoch loss: 16.040524
train phase, Epoch 14/25, Loss: 15.717936
val phase, Epoch 14/25, Loss: 17.476750
Val Best Loss: 16.040524
Epoch loss: 17.476750
train phase, Epoch 15/25, Loss: 15.588085
val phase, Epoch 15/25, Loss: 17.276538
Val Best Loss: 16.040524
Epoch loss: 17.276538
train phase, Epoch 16/25, Loss: 15.535002
val phase, Epoch 16/25, Loss: 17.719553
Val Best Loss: 16.040524
Epoch loss: 17.719553
train phase, Epoch 17/25, Loss: 14.998804
val phase, Epoch 17/25, Loss: 17.139013
Val Best Loss: 16.040524
Epoch loss: 17.139013
train phase, Epoch 18/25, Loss: 15.025790
val phase, Epoch 18/25, Loss: 17.132364
Val Best Loss: 16.040524
Epoch loss: 17.132364
train phase, Epoch 19/25, Loss: 14.381264
val phase, Epoch 19/25, Loss: 16.864635
Val Best Loss: 16.040524
Epoch loss: 16.864635
train phase, Epoch 20/25, Loss: 14.209018
val phase, Epoch 20/25, Loss: 16.723744
Val Best Loss: 16.040524
Epoch loss: 16.723744
train phase, Epoch 21/25, Loss: 13.753959
val phase, Epoch 21/25, Loss: 17.769754
Val Best Loss: 16.040524
Epoch loss: 17.769754
train phase, Epoch 22/25, Loss: 13.701834
val phase, Epoch 22/25, Loss: 17.331864
Val Best Loss: 16.040524
Epoch loss: 17.331864
train phase, Epoch 23/25, Loss: 13.089800
val phase, Epoch 23/25, Loss: 17.866529
Val Best Loss: 16.040524
Epoch loss: 17.866529
train phase, Epoch 24/25, Loss: 12.581803
val phase, Epoch 24/25, Loss: 17.842709
Val Best Loss: 16.040524
Epoch loss: 17.842709
train phase, Epoch 25/25, Loss: 12.321521
val phase, Epoch 25/25, Loss: 18.080213
Val Best Loss: 16.040524
Epoch loss: 18.080213
[Trial 167] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 19.851290
val phase, Epoch 1/30, Loss: 35.254567
Val Best Loss: 35.254567
Epoch loss: 35.254567
train phase, Epoch 2/30, Loss: 18.323185
val phase, Epoch 2/30, Loss: 18.364048
Val Best Loss: 18.364048
Epoch loss: 18.364048
train phase, Epoch 3/30, Loss: 17.675366
val phase, Epoch 3/30, Loss: 18.269076
Val Best Loss: 18.269076
Epoch loss: 18.269076
train phase, Epoch 4/30, Loss: 17.099845
val phase, Epoch 4/30, Loss: 16.130073
Val Best Loss: 16.130073
Epoch loss: 16.130073
train phase, Epoch 5/30, Loss: 16.812723
val phase, Epoch 5/30, Loss: 16.193859
Val Best Loss: 16.130073
Epoch loss: 16.193859
train phase, Epoch 6/30, Loss: 17.149310
val phase, Epoch 6/30, Loss: 16.187611
Val Best Loss: 16.130073
Epoch loss: 16.187611
train phase, Epoch 7/30, Loss: 16.713175
val phase, Epoch 7/30, Loss: 18.164987
Val Best Loss: 16.130073
Epoch loss: 18.164987
train phase, Epoch 8/30, Loss: 16.745102
val phase, Epoch 8/30, Loss: 17.040969
Val Best Loss: 16.130073
Epoch loss: 17.040969
train phase, Epoch 9/30, Loss: 16.404268
val phase, Epoch 9/30, Loss: 15.790559
Val Best Loss: 15.790559
Epoch loss: 15.790559
train phase, Epoch 10/30, Loss: 16.329368
val phase, Epoch 10/30, Loss: 16.542590
Val Best Loss: 15.790559
Epoch loss: 16.542590
train phase, Epoch 11/30, Loss: 16.353812
val phase, Epoch 11/30, Loss: 16.971978
Val Best Loss: 15.790559
Epoch loss: 16.971978
train phase, Epoch 12/30, Loss: 15.866878
val phase, Epoch 12/30, Loss: 15.903897
Val Best Loss: 15.790559
Epoch loss: 15.903897
train phase, Epoch 13/30, Loss: 15.739028
val phase, Epoch 13/30, Loss: 16.245042
Val Best Loss: 15.790559
Epoch loss: 16.245042
train phase, Epoch 14/30, Loss: 15.681164
val phase, Epoch 14/30, Loss: 16.032156
Val Best Loss: 15.790559
Epoch loss: 16.032156
train phase, Epoch 15/30, Loss: 15.573358
val phase, Epoch 15/30, Loss: 17.094856
Val Best Loss: 15.790559
Epoch loss: 17.094856
train phase, Epoch 16/30, Loss: 15.346290
val phase, Epoch 16/30, Loss: 16.159497
Val Best Loss: 15.790559
Epoch loss: 16.159497
train phase, Epoch 17/30, Loss: 15.147444
val phase, Epoch 17/30, Loss: 15.765403
Val Best Loss: 15.765403
Epoch loss: 15.765403
train phase, Epoch 18/30, Loss: 14.859770
val phase, Epoch 18/30, Loss: 17.416032
Val Best Loss: 15.765403
Epoch loss: 17.416032
train phase, Epoch 19/30, Loss: 14.764042
val phase, Epoch 19/30, Loss: 15.929413
Val Best Loss: 15.765403
Epoch loss: 15.929413
train phase, Epoch 20/30, Loss: 14.326052
val phase, Epoch 20/30, Loss: 17.578505
Val Best Loss: 15.765403
Epoch loss: 17.578505
train phase, Epoch 21/30, Loss: 14.175871
val phase, Epoch 21/30, Loss: 16.389457
Val Best Loss: 15.765403
Epoch loss: 16.389457
train phase, Epoch 22/30, Loss: 13.790001
val phase, Epoch 22/30, Loss: 17.400483
Val Best Loss: 15.765403
Epoch loss: 17.400483
train phase, Epoch 23/30, Loss: 13.524586
val phase, Epoch 23/30, Loss: 16.078275
Val Best Loss: 15.765403
Epoch loss: 16.078275
train phase, Epoch 24/30, Loss: 13.343471
val phase, Epoch 24/30, Loss: 19.637291
Val Best Loss: 15.765403
Epoch loss: 19.637291
train phase, Epoch 25/30, Loss: 13.275128
val phase, Epoch 25/30, Loss: 16.660571
Val Best Loss: 15.765403
Epoch loss: 16.660571
train phase, Epoch 26/30, Loss: 12.738957
val phase, Epoch 26/30, Loss: 17.195102
Val Best Loss: 15.765403
Epoch loss: 17.195102
train phase, Epoch 27/30, Loss: 12.150345
val phase, Epoch 27/30, Loss: 16.717958
Val Best Loss: 15.765403
Epoch loss: 16.717958
train phase, Epoch 28/30, Loss: 11.889921
val phase, Epoch 28/30, Loss: 16.758102
Val Best Loss: 15.765403
Epoch loss: 16.758102
train phase, Epoch 29/30, Loss: 11.393253
val phase, Epoch 29/30, Loss: 17.146950
Val Best Loss: 15.765403
Epoch loss: 17.146950
train phase, Epoch 30/30, Loss: 10.956129
val phase, Epoch 30/30, Loss: 17.438774
Val Best Loss: 15.765403
Epoch loss: 17.438774
[Trial 169] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/5, Loss: 23.383126
val phase, Epoch 1/5, Loss: 18.191947
Val Best Loss: 18.191947
Epoch loss: 18.191947
train phase, Epoch 2/5, Loss: 19.312068
val phase, Epoch 2/5, Loss: 17.793819
Val Best Loss: 17.793819
Epoch loss: 17.793819
train phase, Epoch 3/5, Loss: 18.507794
val phase, Epoch 3/5, Loss: 17.605167
Val Best Loss: 17.605167
Epoch loss: 17.605167
train phase, Epoch 4/5, Loss: 18.354410
val phase, Epoch 4/5, Loss: 17.865786
Val Best Loss: 17.605167
Epoch loss: 17.865786
train phase, Epoch 5/5, Loss: 18.380480
val phase, Epoch 5/5, Loss: 16.889069
Val Best Loss: 16.889069
Epoch loss: 16.889069
train phase, Epoch 1/20, Loss: 19.906024
val phase, Epoch 1/20, Loss: 21.239814
Val Best Loss: 21.239814
Epoch loss: 21.239814
train phase, Epoch 2/20, Loss: 17.837938
val phase, Epoch 2/20, Loss: 17.860459
Val Best Loss: 17.860459
Epoch loss: 17.860459
train phase, Epoch 3/20, Loss: 17.510547
val phase, Epoch 3/20, Loss: 17.646808
Val Best Loss: 17.646808
Epoch loss: 17.646808
train phase, Epoch 4/20, Loss: 17.274400
val phase, Epoch 4/20, Loss: 16.470217
Val Best Loss: 16.470217
Epoch loss: 16.470217
train phase, Epoch 5/20, Loss: 17.073066
val phase, Epoch 5/20, Loss: 16.224132
Val Best Loss: 16.224132
Epoch loss: 16.224132
train phase, Epoch 6/20, Loss: 16.787670
val phase, Epoch 6/20, Loss: 15.948423
Val Best Loss: 15.948423
Epoch loss: 15.948423
train phase, Epoch 7/20, Loss: 16.440664
val phase, Epoch 7/20, Loss: 16.632796
Val Best Loss: 15.948423
Epoch loss: 16.632796
train phase, Epoch 8/20, Loss: 16.453878
val phase, Epoch 8/20, Loss: 17.760273
Val Best Loss: 15.948423
Epoch loss: 17.760273
train phase, Epoch 9/20, Loss: 16.347140
val phase, Epoch 9/20, Loss: 15.996619
Val Best Loss: 15.948423
Epoch loss: 15.996619
train phase, Epoch 10/20, Loss: 16.232323
val phase, Epoch 10/20, Loss: 16.906166
Val Best Loss: 15.948423
Epoch loss: 16.906166
train phase, Epoch 11/20, Loss: 16.124653
val phase, Epoch 11/20, Loss: 17.911751
Val Best Loss: 15.948423
Epoch loss: 17.911751
train phase, Epoch 12/20, Loss: 15.777032
val phase, Epoch 12/20, Loss: 16.609940
Val Best Loss: 15.948423
Epoch loss: 16.609940
train phase, Epoch 13/20, Loss: 15.774247
val phase, Epoch 13/20, Loss: 16.327146
Val Best Loss: 15.948423
Epoch loss: 16.327146
train phase, Epoch 14/20, Loss: 15.671004
val phase, Epoch 14/20, Loss: 16.149045
Val Best Loss: 15.948423
Epoch loss: 16.149045
train phase, Epoch 15/20, Loss: 15.070397
val phase, Epoch 15/20, Loss: 16.303106
Val Best Loss: 15.948423
Epoch loss: 16.303106
train phase, Epoch 16/20, Loss: 15.154008
val phase, Epoch 16/20, Loss: 16.271941
Val Best Loss: 15.948423
Epoch loss: 16.271941
train phase, Epoch 17/20, Loss: 14.942360
val phase, Epoch 17/20, Loss: 16.155325
Val Best Loss: 15.948423
Epoch loss: 16.155325
train phase, Epoch 18/20, Loss: 14.599365
val phase, Epoch 18/20, Loss: 15.684528
Val Best Loss: 15.684528
Epoch loss: 15.684528
train phase, Epoch 19/20, Loss: 14.463686
val phase, Epoch 19/20, Loss: 15.927604
Val Best Loss: 15.684528
Epoch loss: 15.927604
train phase, Epoch 20/20, Loss: 14.602895
val phase, Epoch 20/20, Loss: 16.297508
Val Best Loss: 15.684528
Epoch loss: 16.297508
train phase, Epoch 1/20, Loss: 19.346207
val phase, Epoch 1/20, Loss: 18.312543
Val Best Loss: 18.312543
Epoch loss: 18.312543
train phase, Epoch 2/20, Loss: 18.026160
val phase, Epoch 2/20, Loss: 17.851675
Val Best Loss: 17.851675
Epoch loss: 17.851675
train phase, Epoch 3/20, Loss: 17.182946
val phase, Epoch 3/20, Loss: 17.089996
Val Best Loss: 17.089996
Epoch loss: 17.089996
train phase, Epoch 4/20, Loss: 17.341104
val phase, Epoch 4/20, Loss: 16.287051
Val Best Loss: 16.287051
Epoch loss: 16.287051
train phase, Epoch 5/20, Loss: 16.809953
val phase, Epoch 5/20, Loss: 16.438288
Val Best Loss: 16.287051
Epoch loss: 16.438288
train phase, Epoch 6/20, Loss: 16.547160
val phase, Epoch 6/20, Loss: 16.977377
Val Best Loss: 16.287051
Epoch loss: 16.977377
train phase, Epoch 7/20, Loss: 16.617784
val phase, Epoch 7/20, Loss: 17.713868
Val Best Loss: 16.287051
Epoch loss: 17.713868
train phase, Epoch 8/20, Loss: 16.599476
val phase, Epoch 8/20, Loss: 17.765506
Val Best Loss: 16.287051
Epoch loss: 17.765506
train phase, Epoch 9/20, Loss: 16.085225
val phase, Epoch 9/20, Loss: 16.291509
Val Best Loss: 16.287051
Epoch loss: 16.291509
train phase, Epoch 10/20, Loss: 15.809215
val phase, Epoch 10/20, Loss: 16.614346
Val Best Loss: 16.287051
Epoch loss: 16.614346
train phase, Epoch 11/20, Loss: 15.774093
val phase, Epoch 11/20, Loss: 16.702134
Val Best Loss: 16.287051
Epoch loss: 16.702134
train phase, Epoch 12/20, Loss: 15.749345
val phase, Epoch 12/20, Loss: 16.326458
Val Best Loss: 16.287051
Epoch loss: 16.326458
train phase, Epoch 13/20, Loss: 15.692184
val phase, Epoch 13/20, Loss: 16.027814
Val Best Loss: 16.027814
Epoch loss: 16.027814
train phase, Epoch 14/20, Loss: 15.257156
val phase, Epoch 14/20, Loss: 16.708691
Val Best Loss: 16.027814
Epoch loss: 16.708691
train phase, Epoch 15/20, Loss: 15.045494
val phase, Epoch 15/20, Loss: 15.834684
Val Best Loss: 15.834684
Epoch loss: 15.834684
train phase, Epoch 16/20, Loss: 14.875959
val phase, Epoch 16/20, Loss: 17.199359
Val Best Loss: 15.834684
Epoch loss: 17.199359
train phase, Epoch 17/20, Loss: 14.697083
val phase, Epoch 17/20, Loss: 16.397796
Val Best Loss: 15.834684
Epoch loss: 16.397796
train phase, Epoch 18/20, Loss: 14.598699
val phase, Epoch 18/20, Loss: 16.051562
Val Best Loss: 15.834684
Epoch loss: 16.051562
train phase, Epoch 19/20, Loss: 14.100981
val phase, Epoch 19/20, Loss: 18.933565
Val Best Loss: 15.834684
Epoch loss: 18.933565
train phase, Epoch 20/20, Loss: 14.017910
val phase, Epoch 20/20, Loss: 17.254150
Val Best Loss: 15.834684
Epoch loss: 17.254150
train phase, Epoch 1/20, Loss: 19.757582
val phase, Epoch 1/20, Loss: 16.980615
Val Best Loss: 16.980615
Epoch loss: 16.980615
train phase, Epoch 2/20, Loss: 17.673393
val phase, Epoch 2/20, Loss: 16.896283
Val Best Loss: 16.896283
Epoch loss: 16.896283
train phase, Epoch 3/20, Loss: 17.604297
val phase, Epoch 3/20, Loss: 19.351589
Val Best Loss: 16.896283
Epoch loss: 19.351589
train phase, Epoch 4/20, Loss: 17.247592
val phase, Epoch 4/20, Loss: 16.866623
Val Best Loss: 16.866623
Epoch loss: 16.866623
train phase, Epoch 5/20, Loss: 17.146936
val phase, Epoch 5/20, Loss: 16.369082
Val Best Loss: 16.369082
Epoch loss: 16.369082
train phase, Epoch 6/20, Loss: 16.715676
val phase, Epoch 6/20, Loss: 17.549210
Val Best Loss: 16.369082
Epoch loss: 17.549210
train phase, Epoch 7/20, Loss: 16.526626
val phase, Epoch 7/20, Loss: 15.938467
Val Best Loss: 15.938467
Epoch loss: 15.938467
train phase, Epoch 8/20, Loss: 16.308972
val phase, Epoch 8/20, Loss: 15.745197
Val Best Loss: 15.745197
Epoch loss: 15.745197
train phase, Epoch 9/20, Loss: 16.334134
val phase, Epoch 9/20, Loss: 16.151897
Val Best Loss: 15.745197
Epoch loss: 16.151897
train phase, Epoch 10/20, Loss: 16.306965
val phase, Epoch 10/20, Loss: 16.714930
Val Best Loss: 15.745197
Epoch loss: 16.714930
train phase, Epoch 11/20, Loss: 15.974943
val phase, Epoch 11/20, Loss: 15.952006
Val Best Loss: 15.745197
Epoch loss: 15.952006
train phase, Epoch 12/20, Loss: 15.633604
val phase, Epoch 12/20, Loss: 17.836326
Val Best Loss: 15.745197
Epoch loss: 17.836326
train phase, Epoch 13/20, Loss: 15.722165
val phase, Epoch 13/20, Loss: 15.930538
Val Best Loss: 15.745197
Epoch loss: 15.930538
train phase, Epoch 14/20, Loss: 15.628790
val phase, Epoch 14/20, Loss: 15.659694
Val Best Loss: 15.659694
Epoch loss: 15.659694
train phase, Epoch 15/20, Loss: 15.705782
val phase, Epoch 15/20, Loss: 15.756580
Val Best Loss: 15.659694
Epoch loss: 15.756580
train phase, Epoch 16/20, Loss: 15.253354
val phase, Epoch 16/20, Loss: 15.684367
Val Best Loss: 15.659694
Epoch loss: 15.684367
train phase, Epoch 17/20, Loss: 14.873363
val phase, Epoch 17/20, Loss: 15.981758
Val Best Loss: 15.659694
Epoch loss: 15.981758
train phase, Epoch 18/20, Loss: 14.839553
val phase, Epoch 18/20, Loss: 16.082652
Val Best Loss: 15.659694
Epoch loss: 16.082652
train phase, Epoch 19/20, Loss: 14.565236
val phase, Epoch 19/20, Loss: 16.099656
Val Best Loss: 15.659694
Epoch loss: 16.099656
train phase, Epoch 20/20, Loss: 14.223971
val phase, Epoch 20/20, Loss: 17.781251
Val Best Loss: 15.659694
Epoch loss: 17.781251
train phase, Epoch 1/20, Loss: 19.634877
val phase, Epoch 1/20, Loss: 16.693073
Val Best Loss: 16.693073
Epoch loss: 16.693073
train phase, Epoch 2/20, Loss: 17.841113
val phase, Epoch 2/20, Loss: 17.438773
Val Best Loss: 16.693073
Epoch loss: 17.438773
train phase, Epoch 3/20, Loss: 17.394629
val phase, Epoch 3/20, Loss: 16.403252
Val Best Loss: 16.403252
Epoch loss: 16.403252
train phase, Epoch 4/20, Loss: 17.184516
val phase, Epoch 4/20, Loss: 17.043204
Val Best Loss: 16.403252
Epoch loss: 17.043204
train phase, Epoch 5/20, Loss: 16.880248
val phase, Epoch 5/20, Loss: 16.146719
Val Best Loss: 16.146719
Epoch loss: 16.146719
train phase, Epoch 6/20, Loss: 16.797642
val phase, Epoch 6/20, Loss: 16.254048
Val Best Loss: 16.146719
Epoch loss: 16.254048
train phase, Epoch 7/20, Loss: 16.516325
val phase, Epoch 7/20, Loss: 16.287612
Val Best Loss: 16.146719
Epoch loss: 16.287612
train phase, Epoch 8/20, Loss: 16.179988
val phase, Epoch 8/20, Loss: 16.179449
Val Best Loss: 16.146719
Epoch loss: 16.179449
train phase, Epoch 9/20, Loss: 16.128812
val phase, Epoch 9/20, Loss: 16.005166
Val Best Loss: 16.005166
Epoch loss: 16.005166
train phase, Epoch 10/20, Loss: 15.967611
val phase, Epoch 10/20, Loss: 17.242894
Val Best Loss: 16.005166
Epoch loss: 17.242894
train phase, Epoch 11/20, Loss: 15.882087
val phase, Epoch 11/20, Loss: 17.066529
Val Best Loss: 16.005166
Epoch loss: 17.066529
train phase, Epoch 12/20, Loss: 15.746674
val phase, Epoch 12/20, Loss: 15.697625
Val Best Loss: 15.697625
Epoch loss: 15.697625
train phase, Epoch 13/20, Loss: 15.648572
val phase, Epoch 13/20, Loss: 15.579525
Val Best Loss: 15.579525
Epoch loss: 15.579525
train phase, Epoch 14/20, Loss: 15.230246
val phase, Epoch 14/20, Loss: 16.208199
Val Best Loss: 15.579525
Epoch loss: 16.208199
train phase, Epoch 15/20, Loss: 15.298510
val phase, Epoch 15/20, Loss: 16.171642
Val Best Loss: 15.579525
Epoch loss: 16.171642
train phase, Epoch 16/20, Loss: 14.865117
val phase, Epoch 16/20, Loss: 17.999920
Val Best Loss: 15.579525
Epoch loss: 17.999920
train phase, Epoch 17/20, Loss: 14.619556
val phase, Epoch 17/20, Loss: 16.652574
Val Best Loss: 15.579525
Epoch loss: 16.652574
train phase, Epoch 18/20, Loss: 14.452082
val phase, Epoch 18/20, Loss: 16.527848
Val Best Loss: 15.579525
Epoch loss: 16.527848
train phase, Epoch 19/20, Loss: 14.381967
val phase, Epoch 19/20, Loss: 16.809891
Val Best Loss: 15.579525
Epoch loss: 16.809891
train phase, Epoch 20/20, Loss: 13.801009
val phase, Epoch 20/20, Loss: 16.352169
Val Best Loss: 15.579525
Epoch loss: 16.352169
train phase, Epoch 1/20, Loss: 20.593187
val phase, Epoch 1/20, Loss: 16.914008
Val Best Loss: 16.914008
Epoch loss: 16.914008
train phase, Epoch 2/20, Loss: 17.899779
val phase, Epoch 2/20, Loss: 19.772488
Val Best Loss: 16.914008
Epoch loss: 19.772488
train phase, Epoch 3/20, Loss: 17.623564
val phase, Epoch 3/20, Loss: 17.243084
Val Best Loss: 16.914008
Epoch loss: 17.243084
train phase, Epoch 4/20, Loss: 17.329193
val phase, Epoch 4/20, Loss: 16.724783
Val Best Loss: 16.724783
Epoch loss: 16.724783
train phase, Epoch 5/20, Loss: 17.048135
val phase, Epoch 5/20, Loss: 17.085342
Val Best Loss: 16.724783
Epoch loss: 17.085342
train phase, Epoch 6/20, Loss: 16.768070
val phase, Epoch 6/20, Loss: 16.974355
Val Best Loss: 16.724783
Epoch loss: 16.974355
train phase, Epoch 7/20, Loss: 16.657694
val phase, Epoch 7/20, Loss: 16.595201
Val Best Loss: 16.595201
Epoch loss: 16.595201
train phase, Epoch 8/20, Loss: 16.585787
val phase, Epoch 8/20, Loss: 18.927508
Val Best Loss: 16.595201
Epoch loss: 18.927508
train phase, Epoch 9/20, Loss: 16.695528
val phase, Epoch 9/20, Loss: 16.282446
Val Best Loss: 16.282446
Epoch loss: 16.282446
train phase, Epoch 10/20, Loss: 16.066134
val phase, Epoch 10/20, Loss: 16.025463
Val Best Loss: 16.025463
Epoch loss: 16.025463
train phase, Epoch 11/20, Loss: 15.889582
val phase, Epoch 11/20, Loss: 15.944240
Val Best Loss: 15.944240
Epoch loss: 15.944240
train phase, Epoch 12/20, Loss: 15.684521
val phase, Epoch 12/20, Loss: 17.117681
Val Best Loss: 15.944240
Epoch loss: 17.117681
train phase, Epoch 13/20, Loss: 15.591203
val phase, Epoch 13/20, Loss: 16.444401
Val Best Loss: 15.944240
Epoch loss: 16.444401
train phase, Epoch 14/20, Loss: 15.491989
val phase, Epoch 14/20, Loss: 15.892866
Val Best Loss: 15.892866
Epoch loss: 15.892866
train phase, Epoch 15/20, Loss: 15.313916
val phase, Epoch 15/20, Loss: 16.507061
Val Best Loss: 15.892866
Epoch loss: 16.507061
train phase, Epoch 16/20, Loss: 14.939624
val phase, Epoch 16/20, Loss: 17.402782
Val Best Loss: 15.892866
Epoch loss: 17.402782
train phase, Epoch 17/20, Loss: 14.690997
val phase, Epoch 17/20, Loss: 16.381808
Val Best Loss: 15.892866
Epoch loss: 16.381808
train phase, Epoch 18/20, Loss: 14.723226
val phase, Epoch 18/20, Loss: 16.105699
Val Best Loss: 15.892866
Epoch loss: 16.105699
train phase, Epoch 19/20, Loss: 14.304731
val phase, Epoch 19/20, Loss: 16.068314
Val Best Loss: 15.892866
Epoch loss: 16.068314
train phase, Epoch 20/20, Loss: 14.101911
val phase, Epoch 20/20, Loss: 16.200558
Val Best Loss: 15.892866
Epoch loss: 16.200558
train phase, Epoch 1/20, Loss: 20.404002
val phase, Epoch 1/20, Loss: 17.014591
Val Best Loss: 17.014591
Epoch loss: 17.014591
train phase, Epoch 2/20, Loss: 18.259031
val phase, Epoch 2/20, Loss: 16.720244
Val Best Loss: 16.720244
Epoch loss: 16.720244
train phase, Epoch 3/20, Loss: 17.465326
val phase, Epoch 3/20, Loss: 18.235016
Val Best Loss: 16.720244
Epoch loss: 18.235016
train phase, Epoch 4/20, Loss: 17.464014
val phase, Epoch 4/20, Loss: 16.226382
Val Best Loss: 16.226382
Epoch loss: 16.226382
train phase, Epoch 5/20, Loss: 16.846153
val phase, Epoch 5/20, Loss: 17.361970
Val Best Loss: 16.226382
Epoch loss: 17.361970
train phase, Epoch 6/20, Loss: 16.922685
val phase, Epoch 6/20, Loss: 18.588531
Val Best Loss: 16.226382
Epoch loss: 18.588531
train phase, Epoch 7/20, Loss: 16.684109
val phase, Epoch 7/20, Loss: 16.451935
Val Best Loss: 16.226382
Epoch loss: 16.451935
train phase, Epoch 8/20, Loss: 16.562096
val phase, Epoch 8/20, Loss: 16.215858
Val Best Loss: 16.215858
Epoch loss: 16.215858
train phase, Epoch 9/20, Loss: 16.200545
val phase, Epoch 9/20, Loss: 16.332328
Val Best Loss: 16.215858
Epoch loss: 16.332328
train phase, Epoch 10/20, Loss: 16.206704
val phase, Epoch 10/20, Loss: 16.163187
Val Best Loss: 16.163187
Epoch loss: 16.163187
train phase, Epoch 11/20, Loss: 15.912076
val phase, Epoch 11/20, Loss: 15.801874
Val Best Loss: 15.801874
Epoch loss: 15.801874
train phase, Epoch 12/20, Loss: 15.819361
val phase, Epoch 12/20, Loss: 19.776494
Val Best Loss: 15.801874
Epoch loss: 19.776494
train phase, Epoch 13/20, Loss: 15.509544
val phase, Epoch 13/20, Loss: 16.342750
Val Best Loss: 15.801874
Epoch loss: 16.342750
train phase, Epoch 14/20, Loss: 15.569197
val phase, Epoch 14/20, Loss: 17.334820
Val Best Loss: 15.801874
Epoch loss: 17.334820
train phase, Epoch 15/20, Loss: 15.438446
val phase, Epoch 15/20, Loss: 16.017365
Val Best Loss: 15.801874
Epoch loss: 16.017365
train phase, Epoch 16/20, Loss: 15.151128
val phase, Epoch 16/20, Loss: 15.833856
Val Best Loss: 15.801874
Epoch loss: 15.833856
train phase, Epoch 17/20, Loss: 14.806352
val phase, Epoch 17/20, Loss: 15.998016
Val Best Loss: 15.801874
Epoch loss: 15.998016
train phase, Epoch 18/20, Loss: 14.484358
val phase, Epoch 18/20, Loss: 16.259852
Val Best Loss: 15.801874
Epoch loss: 16.259852
train phase, Epoch 19/20, Loss: 14.505375
val phase, Epoch 19/20, Loss: 15.804084
Val Best Loss: 15.801874
Epoch loss: 15.804084
train phase, Epoch 20/20, Loss: 13.994695
val phase, Epoch 20/20, Loss: 16.061453
Val Best Loss: 15.801874
Epoch loss: 16.061453
train phase, Epoch 1/20, Loss: 20.569452
val phase, Epoch 1/20, Loss: 17.231485
Val Best Loss: 17.231485
Epoch loss: 17.231485
train phase, Epoch 2/20, Loss: 18.370089
val phase, Epoch 2/20, Loss: 17.039216
Val Best Loss: 17.039216
Epoch loss: 17.039216
train phase, Epoch 3/20, Loss: 17.470180
val phase, Epoch 3/20, Loss: 17.534471
Val Best Loss: 17.039216
Epoch loss: 17.534471
train phase, Epoch 4/20, Loss: 17.231723
val phase, Epoch 4/20, Loss: 19.290419
Val Best Loss: 17.039216
Epoch loss: 19.290419
train phase, Epoch 5/20, Loss: 17.075481
val phase, Epoch 5/20, Loss: 16.366817
Val Best Loss: 16.366817
Epoch loss: 16.366817
train phase, Epoch 6/20, Loss: 17.079170
val phase, Epoch 6/20, Loss: 16.620635
Val Best Loss: 16.366817
Epoch loss: 16.620635
train phase, Epoch 7/20, Loss: 16.700468
val phase, Epoch 7/20, Loss: 16.686339
Val Best Loss: 16.366817
Epoch loss: 16.686339
train phase, Epoch 8/20, Loss: 16.590179
val phase, Epoch 8/20, Loss: 17.231791
Val Best Loss: 16.366817
Epoch loss: 17.231791
train phase, Epoch 9/20, Loss: 16.261031
val phase, Epoch 9/20, Loss: 16.373174
Val Best Loss: 16.366817
Epoch loss: 16.373174
train phase, Epoch 10/20, Loss: 16.303177
val phase, Epoch 10/20, Loss: 16.149198
Val Best Loss: 16.149198
Epoch loss: 16.149198
train phase, Epoch 11/20, Loss: 16.254554
val phase, Epoch 11/20, Loss: 16.085224
Val Best Loss: 16.085224
Epoch loss: 16.085224
train phase, Epoch 12/20, Loss: 16.044306
val phase, Epoch 12/20, Loss: 17.887564
Val Best Loss: 16.085224
Epoch loss: 17.887564
train phase, Epoch 13/20, Loss: 15.870691
val phase, Epoch 13/20, Loss: 17.241047
Val Best Loss: 16.085224
Epoch loss: 17.241047
train phase, Epoch 14/20, Loss: 15.622652
val phase, Epoch 14/20, Loss: 15.847061
Val Best Loss: 15.847061
Epoch loss: 15.847061
train phase, Epoch 15/20, Loss: 15.274476
val phase, Epoch 15/20, Loss: 16.743337
Val Best Loss: 15.847061
Epoch loss: 16.743337
train phase, Epoch 16/20, Loss: 15.189671
val phase, Epoch 16/20, Loss: 17.409090
Val Best Loss: 15.847061
Epoch loss: 17.409090
train phase, Epoch 17/20, Loss: 15.165285
val phase, Epoch 17/20, Loss: 16.203834
Val Best Loss: 15.847061
Epoch loss: 16.203834
train phase, Epoch 18/20, Loss: 15.152234
val phase, Epoch 18/20, Loss: 18.179479
Val Best Loss: 15.847061
Epoch loss: 18.179479
train phase, Epoch 19/20, Loss: 14.930470
val phase, Epoch 19/20, Loss: 16.570576
Val Best Loss: 15.847061
Epoch loss: 16.570576
train phase, Epoch 20/20, Loss: 14.325747
val phase, Epoch 20/20, Loss: 16.324247
Val Best Loss: 15.847061
Epoch loss: 16.324247
train phase, Epoch 1/20, Loss: 22.295314
val phase, Epoch 1/20, Loss: 17.336375
Val Best Loss: 17.336375
Epoch loss: 17.336375
train phase, Epoch 2/20, Loss: 17.411304
val phase, Epoch 2/20, Loss: 17.091631
Val Best Loss: 17.091631
Epoch loss: 17.091631
train phase, Epoch 3/20, Loss: 17.289471
val phase, Epoch 3/20, Loss: 16.734911
Val Best Loss: 16.734911
Epoch loss: 16.734911
train phase, Epoch 4/20, Loss: 17.330104
val phase, Epoch 4/20, Loss: 16.372115
Val Best Loss: 16.372115
Epoch loss: 16.372115
train phase, Epoch 5/20, Loss: 17.178283
val phase, Epoch 5/20, Loss: 16.282269
Val Best Loss: 16.282269
Epoch loss: 16.282269
train phase, Epoch 6/20, Loss: 16.988492
val phase, Epoch 6/20, Loss: 16.336789
Val Best Loss: 16.282269
Epoch loss: 16.336789
train phase, Epoch 7/20, Loss: 16.768448
val phase, Epoch 7/20, Loss: 17.030505
Val Best Loss: 16.282269
Epoch loss: 17.030505
train phase, Epoch 8/20, Loss: 16.533187
val phase, Epoch 8/20, Loss: 15.831190
Val Best Loss: 15.831190
Epoch loss: 15.831190
train phase, Epoch 9/20, Loss: 16.380221
val phase, Epoch 9/20, Loss: 16.604791
Val Best Loss: 15.831190
Epoch loss: 16.604791
train phase, Epoch 10/20, Loss: 15.849671
val phase, Epoch 10/20, Loss: 17.562629
Val Best Loss: 15.831190
Epoch loss: 17.562629
train phase, Epoch 11/20, Loss: 15.695561
val phase, Epoch 11/20, Loss: 16.260257
Val Best Loss: 15.831190
Epoch loss: 16.260257
train phase, Epoch 12/20, Loss: 15.652707
val phase, Epoch 12/20, Loss: 16.968310
Val Best Loss: 15.831190
Epoch loss: 16.968310
train phase, Epoch 13/20, Loss: 15.306923
val phase, Epoch 13/20, Loss: 16.564301
Val Best Loss: 15.831190
Epoch loss: 16.564301
train phase, Epoch 14/20, Loss: 15.290699
val phase, Epoch 14/20, Loss: 15.892049
Val Best Loss: 15.831190
Epoch loss: 15.892049
train phase, Epoch 15/20, Loss: 15.003499
val phase, Epoch 15/20, Loss: 18.247578
Val Best Loss: 15.831190
Epoch loss: 18.247578
train phase, Epoch 16/20, Loss: 15.364131
val phase, Epoch 16/20, Loss: 16.191350
Val Best Loss: 15.831190
Epoch loss: 16.191350
train phase, Epoch 17/20, Loss: 14.638589
val phase, Epoch 17/20, Loss: 16.330175
Val Best Loss: 15.831190
Epoch loss: 16.330175
train phase, Epoch 18/20, Loss: 14.844983
val phase, Epoch 18/20, Loss: 16.014913
Val Best Loss: 15.831190
Epoch loss: 16.014913
train phase, Epoch 19/20, Loss: 14.325449
val phase, Epoch 19/20, Loss: 17.950323
Val Best Loss: 15.831190
Epoch loss: 17.950323
train phase, Epoch 20/20, Loss: 14.018819
val phase, Epoch 20/20, Loss: 16.334595
Val Best Loss: 15.831190
Epoch loss: 16.334595
[Trial 179] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.970211
val phase, Epoch 1/20, Loss: 17.270096
Val Best Loss: 17.270096
Epoch loss: 17.270096
train phase, Epoch 2/20, Loss: 18.456651
val phase, Epoch 2/20, Loss: 27.062941
Val Best Loss: 17.270096
Epoch loss: 27.062941
train phase, Epoch 3/20, Loss: 17.870421
val phase, Epoch 3/20, Loss: 16.991194
Val Best Loss: 16.991194
Epoch loss: 16.991194
train phase, Epoch 4/20, Loss: 17.299277
val phase, Epoch 4/20, Loss: 22.308560
Val Best Loss: 16.991194
Epoch loss: 22.308560
train phase, Epoch 5/20, Loss: 17.373801
val phase, Epoch 5/20, Loss: 16.913740
Val Best Loss: 16.913740
Epoch loss: 16.913740
train phase, Epoch 6/20, Loss: 17.024955
val phase, Epoch 6/20, Loss: 17.016178
Val Best Loss: 16.913740
Epoch loss: 17.016178
train phase, Epoch 7/20, Loss: 16.717361
val phase, Epoch 7/20, Loss: 16.963525
Val Best Loss: 16.913740
Epoch loss: 16.963525
train phase, Epoch 8/20, Loss: 16.744203
val phase, Epoch 8/20, Loss: 17.499126
Val Best Loss: 16.913740
Epoch loss: 17.499126
train phase, Epoch 9/20, Loss: 16.616258
val phase, Epoch 9/20, Loss: 16.189709
Val Best Loss: 16.189709
Epoch loss: 16.189709
train phase, Epoch 10/20, Loss: 16.252051
val phase, Epoch 10/20, Loss: 16.351056
Val Best Loss: 16.189709
Epoch loss: 16.351056
train phase, Epoch 11/20, Loss: 16.223574
val phase, Epoch 11/20, Loss: 16.848183
Val Best Loss: 16.189709
Epoch loss: 16.848183
train phase, Epoch 12/20, Loss: 16.028833
val phase, Epoch 12/20, Loss: 16.427178
Val Best Loss: 16.189709
Epoch loss: 16.427178
train phase, Epoch 13/20, Loss: 15.713800
val phase, Epoch 13/20, Loss: 16.014601
Val Best Loss: 16.014601
Epoch loss: 16.014601
train phase, Epoch 14/20, Loss: 15.715779
val phase, Epoch 14/20, Loss: 16.302277
Val Best Loss: 16.014601
Epoch loss: 16.302277
train phase, Epoch 15/20, Loss: 15.356094
val phase, Epoch 15/20, Loss: 16.203293
Val Best Loss: 16.014601
Epoch loss: 16.203293
train phase, Epoch 16/20, Loss: 15.202777
val phase, Epoch 16/20, Loss: 16.132117
Val Best Loss: 16.014601
Epoch loss: 16.132117
train phase, Epoch 17/20, Loss: 14.952130
val phase, Epoch 17/20, Loss: 15.903155
Val Best Loss: 15.903155
Epoch loss: 15.903155
train phase, Epoch 18/20, Loss: 14.850387
val phase, Epoch 18/20, Loss: 16.749609
Val Best Loss: 15.903155
Epoch loss: 16.749609
train phase, Epoch 19/20, Loss: 14.415580
val phase, Epoch 19/20, Loss: 17.037614
Val Best Loss: 15.903155
Epoch loss: 17.037614
train phase, Epoch 20/20, Loss: 14.389871
val phase, Epoch 20/20, Loss: 16.356847
Val Best Loss: 15.903155
Epoch loss: 16.356847
train phase, Epoch 1/20, Loss: 19.681269
val phase, Epoch 1/20, Loss: 17.102217
Val Best Loss: 17.102217
Epoch loss: 17.102217
train phase, Epoch 2/20, Loss: 17.594115
val phase, Epoch 2/20, Loss: 19.136686
Val Best Loss: 17.102217
Epoch loss: 19.136686
train phase, Epoch 3/20, Loss: 17.725880
val phase, Epoch 3/20, Loss: 16.895823
Val Best Loss: 16.895823
Epoch loss: 16.895823
train phase, Epoch 4/20, Loss: 16.934351
val phase, Epoch 4/20, Loss: 24.400522
Val Best Loss: 16.895823
Epoch loss: 24.400522
train phase, Epoch 5/20, Loss: 17.033410
val phase, Epoch 5/20, Loss: 16.524108
Val Best Loss: 16.524108
Epoch loss: 16.524108
train phase, Epoch 6/20, Loss: 16.704493
val phase, Epoch 6/20, Loss: 16.548032
Val Best Loss: 16.524108
Epoch loss: 16.548032
train phase, Epoch 7/20, Loss: 16.798606
val phase, Epoch 7/20, Loss: 16.487833
Val Best Loss: 16.487833
Epoch loss: 16.487833
train phase, Epoch 8/20, Loss: 16.398863
val phase, Epoch 8/20, Loss: 16.400155
Val Best Loss: 16.400155
Epoch loss: 16.400155
train phase, Epoch 9/20, Loss: 16.304888
val phase, Epoch 9/20, Loss: 17.967559
Val Best Loss: 16.400155
Epoch loss: 17.967559
train phase, Epoch 10/20, Loss: 16.049722
val phase, Epoch 10/20, Loss: 16.856775
Val Best Loss: 16.400155
Epoch loss: 16.856775
train phase, Epoch 11/20, Loss: 15.841995
val phase, Epoch 11/20, Loss: 16.324599
Val Best Loss: 16.324599
Epoch loss: 16.324599
train phase, Epoch 12/20, Loss: 15.515176
val phase, Epoch 12/20, Loss: 16.533113
Val Best Loss: 16.324599
Epoch loss: 16.533113
train phase, Epoch 13/20, Loss: 15.592605
val phase, Epoch 13/20, Loss: 16.820142
Val Best Loss: 16.324599
Epoch loss: 16.820142
train phase, Epoch 14/20, Loss: 15.401871
val phase, Epoch 14/20, Loss: 16.805015
Val Best Loss: 16.324599
Epoch loss: 16.805015
train phase, Epoch 15/20, Loss: 15.063835
val phase, Epoch 15/20, Loss: 16.451153
Val Best Loss: 16.324599
Epoch loss: 16.451153
train phase, Epoch 16/20, Loss: 15.148644
val phase, Epoch 16/20, Loss: 19.768726
Val Best Loss: 16.324599
Epoch loss: 19.768726
train phase, Epoch 17/20, Loss: 14.622025
val phase, Epoch 17/20, Loss: 15.750391
Val Best Loss: 15.750391
Epoch loss: 15.750391
train phase, Epoch 18/20, Loss: 14.383590
val phase, Epoch 18/20, Loss: 17.102014
Val Best Loss: 15.750391
Epoch loss: 17.102014
train phase, Epoch 19/20, Loss: 14.186982
val phase, Epoch 19/20, Loss: 18.081014
Val Best Loss: 15.750391
Epoch loss: 18.081014
train phase, Epoch 20/20, Loss: 13.730535
val phase, Epoch 20/20, Loss: 16.467911
Val Best Loss: 15.750391
Epoch loss: 16.467911
train phase, Epoch 1/20, Loss: 20.009723
val phase, Epoch 1/20, Loss: 16.911949
Val Best Loss: 16.911949
Epoch loss: 16.911949
train phase, Epoch 2/20, Loss: 17.946980
val phase, Epoch 2/20, Loss: 24.554072
Val Best Loss: 16.911949
Epoch loss: 24.554072
train phase, Epoch 3/20, Loss: 17.507439
val phase, Epoch 3/20, Loss: 16.195527
Val Best Loss: 16.195527
Epoch loss: 16.195527
train phase, Epoch 4/20, Loss: 17.358822
val phase, Epoch 4/20, Loss: 17.055802
Val Best Loss: 16.195527
Epoch loss: 17.055802
train phase, Epoch 5/20, Loss: 16.996025
val phase, Epoch 5/20, Loss: 16.210888
Val Best Loss: 16.195527
Epoch loss: 16.210888
train phase, Epoch 6/20, Loss: 16.826052
val phase, Epoch 6/20, Loss: 17.328177
Val Best Loss: 16.195527
Epoch loss: 17.328177
train phase, Epoch 7/20, Loss: 16.415415
val phase, Epoch 7/20, Loss: 16.565595
Val Best Loss: 16.195527
Epoch loss: 16.565595
train phase, Epoch 8/20, Loss: 16.488104
val phase, Epoch 8/20, Loss: 16.667928
Val Best Loss: 16.195527
Epoch loss: 16.667928
train phase, Epoch 9/20, Loss: 16.106994
val phase, Epoch 9/20, Loss: 16.262662
Val Best Loss: 16.195527
Epoch loss: 16.262662
train phase, Epoch 10/20, Loss: 16.106286
val phase, Epoch 10/20, Loss: 15.910737
Val Best Loss: 15.910737
Epoch loss: 15.910737
train phase, Epoch 11/20, Loss: 16.073613
val phase, Epoch 11/20, Loss: 16.220409
Val Best Loss: 15.910737
Epoch loss: 16.220409
train phase, Epoch 12/20, Loss: 15.685353
val phase, Epoch 12/20, Loss: 16.635458
Val Best Loss: 15.910737
Epoch loss: 16.635458
train phase, Epoch 13/20, Loss: 15.553437
val phase, Epoch 13/20, Loss: 17.291217
Val Best Loss: 15.910737
Epoch loss: 17.291217
train phase, Epoch 14/20, Loss: 15.473267
val phase, Epoch 14/20, Loss: 16.666518
Val Best Loss: 15.910737
Epoch loss: 16.666518
train phase, Epoch 15/20, Loss: 15.100855
val phase, Epoch 15/20, Loss: 16.044087
Val Best Loss: 15.910737
Epoch loss: 16.044087
train phase, Epoch 16/20, Loss: 15.013737
val phase, Epoch 16/20, Loss: 16.361645
Val Best Loss: 15.910737
Epoch loss: 16.361645
train phase, Epoch 17/20, Loss: 14.795314
val phase, Epoch 17/20, Loss: 16.242643
Val Best Loss: 15.910737
Epoch loss: 16.242643
train phase, Epoch 18/20, Loss: 14.760570
val phase, Epoch 18/20, Loss: 16.270177
Val Best Loss: 15.910737
Epoch loss: 16.270177
train phase, Epoch 19/20, Loss: 14.326374
val phase, Epoch 19/20, Loss: 17.075217
Val Best Loss: 15.910737
Epoch loss: 17.075217
train phase, Epoch 20/20, Loss: 14.175073
val phase, Epoch 20/20, Loss: 17.135202
Val Best Loss: 15.910737
Epoch loss: 17.135202
train phase, Epoch 1/20, Loss: 19.995960
val phase, Epoch 1/20, Loss: 17.234596
Val Best Loss: 17.234596
Epoch loss: 17.234596
train phase, Epoch 2/20, Loss: 17.974849
val phase, Epoch 2/20, Loss: 16.740229
Val Best Loss: 16.740229
Epoch loss: 16.740229
train phase, Epoch 3/20, Loss: 17.637072
val phase, Epoch 3/20, Loss: 18.808833
Val Best Loss: 16.740229
Epoch loss: 18.808833
train phase, Epoch 4/20, Loss: 17.380894
val phase, Epoch 4/20, Loss: 16.363563
Val Best Loss: 16.363563
Epoch loss: 16.363563
train phase, Epoch 5/20, Loss: 16.687302
val phase, Epoch 5/20, Loss: 16.010739
Val Best Loss: 16.010739
Epoch loss: 16.010739
train phase, Epoch 6/20, Loss: 16.681764
val phase, Epoch 6/20, Loss: 17.190672
Val Best Loss: 16.010739
Epoch loss: 17.190672
train phase, Epoch 7/20, Loss: 16.225831
val phase, Epoch 7/20, Loss: 16.133686
Val Best Loss: 16.010739
Epoch loss: 16.133686
train phase, Epoch 8/20, Loss: 16.064751
val phase, Epoch 8/20, Loss: 16.004224
Val Best Loss: 16.004224
Epoch loss: 16.004224
train phase, Epoch 9/20, Loss: 16.217017
val phase, Epoch 9/20, Loss: 16.748381
Val Best Loss: 16.004224
Epoch loss: 16.748381
train phase, Epoch 10/20, Loss: 16.111345
val phase, Epoch 10/20, Loss: 16.283715
Val Best Loss: 16.004224
Epoch loss: 16.283715
train phase, Epoch 11/20, Loss: 15.709484
val phase, Epoch 11/20, Loss: 18.319314
Val Best Loss: 16.004224
Epoch loss: 18.319314
train phase, Epoch 12/20, Loss: 15.652274
val phase, Epoch 12/20, Loss: 16.090871
Val Best Loss: 16.004224
Epoch loss: 16.090871
train phase, Epoch 13/20, Loss: 15.392021
val phase, Epoch 13/20, Loss: 17.527076
Val Best Loss: 16.004224
Epoch loss: 17.527076
train phase, Epoch 14/20, Loss: 15.205275
val phase, Epoch 14/20, Loss: 15.870228
Val Best Loss: 15.870228
Epoch loss: 15.870228
train phase, Epoch 15/20, Loss: 15.037587
val phase, Epoch 15/20, Loss: 16.067729
Val Best Loss: 15.870228
Epoch loss: 16.067729
train phase, Epoch 16/20, Loss: 14.725138
val phase, Epoch 16/20, Loss: 17.989405
Val Best Loss: 15.870228
Epoch loss: 17.989405
train phase, Epoch 17/20, Loss: 14.737204
val phase, Epoch 17/20, Loss: 18.925637
Val Best Loss: 15.870228
Epoch loss: 18.925637
train phase, Epoch 18/20, Loss: 14.202525
val phase, Epoch 18/20, Loss: 15.860399
Val Best Loss: 15.860399
Epoch loss: 15.860399
train phase, Epoch 19/20, Loss: 13.905093
val phase, Epoch 19/20, Loss: 16.483573
Val Best Loss: 15.860399
Epoch loss: 16.483573
train phase, Epoch 20/20, Loss: 13.844177
val phase, Epoch 20/20, Loss: 16.253364
Val Best Loss: 15.860399
Epoch loss: 16.253364
train phase, Epoch 1/20, Loss: 20.033585
val phase, Epoch 1/20, Loss: 17.024820
Val Best Loss: 17.024820
Epoch loss: 17.024820
train phase, Epoch 2/20, Loss: 17.945548
val phase, Epoch 2/20, Loss: 16.495999
Val Best Loss: 16.495999
Epoch loss: 16.495999
train phase, Epoch 3/20, Loss: 17.340560
val phase, Epoch 3/20, Loss: 16.511989
Val Best Loss: 16.495999
Epoch loss: 16.511989
train phase, Epoch 4/20, Loss: 17.006357
val phase, Epoch 4/20, Loss: 16.634734
Val Best Loss: 16.495999
Epoch loss: 16.634734
train phase, Epoch 5/20, Loss: 16.763610
val phase, Epoch 5/20, Loss: 15.923532
Val Best Loss: 15.923532
Epoch loss: 15.923532
train phase, Epoch 6/20, Loss: 16.492316
val phase, Epoch 6/20, Loss: 17.639849
Val Best Loss: 15.923532
Epoch loss: 17.639849
train phase, Epoch 7/20, Loss: 16.438428
val phase, Epoch 7/20, Loss: 16.127389
Val Best Loss: 15.923532
Epoch loss: 16.127389
train phase, Epoch 8/20, Loss: 16.018000
val phase, Epoch 8/20, Loss: 16.752714
Val Best Loss: 15.923532
Epoch loss: 16.752714
train phase, Epoch 9/20, Loss: 16.349990
val phase, Epoch 9/20, Loss: 15.992074
Val Best Loss: 15.923532
Epoch loss: 15.992074
train phase, Epoch 10/20, Loss: 15.767358
val phase, Epoch 10/20, Loss: 16.739252
Val Best Loss: 15.923532
Epoch loss: 16.739252
train phase, Epoch 11/20, Loss: 15.805763
val phase, Epoch 11/20, Loss: 16.176951
Val Best Loss: 15.923532
Epoch loss: 16.176951
train phase, Epoch 12/20, Loss: 15.567015
val phase, Epoch 12/20, Loss: 16.327086
Val Best Loss: 15.923532
Epoch loss: 16.327086
train phase, Epoch 13/20, Loss: 15.547335
val phase, Epoch 13/20, Loss: 15.949681
Val Best Loss: 15.923532
Epoch loss: 15.949681
train phase, Epoch 14/20, Loss: 15.320812
val phase, Epoch 14/20, Loss: 18.160523
Val Best Loss: 15.923532
Epoch loss: 18.160523
train phase, Epoch 15/20, Loss: 15.027063
val phase, Epoch 15/20, Loss: 15.717924
Val Best Loss: 15.717924
Epoch loss: 15.717924
train phase, Epoch 16/20, Loss: 14.852455
val phase, Epoch 16/20, Loss: 17.016033
Val Best Loss: 15.717924
Epoch loss: 17.016033
train phase, Epoch 17/20, Loss: 14.772692
val phase, Epoch 17/20, Loss: 16.669133
Val Best Loss: 15.717924
Epoch loss: 16.669133
train phase, Epoch 18/20, Loss: 14.290654
val phase, Epoch 18/20, Loss: 16.140456
Val Best Loss: 15.717924
Epoch loss: 16.140456
train phase, Epoch 19/20, Loss: 13.908719
val phase, Epoch 19/20, Loss: 16.272081
Val Best Loss: 15.717924
Epoch loss: 16.272081
train phase, Epoch 20/20, Loss: 13.544082
val phase, Epoch 20/20, Loss: 16.437484
Val Best Loss: 15.717924
Epoch loss: 16.437484
train phase, Epoch 1/20, Loss: 20.132718
val phase, Epoch 1/20, Loss: 17.108186
Val Best Loss: 17.108186
Epoch loss: 17.108186
train phase, Epoch 2/20, Loss: 17.858179
val phase, Epoch 2/20, Loss: 18.706409
Val Best Loss: 17.108186
Epoch loss: 18.706409
train phase, Epoch 3/20, Loss: 17.912282
val phase, Epoch 3/20, Loss: 16.248687
Val Best Loss: 16.248687
Epoch loss: 16.248687
train phase, Epoch 4/20, Loss: 17.120963
val phase, Epoch 4/20, Loss: 16.432956
Val Best Loss: 16.248687
Epoch loss: 16.432956
train phase, Epoch 5/20, Loss: 16.907737
val phase, Epoch 5/20, Loss: 17.774595
Val Best Loss: 16.248687
Epoch loss: 17.774595
train phase, Epoch 6/20, Loss: 16.872722
val phase, Epoch 6/20, Loss: 16.369605
Val Best Loss: 16.248687
Epoch loss: 16.369605
train phase, Epoch 7/20, Loss: 16.576732
val phase, Epoch 7/20, Loss: 16.305663
Val Best Loss: 16.248687
Epoch loss: 16.305663
train phase, Epoch 8/20, Loss: 16.198703
val phase, Epoch 8/20, Loss: 16.541707
Val Best Loss: 16.248687
Epoch loss: 16.541707
train phase, Epoch 9/20, Loss: 16.354402
val phase, Epoch 9/20, Loss: 16.958937
Val Best Loss: 16.248687
Epoch loss: 16.958937
train phase, Epoch 10/20, Loss: 15.958351
val phase, Epoch 10/20, Loss: 15.841076
Val Best Loss: 15.841076
Epoch loss: 15.841076
train phase, Epoch 11/20, Loss: 15.800411
val phase, Epoch 11/20, Loss: 16.772899
Val Best Loss: 15.841076
Epoch loss: 16.772899
train phase, Epoch 12/20, Loss: 15.667163
val phase, Epoch 12/20, Loss: 16.705647
Val Best Loss: 15.841076
Epoch loss: 16.705647
train phase, Epoch 13/20, Loss: 15.465885
val phase, Epoch 13/20, Loss: 16.102369
Val Best Loss: 15.841076
Epoch loss: 16.102369
train phase, Epoch 14/20, Loss: 15.302602
val phase, Epoch 14/20, Loss: 16.185435
Val Best Loss: 15.841076
Epoch loss: 16.185435
train phase, Epoch 15/20, Loss: 15.130211
val phase, Epoch 15/20, Loss: 15.891809
Val Best Loss: 15.841076
Epoch loss: 15.891809
train phase, Epoch 16/20, Loss: 14.906284
val phase, Epoch 16/20, Loss: 16.312953
Val Best Loss: 15.841076
Epoch loss: 16.312953
train phase, Epoch 17/20, Loss: 14.783371
val phase, Epoch 17/20, Loss: 16.468612
Val Best Loss: 15.841076
Epoch loss: 16.468612
train phase, Epoch 18/20, Loss: 14.561654
val phase, Epoch 18/20, Loss: 17.284283
Val Best Loss: 15.841076
Epoch loss: 17.284283
train phase, Epoch 19/20, Loss: 14.282894
val phase, Epoch 19/20, Loss: 17.249729
Val Best Loss: 15.841076
Epoch loss: 17.249729
train phase, Epoch 20/20, Loss: 13.881503
val phase, Epoch 20/20, Loss: 16.583345
Val Best Loss: 15.841076
Epoch loss: 16.583345
train phase, Epoch 1/20, Loss: nan
val phase, Epoch 1/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/20, Loss: nan
val phase, Epoch 2/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/20, Loss: nan
val phase, Epoch 3/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/20, Loss: nan
val phase, Epoch 4/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/20, Loss: nan
val phase, Epoch 5/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/20, Loss: nan
val phase, Epoch 6/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/20, Loss: nan
val phase, Epoch 7/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/20, Loss: nan
val phase, Epoch 8/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/20, Loss: nan
val phase, Epoch 9/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/20, Loss: nan
val phase, Epoch 10/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 11/20, Loss: nan
val phase, Epoch 11/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 12/20, Loss: nan
val phase, Epoch 12/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 13/20, Loss: nan
val phase, Epoch 13/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 14/20, Loss: nan
val phase, Epoch 14/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 15/20, Loss: nan
val phase, Epoch 15/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 16/20, Loss: nan
val phase, Epoch 16/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 17/20, Loss: nan
val phase, Epoch 17/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 18/20, Loss: nan
val phase, Epoch 18/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 19/20, Loss: nan
val phase, Epoch 19/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 20/20, Loss: nan
val phase, Epoch 20/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 1/20, Loss: 19.957340
val phase, Epoch 1/20, Loss: 17.075754
Val Best Loss: 17.075754
Epoch loss: 17.075754
train phase, Epoch 2/20, Loss: 17.923478
val phase, Epoch 2/20, Loss: 18.570701
Val Best Loss: 17.075754
Epoch loss: 18.570701
train phase, Epoch 3/20, Loss: 17.793959
val phase, Epoch 3/20, Loss: 16.390624
Val Best Loss: 16.390624
Epoch loss: 16.390624
train phase, Epoch 4/20, Loss: 17.070202
val phase, Epoch 4/20, Loss: 16.516677
Val Best Loss: 16.390624
Epoch loss: 16.516677
train phase, Epoch 5/20, Loss: 16.693974
val phase, Epoch 5/20, Loss: 16.630060
Val Best Loss: 16.390624
Epoch loss: 16.630060
train phase, Epoch 6/20, Loss: 16.478040
val phase, Epoch 6/20, Loss: 15.946819
Val Best Loss: 15.946819
Epoch loss: 15.946819
train phase, Epoch 7/20, Loss: 16.247640
val phase, Epoch 7/20, Loss: 16.015906
Val Best Loss: 15.946819
Epoch loss: 16.015906
train phase, Epoch 8/20, Loss: 16.171615
val phase, Epoch 8/20, Loss: 21.802209
Val Best Loss: 15.946819
Epoch loss: 21.802209
train phase, Epoch 9/20, Loss: 16.075724
val phase, Epoch 9/20, Loss: 16.625912
Val Best Loss: 15.946819
Epoch loss: 16.625912
train phase, Epoch 10/20, Loss: 15.982567
val phase, Epoch 10/20, Loss: 16.124799
Val Best Loss: 15.946819
Epoch loss: 16.124799
train phase, Epoch 11/20, Loss: 15.697677
val phase, Epoch 11/20, Loss: 16.888138
Val Best Loss: 15.946819
Epoch loss: 16.888138
train phase, Epoch 12/20, Loss: 15.634325
val phase, Epoch 12/20, Loss: 18.867147
Val Best Loss: 15.946819
Epoch loss: 18.867147
train phase, Epoch 13/20, Loss: 15.553910
val phase, Epoch 13/20, Loss: 16.221167
Val Best Loss: 15.946819
Epoch loss: 16.221167
train phase, Epoch 14/20, Loss: 15.162607
val phase, Epoch 14/20, Loss: 16.266050
Val Best Loss: 15.946819
Epoch loss: 16.266050
train phase, Epoch 15/20, Loss: 14.888135
val phase, Epoch 15/20, Loss: 17.322326
Val Best Loss: 15.946819
Epoch loss: 17.322326
train phase, Epoch 16/20, Loss: 14.796670
val phase, Epoch 16/20, Loss: 17.034549
Val Best Loss: 15.946819
Epoch loss: 17.034549
train phase, Epoch 17/20, Loss: 14.482240
val phase, Epoch 17/20, Loss: 16.216343
Val Best Loss: 15.946819
Epoch loss: 16.216343
train phase, Epoch 18/20, Loss: 14.434863
val phase, Epoch 18/20, Loss: 16.258753
Val Best Loss: 15.946819
Epoch loss: 16.258753
train phase, Epoch 19/20, Loss: 13.921673
val phase, Epoch 19/20, Loss: 18.645174
Val Best Loss: 15.946819
Epoch loss: 18.645174
train phase, Epoch 20/20, Loss: 14.087013
val phase, Epoch 20/20, Loss: 16.681251
Val Best Loss: 15.946819
Epoch loss: 16.681251
train phase, Epoch 1/20, Loss: 19.962361
val phase, Epoch 1/20, Loss: 31.139980
Val Best Loss: 31.139980
Epoch loss: 31.139980
train phase, Epoch 2/20, Loss: 18.345107
val phase, Epoch 2/20, Loss: 30.110114
Val Best Loss: 30.110114
Epoch loss: 30.110114
train phase, Epoch 3/20, Loss: 17.644755
val phase, Epoch 3/20, Loss: 29.296702
Val Best Loss: 29.296702
Epoch loss: 29.296702
train phase, Epoch 4/20, Loss: 17.301673
val phase, Epoch 4/20, Loss: 35.907702
Val Best Loss: 29.296702
Epoch loss: 35.907702
train phase, Epoch 5/20, Loss: 16.891238
val phase, Epoch 5/20, Loss: 50.327441
Val Best Loss: 29.296702
Epoch loss: 50.327441
train phase, Epoch 6/20, Loss: 16.652464
val phase, Epoch 6/20, Loss: 55.029492
Val Best Loss: 29.296702
Epoch loss: 55.029492
train phase, Epoch 7/20, Loss: 16.309584
val phase, Epoch 7/20, Loss: 46.941021
Val Best Loss: 29.296702
Epoch loss: 46.941021
train phase, Epoch 8/20, Loss: 16.288691
val phase, Epoch 8/20, Loss: 40.004711
Val Best Loss: 29.296702
Epoch loss: 40.004711
train phase, Epoch 9/20, Loss: 16.159708
val phase, Epoch 9/20, Loss: 45.190285
Val Best Loss: 29.296702
Epoch loss: 45.190285
train phase, Epoch 10/20, Loss: 15.871307
val phase, Epoch 10/20, Loss: 57.750782
Val Best Loss: 29.296702
Epoch loss: 57.750782
train phase, Epoch 11/20, Loss: 15.776543
val phase, Epoch 11/20, Loss: 42.722012
Val Best Loss: 29.296702
Epoch loss: 42.722012
train phase, Epoch 12/20, Loss: 15.560883
val phase, Epoch 12/20, Loss: 46.790645
Val Best Loss: 29.296702
Epoch loss: 46.790645
train phase, Epoch 13/20, Loss: 15.280526
val phase, Epoch 13/20, Loss: 57.918385
Val Best Loss: 29.296702
Epoch loss: 57.918385
train phase, Epoch 14/20, Loss: 15.325077
val phase, Epoch 14/20, Loss: 47.621203
Val Best Loss: 29.296702
Epoch loss: 47.621203
train phase, Epoch 15/20, Loss: 15.001596
val phase, Epoch 15/20, Loss: 41.553971
Val Best Loss: 29.296702
Epoch loss: 41.553971
train phase, Epoch 16/20, Loss: 14.707606
val phase, Epoch 16/20, Loss: 49.170797
Val Best Loss: 29.296702
Epoch loss: 49.170797
train phase, Epoch 17/20, Loss: 14.580098
val phase, Epoch 17/20, Loss: 38.391407
Val Best Loss: 29.296702
Epoch loss: 38.391407
train phase, Epoch 18/20, Loss: 14.473528
val phase, Epoch 18/20, Loss: 47.812627
Val Best Loss: 29.296702
Epoch loss: 47.812627
train phase, Epoch 19/20, Loss: 14.097870
val phase, Epoch 19/20, Loss: 52.072791
Val Best Loss: 29.296702
Epoch loss: 52.072791
train phase, Epoch 20/20, Loss: 13.913097
val phase, Epoch 20/20, Loss: 71.752776
Val Best Loss: 29.296702
Epoch loss: 71.752776
train phase, Epoch 1/20, Loss: 20.106783
val phase, Epoch 1/20, Loss: 18.330618
Val Best Loss: 18.330618
Epoch loss: 18.330618
train phase, Epoch 2/20, Loss: 18.445362
val phase, Epoch 2/20, Loss: 17.276396
Val Best Loss: 17.276396
Epoch loss: 17.276396
train phase, Epoch 3/20, Loss: 17.693525
val phase, Epoch 3/20, Loss: 16.378181
Val Best Loss: 16.378181
Epoch loss: 16.378181
train phase, Epoch 4/20, Loss: 17.277830
val phase, Epoch 4/20, Loss: 17.565633
Val Best Loss: 16.378181
Epoch loss: 17.565633
train phase, Epoch 5/20, Loss: 16.956891
val phase, Epoch 5/20, Loss: 16.928721
Val Best Loss: 16.378181
Epoch loss: 16.928721
train phase, Epoch 6/20, Loss: 16.550832
val phase, Epoch 6/20, Loss: 16.192763
Val Best Loss: 16.192763
Epoch loss: 16.192763
train phase, Epoch 7/20, Loss: 16.627861
val phase, Epoch 7/20, Loss: 15.970073
Val Best Loss: 15.970073
Epoch loss: 15.970073
train phase, Epoch 8/20, Loss: 16.702324
val phase, Epoch 8/20, Loss: 16.530579
Val Best Loss: 15.970073
Epoch loss: 16.530579
train phase, Epoch 9/20, Loss: 16.249758
val phase, Epoch 9/20, Loss: 15.806202
Val Best Loss: 15.806202
Epoch loss: 15.806202
train phase, Epoch 10/20, Loss: 16.145525
val phase, Epoch 10/20, Loss: 16.124550
Val Best Loss: 15.806202
Epoch loss: 16.124550
train phase, Epoch 11/20, Loss: 15.964848
val phase, Epoch 11/20, Loss: 15.896319
Val Best Loss: 15.806202
Epoch loss: 15.896319
train phase, Epoch 12/20, Loss: 15.867182
val phase, Epoch 12/20, Loss: 15.800603
Val Best Loss: 15.800603
Epoch loss: 15.800603
train phase, Epoch 13/20, Loss: 15.654044
val phase, Epoch 13/20, Loss: 16.078092
Val Best Loss: 15.800603
Epoch loss: 16.078092
train phase, Epoch 14/20, Loss: 15.507746
val phase, Epoch 14/20, Loss: 21.290987
Val Best Loss: 15.800603
Epoch loss: 21.290987
train phase, Epoch 15/20, Loss: 15.536865
val phase, Epoch 15/20, Loss: 16.034745
Val Best Loss: 15.800603
Epoch loss: 16.034745
train phase, Epoch 16/20, Loss: 15.289880
val phase, Epoch 16/20, Loss: 15.874735
Val Best Loss: 15.800603
Epoch loss: 15.874735
train phase, Epoch 17/20, Loss: 14.815803
val phase, Epoch 17/20, Loss: 16.650864
Val Best Loss: 15.800603
Epoch loss: 16.650864
train phase, Epoch 18/20, Loss: 14.718791
val phase, Epoch 18/20, Loss: 16.421509
Val Best Loss: 15.800603
Epoch loss: 16.421509
train phase, Epoch 19/20, Loss: 14.558148
val phase, Epoch 19/20, Loss: 16.326102
Val Best Loss: 15.800603
Epoch loss: 16.326102
train phase, Epoch 20/20, Loss: 14.208661
val phase, Epoch 20/20, Loss: 17.302105
Val Best Loss: 15.800603
Epoch loss: 17.302105
train phase, Epoch 1/20, Loss: 33.484396
val phase, Epoch 1/20, Loss: 18.285615
Val Best Loss: 18.285615
Epoch loss: 18.285615
train phase, Epoch 2/20, Loss: 17.529483
val phase, Epoch 2/20, Loss: 17.748378
Val Best Loss: 17.748378
Epoch loss: 17.748378
train phase, Epoch 3/20, Loss: 16.956469
val phase, Epoch 3/20, Loss: 17.437147
Val Best Loss: 17.437147
Epoch loss: 17.437147
train phase, Epoch 4/20, Loss: 16.581425
val phase, Epoch 4/20, Loss: 17.652864
Val Best Loss: 17.437147
Epoch loss: 17.652864
train phase, Epoch 5/20, Loss: 16.285691
val phase, Epoch 5/20, Loss: 17.120992
Val Best Loss: 17.120992
Epoch loss: 17.120992
train phase, Epoch 6/20, Loss: 16.022178
val phase, Epoch 6/20, Loss: 17.890684
Val Best Loss: 17.120992
Epoch loss: 17.890684
train phase, Epoch 7/20, Loss: 15.679230
val phase, Epoch 7/20, Loss: 18.344459
Val Best Loss: 17.120992
Epoch loss: 18.344459
train phase, Epoch 8/20, Loss: 15.354820
val phase, Epoch 8/20, Loss: 17.357847
Val Best Loss: 17.120992
Epoch loss: 17.357847
train phase, Epoch 9/20, Loss: 15.127504
val phase, Epoch 9/20, Loss: 17.360064
Val Best Loss: 17.120992
Epoch loss: 17.360064
train phase, Epoch 10/20, Loss: 14.754935
val phase, Epoch 10/20, Loss: 17.017331
Val Best Loss: 17.017331
Epoch loss: 17.017331
train phase, Epoch 11/20, Loss: 14.458572
val phase, Epoch 11/20, Loss: 18.259957
Val Best Loss: 17.017331
Epoch loss: 18.259957
train phase, Epoch 12/20, Loss: 14.057082
val phase, Epoch 12/20, Loss: 17.812886
Val Best Loss: 17.017331
Epoch loss: 17.812886
train phase, Epoch 13/20, Loss: 13.726762
val phase, Epoch 13/20, Loss: 17.544775
Val Best Loss: 17.017331
Epoch loss: 17.544775
train phase, Epoch 14/20, Loss: 13.234306
val phase, Epoch 14/20, Loss: 17.486359
Val Best Loss: 17.017331
Epoch loss: 17.486359
train phase, Epoch 15/20, Loss: 12.885824
val phase, Epoch 15/20, Loss: 17.595668
Val Best Loss: 17.017331
Epoch loss: 17.595668
train phase, Epoch 16/20, Loss: 12.357036
val phase, Epoch 16/20, Loss: 18.011742
Val Best Loss: 17.017331
Epoch loss: 18.011742
train phase, Epoch 17/20, Loss: 12.030948
val phase, Epoch 17/20, Loss: 18.406564
Val Best Loss: 17.017331
Epoch loss: 18.406564
train phase, Epoch 18/20, Loss: 11.538706
val phase, Epoch 18/20, Loss: 18.049001
Val Best Loss: 17.017331
Epoch loss: 18.049001
train phase, Epoch 19/20, Loss: 11.161248
val phase, Epoch 19/20, Loss: 19.410934
Val Best Loss: 17.017331
Epoch loss: 19.410934
train phase, Epoch 20/20, Loss: 10.630895
val phase, Epoch 20/20, Loss: 18.308415
Val Best Loss: 17.017331
Epoch loss: 18.308415
train phase, Epoch 1/30, Loss: 20.479464
val phase, Epoch 1/30, Loss: 20.361280
Val Best Loss: 20.361280
Epoch loss: 20.361280
train phase, Epoch 2/30, Loss: 18.210896
val phase, Epoch 2/30, Loss: 17.643068
Val Best Loss: 17.643068
Epoch loss: 17.643068
train phase, Epoch 3/30, Loss: 17.900848
val phase, Epoch 3/30, Loss: 17.477312
Val Best Loss: 17.477312
Epoch loss: 17.477312
train phase, Epoch 4/30, Loss: 17.267356
val phase, Epoch 4/30, Loss: 20.925597
Val Best Loss: 17.477312
Epoch loss: 20.925597
train phase, Epoch 5/30, Loss: 17.056978
val phase, Epoch 5/30, Loss: 16.936380
Val Best Loss: 16.936380
Epoch loss: 16.936380
train phase, Epoch 6/30, Loss: 16.995510
val phase, Epoch 6/30, Loss: 18.451950
Val Best Loss: 16.936380
Epoch loss: 18.451950
train phase, Epoch 7/30, Loss: 16.850166
val phase, Epoch 7/30, Loss: 16.773295
Val Best Loss: 16.773295
Epoch loss: 16.773295
train phase, Epoch 8/30, Loss: 16.848000
val phase, Epoch 8/30, Loss: 15.897055
Val Best Loss: 15.897055
Epoch loss: 15.897055
train phase, Epoch 9/30, Loss: 16.156439
val phase, Epoch 9/30, Loss: 16.026920
Val Best Loss: 15.897055
Epoch loss: 16.026920
train phase, Epoch 10/30, Loss: 16.389141
val phase, Epoch 10/30, Loss: 16.736580
Val Best Loss: 15.897055
Epoch loss: 16.736580
train phase, Epoch 11/30, Loss: 16.203405
val phase, Epoch 11/30, Loss: 15.886349
Val Best Loss: 15.886349
Epoch loss: 15.886349
train phase, Epoch 12/30, Loss: 15.891502
val phase, Epoch 12/30, Loss: 16.678680
Val Best Loss: 15.886349
Epoch loss: 16.678680
train phase, Epoch 13/30, Loss: 15.830575
val phase, Epoch 13/30, Loss: 16.145797
Val Best Loss: 15.886349
Epoch loss: 16.145797
train phase, Epoch 14/30, Loss: 15.753913
val phase, Epoch 14/30, Loss: 15.866773
Val Best Loss: 15.866773
Epoch loss: 15.866773
train phase, Epoch 15/30, Loss: 15.774924
val phase, Epoch 15/30, Loss: 16.162807
Val Best Loss: 15.866773
Epoch loss: 16.162807
train phase, Epoch 16/30, Loss: 15.358747
val phase, Epoch 16/30, Loss: 16.381465
Val Best Loss: 15.866773
Epoch loss: 16.381465
train phase, Epoch 17/30, Loss: 15.184303
val phase, Epoch 17/30, Loss: 16.505760
Val Best Loss: 15.866773
Epoch loss: 16.505760
train phase, Epoch 18/30, Loss: 15.113346
val phase, Epoch 18/30, Loss: 15.838658
Val Best Loss: 15.838658
Epoch loss: 15.838658
train phase, Epoch 19/30, Loss: 14.974188
val phase, Epoch 19/30, Loss: 16.670710
Val Best Loss: 15.838658
Epoch loss: 16.670710
train phase, Epoch 20/30, Loss: 14.902910
val phase, Epoch 20/30, Loss: 16.924401
Val Best Loss: 15.838658
Epoch loss: 16.924401
train phase, Epoch 21/30, Loss: 14.304378
val phase, Epoch 21/30, Loss: 20.804190
Val Best Loss: 15.838658
Epoch loss: 20.804190
train phase, Epoch 22/30, Loss: 14.161653
val phase, Epoch 22/30, Loss: 17.400581
Val Best Loss: 15.838658
Epoch loss: 17.400581
train phase, Epoch 23/30, Loss: 13.832835
val phase, Epoch 23/30, Loss: 16.186313
Val Best Loss: 15.838658
Epoch loss: 16.186313
train phase, Epoch 24/30, Loss: 13.857108
val phase, Epoch 24/30, Loss: 17.013430
Val Best Loss: 15.838658
Epoch loss: 17.013430
train phase, Epoch 25/30, Loss: 13.273635
val phase, Epoch 25/30, Loss: 16.240952
Val Best Loss: 15.838658
Epoch loss: 16.240952
train phase, Epoch 26/30, Loss: 12.963166
val phase, Epoch 26/30, Loss: 16.571654
Val Best Loss: 15.838658
Epoch loss: 16.571654
train phase, Epoch 27/30, Loss: 12.641761
val phase, Epoch 27/30, Loss: 17.219859
Val Best Loss: 15.838658
Epoch loss: 17.219859
train phase, Epoch 28/30, Loss: 12.339806
val phase, Epoch 28/30, Loss: 19.486007
Val Best Loss: 15.838658
Epoch loss: 19.486007
train phase, Epoch 29/30, Loss: 12.022106
val phase, Epoch 29/30, Loss: 17.471623
Val Best Loss: 15.838658
Epoch loss: 17.471623
train phase, Epoch 30/30, Loss: 11.157302
val phase, Epoch 30/30, Loss: 18.278546
Val Best Loss: 15.838658
Epoch loss: 18.278546
train phase, Epoch 1/30, Loss: 19.655071
val phase, Epoch 1/30, Loss: 17.881007
Val Best Loss: 17.881007
Epoch loss: 17.881007
train phase, Epoch 2/30, Loss: 17.630712
val phase, Epoch 2/30, Loss: 17.056862
Val Best Loss: 17.056862
Epoch loss: 17.056862
train phase, Epoch 3/30, Loss: 17.489660
val phase, Epoch 3/30, Loss: 16.335181
Val Best Loss: 16.335181
Epoch loss: 16.335181
train phase, Epoch 4/30, Loss: 16.773700
val phase, Epoch 4/30, Loss: 18.791768
Val Best Loss: 16.335181
Epoch loss: 18.791768
train phase, Epoch 5/30, Loss: 16.710280
val phase, Epoch 5/30, Loss: 16.422869
Val Best Loss: 16.335181
Epoch loss: 16.422869
train phase, Epoch 6/30, Loss: 16.378738
val phase, Epoch 6/30, Loss: 17.489447
Val Best Loss: 16.335181
Epoch loss: 17.489447
train phase, Epoch 7/30, Loss: 16.496479
val phase, Epoch 7/30, Loss: 17.678054
Val Best Loss: 16.335181
Epoch loss: 17.678054
train phase, Epoch 8/30, Loss: 16.043916
val phase, Epoch 8/30, Loss: 16.498635
Val Best Loss: 16.335181
Epoch loss: 16.498635
train phase, Epoch 9/30, Loss: 16.166188
val phase, Epoch 9/30, Loss: 16.361401
Val Best Loss: 16.335181
Epoch loss: 16.361401
train phase, Epoch 10/30, Loss: 15.864817
val phase, Epoch 10/30, Loss: 16.028522
Val Best Loss: 16.028522
Epoch loss: 16.028522
train phase, Epoch 11/30, Loss: 15.728860
val phase, Epoch 11/30, Loss: 16.005676
Val Best Loss: 16.005676
Epoch loss: 16.005676
train phase, Epoch 12/30, Loss: 15.565906
val phase, Epoch 12/30, Loss: 16.306317
Val Best Loss: 16.005676
Epoch loss: 16.306317
train phase, Epoch 13/30, Loss: 15.544328
val phase, Epoch 13/30, Loss: 16.632703
Val Best Loss: 16.005676
Epoch loss: 16.632703
train phase, Epoch 14/30, Loss: 15.073658
val phase, Epoch 14/30, Loss: 15.994629
Val Best Loss: 15.994629
Epoch loss: 15.994629
train phase, Epoch 15/30, Loss: 14.933458
val phase, Epoch 15/30, Loss: 15.900379
Val Best Loss: 15.900379
Epoch loss: 15.900379
train phase, Epoch 16/30, Loss: 14.910927
val phase, Epoch 16/30, Loss: 16.810308
Val Best Loss: 15.900379
Epoch loss: 16.810308
train phase, Epoch 17/30, Loss: 14.477107
val phase, Epoch 17/30, Loss: 16.259617
Val Best Loss: 15.900379
Epoch loss: 16.259617
train phase, Epoch 18/30, Loss: 14.296744
val phase, Epoch 18/30, Loss: 19.726331
Val Best Loss: 15.900379
Epoch loss: 19.726331
train phase, Epoch 19/30, Loss: 13.997045
val phase, Epoch 19/30, Loss: 16.732485
Val Best Loss: 15.900379
Epoch loss: 16.732485
train phase, Epoch 20/30, Loss: 13.581333
val phase, Epoch 20/30, Loss: 16.003941
Val Best Loss: 15.900379
Epoch loss: 16.003941
train phase, Epoch 21/30, Loss: 13.543514
val phase, Epoch 21/30, Loss: 17.014338
Val Best Loss: 15.900379
Epoch loss: 17.014338
train phase, Epoch 22/30, Loss: 13.069497
val phase, Epoch 22/30, Loss: 16.946627
Val Best Loss: 15.900379
Epoch loss: 16.946627
train phase, Epoch 23/30, Loss: 12.509634
val phase, Epoch 23/30, Loss: 16.921526
Val Best Loss: 15.900379
Epoch loss: 16.921526
train phase, Epoch 24/30, Loss: 12.396853
val phase, Epoch 24/30, Loss: 18.101399
Val Best Loss: 15.900379
Epoch loss: 18.101399
train phase, Epoch 25/30, Loss: 11.821994
val phase, Epoch 25/30, Loss: 17.274307
Val Best Loss: 15.900379
Epoch loss: 17.274307
train phase, Epoch 26/30, Loss: 11.191878
val phase, Epoch 26/30, Loss: 18.025816
Val Best Loss: 15.900379
Epoch loss: 18.025816
train phase, Epoch 27/30, Loss: 10.578501
val phase, Epoch 27/30, Loss: 17.908133
Val Best Loss: 15.900379
Epoch loss: 17.908133
train phase, Epoch 28/30, Loss: 10.309125
val phase, Epoch 28/30, Loss: 23.388264
Val Best Loss: 15.900379
Epoch loss: 23.388264
train phase, Epoch 29/30, Loss: 9.752536
val phase, Epoch 29/30, Loss: 18.070109
Val Best Loss: 15.900379
Epoch loss: 18.070109
train phase, Epoch 30/30, Loss: 9.479072
val phase, Epoch 30/30, Loss: 18.356452
Val Best Loss: 15.900379
Epoch loss: 18.356452
train phase, Epoch 1/15, Loss: 20.714491
val phase, Epoch 1/15, Loss: 17.416654
Val Best Loss: 17.416654
Epoch loss: 17.416654
train phase, Epoch 2/15, Loss: 18.098671
val phase, Epoch 2/15, Loss: 17.745930
Val Best Loss: 17.416654
Epoch loss: 17.745930
train phase, Epoch 3/15, Loss: 18.010622
val phase, Epoch 3/15, Loss: 17.484574
Val Best Loss: 17.416654
Epoch loss: 17.484574
train phase, Epoch 4/15, Loss: 17.458101
val phase, Epoch 4/15, Loss: 16.775463
Val Best Loss: 16.775463
Epoch loss: 16.775463
train phase, Epoch 5/15, Loss: 17.104112
val phase, Epoch 5/15, Loss: 16.737976
Val Best Loss: 16.737976
Epoch loss: 16.737976
train phase, Epoch 6/15, Loss: 17.000474
val phase, Epoch 6/15, Loss: 16.274229
Val Best Loss: 16.274229
Epoch loss: 16.274229
train phase, Epoch 7/15, Loss: 16.978869
val phase, Epoch 7/15, Loss: 16.614651
Val Best Loss: 16.274229
Epoch loss: 16.614651
train phase, Epoch 8/15, Loss: 16.488923
val phase, Epoch 8/15, Loss: 18.432484
Val Best Loss: 16.274229
Epoch loss: 18.432484
train phase, Epoch 9/15, Loss: 16.438751
val phase, Epoch 9/15, Loss: 18.616673
Val Best Loss: 16.274229
Epoch loss: 18.616673
train phase, Epoch 10/15, Loss: 16.118913
val phase, Epoch 10/15, Loss: 16.213663
Val Best Loss: 16.213663
Epoch loss: 16.213663
train phase, Epoch 11/15, Loss: 16.227194
val phase, Epoch 11/15, Loss: 16.235171
Val Best Loss: 16.213663
Epoch loss: 16.235171
train phase, Epoch 12/15, Loss: 15.878690
val phase, Epoch 12/15, Loss: 16.490143
Val Best Loss: 16.213663
Epoch loss: 16.490143
train phase, Epoch 13/15, Loss: 15.925777
val phase, Epoch 13/15, Loss: 16.220498
Val Best Loss: 16.213663
Epoch loss: 16.220498
train phase, Epoch 14/15, Loss: 15.794101
val phase, Epoch 14/15, Loss: 15.990167
Val Best Loss: 15.990167
Epoch loss: 15.990167
train phase, Epoch 15/15, Loss: 15.794790
val phase, Epoch 15/15, Loss: 15.909772
Val Best Loss: 15.909772
Epoch loss: 15.909772
train phase, Epoch 1/30, Loss: 19.951658
val phase, Epoch 1/30, Loss: 18.813812
Val Best Loss: 18.813812
Epoch loss: 18.813812
train phase, Epoch 2/30, Loss: 17.728127
val phase, Epoch 2/30, Loss: 17.117451
Val Best Loss: 17.117451
Epoch loss: 17.117451
train phase, Epoch 3/30, Loss: 17.592751
val phase, Epoch 3/30, Loss: 18.095330
Val Best Loss: 17.117451
Epoch loss: 18.095330
train phase, Epoch 4/30, Loss: 17.251458
val phase, Epoch 4/30, Loss: 16.074569
Val Best Loss: 16.074569
Epoch loss: 16.074569
train phase, Epoch 5/30, Loss: 16.709970
val phase, Epoch 5/30, Loss: 16.375667
Val Best Loss: 16.074569
Epoch loss: 16.375667
train phase, Epoch 6/30, Loss: 16.722725
val phase, Epoch 6/30, Loss: 16.755328
Val Best Loss: 16.074569
Epoch loss: 16.755328
train phase, Epoch 7/30, Loss: 16.350666
val phase, Epoch 7/30, Loss: 16.310480
Val Best Loss: 16.074569
Epoch loss: 16.310480
train phase, Epoch 8/30, Loss: 16.104764
val phase, Epoch 8/30, Loss: 18.924263
Val Best Loss: 16.074569
Epoch loss: 18.924263
train phase, Epoch 9/30, Loss: 16.383532
val phase, Epoch 9/30, Loss: 17.670713
Val Best Loss: 16.074569
Epoch loss: 17.670713
train phase, Epoch 10/30, Loss: 16.335740
val phase, Epoch 10/30, Loss: 16.434777
Val Best Loss: 16.074569
Epoch loss: 16.434777
train phase, Epoch 11/30, Loss: 15.886187
val phase, Epoch 11/30, Loss: 15.784140
Val Best Loss: 15.784140
Epoch loss: 15.784140
train phase, Epoch 12/30, Loss: 15.622580
val phase, Epoch 12/30, Loss: 22.537220
Val Best Loss: 15.784140
Epoch loss: 22.537220
train phase, Epoch 13/30, Loss: 16.202705
val phase, Epoch 13/30, Loss: 16.644239
Val Best Loss: 15.784140
Epoch loss: 16.644239
train phase, Epoch 14/30, Loss: 15.396718
val phase, Epoch 14/30, Loss: 15.952090
Val Best Loss: 15.784140
Epoch loss: 15.952090
train phase, Epoch 15/30, Loss: 14.917257
val phase, Epoch 15/30, Loss: 16.737311
Val Best Loss: 15.784140
Epoch loss: 16.737311
train phase, Epoch 16/30, Loss: 14.859106
val phase, Epoch 16/30, Loss: 17.029067
Val Best Loss: 15.784140
Epoch loss: 17.029067
train phase, Epoch 17/30, Loss: 14.628010
val phase, Epoch 17/30, Loss: 15.909969
Val Best Loss: 15.784140
Epoch loss: 15.909969
train phase, Epoch 18/30, Loss: 14.447886
val phase, Epoch 18/30, Loss: 15.961898
Val Best Loss: 15.784140
Epoch loss: 15.961898
train phase, Epoch 19/30, Loss: 14.129738
val phase, Epoch 19/30, Loss: 17.531319
Val Best Loss: 15.784140
Epoch loss: 17.531319
train phase, Epoch 20/30, Loss: 14.003820
val phase, Epoch 20/30, Loss: 16.375188
Val Best Loss: 15.784140
Epoch loss: 16.375188
train phase, Epoch 21/30, Loss: 13.695366
val phase, Epoch 21/30, Loss: 17.143413
Val Best Loss: 15.784140
Epoch loss: 17.143413
train phase, Epoch 22/30, Loss: 13.298069
val phase, Epoch 22/30, Loss: 16.664299
Val Best Loss: 15.784140
Epoch loss: 16.664299
train phase, Epoch 23/30, Loss: 13.078952
val phase, Epoch 23/30, Loss: 19.605775
Val Best Loss: 15.784140
Epoch loss: 19.605775
train phase, Epoch 24/30, Loss: 12.600498
val phase, Epoch 24/30, Loss: 17.219519
Val Best Loss: 15.784140
Epoch loss: 17.219519
train phase, Epoch 25/30, Loss: 12.169218
val phase, Epoch 25/30, Loss: 18.545871
Val Best Loss: 15.784140
Epoch loss: 18.545871
train phase, Epoch 26/30, Loss: 11.754016
val phase, Epoch 26/30, Loss: 16.830140
Val Best Loss: 15.784140
Epoch loss: 16.830140
train phase, Epoch 27/30, Loss: 11.362679
val phase, Epoch 27/30, Loss: 17.347351
Val Best Loss: 15.784140
Epoch loss: 17.347351
train phase, Epoch 28/30, Loss: 11.054889
val phase, Epoch 28/30, Loss: 18.640888
Val Best Loss: 15.784140
Epoch loss: 18.640888
train phase, Epoch 29/30, Loss: 10.520097
val phase, Epoch 29/30, Loss: 18.045097
Val Best Loss: 15.784140
Epoch loss: 18.045097
train phase, Epoch 30/30, Loss: 9.882214
val phase, Epoch 30/30, Loss: 18.344323
Val Best Loss: 15.784140
Epoch loss: 18.344323
train phase, Epoch 1/20, Loss: 121.599453
val phase, Epoch 1/20, Loss: 19.274805
Val Best Loss: 19.274805
Epoch loss: 19.274805
train phase, Epoch 2/20, Loss: 19.336525
val phase, Epoch 2/20, Loss: 17.703096
Val Best Loss: 17.703096
Epoch loss: 17.703096
train phase, Epoch 3/20, Loss: 18.657925
val phase, Epoch 3/20, Loss: 18.224223
Val Best Loss: 17.703096
Epoch loss: 18.224223
train phase, Epoch 4/20, Loss: 18.313295
val phase, Epoch 4/20, Loss: 17.283892
Val Best Loss: 17.283892
Epoch loss: 17.283892
train phase, Epoch 5/20, Loss: 17.928375
val phase, Epoch 5/20, Loss: 17.318639
Val Best Loss: 17.283892
Epoch loss: 17.318639
train phase, Epoch 6/20, Loss: 18.293764
val phase, Epoch 6/20, Loss: 18.886394
Val Best Loss: 17.283892
Epoch loss: 18.886394
train phase, Epoch 7/20, Loss: 17.661501
val phase, Epoch 7/20, Loss: 18.093497
Val Best Loss: 17.283892
Epoch loss: 18.093497
train phase, Epoch 8/20, Loss: 17.639526
val phase, Epoch 8/20, Loss: 16.932057
Val Best Loss: 16.932057
Epoch loss: 16.932057
train phase, Epoch 9/20, Loss: 17.438748
val phase, Epoch 9/20, Loss: 17.063227
Val Best Loss: 16.932057
Epoch loss: 17.063227
train phase, Epoch 10/20, Loss: 17.421192
val phase, Epoch 10/20, Loss: 17.254224
Val Best Loss: 16.932057
Epoch loss: 17.254224
train phase, Epoch 11/20, Loss: 17.325853
val phase, Epoch 11/20, Loss: 16.765713
Val Best Loss: 16.765713
Epoch loss: 16.765713
train phase, Epoch 12/20, Loss: 17.186288
val phase, Epoch 12/20, Loss: 17.205457
Val Best Loss: 16.765713
Epoch loss: 17.205457
train phase, Epoch 13/20, Loss: 17.175997
val phase, Epoch 13/20, Loss: 17.442976
Val Best Loss: 16.765713
Epoch loss: 17.442976
train phase, Epoch 14/20, Loss: 16.861118
val phase, Epoch 14/20, Loss: 18.261760
Val Best Loss: 16.765713
Epoch loss: 18.261760
train phase, Epoch 15/20, Loss: 17.310738
val phase, Epoch 15/20, Loss: 20.754572
Val Best Loss: 16.765713
Epoch loss: 20.754572
train phase, Epoch 16/20, Loss: 21.215677
val phase, Epoch 16/20, Loss: 20.353376
Val Best Loss: 16.765713
Epoch loss: 20.353376
train phase, Epoch 17/20, Loss: 18.611512
val phase, Epoch 17/20, Loss: 19.796967
Val Best Loss: 16.765713
Epoch loss: 19.796967
train phase, Epoch 18/20, Loss: 171955.104841
val phase, Epoch 18/20, Loss: 4066.118365
Val Best Loss: 16.765713
Epoch loss: 4066.118365
train phase, Epoch 19/20, Loss: 1504.058264
val phase, Epoch 19/20, Loss: 501.521217
Val Best Loss: 16.765713
Epoch loss: 501.521217
train phase, Epoch 20/20, Loss: 622.236831
val phase, Epoch 20/20, Loss: 496.078039
Val Best Loss: 16.765713
Epoch loss: 496.078039
[Trial 196] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 19.767825
val phase, Epoch 1/30, Loss: 18.506881
Val Best Loss: 18.506881
Epoch loss: 18.506881
train phase, Epoch 2/30, Loss: 17.682364
val phase, Epoch 2/30, Loss: 17.126778
Val Best Loss: 17.126778
Epoch loss: 17.126778
train phase, Epoch 3/30, Loss: 17.660217
val phase, Epoch 3/30, Loss: 17.103247
Val Best Loss: 17.103247
Epoch loss: 17.103247
train phase, Epoch 4/30, Loss: 16.974647
val phase, Epoch 4/30, Loss: 16.707716
Val Best Loss: 16.707716
Epoch loss: 16.707716
train phase, Epoch 5/30, Loss: 16.835116
val phase, Epoch 5/30, Loss: 16.405482
Val Best Loss: 16.405482
Epoch loss: 16.405482
train phase, Epoch 6/30, Loss: 16.630754
val phase, Epoch 6/30, Loss: 16.120808
Val Best Loss: 16.120808
Epoch loss: 16.120808
train phase, Epoch 7/30, Loss: 16.555460
val phase, Epoch 7/30, Loss: 15.956458
Val Best Loss: 15.956458
Epoch loss: 15.956458
train phase, Epoch 8/30, Loss: 16.320806
val phase, Epoch 8/30, Loss: 17.083362
Val Best Loss: 15.956458
Epoch loss: 17.083362
train phase, Epoch 9/30, Loss: 16.073860
val phase, Epoch 9/30, Loss: 16.696335
Val Best Loss: 15.956458
Epoch loss: 16.696335
train phase, Epoch 10/30, Loss: 16.014693
val phase, Epoch 10/30, Loss: 17.043524
Val Best Loss: 15.956458
Epoch loss: 17.043524
train phase, Epoch 11/30, Loss: 15.718092
val phase, Epoch 11/30, Loss: 16.060048
Val Best Loss: 15.956458
Epoch loss: 16.060048
train phase, Epoch 12/30, Loss: 15.664389
val phase, Epoch 12/30, Loss: 17.930191
Val Best Loss: 15.956458
Epoch loss: 17.930191
train phase, Epoch 13/30, Loss: 15.866446
val phase, Epoch 13/30, Loss: 15.980538
Val Best Loss: 15.956458
Epoch loss: 15.980538
train phase, Epoch 14/30, Loss: 15.403777
val phase, Epoch 14/30, Loss: 16.136910
Val Best Loss: 15.956458
Epoch loss: 16.136910
train phase, Epoch 15/30, Loss: 15.094819
val phase, Epoch 15/30, Loss: 16.879801
Val Best Loss: 15.956458
Epoch loss: 16.879801
train phase, Epoch 16/30, Loss: 14.842811
val phase, Epoch 16/30, Loss: 17.098809
Val Best Loss: 15.956458
Epoch loss: 17.098809
train phase, Epoch 17/30, Loss: 14.665228
val phase, Epoch 17/30, Loss: 16.410398
Val Best Loss: 15.956458
Epoch loss: 16.410398
train phase, Epoch 18/30, Loss: 14.223944
val phase, Epoch 18/30, Loss: 16.895344
Val Best Loss: 15.956458
Epoch loss: 16.895344
train phase, Epoch 19/30, Loss: 14.025956
val phase, Epoch 19/30, Loss: 16.451605
Val Best Loss: 15.956458
Epoch loss: 16.451605
train phase, Epoch 20/30, Loss: 13.930174
val phase, Epoch 20/30, Loss: 17.124702
Val Best Loss: 15.956458
Epoch loss: 17.124702
train phase, Epoch 21/30, Loss: 13.807103
val phase, Epoch 21/30, Loss: 19.960788
Val Best Loss: 15.956458
Epoch loss: 19.960788
train phase, Epoch 22/30, Loss: 13.350415
val phase, Epoch 22/30, Loss: 16.915883
Val Best Loss: 15.956458
Epoch loss: 16.915883
train phase, Epoch 23/30, Loss: 13.140448
val phase, Epoch 23/30, Loss: 16.525323
Val Best Loss: 15.956458
Epoch loss: 16.525323
train phase, Epoch 24/30, Loss: 12.537028
val phase, Epoch 24/30, Loss: 16.655030
Val Best Loss: 15.956458
Epoch loss: 16.655030
train phase, Epoch 25/30, Loss: 12.027273
val phase, Epoch 25/30, Loss: 17.152201
Val Best Loss: 15.956458
Epoch loss: 17.152201
train phase, Epoch 26/30, Loss: 11.540397
val phase, Epoch 26/30, Loss: 17.272188
Val Best Loss: 15.956458
Epoch loss: 17.272188
train phase, Epoch 27/30, Loss: 11.191270
val phase, Epoch 27/30, Loss: 17.583395
Val Best Loss: 15.956458
Epoch loss: 17.583395
train phase, Epoch 28/30, Loss: 10.845645
val phase, Epoch 28/30, Loss: 17.673756
Val Best Loss: 15.956458
Epoch loss: 17.673756
train phase, Epoch 29/30, Loss: 10.343871
val phase, Epoch 29/30, Loss: 18.459482
Val Best Loss: 15.956458
Epoch loss: 18.459482
train phase, Epoch 30/30, Loss: 9.767597
val phase, Epoch 30/30, Loss: 18.649842
Val Best Loss: 15.956458
Epoch loss: 18.649842
train phase, Epoch 1/20, Loss: 20.425833
val phase, Epoch 1/20, Loss: 17.723205
Val Best Loss: 17.723205
Epoch loss: 17.723205
train phase, Epoch 2/20, Loss: 18.082443
val phase, Epoch 2/20, Loss: 17.052074
Val Best Loss: 17.052074
Epoch loss: 17.052074
train phase, Epoch 3/20, Loss: 17.586780
val phase, Epoch 3/20, Loss: 18.820742
Val Best Loss: 17.052074
Epoch loss: 18.820742
train phase, Epoch 4/20, Loss: 17.527818
val phase, Epoch 4/20, Loss: 16.442880
Val Best Loss: 16.442880
Epoch loss: 16.442880
train phase, Epoch 5/20, Loss: 17.411662
val phase, Epoch 5/20, Loss: 16.268665
Val Best Loss: 16.268665
Epoch loss: 16.268665
train phase, Epoch 6/20, Loss: 16.898340
val phase, Epoch 6/20, Loss: 17.454509
Val Best Loss: 16.268665
Epoch loss: 17.454509
train phase, Epoch 7/20, Loss: 17.203465
val phase, Epoch 7/20, Loss: 16.171520
Val Best Loss: 16.171520
Epoch loss: 16.171520
train phase, Epoch 8/20, Loss: 16.928265
val phase, Epoch 8/20, Loss: 16.443105
Val Best Loss: 16.171520
Epoch loss: 16.443105
train phase, Epoch 9/20, Loss: 16.678567
val phase, Epoch 9/20, Loss: 16.772767
Val Best Loss: 16.171520
Epoch loss: 16.772767
train phase, Epoch 10/20, Loss: 16.367057
val phase, Epoch 10/20, Loss: 16.144455
Val Best Loss: 16.144455
Epoch loss: 16.144455
train phase, Epoch 11/20, Loss: 16.296927
val phase, Epoch 11/20, Loss: 17.449044
Val Best Loss: 16.144455
Epoch loss: 17.449044
train phase, Epoch 12/20, Loss: 15.982717
val phase, Epoch 12/20, Loss: 16.209702
Val Best Loss: 16.144455
Epoch loss: 16.209702
train phase, Epoch 13/20, Loss: 16.000022
val phase, Epoch 13/20, Loss: 16.092167
Val Best Loss: 16.092167
Epoch loss: 16.092167
train phase, Epoch 14/20, Loss: 15.752506
val phase, Epoch 14/20, Loss: 16.758368
Val Best Loss: 16.092167
Epoch loss: 16.758368
train phase, Epoch 15/20, Loss: 15.611978
val phase, Epoch 15/20, Loss: 18.397637
Val Best Loss: 16.092167
Epoch loss: 18.397637
train phase, Epoch 16/20, Loss: 15.554463
val phase, Epoch 16/20, Loss: 17.474877
Val Best Loss: 16.092167
Epoch loss: 17.474877
train phase, Epoch 17/20, Loss: 15.383684
val phase, Epoch 17/20, Loss: 20.890545
Val Best Loss: 16.092167
Epoch loss: 20.890545
train phase, Epoch 18/20, Loss: 15.140859
val phase, Epoch 18/20, Loss: 18.443817
Val Best Loss: 16.092167
Epoch loss: 18.443817
train phase, Epoch 19/20, Loss: 15.116204
val phase, Epoch 19/20, Loss: 16.396498
Val Best Loss: 16.092167
Epoch loss: 16.396498
train phase, Epoch 20/20, Loss: 14.531470
val phase, Epoch 20/20, Loss: 16.438245
Val Best Loss: 16.092167
Epoch loss: 16.438245
train phase, Epoch 1/12, Loss: 20.592775
val phase, Epoch 1/12, Loss: 19.197031
Val Best Loss: 19.197031
Epoch loss: 19.197031
train phase, Epoch 2/12, Loss: 18.160246
val phase, Epoch 2/12, Loss: 18.814203
Val Best Loss: 18.814203
Epoch loss: 18.814203
train phase, Epoch 3/12, Loss: 17.800884
val phase, Epoch 3/12, Loss: 16.945622
Val Best Loss: 16.945622
Epoch loss: 16.945622
train phase, Epoch 4/12, Loss: 17.554930
val phase, Epoch 4/12, Loss: 17.726380
Val Best Loss: 16.945622
Epoch loss: 17.726380
train phase, Epoch 5/12, Loss: 17.338625
val phase, Epoch 5/12, Loss: 17.420867
Val Best Loss: 16.945622
Epoch loss: 17.420867
train phase, Epoch 6/12, Loss: 17.068603
val phase, Epoch 6/12, Loss: 16.427889
Val Best Loss: 16.427889
Epoch loss: 16.427889
train phase, Epoch 7/12, Loss: 17.003535
val phase, Epoch 7/12, Loss: 16.503996
Val Best Loss: 16.427889
Epoch loss: 16.503996
train phase, Epoch 8/12, Loss: 16.915549
val phase, Epoch 8/12, Loss: 16.349974
Val Best Loss: 16.349974
Epoch loss: 16.349974
train phase, Epoch 9/12, Loss: 16.834246
val phase, Epoch 9/12, Loss: 17.558428
Val Best Loss: 16.349974
Epoch loss: 17.558428
train phase, Epoch 10/12, Loss: 16.436866
val phase, Epoch 10/12, Loss: 16.736016
Val Best Loss: 16.349974
Epoch loss: 16.736016
train phase, Epoch 11/12, Loss: 16.326780
val phase, Epoch 11/12, Loss: 17.080719
Val Best Loss: 16.349974
Epoch loss: 17.080719
train phase, Epoch 12/12, Loss: 15.956319
val phase, Epoch 12/12, Loss: 18.891926
Val Best Loss: 16.349974
Epoch loss: 18.891926
[Trial 200] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.925891
val phase, Epoch 1/20, Loss: 18.348443
Val Best Loss: 18.348443
Epoch loss: 18.348443
train phase, Epoch 2/20, Loss: 17.838439
val phase, Epoch 2/20, Loss: 16.931053
Val Best Loss: 16.931053
Epoch loss: 16.931053
train phase, Epoch 3/20, Loss: 17.477779
val phase, Epoch 3/20, Loss: 16.599170
Val Best Loss: 16.599170
Epoch loss: 16.599170
train phase, Epoch 4/20, Loss: 17.199251
val phase, Epoch 4/20, Loss: 16.200190
Val Best Loss: 16.200190
Epoch loss: 16.200190
train phase, Epoch 5/20, Loss: 16.718924
val phase, Epoch 5/20, Loss: 16.168315
Val Best Loss: 16.168315
Epoch loss: 16.168315
train phase, Epoch 6/20, Loss: 17.106954
val phase, Epoch 6/20, Loss: 16.806646
Val Best Loss: 16.168315
Epoch loss: 16.806646
train phase, Epoch 7/20, Loss: 16.381033
val phase, Epoch 7/20, Loss: 17.554932
Val Best Loss: 16.168315
Epoch loss: 17.554932
train phase, Epoch 8/20, Loss: 16.493732
val phase, Epoch 8/20, Loss: 15.974433
Val Best Loss: 15.974433
Epoch loss: 15.974433
train phase, Epoch 9/20, Loss: 16.057173
val phase, Epoch 9/20, Loss: 16.266762
Val Best Loss: 15.974433
Epoch loss: 16.266762
train phase, Epoch 10/20, Loss: 16.034246
val phase, Epoch 10/20, Loss: 16.431142
Val Best Loss: 15.974433
Epoch loss: 16.431142
train phase, Epoch 11/20, Loss: 15.781028
val phase, Epoch 11/20, Loss: 16.359647
Val Best Loss: 15.974433
Epoch loss: 16.359647
train phase, Epoch 12/20, Loss: 15.690245
val phase, Epoch 12/20, Loss: 16.379854
Val Best Loss: 15.974433
Epoch loss: 16.379854
train phase, Epoch 13/20, Loss: 15.573808
val phase, Epoch 13/20, Loss: 16.032824
Val Best Loss: 15.974433
Epoch loss: 16.032824
train phase, Epoch 14/20, Loss: 15.535961
val phase, Epoch 14/20, Loss: 15.737083
Val Best Loss: 15.737083
Epoch loss: 15.737083
train phase, Epoch 15/20, Loss: 15.313828
val phase, Epoch 15/20, Loss: 15.803078
Val Best Loss: 15.737083
Epoch loss: 15.803078
train phase, Epoch 16/20, Loss: 15.021799
val phase, Epoch 16/20, Loss: 16.709735
Val Best Loss: 15.737083
Epoch loss: 16.709735
train phase, Epoch 17/20, Loss: 14.854123
val phase, Epoch 17/20, Loss: 16.048900
Val Best Loss: 15.737083
Epoch loss: 16.048900
train phase, Epoch 18/20, Loss: 14.592386
val phase, Epoch 18/20, Loss: 16.746613
Val Best Loss: 15.737083
Epoch loss: 16.746613
train phase, Epoch 19/20, Loss: 14.355977
val phase, Epoch 19/20, Loss: 15.893395
Val Best Loss: 15.737083
Epoch loss: 15.893395
train phase, Epoch 20/20, Loss: 14.172261
val phase, Epoch 20/20, Loss: 16.602658
Val Best Loss: 15.737083
Epoch loss: 16.602658
train phase, Epoch 1/20, Loss: 20.016287
val phase, Epoch 1/20, Loss: 18.486681
Val Best Loss: 18.486681
Epoch loss: 18.486681
train phase, Epoch 2/20, Loss: 17.512119
val phase, Epoch 2/20, Loss: 22.180476
Val Best Loss: 18.486681
Epoch loss: 22.180476
train phase, Epoch 3/20, Loss: 17.260756
val phase, Epoch 3/20, Loss: 16.693559
Val Best Loss: 16.693559
Epoch loss: 16.693559
train phase, Epoch 4/20, Loss: 17.028780
val phase, Epoch 4/20, Loss: 17.009476
Val Best Loss: 16.693559
Epoch loss: 17.009476
train phase, Epoch 5/20, Loss: 16.781353
val phase, Epoch 5/20, Loss: 17.100324
Val Best Loss: 16.693559
Epoch loss: 17.100324
train phase, Epoch 6/20, Loss: 16.616439
val phase, Epoch 6/20, Loss: 16.122449
Val Best Loss: 16.122449
Epoch loss: 16.122449
train phase, Epoch 7/20, Loss: 16.451387
val phase, Epoch 7/20, Loss: 16.700249
Val Best Loss: 16.122449
Epoch loss: 16.700249
train phase, Epoch 8/20, Loss: 16.394433
val phase, Epoch 8/20, Loss: 17.024131
Val Best Loss: 16.122449
Epoch loss: 17.024131
train phase, Epoch 9/20, Loss: 16.063187
val phase, Epoch 9/20, Loss: 15.777422
Val Best Loss: 15.777422
Epoch loss: 15.777422
train phase, Epoch 10/20, Loss: 16.069963
val phase, Epoch 10/20, Loss: 16.043382
Val Best Loss: 15.777422
Epoch loss: 16.043382
train phase, Epoch 11/20, Loss: 15.737641
val phase, Epoch 11/20, Loss: 16.595234
Val Best Loss: 15.777422
Epoch loss: 16.595234
train phase, Epoch 12/20, Loss: 15.491340
val phase, Epoch 12/20, Loss: 16.774156
Val Best Loss: 15.777422
Epoch loss: 16.774156
train phase, Epoch 13/20, Loss: 15.245911
val phase, Epoch 13/20, Loss: 16.075881
Val Best Loss: 15.777422
Epoch loss: 16.075881
train phase, Epoch 14/20, Loss: 15.313223
val phase, Epoch 14/20, Loss: 16.515938
Val Best Loss: 15.777422
Epoch loss: 16.515938
train phase, Epoch 15/20, Loss: 14.919849
val phase, Epoch 15/20, Loss: 17.985542
Val Best Loss: 15.777422
Epoch loss: 17.985542
train phase, Epoch 16/20, Loss: 14.983613
val phase, Epoch 16/20, Loss: 16.522213
Val Best Loss: 15.777422
Epoch loss: 16.522213
train phase, Epoch 17/20, Loss: 14.699406
val phase, Epoch 17/20, Loss: 16.603354
Val Best Loss: 15.777422
Epoch loss: 16.603354
train phase, Epoch 18/20, Loss: 14.131366
val phase, Epoch 18/20, Loss: 16.653656
Val Best Loss: 15.777422
Epoch loss: 16.653656
train phase, Epoch 19/20, Loss: 14.114735
val phase, Epoch 19/20, Loss: 16.624286
Val Best Loss: 15.777422
Epoch loss: 16.624286
train phase, Epoch 20/20, Loss: 13.665895
val phase, Epoch 20/20, Loss: 16.712932
Val Best Loss: 15.777422
Epoch loss: 16.712932
train phase, Epoch 1/20, Loss: 20.018250
val phase, Epoch 1/20, Loss: 18.959337
Val Best Loss: 18.959337
Epoch loss: 18.959337
train phase, Epoch 2/20, Loss: 17.954086
val phase, Epoch 2/20, Loss: 18.254685
Val Best Loss: 18.254685
Epoch loss: 18.254685
train phase, Epoch 3/20, Loss: 17.301925
val phase, Epoch 3/20, Loss: 16.463418
Val Best Loss: 16.463418
Epoch loss: 16.463418
train phase, Epoch 4/20, Loss: 16.926238
val phase, Epoch 4/20, Loss: 16.445176
Val Best Loss: 16.445176
Epoch loss: 16.445176
train phase, Epoch 5/20, Loss: 17.083003
val phase, Epoch 5/20, Loss: 16.759301
Val Best Loss: 16.445176
Epoch loss: 16.759301
train phase, Epoch 6/20, Loss: 16.627426
val phase, Epoch 6/20, Loss: 16.436620
Val Best Loss: 16.436620
Epoch loss: 16.436620
train phase, Epoch 7/20, Loss: 16.369476
val phase, Epoch 7/20, Loss: 17.873339
Val Best Loss: 16.436620
Epoch loss: 17.873339
train phase, Epoch 8/20, Loss: 16.526414
val phase, Epoch 8/20, Loss: 16.061798
Val Best Loss: 16.061798
Epoch loss: 16.061798
train phase, Epoch 9/20, Loss: 16.082831
val phase, Epoch 9/20, Loss: 16.757820
Val Best Loss: 16.061798
Epoch loss: 16.757820
train phase, Epoch 10/20, Loss: 15.896365
val phase, Epoch 10/20, Loss: 16.145959
Val Best Loss: 16.061798
Epoch loss: 16.145959
train phase, Epoch 11/20, Loss: 15.765084
val phase, Epoch 11/20, Loss: 15.952530
Val Best Loss: 15.952530
Epoch loss: 15.952530
train phase, Epoch 12/20, Loss: 15.748154
val phase, Epoch 12/20, Loss: 16.998938
Val Best Loss: 15.952530
Epoch loss: 16.998938
train phase, Epoch 13/20, Loss: 15.523998
val phase, Epoch 13/20, Loss: 16.134891
Val Best Loss: 15.952530
Epoch loss: 16.134891
train phase, Epoch 14/20, Loss: 15.240086
val phase, Epoch 14/20, Loss: 16.153180
Val Best Loss: 15.952530
Epoch loss: 16.153180
train phase, Epoch 15/20, Loss: 15.298010
val phase, Epoch 15/20, Loss: 18.283550
Val Best Loss: 15.952530
Epoch loss: 18.283550
train phase, Epoch 16/20, Loss: 14.923957
val phase, Epoch 16/20, Loss: 16.437952
Val Best Loss: 15.952530
Epoch loss: 16.437952
train phase, Epoch 17/20, Loss: 14.672847
val phase, Epoch 17/20, Loss: 17.928985
Val Best Loss: 15.952530
Epoch loss: 17.928985
train phase, Epoch 18/20, Loss: 14.482479
val phase, Epoch 18/20, Loss: 16.128082
Val Best Loss: 15.952530
Epoch loss: 16.128082
train phase, Epoch 19/20, Loss: 14.369198
val phase, Epoch 19/20, Loss: 18.517569
Val Best Loss: 15.952530
Epoch loss: 18.517569
train phase, Epoch 20/20, Loss: 14.123502
val phase, Epoch 20/20, Loss: 16.408716
Val Best Loss: 15.952530
Epoch loss: 16.408716
train phase, Epoch 1/20, Loss: 19.792067
val phase, Epoch 1/20, Loss: 20.108788
Val Best Loss: 20.108788
Epoch loss: 20.108788
train phase, Epoch 2/20, Loss: 17.915340
val phase, Epoch 2/20, Loss: 16.974336
Val Best Loss: 16.974336
Epoch loss: 16.974336
train phase, Epoch 3/20, Loss: 17.281107
val phase, Epoch 3/20, Loss: 16.538932
Val Best Loss: 16.538932
Epoch loss: 16.538932
train phase, Epoch 4/20, Loss: 17.259726
val phase, Epoch 4/20, Loss: 16.919580
Val Best Loss: 16.538932
Epoch loss: 16.919580
train phase, Epoch 5/20, Loss: 16.732932
val phase, Epoch 5/20, Loss: 16.556262
Val Best Loss: 16.538932
Epoch loss: 16.556262
train phase, Epoch 6/20, Loss: 16.729679
val phase, Epoch 6/20, Loss: 20.629049
Val Best Loss: 16.538932
Epoch loss: 20.629049
train phase, Epoch 7/20, Loss: 16.404315
val phase, Epoch 7/20, Loss: 16.301553
Val Best Loss: 16.301553
Epoch loss: 16.301553
train phase, Epoch 8/20, Loss: 16.206681
val phase, Epoch 8/20, Loss: 15.990082
Val Best Loss: 15.990082
Epoch loss: 15.990082
train phase, Epoch 9/20, Loss: 15.985879
val phase, Epoch 9/20, Loss: 16.129813
Val Best Loss: 15.990082
Epoch loss: 16.129813
train phase, Epoch 10/20, Loss: 15.963794
val phase, Epoch 10/20, Loss: 16.225665
Val Best Loss: 15.990082
Epoch loss: 16.225665
train phase, Epoch 11/20, Loss: 15.990771
val phase, Epoch 11/20, Loss: 18.978364
Val Best Loss: 15.990082
Epoch loss: 18.978364
train phase, Epoch 12/20, Loss: 15.695556
val phase, Epoch 12/20, Loss: 16.283597
Val Best Loss: 15.990082
Epoch loss: 16.283597
train phase, Epoch 13/20, Loss: 15.555098
val phase, Epoch 13/20, Loss: 16.778992
Val Best Loss: 15.990082
Epoch loss: 16.778992
train phase, Epoch 14/20, Loss: 15.327152
val phase, Epoch 14/20, Loss: 16.031240
Val Best Loss: 15.990082
Epoch loss: 16.031240
train phase, Epoch 15/20, Loss: 15.222443
val phase, Epoch 15/20, Loss: 17.900010
Val Best Loss: 15.990082
Epoch loss: 17.900010
train phase, Epoch 16/20, Loss: 15.008825
val phase, Epoch 16/20, Loss: 16.699518
Val Best Loss: 15.990082
Epoch loss: 16.699518
train phase, Epoch 17/20, Loss: 14.673921
val phase, Epoch 17/20, Loss: 16.521152
Val Best Loss: 15.990082
Epoch loss: 16.521152
train phase, Epoch 18/20, Loss: 14.440825
val phase, Epoch 18/20, Loss: 16.312451
Val Best Loss: 15.990082
Epoch loss: 16.312451
train phase, Epoch 19/20, Loss: 14.176556
val phase, Epoch 19/20, Loss: 16.466341
Val Best Loss: 15.990082
Epoch loss: 16.466341
train phase, Epoch 20/20, Loss: 13.856084
val phase, Epoch 20/20, Loss: 17.356831
Val Best Loss: 15.990082
Epoch loss: 17.356831
train phase, Epoch 1/20, Loss: 20.145549
val phase, Epoch 1/20, Loss: 18.099185
Val Best Loss: 18.099185
Epoch loss: 18.099185
train phase, Epoch 2/20, Loss: 17.907194
val phase, Epoch 2/20, Loss: 17.760563
Val Best Loss: 17.760563
Epoch loss: 17.760563
train phase, Epoch 3/20, Loss: 17.456364
val phase, Epoch 3/20, Loss: 16.670329
Val Best Loss: 16.670329
Epoch loss: 16.670329
train phase, Epoch 4/20, Loss: 17.114629
val phase, Epoch 4/20, Loss: 16.762834
Val Best Loss: 16.670329
Epoch loss: 16.762834
train phase, Epoch 5/20, Loss: 16.899688
val phase, Epoch 5/20, Loss: 16.517241
Val Best Loss: 16.517241
Epoch loss: 16.517241
train phase, Epoch 6/20, Loss: 16.603708
val phase, Epoch 6/20, Loss: 16.053829
Val Best Loss: 16.053829
Epoch loss: 16.053829
train phase, Epoch 7/20, Loss: 16.453035
val phase, Epoch 7/20, Loss: 16.393252
Val Best Loss: 16.053829
Epoch loss: 16.393252
train phase, Epoch 8/20, Loss: 16.408850
val phase, Epoch 8/20, Loss: 17.002430
Val Best Loss: 16.053829
Epoch loss: 17.002430
train phase, Epoch 9/20, Loss: 16.121455
val phase, Epoch 9/20, Loss: 16.687184
Val Best Loss: 16.053829
Epoch loss: 16.687184
train phase, Epoch 10/20, Loss: 16.023213
val phase, Epoch 10/20, Loss: 16.504371
Val Best Loss: 16.053829
Epoch loss: 16.504371
train phase, Epoch 11/20, Loss: 16.072771
val phase, Epoch 11/20, Loss: 16.202651
Val Best Loss: 16.053829
Epoch loss: 16.202651
train phase, Epoch 12/20, Loss: 15.589353
val phase, Epoch 12/20, Loss: 16.709320
Val Best Loss: 16.053829
Epoch loss: 16.709320
train phase, Epoch 13/20, Loss: 15.532449
val phase, Epoch 13/20, Loss: 17.553406
Val Best Loss: 16.053829
Epoch loss: 17.553406
train phase, Epoch 14/20, Loss: 15.154314
val phase, Epoch 14/20, Loss: 17.491485
Val Best Loss: 16.053829
Epoch loss: 17.491485
train phase, Epoch 15/20, Loss: 15.214881
val phase, Epoch 15/20, Loss: 15.924412
Val Best Loss: 15.924412
Epoch loss: 15.924412
train phase, Epoch 16/20, Loss: 14.894631
val phase, Epoch 16/20, Loss: 16.156590
Val Best Loss: 15.924412
Epoch loss: 16.156590
train phase, Epoch 17/20, Loss: 14.764926
val phase, Epoch 17/20, Loss: 20.724165
Val Best Loss: 15.924412
Epoch loss: 20.724165
train phase, Epoch 18/20, Loss: 14.656472
val phase, Epoch 18/20, Loss: 16.101493
Val Best Loss: 15.924412
Epoch loss: 16.101493
train phase, Epoch 19/20, Loss: 14.084050
val phase, Epoch 19/20, Loss: 16.443070
Val Best Loss: 15.924412
Epoch loss: 16.443070
train phase, Epoch 20/20, Loss: 13.815425
val phase, Epoch 20/20, Loss: 16.790743
Val Best Loss: 15.924412
Epoch loss: 16.790743
train phase, Epoch 1/20, Loss: 20.425211
val phase, Epoch 1/20, Loss: 18.065753
Val Best Loss: 18.065753
Epoch loss: 18.065753
train phase, Epoch 2/20, Loss: 18.207132
val phase, Epoch 2/20, Loss: 17.180228
Val Best Loss: 17.180228
Epoch loss: 17.180228
train phase, Epoch 3/20, Loss: 17.647807
val phase, Epoch 3/20, Loss: 18.088791
Val Best Loss: 17.180228
Epoch loss: 18.088791
train phase, Epoch 4/20, Loss: 17.511667
val phase, Epoch 4/20, Loss: 18.067879
Val Best Loss: 17.180228
Epoch loss: 18.067879
train phase, Epoch 5/20, Loss: 17.368034
val phase, Epoch 5/20, Loss: 17.550374
Val Best Loss: 17.180228
Epoch loss: 17.550374
train phase, Epoch 6/20, Loss: 17.422346
val phase, Epoch 6/20, Loss: 16.801590
Val Best Loss: 16.801590
Epoch loss: 16.801590
train phase, Epoch 7/20, Loss: 16.869653
val phase, Epoch 7/20, Loss: 16.513247
Val Best Loss: 16.513247
Epoch loss: 16.513247
train phase, Epoch 8/20, Loss: 16.530101
val phase, Epoch 8/20, Loss: 18.330190
Val Best Loss: 16.513247
Epoch loss: 18.330190
train phase, Epoch 9/20, Loss: 16.526755
val phase, Epoch 9/20, Loss: 16.594613
Val Best Loss: 16.513247
Epoch loss: 16.594613
train phase, Epoch 10/20, Loss: 16.389164
val phase, Epoch 10/20, Loss: 16.074721
Val Best Loss: 16.074721
Epoch loss: 16.074721
train phase, Epoch 11/20, Loss: 16.114365
val phase, Epoch 11/20, Loss: 17.053444
Val Best Loss: 16.074721
Epoch loss: 17.053444
train phase, Epoch 12/20, Loss: 16.014044
val phase, Epoch 12/20, Loss: 16.659000
Val Best Loss: 16.074721
Epoch loss: 16.659000
train phase, Epoch 13/20, Loss: 16.089018
val phase, Epoch 13/20, Loss: 16.647713
Val Best Loss: 16.074721
Epoch loss: 16.647713
train phase, Epoch 14/20, Loss: 15.862087
val phase, Epoch 14/20, Loss: 16.421842
Val Best Loss: 16.074721
Epoch loss: 16.421842
train phase, Epoch 15/20, Loss: 15.428999
val phase, Epoch 15/20, Loss: 16.679397
Val Best Loss: 16.074721
Epoch loss: 16.679397
train phase, Epoch 16/20, Loss: 15.493778
val phase, Epoch 16/20, Loss: 16.244337
Val Best Loss: 16.074721
Epoch loss: 16.244337
train phase, Epoch 17/20, Loss: 15.188527
val phase, Epoch 17/20, Loss: 16.799006
Val Best Loss: 16.074721
Epoch loss: 16.799006
train phase, Epoch 18/20, Loss: 15.212174
val phase, Epoch 18/20, Loss: 16.453018
Val Best Loss: 16.074721
Epoch loss: 16.453018
train phase, Epoch 19/20, Loss: 14.867977
val phase, Epoch 19/20, Loss: 16.578852
Val Best Loss: 16.074721
Epoch loss: 16.578852
train phase, Epoch 20/20, Loss: 14.913723
val phase, Epoch 20/20, Loss: 16.821304
Val Best Loss: 16.074721
Epoch loss: 16.821304
train phase, Epoch 1/25, Loss: 20.584631
val phase, Epoch 1/25, Loss: 18.401782
Val Best Loss: 18.401782
Epoch loss: 18.401782
train phase, Epoch 2/25, Loss: 19.155522
val phase, Epoch 2/25, Loss: 18.747094
Val Best Loss: 18.401782
Epoch loss: 18.747094
train phase, Epoch 3/25, Loss: 18.257189
val phase, Epoch 3/25, Loss: 17.410456
Val Best Loss: 17.410456
Epoch loss: 17.410456
train phase, Epoch 4/25, Loss: 17.667928
val phase, Epoch 4/25, Loss: 17.614257
Val Best Loss: 17.410456
Epoch loss: 17.614257
train phase, Epoch 5/25, Loss: 17.915842
val phase, Epoch 5/25, Loss: 18.068848
Val Best Loss: 17.410456
Epoch loss: 18.068848
train phase, Epoch 6/25, Loss: 17.249133
val phase, Epoch 6/25, Loss: 17.616580
Val Best Loss: 17.410456
Epoch loss: 17.616580
train phase, Epoch 7/25, Loss: 17.606316
val phase, Epoch 7/25, Loss: 17.196944
Val Best Loss: 17.196944
Epoch loss: 17.196944
train phase, Epoch 8/25, Loss: 17.186161
val phase, Epoch 8/25, Loss: 16.670371
Val Best Loss: 16.670371
Epoch loss: 16.670371
train phase, Epoch 9/25, Loss: 16.939303
val phase, Epoch 9/25, Loss: 17.057205
Val Best Loss: 16.670371
Epoch loss: 17.057205
train phase, Epoch 10/25, Loss: 16.899747
val phase, Epoch 10/25, Loss: 16.586271
Val Best Loss: 16.586271
Epoch loss: 16.586271
train phase, Epoch 11/25, Loss: 16.694545
val phase, Epoch 11/25, Loss: 16.613941
Val Best Loss: 16.586271
Epoch loss: 16.613941
train phase, Epoch 12/25, Loss: 16.517834
val phase, Epoch 12/25, Loss: 17.612591
Val Best Loss: 16.586271
Epoch loss: 17.612591
train phase, Epoch 13/25, Loss: 16.442153
val phase, Epoch 13/25, Loss: 16.533694
Val Best Loss: 16.533694
Epoch loss: 16.533694
train phase, Epoch 14/25, Loss: 16.421844
val phase, Epoch 14/25, Loss: 17.354539
Val Best Loss: 16.533694
Epoch loss: 17.354539
train phase, Epoch 15/25, Loss: 16.143564
val phase, Epoch 15/25, Loss: 16.082337
Val Best Loss: 16.082337
Epoch loss: 16.082337
train phase, Epoch 16/25, Loss: 15.971217
val phase, Epoch 16/25, Loss: 16.438986
Val Best Loss: 16.082337
Epoch loss: 16.438986
train phase, Epoch 17/25, Loss: 15.962507
val phase, Epoch 17/25, Loss: 16.723304
Val Best Loss: 16.082337
Epoch loss: 16.723304
train phase, Epoch 18/25, Loss: 15.706034
val phase, Epoch 18/25, Loss: 16.496050
Val Best Loss: 16.082337
Epoch loss: 16.496050
train phase, Epoch 19/25, Loss: 15.757767
val phase, Epoch 19/25, Loss: 16.268034
Val Best Loss: 16.082337
Epoch loss: 16.268034
train phase, Epoch 20/25, Loss: 15.311645
val phase, Epoch 20/25, Loss: 16.378790
Val Best Loss: 16.082337
Epoch loss: 16.378790
train phase, Epoch 21/25, Loss: 15.217103
val phase, Epoch 21/25, Loss: 17.097377
Val Best Loss: 16.082337
Epoch loss: 17.097377
train phase, Epoch 22/25, Loss: 15.292991
val phase, Epoch 22/25, Loss: 19.126184
Val Best Loss: 16.082337
Epoch loss: 19.126184
train phase, Epoch 23/25, Loss: 14.860557
val phase, Epoch 23/25, Loss: 17.228848
Val Best Loss: 16.082337
Epoch loss: 17.228848
train phase, Epoch 24/25, Loss: 14.533056
val phase, Epoch 24/25, Loss: 17.133308
Val Best Loss: 16.082337
Epoch loss: 17.133308
train phase, Epoch 25/25, Loss: 14.351678
val phase, Epoch 25/25, Loss: 16.460934
Val Best Loss: 16.082337
Epoch loss: 16.460934
train phase, Epoch 1/20, Loss: 20.665559
val phase, Epoch 1/20, Loss: 17.297181
Val Best Loss: 17.297181
Epoch loss: 17.297181
train phase, Epoch 2/20, Loss: 17.682731
val phase, Epoch 2/20, Loss: 17.052684
Val Best Loss: 17.052684
Epoch loss: 17.052684
train phase, Epoch 3/20, Loss: 17.092999
val phase, Epoch 3/20, Loss: 16.704177
Val Best Loss: 16.704177
Epoch loss: 16.704177
train phase, Epoch 4/20, Loss: 16.779859
val phase, Epoch 4/20, Loss: 16.679957
Val Best Loss: 16.679957
Epoch loss: 16.679957
train phase, Epoch 5/20, Loss: 16.809597
val phase, Epoch 5/20, Loss: 16.778680
Val Best Loss: 16.679957
Epoch loss: 16.778680
train phase, Epoch 6/20, Loss: 16.415065
val phase, Epoch 6/20, Loss: 17.447066
Val Best Loss: 16.679957
Epoch loss: 17.447066
train phase, Epoch 7/20, Loss: 16.525432
val phase, Epoch 7/20, Loss: 16.989495
Val Best Loss: 16.679957
Epoch loss: 16.989495
train phase, Epoch 8/20, Loss: 16.141467
val phase, Epoch 8/20, Loss: 16.064310
Val Best Loss: 16.064310
Epoch loss: 16.064310
train phase, Epoch 9/20, Loss: 15.785688
val phase, Epoch 9/20, Loss: 15.899689
Val Best Loss: 15.899689
Epoch loss: 15.899689
train phase, Epoch 10/20, Loss: 15.611510
val phase, Epoch 10/20, Loss: 16.658524
Val Best Loss: 15.899689
Epoch loss: 16.658524
train phase, Epoch 11/20, Loss: 15.619842
val phase, Epoch 11/20, Loss: 16.284227
Val Best Loss: 15.899689
Epoch loss: 16.284227
train phase, Epoch 12/20, Loss: 15.427593
val phase, Epoch 12/20, Loss: 15.963871
Val Best Loss: 15.899689
Epoch loss: 15.963871
train phase, Epoch 13/20, Loss: 15.423196
val phase, Epoch 13/20, Loss: 16.190718
Val Best Loss: 15.899689
Epoch loss: 16.190718
train phase, Epoch 14/20, Loss: 15.149694
val phase, Epoch 14/20, Loss: 16.069838
Val Best Loss: 15.899689
Epoch loss: 16.069838
train phase, Epoch 15/20, Loss: 14.770867
val phase, Epoch 15/20, Loss: 16.266674
Val Best Loss: 15.899689
Epoch loss: 16.266674
train phase, Epoch 16/20, Loss: 15.137187
val phase, Epoch 16/20, Loss: 16.153529
Val Best Loss: 15.899689
Epoch loss: 16.153529
train phase, Epoch 17/20, Loss: 14.311829
val phase, Epoch 17/20, Loss: 17.193828
Val Best Loss: 15.899689
Epoch loss: 17.193828
train phase, Epoch 18/20, Loss: 14.413744
val phase, Epoch 18/20, Loss: 17.800657
Val Best Loss: 15.899689
Epoch loss: 17.800657
train phase, Epoch 19/20, Loss: 13.697826
val phase, Epoch 19/20, Loss: 16.165678
Val Best Loss: 15.899689
Epoch loss: 16.165678
train phase, Epoch 20/20, Loss: 13.967572
val phase, Epoch 20/20, Loss: 16.270785
Val Best Loss: 15.899689
Epoch loss: 16.270785
[Trial 209] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 20.101113
val phase, Epoch 1/30, Loss: 17.376690
Val Best Loss: 17.376690
Epoch loss: 17.376690
train phase, Epoch 2/30, Loss: 17.966757
val phase, Epoch 2/30, Loss: 16.495539
Val Best Loss: 16.495539
Epoch loss: 16.495539
train phase, Epoch 3/30, Loss: 17.340506
val phase, Epoch 3/30, Loss: 16.933956
Val Best Loss: 16.495539
Epoch loss: 16.933956
train phase, Epoch 4/30, Loss: 17.123015
val phase, Epoch 4/30, Loss: 16.480571
Val Best Loss: 16.480571
Epoch loss: 16.480571
train phase, Epoch 5/30, Loss: 17.162985
val phase, Epoch 5/30, Loss: 17.096445
Val Best Loss: 16.480571
Epoch loss: 17.096445
train phase, Epoch 6/30, Loss: 16.556906
val phase, Epoch 6/30, Loss: 18.658377
Val Best Loss: 16.480571
Epoch loss: 18.658377
train phase, Epoch 7/30, Loss: 16.514573
val phase, Epoch 7/30, Loss: 17.007462
Val Best Loss: 16.480571
Epoch loss: 17.007462
train phase, Epoch 8/30, Loss: 16.319747
val phase, Epoch 8/30, Loss: 16.381104
Val Best Loss: 16.381104
Epoch loss: 16.381104
train phase, Epoch 9/30, Loss: 16.152299
val phase, Epoch 9/30, Loss: 16.048740
Val Best Loss: 16.048740
Epoch loss: 16.048740
train phase, Epoch 10/30, Loss: 16.031963
val phase, Epoch 10/30, Loss: 17.314500
Val Best Loss: 16.048740
Epoch loss: 17.314500
train phase, Epoch 11/30, Loss: 15.739547
val phase, Epoch 11/30, Loss: 17.200056
Val Best Loss: 16.048740
Epoch loss: 17.200056
train phase, Epoch 12/30, Loss: 15.604442
val phase, Epoch 12/30, Loss: 15.794232
Val Best Loss: 15.794232
Epoch loss: 15.794232
train phase, Epoch 13/30, Loss: 15.558269
val phase, Epoch 13/30, Loss: 17.305480
Val Best Loss: 15.794232
Epoch loss: 17.305480
train phase, Epoch 14/30, Loss: 15.236298
val phase, Epoch 14/30, Loss: 17.157502
Val Best Loss: 15.794232
Epoch loss: 17.157502
train phase, Epoch 15/30, Loss: 15.106720
val phase, Epoch 15/30, Loss: 16.454891
Val Best Loss: 15.794232
Epoch loss: 16.454891
train phase, Epoch 16/30, Loss: 15.099702
val phase, Epoch 16/30, Loss: 16.864321
Val Best Loss: 15.794232
Epoch loss: 16.864321
train phase, Epoch 17/30, Loss: 14.756076
val phase, Epoch 17/30, Loss: 15.955003
Val Best Loss: 15.794232
Epoch loss: 15.955003
train phase, Epoch 18/30, Loss: 14.493513
val phase, Epoch 18/30, Loss: 16.164547
Val Best Loss: 15.794232
Epoch loss: 16.164547
train phase, Epoch 19/30, Loss: 14.188913
val phase, Epoch 19/30, Loss: 17.050292
Val Best Loss: 15.794232
Epoch loss: 17.050292
train phase, Epoch 20/30, Loss: 13.991413
val phase, Epoch 20/30, Loss: 16.468861
Val Best Loss: 15.794232
Epoch loss: 16.468861
train phase, Epoch 21/30, Loss: 13.594379
val phase, Epoch 21/30, Loss: 16.407769
Val Best Loss: 15.794232
Epoch loss: 16.407769
train phase, Epoch 22/30, Loss: 13.294129
val phase, Epoch 22/30, Loss: 16.385305
Val Best Loss: 15.794232
Epoch loss: 16.385305
train phase, Epoch 23/30, Loss: 12.990277
val phase, Epoch 23/30, Loss: 17.397292
Val Best Loss: 15.794232
Epoch loss: 17.397292
train phase, Epoch 24/30, Loss: 12.623309
val phase, Epoch 24/30, Loss: 17.442264
Val Best Loss: 15.794232
Epoch loss: 17.442264
train phase, Epoch 25/30, Loss: 12.259864
val phase, Epoch 25/30, Loss: 17.151488
Val Best Loss: 15.794232
Epoch loss: 17.151488
train phase, Epoch 26/30, Loss: 11.757970
val phase, Epoch 26/30, Loss: 17.571099
Val Best Loss: 15.794232
Epoch loss: 17.571099
train phase, Epoch 27/30, Loss: 11.317606
val phase, Epoch 27/30, Loss: 17.645948
Val Best Loss: 15.794232
Epoch loss: 17.645948
train phase, Epoch 28/30, Loss: 10.905399
val phase, Epoch 28/30, Loss: 17.848528
Val Best Loss: 15.794232
Epoch loss: 17.848528
train phase, Epoch 29/30, Loss: 10.392152
val phase, Epoch 29/30, Loss: 17.588325
Val Best Loss: 15.794232
Epoch loss: 17.588325
train phase, Epoch 30/30, Loss: 9.994172
val phase, Epoch 30/30, Loss: 18.572135
Val Best Loss: 15.794232
Epoch loss: 18.572135
train phase, Epoch 1/20, Loss: 19.786845
val phase, Epoch 1/20, Loss: 17.836178
Val Best Loss: 17.836178
Epoch loss: 17.836178
train phase, Epoch 2/20, Loss: 18.162266
val phase, Epoch 2/20, Loss: 16.576376
Val Best Loss: 16.576376
Epoch loss: 16.576376
train phase, Epoch 3/20, Loss: 17.292574
val phase, Epoch 3/20, Loss: 16.783596
Val Best Loss: 16.576376
Epoch loss: 16.783596
train phase, Epoch 4/20, Loss: 16.937493
val phase, Epoch 4/20, Loss: 16.906121
Val Best Loss: 16.576376
Epoch loss: 16.906121
train phase, Epoch 5/20, Loss: 17.066980
val phase, Epoch 5/20, Loss: 16.613455
Val Best Loss: 16.576376
Epoch loss: 16.613455
train phase, Epoch 6/20, Loss: 16.549362
val phase, Epoch 6/20, Loss: 17.721175
Val Best Loss: 16.576376
Epoch loss: 17.721175
train phase, Epoch 7/20, Loss: 16.449291
val phase, Epoch 7/20, Loss: 15.848973
Val Best Loss: 15.848973
Epoch loss: 15.848973
train phase, Epoch 8/20, Loss: 16.329028
val phase, Epoch 8/20, Loss: 16.057051
Val Best Loss: 15.848973
Epoch loss: 16.057051
train phase, Epoch 9/20, Loss: 15.980827
val phase, Epoch 9/20, Loss: 15.866219
Val Best Loss: 15.848973
Epoch loss: 15.866219
train phase, Epoch 10/20, Loss: 15.952454
val phase, Epoch 10/20, Loss: 16.303083
Val Best Loss: 15.848973
Epoch loss: 16.303083
train phase, Epoch 11/20, Loss: 15.606679
val phase, Epoch 11/20, Loss: 15.744601
Val Best Loss: 15.744601
Epoch loss: 15.744601
train phase, Epoch 12/20, Loss: 15.677903
val phase, Epoch 12/20, Loss: 16.204171
Val Best Loss: 15.744601
Epoch loss: 16.204171
train phase, Epoch 13/20, Loss: 15.364103
val phase, Epoch 13/20, Loss: 16.684592
Val Best Loss: 15.744601
Epoch loss: 16.684592
train phase, Epoch 14/20, Loss: 15.190361
val phase, Epoch 14/20, Loss: 16.733767
Val Best Loss: 15.744601
Epoch loss: 16.733767
train phase, Epoch 15/20, Loss: 15.047418
val phase, Epoch 15/20, Loss: 17.085797
Val Best Loss: 15.744601
Epoch loss: 17.085797
train phase, Epoch 16/20, Loss: 14.798695
val phase, Epoch 16/20, Loss: 15.986570
Val Best Loss: 15.744601
Epoch loss: 15.986570
train phase, Epoch 17/20, Loss: 14.874942
val phase, Epoch 17/20, Loss: 16.092479
Val Best Loss: 15.744601
Epoch loss: 16.092479
train phase, Epoch 18/20, Loss: 14.226946
val phase, Epoch 18/20, Loss: 17.994541
Val Best Loss: 15.744601
Epoch loss: 17.994541
train phase, Epoch 19/20, Loss: 14.272137
val phase, Epoch 19/20, Loss: 16.265164
Val Best Loss: 15.744601
Epoch loss: 16.265164
train phase, Epoch 20/20, Loss: 13.799018
val phase, Epoch 20/20, Loss: 18.125921
Val Best Loss: 15.744601
Epoch loss: 18.125921
train phase, Epoch 1/20, Loss: 19.687977
val phase, Epoch 1/20, Loss: 25.788410
Val Best Loss: 25.788410
Epoch loss: 25.788410
train phase, Epoch 2/20, Loss: 17.878168
val phase, Epoch 2/20, Loss: 17.192777
Val Best Loss: 17.192777
Epoch loss: 17.192777
train phase, Epoch 3/20, Loss: 17.178392
val phase, Epoch 3/20, Loss: 16.542718
Val Best Loss: 16.542718
Epoch loss: 16.542718
train phase, Epoch 4/20, Loss: 16.981557
val phase, Epoch 4/20, Loss: 17.252710
Val Best Loss: 16.542718
Epoch loss: 17.252710
train phase, Epoch 5/20, Loss: 16.754204
val phase, Epoch 5/20, Loss: 20.488112
Val Best Loss: 16.542718
Epoch loss: 20.488112
train phase, Epoch 6/20, Loss: 16.877339
val phase, Epoch 6/20, Loss: 16.898948
Val Best Loss: 16.542718
Epoch loss: 16.898948
train phase, Epoch 7/20, Loss: 16.554709
val phase, Epoch 7/20, Loss: 16.308805
Val Best Loss: 16.308805
Epoch loss: 16.308805
train phase, Epoch 8/20, Loss: 16.040630
val phase, Epoch 8/20, Loss: 15.967013
Val Best Loss: 15.967013
Epoch loss: 15.967013
train phase, Epoch 9/20, Loss: 16.030177
val phase, Epoch 9/20, Loss: 16.867536
Val Best Loss: 15.967013
Epoch loss: 16.867536
train phase, Epoch 10/20, Loss: 15.984209
val phase, Epoch 10/20, Loss: 15.649223
Val Best Loss: 15.649223
Epoch loss: 15.649223
train phase, Epoch 11/20, Loss: 15.632200
val phase, Epoch 11/20, Loss: 17.404014
Val Best Loss: 15.649223
Epoch loss: 17.404014
train phase, Epoch 12/20, Loss: 15.422145
val phase, Epoch 12/20, Loss: 16.357033
Val Best Loss: 15.649223
Epoch loss: 16.357033
train phase, Epoch 13/20, Loss: 15.391492
val phase, Epoch 13/20, Loss: 16.116334
Val Best Loss: 15.649223
Epoch loss: 16.116334
train phase, Epoch 14/20, Loss: 15.367941
val phase, Epoch 14/20, Loss: 16.488003
Val Best Loss: 15.649223
Epoch loss: 16.488003
train phase, Epoch 15/20, Loss: 15.075496
val phase, Epoch 15/20, Loss: 16.203294
Val Best Loss: 15.649223
Epoch loss: 16.203294
train phase, Epoch 16/20, Loss: 14.939974
val phase, Epoch 16/20, Loss: 17.596801
Val Best Loss: 15.649223
Epoch loss: 17.596801
train phase, Epoch 17/20, Loss: 14.802783
val phase, Epoch 17/20, Loss: 17.088420
Val Best Loss: 15.649223
Epoch loss: 17.088420
train phase, Epoch 18/20, Loss: 14.433333
val phase, Epoch 18/20, Loss: 16.323055
Val Best Loss: 15.649223
Epoch loss: 16.323055
train phase, Epoch 19/20, Loss: 14.157204
val phase, Epoch 19/20, Loss: 17.024791
Val Best Loss: 15.649223
Epoch loss: 17.024791
train phase, Epoch 20/20, Loss: 13.959267
val phase, Epoch 20/20, Loss: 16.377332
Val Best Loss: 15.649223
Epoch loss: 16.377332
train phase, Epoch 1/20, Loss: 20.323979
val phase, Epoch 1/20, Loss: 16.995027
Val Best Loss: 16.995027
Epoch loss: 16.995027
train phase, Epoch 2/20, Loss: 17.540051
val phase, Epoch 2/20, Loss: 17.027356
Val Best Loss: 16.995027
Epoch loss: 17.027356
train phase, Epoch 3/20, Loss: 17.338884
val phase, Epoch 3/20, Loss: 18.023963
Val Best Loss: 16.995027
Epoch loss: 18.023963
train phase, Epoch 4/20, Loss: 17.127195
val phase, Epoch 4/20, Loss: 17.634971
Val Best Loss: 16.995027
Epoch loss: 17.634971
train phase, Epoch 5/20, Loss: 16.758293
val phase, Epoch 5/20, Loss: 17.311683
Val Best Loss: 16.995027
Epoch loss: 17.311683
train phase, Epoch 6/20, Loss: 16.755155
val phase, Epoch 6/20, Loss: 17.216175
Val Best Loss: 16.995027
Epoch loss: 17.216175
train phase, Epoch 7/20, Loss: 16.450165
val phase, Epoch 7/20, Loss: 15.901745
Val Best Loss: 15.901745
Epoch loss: 15.901745
train phase, Epoch 8/20, Loss: 16.199314
val phase, Epoch 8/20, Loss: 16.185763
Val Best Loss: 15.901745
Epoch loss: 16.185763
train phase, Epoch 9/20, Loss: 16.238584
val phase, Epoch 9/20, Loss: 16.125717
Val Best Loss: 15.901745
Epoch loss: 16.125717
train phase, Epoch 10/20, Loss: 15.962530
val phase, Epoch 10/20, Loss: 16.749914
Val Best Loss: 15.901745
Epoch loss: 16.749914
train phase, Epoch 11/20, Loss: 15.927811
val phase, Epoch 11/20, Loss: 15.792330
Val Best Loss: 15.792330
Epoch loss: 15.792330
train phase, Epoch 12/20, Loss: 15.522456
val phase, Epoch 12/20, Loss: 16.879365
Val Best Loss: 15.792330
Epoch loss: 16.879365
train phase, Epoch 13/20, Loss: 15.431777
val phase, Epoch 13/20, Loss: 16.425567
Val Best Loss: 15.792330
Epoch loss: 16.425567
train phase, Epoch 14/20, Loss: 15.100275
val phase, Epoch 14/20, Loss: 16.313022
Val Best Loss: 15.792330
Epoch loss: 16.313022
train phase, Epoch 15/20, Loss: 14.945243
val phase, Epoch 15/20, Loss: 16.020960
Val Best Loss: 15.792330
Epoch loss: 16.020960
train phase, Epoch 16/20, Loss: 14.837985
val phase, Epoch 16/20, Loss: 16.369790
Val Best Loss: 15.792330
Epoch loss: 16.369790
train phase, Epoch 17/20, Loss: 14.682788
val phase, Epoch 17/20, Loss: 15.906603
Val Best Loss: 15.792330
Epoch loss: 15.906603
train phase, Epoch 18/20, Loss: 14.268944
val phase, Epoch 18/20, Loss: 17.415325
Val Best Loss: 15.792330
Epoch loss: 17.415325
train phase, Epoch 19/20, Loss: 13.989001
val phase, Epoch 19/20, Loss: 16.418806
Val Best Loss: 15.792330
Epoch loss: 16.418806
train phase, Epoch 20/20, Loss: 13.842197
val phase, Epoch 20/20, Loss: 16.418513
Val Best Loss: 15.792330
Epoch loss: 16.418513
train phase, Epoch 1/20, Loss: 20.073760
val phase, Epoch 1/20, Loss: 17.204413
Val Best Loss: 17.204413
Epoch loss: 17.204413
train phase, Epoch 2/20, Loss: 17.624954
val phase, Epoch 2/20, Loss: 17.229686
Val Best Loss: 17.204413
Epoch loss: 17.229686
train phase, Epoch 3/20, Loss: 17.038902
val phase, Epoch 3/20, Loss: 16.760857
Val Best Loss: 16.760857
Epoch loss: 16.760857
train phase, Epoch 4/20, Loss: 16.755437
val phase, Epoch 4/20, Loss: 16.514556
Val Best Loss: 16.514556
Epoch loss: 16.514556
train phase, Epoch 5/20, Loss: 16.705382
val phase, Epoch 5/20, Loss: 18.545229
Val Best Loss: 16.514556
Epoch loss: 18.545229
train phase, Epoch 6/20, Loss: 16.474818
val phase, Epoch 6/20, Loss: 18.749974
Val Best Loss: 16.514556
Epoch loss: 18.749974
train phase, Epoch 7/20, Loss: 16.374065
val phase, Epoch 7/20, Loss: 16.189748
Val Best Loss: 16.189748
Epoch loss: 16.189748
train phase, Epoch 8/20, Loss: 16.034914
val phase, Epoch 8/20, Loss: 16.241865
Val Best Loss: 16.189748
Epoch loss: 16.241865
train phase, Epoch 9/20, Loss: 16.177814
val phase, Epoch 9/20, Loss: 15.908939
Val Best Loss: 15.908939
Epoch loss: 15.908939
train phase, Epoch 10/20, Loss: 15.834050
val phase, Epoch 10/20, Loss: 16.089923
Val Best Loss: 15.908939
Epoch loss: 16.089923
train phase, Epoch 11/20, Loss: 15.660830
val phase, Epoch 11/20, Loss: 16.799332
Val Best Loss: 15.908939
Epoch loss: 16.799332
train phase, Epoch 12/20, Loss: 15.449190
val phase, Epoch 12/20, Loss: 16.379051
Val Best Loss: 15.908939
Epoch loss: 16.379051
train phase, Epoch 13/20, Loss: 15.304458
val phase, Epoch 13/20, Loss: 16.673344
Val Best Loss: 15.908939
Epoch loss: 16.673344
train phase, Epoch 14/20, Loss: 15.292230
val phase, Epoch 14/20, Loss: 16.041678
Val Best Loss: 15.908939
Epoch loss: 16.041678
train phase, Epoch 15/20, Loss: 14.953347
val phase, Epoch 15/20, Loss: 16.321407
Val Best Loss: 15.908939
Epoch loss: 16.321407
train phase, Epoch 16/20, Loss: 14.753896
val phase, Epoch 16/20, Loss: 17.589068
Val Best Loss: 15.908939
Epoch loss: 17.589068
train phase, Epoch 17/20, Loss: 14.666794
val phase, Epoch 17/20, Loss: 16.013263
Val Best Loss: 15.908939
Epoch loss: 16.013263
train phase, Epoch 18/20, Loss: 14.268612
val phase, Epoch 18/20, Loss: 15.747367
Val Best Loss: 15.747367
Epoch loss: 15.747367
train phase, Epoch 19/20, Loss: 14.027627
val phase, Epoch 19/20, Loss: 15.936837
Val Best Loss: 15.747367
Epoch loss: 15.936837
train phase, Epoch 20/20, Loss: 13.830907
val phase, Epoch 20/20, Loss: 17.228889
Val Best Loss: 15.747367
Epoch loss: 17.228889
train phase, Epoch 1/10, Loss: 19.899462
val phase, Epoch 1/10, Loss: 19.398390
Val Best Loss: 19.398390
Epoch loss: 19.398390
train phase, Epoch 2/10, Loss: 17.685587
val phase, Epoch 2/10, Loss: 19.132844
Val Best Loss: 19.132844
Epoch loss: 19.132844
train phase, Epoch 3/10, Loss: 17.235284
val phase, Epoch 3/10, Loss: 16.138117
Val Best Loss: 16.138117
Epoch loss: 16.138117
train phase, Epoch 4/10, Loss: 16.933901
val phase, Epoch 4/10, Loss: 16.358186
Val Best Loss: 16.138117
Epoch loss: 16.358186
train phase, Epoch 5/10, Loss: 16.772526
val phase, Epoch 5/10, Loss: 16.260599
Val Best Loss: 16.138117
Epoch loss: 16.260599
train phase, Epoch 6/10, Loss: 16.588419
val phase, Epoch 6/10, Loss: 17.563510
Val Best Loss: 16.138117
Epoch loss: 17.563510
train phase, Epoch 7/10, Loss: 16.322522
val phase, Epoch 7/10, Loss: 16.442439
Val Best Loss: 16.138117
Epoch loss: 16.442439
train phase, Epoch 8/10, Loss: 16.266320
val phase, Epoch 8/10, Loss: 15.976343
Val Best Loss: 15.976343
Epoch loss: 15.976343
train phase, Epoch 9/10, Loss: 16.149072
val phase, Epoch 9/10, Loss: 19.811569
Val Best Loss: 15.976343
Epoch loss: 19.811569
train phase, Epoch 10/10, Loss: 15.959948
val phase, Epoch 10/10, Loss: 16.349666
Val Best Loss: 15.976343
Epoch loss: 16.349666
train phase, Epoch 1/20, Loss: 20.588419
val phase, Epoch 1/20, Loss: 19.126636
Val Best Loss: 19.126636
Epoch loss: 19.126636
train phase, Epoch 2/20, Loss: 18.285306
val phase, Epoch 2/20, Loss: 17.017795
Val Best Loss: 17.017795
Epoch loss: 17.017795
train phase, Epoch 3/20, Loss: 17.385978
val phase, Epoch 3/20, Loss: 16.562010
Val Best Loss: 16.562010
Epoch loss: 16.562010
train phase, Epoch 4/20, Loss: 16.835507
val phase, Epoch 4/20, Loss: 16.256208
Val Best Loss: 16.256208
Epoch loss: 16.256208
train phase, Epoch 5/20, Loss: 16.863032
val phase, Epoch 5/20, Loss: 16.642487
Val Best Loss: 16.256208
Epoch loss: 16.642487
train phase, Epoch 6/20, Loss: 16.752808
val phase, Epoch 6/20, Loss: 18.850354
Val Best Loss: 16.256208
Epoch loss: 18.850354
train phase, Epoch 7/20, Loss: 16.567542
val phase, Epoch 7/20, Loss: 16.133600
Val Best Loss: 16.133600
Epoch loss: 16.133600
train phase, Epoch 8/20, Loss: 16.501024
val phase, Epoch 8/20, Loss: 16.533589
Val Best Loss: 16.133600
Epoch loss: 16.533589
train phase, Epoch 9/20, Loss: 16.395854
val phase, Epoch 9/20, Loss: 16.535792
Val Best Loss: 16.133600
Epoch loss: 16.535792
train phase, Epoch 10/20, Loss: 16.017816
val phase, Epoch 10/20, Loss: 17.389055
Val Best Loss: 16.133600
Epoch loss: 17.389055
train phase, Epoch 11/20, Loss: 15.882822
val phase, Epoch 11/20, Loss: 16.524142
Val Best Loss: 16.133600
Epoch loss: 16.524142
train phase, Epoch 12/20, Loss: 15.623219
val phase, Epoch 12/20, Loss: 16.090830
Val Best Loss: 16.090830
Epoch loss: 16.090830
train phase, Epoch 13/20, Loss: 15.473892
val phase, Epoch 13/20, Loss: 15.931187
Val Best Loss: 15.931187
Epoch loss: 15.931187
train phase, Epoch 14/20, Loss: 15.333605
val phase, Epoch 14/20, Loss: 16.259524
Val Best Loss: 15.931187
Epoch loss: 16.259524
train phase, Epoch 15/20, Loss: 14.983727
val phase, Epoch 15/20, Loss: 16.250212
Val Best Loss: 15.931187
Epoch loss: 16.250212
train phase, Epoch 16/20, Loss: 14.971317
val phase, Epoch 16/20, Loss: 16.554375
Val Best Loss: 15.931187
Epoch loss: 16.554375
train phase, Epoch 17/20, Loss: 14.789935
val phase, Epoch 17/20, Loss: 16.057706
Val Best Loss: 15.931187
Epoch loss: 16.057706
train phase, Epoch 18/20, Loss: 14.682681
val phase, Epoch 18/20, Loss: 16.282979
Val Best Loss: 15.931187
Epoch loss: 16.282979
train phase, Epoch 19/20, Loss: 14.223827
val phase, Epoch 19/20, Loss: 17.127135
Val Best Loss: 15.931187
Epoch loss: 17.127135
train phase, Epoch 20/20, Loss: 14.019683
val phase, Epoch 20/20, Loss: 16.677961
Val Best Loss: 15.931187
Epoch loss: 16.677961
train phase, Epoch 1/20, Loss: nan
val phase, Epoch 1/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/20, Loss: nan
val phase, Epoch 2/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/20, Loss: nan
val phase, Epoch 3/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/20, Loss: nan
val phase, Epoch 4/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/20, Loss: nan
val phase, Epoch 5/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/20, Loss: nan
val phase, Epoch 6/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/20, Loss: nan
val phase, Epoch 7/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/20, Loss: nan
val phase, Epoch 8/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/20, Loss: nan
val phase, Epoch 9/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/20, Loss: nan
val phase, Epoch 10/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 11/20, Loss: nan
val phase, Epoch 11/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 12/20, Loss: nan
val phase, Epoch 12/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 13/20, Loss: nan
val phase, Epoch 13/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 14/20, Loss: nan
val phase, Epoch 14/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 15/20, Loss: nan
val phase, Epoch 15/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 16/20, Loss: nan
val phase, Epoch 16/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 17/20, Loss: nan
val phase, Epoch 17/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 18/20, Loss: nan
val phase, Epoch 18/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 19/20, Loss: nan
val phase, Epoch 19/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 20/20, Loss: nan
val phase, Epoch 20/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 1/20, Loss: 20.319927
val phase, Epoch 1/20, Loss: 19.940415
Val Best Loss: 19.940415
Epoch loss: 19.940415
train phase, Epoch 2/20, Loss: 18.279004
val phase, Epoch 2/20, Loss: 18.362157
Val Best Loss: 18.362157
Epoch loss: 18.362157
train phase, Epoch 3/20, Loss: 17.413006
val phase, Epoch 3/20, Loss: 17.570005
Val Best Loss: 17.570005
Epoch loss: 17.570005
train phase, Epoch 4/20, Loss: 17.057497
val phase, Epoch 4/20, Loss: 18.826118
Val Best Loss: 17.570005
Epoch loss: 18.826118
train phase, Epoch 5/20, Loss: 16.967649
val phase, Epoch 5/20, Loss: 17.127975
Val Best Loss: 17.127975
Epoch loss: 17.127975
train phase, Epoch 6/20, Loss: 16.865313
val phase, Epoch 6/20, Loss: 16.356313
Val Best Loss: 16.356313
Epoch loss: 16.356313
train phase, Epoch 7/20, Loss: 16.586447
val phase, Epoch 7/20, Loss: 18.011602
Val Best Loss: 16.356313
Epoch loss: 18.011602
train phase, Epoch 8/20, Loss: 16.775467
val phase, Epoch 8/20, Loss: 17.613273
Val Best Loss: 16.356313
Epoch loss: 17.613273
train phase, Epoch 9/20, Loss: 16.207750
val phase, Epoch 9/20, Loss: 17.277711
Val Best Loss: 16.356313
Epoch loss: 17.277711
train phase, Epoch 10/20, Loss: 16.175130
val phase, Epoch 10/20, Loss: 16.733594
Val Best Loss: 16.356313
Epoch loss: 16.733594
train phase, Epoch 11/20, Loss: 16.130987
val phase, Epoch 11/20, Loss: 16.257086
Val Best Loss: 16.257086
Epoch loss: 16.257086
train phase, Epoch 12/20, Loss: 15.868148
val phase, Epoch 12/20, Loss: 16.200790
Val Best Loss: 16.200790
Epoch loss: 16.200790
train phase, Epoch 13/20, Loss: 15.473449
val phase, Epoch 13/20, Loss: 19.455227
Val Best Loss: 16.200790
Epoch loss: 19.455227
train phase, Epoch 14/20, Loss: 15.608277
val phase, Epoch 14/20, Loss: 16.425540
Val Best Loss: 16.200790
Epoch loss: 16.425540
train phase, Epoch 15/20, Loss: 15.507842
val phase, Epoch 15/20, Loss: 17.142224
Val Best Loss: 16.200790
Epoch loss: 17.142224
train phase, Epoch 16/20, Loss: 15.327300
val phase, Epoch 16/20, Loss: 17.586557
Val Best Loss: 16.200790
Epoch loss: 17.586557
train phase, Epoch 17/20, Loss: 15.056512
val phase, Epoch 17/20, Loss: 15.949955
Val Best Loss: 15.949955
Epoch loss: 15.949955
train phase, Epoch 18/20, Loss: 14.751055
val phase, Epoch 18/20, Loss: 16.138396
Val Best Loss: 15.949955
Epoch loss: 16.138396
train phase, Epoch 19/20, Loss: 14.537079
val phase, Epoch 19/20, Loss: 17.166883
Val Best Loss: 15.949955
Epoch loss: 17.166883
train phase, Epoch 20/20, Loss: 14.518146
val phase, Epoch 20/20, Loss: 16.173967
Val Best Loss: 15.949955
Epoch loss: 16.173967
train phase, Epoch 1/30, Loss: 20.159750
val phase, Epoch 1/30, Loss: 18.358081
Val Best Loss: 18.358081
Epoch loss: 18.358081
train phase, Epoch 2/30, Loss: 17.343151
val phase, Epoch 2/30, Loss: 18.390320
Val Best Loss: 18.358081
Epoch loss: 18.390320
train phase, Epoch 3/30, Loss: 16.802116
val phase, Epoch 3/30, Loss: 18.261538
Val Best Loss: 18.261538
Epoch loss: 18.261538
train phase, Epoch 4/30, Loss: 16.693588
val phase, Epoch 4/30, Loss: 16.703549
Val Best Loss: 16.703549
Epoch loss: 16.703549
train phase, Epoch 5/30, Loss: 16.298146
val phase, Epoch 5/30, Loss: 16.235229
Val Best Loss: 16.235229
Epoch loss: 16.235229
train phase, Epoch 6/30, Loss: 16.298237
val phase, Epoch 6/30, Loss: 17.769033
Val Best Loss: 16.235229
Epoch loss: 17.769033
train phase, Epoch 7/30, Loss: 16.216209
val phase, Epoch 7/30, Loss: 19.318974
Val Best Loss: 16.235229
Epoch loss: 19.318974
train phase, Epoch 8/30, Loss: 15.838724
val phase, Epoch 8/30, Loss: 16.431011
Val Best Loss: 16.235229
Epoch loss: 16.431011
train phase, Epoch 9/30, Loss: 15.573625
val phase, Epoch 9/30, Loss: 17.106135
Val Best Loss: 16.235229
Epoch loss: 17.106135
train phase, Epoch 10/30, Loss: 15.476283
val phase, Epoch 10/30, Loss: 16.587007
Val Best Loss: 16.235229
Epoch loss: 16.587007
train phase, Epoch 11/30, Loss: 15.197718
val phase, Epoch 11/30, Loss: 17.023124
Val Best Loss: 16.235229
Epoch loss: 17.023124
train phase, Epoch 12/30, Loss: 14.914625
val phase, Epoch 12/30, Loss: 16.364437
Val Best Loss: 16.235229
Epoch loss: 16.364437
train phase, Epoch 13/30, Loss: 14.886591
val phase, Epoch 13/30, Loss: 16.572720
Val Best Loss: 16.235229
Epoch loss: 16.572720
train phase, Epoch 14/30, Loss: 14.472931
val phase, Epoch 14/30, Loss: 16.540453
Val Best Loss: 16.235229
Epoch loss: 16.540453
train phase, Epoch 15/30, Loss: 13.962559
val phase, Epoch 15/30, Loss: 16.608117
Val Best Loss: 16.235229
Epoch loss: 16.608117
train phase, Epoch 16/30, Loss: 13.805305
val phase, Epoch 16/30, Loss: 17.144893
Val Best Loss: 16.235229
Epoch loss: 17.144893
train phase, Epoch 17/30, Loss: 13.331605
val phase, Epoch 17/30, Loss: 16.708020
Val Best Loss: 16.235229
Epoch loss: 16.708020
train phase, Epoch 18/30, Loss: 12.949919
val phase, Epoch 18/30, Loss: 17.633804
Val Best Loss: 16.235229
Epoch loss: 17.633804
train phase, Epoch 19/30, Loss: 12.677585
val phase, Epoch 19/30, Loss: 17.149021
Val Best Loss: 16.235229
Epoch loss: 17.149021
train phase, Epoch 20/30, Loss: 12.235401
val phase, Epoch 20/30, Loss: 16.882857
Val Best Loss: 16.235229
Epoch loss: 16.882857
train phase, Epoch 21/30, Loss: 11.975785
val phase, Epoch 21/30, Loss: 17.215569
Val Best Loss: 16.235229
Epoch loss: 17.215569
train phase, Epoch 22/30, Loss: 11.112153
val phase, Epoch 22/30, Loss: 19.570376
Val Best Loss: 16.235229
Epoch loss: 19.570376
train phase, Epoch 23/30, Loss: 10.597307
val phase, Epoch 23/30, Loss: 18.580825
Val Best Loss: 16.235229
Epoch loss: 18.580825
train phase, Epoch 24/30, Loss: 10.186719
val phase, Epoch 24/30, Loss: 25.162219
Val Best Loss: 16.235229
Epoch loss: 25.162219
train phase, Epoch 25/30, Loss: 9.597434
val phase, Epoch 25/30, Loss: 19.743685
Val Best Loss: 16.235229
Epoch loss: 19.743685
train phase, Epoch 26/30, Loss: 9.298399
val phase, Epoch 26/30, Loss: 19.115023
Val Best Loss: 16.235229
Epoch loss: 19.115023
train phase, Epoch 27/30, Loss: 9.451752
val phase, Epoch 27/30, Loss: 19.604564
Val Best Loss: 16.235229
Epoch loss: 19.604564
train phase, Epoch 28/30, Loss: 8.179896
val phase, Epoch 28/30, Loss: 19.771381
Val Best Loss: 16.235229
Epoch loss: 19.771381
train phase, Epoch 29/30, Loss: 8.074669
val phase, Epoch 29/30, Loss: 18.836515
Val Best Loss: 16.235229
Epoch loss: 18.836515
train phase, Epoch 30/30, Loss: 7.058446
val phase, Epoch 30/30, Loss: 21.125081
Val Best Loss: 16.235229
Epoch loss: 21.125081
train phase, Epoch 1/20, Loss: 20.012433
val phase, Epoch 1/20, Loss: 17.199385
Val Best Loss: 17.199385
Epoch loss: 17.199385
train phase, Epoch 2/20, Loss: 17.928301
val phase, Epoch 2/20, Loss: 16.761118
Val Best Loss: 16.761118
Epoch loss: 16.761118
train phase, Epoch 3/20, Loss: 17.660562
val phase, Epoch 3/20, Loss: 16.289192
Val Best Loss: 16.289192
Epoch loss: 16.289192
train phase, Epoch 4/20, Loss: 17.196222
val phase, Epoch 4/20, Loss: 16.569828
Val Best Loss: 16.289192
Epoch loss: 16.569828
train phase, Epoch 5/20, Loss: 16.879892
val phase, Epoch 5/20, Loss: 17.170556
Val Best Loss: 16.289192
Epoch loss: 17.170556
train phase, Epoch 6/20, Loss: 16.699908
val phase, Epoch 6/20, Loss: 16.114560
Val Best Loss: 16.114560
Epoch loss: 16.114560
train phase, Epoch 7/20, Loss: 16.663902
val phase, Epoch 7/20, Loss: 17.964933
Val Best Loss: 16.114560
Epoch loss: 17.964933
train phase, Epoch 8/20, Loss: 16.288723
val phase, Epoch 8/20, Loss: 16.308722
Val Best Loss: 16.114560
Epoch loss: 16.308722
train phase, Epoch 9/20, Loss: 16.258497
val phase, Epoch 9/20, Loss: 15.588127
Val Best Loss: 15.588127
Epoch loss: 15.588127
train phase, Epoch 10/20, Loss: 15.966226
val phase, Epoch 10/20, Loss: 16.347806
Val Best Loss: 15.588127
Epoch loss: 16.347806
train phase, Epoch 11/20, Loss: 15.986575
val phase, Epoch 11/20, Loss: 16.076631
Val Best Loss: 15.588127
Epoch loss: 16.076631
train phase, Epoch 12/20, Loss: 15.847520
val phase, Epoch 12/20, Loss: 15.848816
Val Best Loss: 15.588127
Epoch loss: 15.848816
train phase, Epoch 13/20, Loss: 15.715433
val phase, Epoch 13/20, Loss: 16.049215
Val Best Loss: 15.588127
Epoch loss: 16.049215
train phase, Epoch 14/20, Loss: 15.654755
val phase, Epoch 14/20, Loss: 16.847094
Val Best Loss: 15.588127
Epoch loss: 16.847094
train phase, Epoch 15/20, Loss: 15.292310
val phase, Epoch 15/20, Loss: 16.465308
Val Best Loss: 15.588127
Epoch loss: 16.465308
train phase, Epoch 16/20, Loss: 15.021822
val phase, Epoch 16/20, Loss: 17.267061
Val Best Loss: 15.588127
Epoch loss: 17.267061
train phase, Epoch 17/20, Loss: 14.956599
val phase, Epoch 17/20, Loss: 16.992608
Val Best Loss: 15.588127
Epoch loss: 16.992608
train phase, Epoch 18/20, Loss: 14.567784
val phase, Epoch 18/20, Loss: 16.125171
Val Best Loss: 15.588127
Epoch loss: 16.125171
train phase, Epoch 19/20, Loss: 14.473577
val phase, Epoch 19/20, Loss: 16.218931
Val Best Loss: 15.588127
Epoch loss: 16.218931
train phase, Epoch 20/20, Loss: 14.204202
val phase, Epoch 20/20, Loss: 16.099673
Val Best Loss: 15.588127
Epoch loss: 16.099673
train phase, Epoch 1/20, Loss: 20.052751
val phase, Epoch 1/20, Loss: 18.136587
Val Best Loss: 18.136587
Epoch loss: 18.136587
train phase, Epoch 2/20, Loss: 18.039854
val phase, Epoch 2/20, Loss: 16.752387
Val Best Loss: 16.752387
Epoch loss: 16.752387
train phase, Epoch 3/20, Loss: 17.747993
val phase, Epoch 3/20, Loss: 17.260299
Val Best Loss: 16.752387
Epoch loss: 17.260299
train phase, Epoch 4/20, Loss: 17.698074
val phase, Epoch 4/20, Loss: 16.841036
Val Best Loss: 16.752387
Epoch loss: 16.841036
train phase, Epoch 5/20, Loss: 16.825005
val phase, Epoch 5/20, Loss: 16.037308
Val Best Loss: 16.037308
Epoch loss: 16.037308
train phase, Epoch 6/20, Loss: 16.657351
val phase, Epoch 6/20, Loss: 18.390441
Val Best Loss: 16.037308
Epoch loss: 18.390441
train phase, Epoch 7/20, Loss: 16.586865
val phase, Epoch 7/20, Loss: 17.145324
Val Best Loss: 16.037308
Epoch loss: 17.145324
train phase, Epoch 8/20, Loss: 16.696097
val phase, Epoch 8/20, Loss: 16.369029
Val Best Loss: 16.037308
Epoch loss: 16.369029
train phase, Epoch 9/20, Loss: 16.321542
val phase, Epoch 9/20, Loss: 16.171307
Val Best Loss: 16.037308
Epoch loss: 16.171307
train phase, Epoch 10/20, Loss: 16.114477
val phase, Epoch 10/20, Loss: 16.798111
Val Best Loss: 16.037308
Epoch loss: 16.798111
train phase, Epoch 11/20, Loss: 15.874417
val phase, Epoch 11/20, Loss: 16.646075
Val Best Loss: 16.037308
Epoch loss: 16.646075
train phase, Epoch 12/20, Loss: 15.659278
val phase, Epoch 12/20, Loss: 17.896999
Val Best Loss: 16.037308
Epoch loss: 17.896999
train phase, Epoch 13/20, Loss: 15.577874
val phase, Epoch 13/20, Loss: 17.712506
Val Best Loss: 16.037308
Epoch loss: 17.712506
train phase, Epoch 14/20, Loss: 15.692581
val phase, Epoch 14/20, Loss: 17.824750
Val Best Loss: 16.037308
Epoch loss: 17.824750
train phase, Epoch 15/20, Loss: 15.132308
val phase, Epoch 15/20, Loss: 16.071242
Val Best Loss: 16.037308
Epoch loss: 16.071242
train phase, Epoch 16/20, Loss: 15.121632
val phase, Epoch 16/20, Loss: 16.248968
Val Best Loss: 16.037308
Epoch loss: 16.248968
train phase, Epoch 17/20, Loss: 14.737971
val phase, Epoch 17/20, Loss: 16.651293
Val Best Loss: 16.037308
Epoch loss: 16.651293
train phase, Epoch 18/20, Loss: 14.568684
val phase, Epoch 18/20, Loss: 17.474560
Val Best Loss: 16.037308
Epoch loss: 17.474560
train phase, Epoch 19/20, Loss: 14.138675
val phase, Epoch 19/20, Loss: 16.464145
Val Best Loss: 16.037308
Epoch loss: 16.464145
train phase, Epoch 20/20, Loss: 14.050861
val phase, Epoch 20/20, Loss: 16.347094
Val Best Loss: 16.037308
Epoch loss: 16.347094
train phase, Epoch 1/20, Loss: 19.976980
val phase, Epoch 1/20, Loss: 17.147303
Val Best Loss: 17.147303
Epoch loss: 17.147303
train phase, Epoch 2/20, Loss: 18.138259
val phase, Epoch 2/20, Loss: 18.006496
Val Best Loss: 17.147303
Epoch loss: 18.006496
train phase, Epoch 3/20, Loss: 17.510854
val phase, Epoch 3/20, Loss: 17.573202
Val Best Loss: 17.147303
Epoch loss: 17.573202
train phase, Epoch 4/20, Loss: 17.365781
val phase, Epoch 4/20, Loss: 18.698417
Val Best Loss: 17.147303
Epoch loss: 18.698417
train phase, Epoch 5/20, Loss: 17.242244
val phase, Epoch 5/20, Loss: 16.311923
Val Best Loss: 16.311923
Epoch loss: 16.311923
train phase, Epoch 6/20, Loss: 17.043483
val phase, Epoch 6/20, Loss: 16.447409
Val Best Loss: 16.311923
Epoch loss: 16.447409
train phase, Epoch 7/20, Loss: 16.782431
val phase, Epoch 7/20, Loss: 15.936494
Val Best Loss: 15.936494
Epoch loss: 15.936494
train phase, Epoch 8/20, Loss: 16.578117
val phase, Epoch 8/20, Loss: 16.728704
Val Best Loss: 15.936494
Epoch loss: 16.728704
train phase, Epoch 9/20, Loss: 16.113096
val phase, Epoch 9/20, Loss: 16.288875
Val Best Loss: 15.936494
Epoch loss: 16.288875
train phase, Epoch 10/20, Loss: 16.127196
val phase, Epoch 10/20, Loss: 18.224237
Val Best Loss: 15.936494
Epoch loss: 18.224237
train phase, Epoch 11/20, Loss: 15.985650
val phase, Epoch 11/20, Loss: 16.080565
Val Best Loss: 15.936494
Epoch loss: 16.080565
train phase, Epoch 12/20, Loss: 15.901800
val phase, Epoch 12/20, Loss: 17.311619
Val Best Loss: 15.936494
Epoch loss: 17.311619
train phase, Epoch 13/20, Loss: 15.834871
val phase, Epoch 13/20, Loss: 16.000281
Val Best Loss: 15.936494
Epoch loss: 16.000281
train phase, Epoch 14/20, Loss: 15.797931
val phase, Epoch 14/20, Loss: 16.033238
Val Best Loss: 15.936494
Epoch loss: 16.033238
train phase, Epoch 15/20, Loss: 15.304486
val phase, Epoch 15/20, Loss: 16.321712
Val Best Loss: 15.936494
Epoch loss: 16.321712
train phase, Epoch 16/20, Loss: 15.110393
val phase, Epoch 16/20, Loss: 15.963326
Val Best Loss: 15.936494
Epoch loss: 15.963326
train phase, Epoch 17/20, Loss: 15.250019
val phase, Epoch 17/20, Loss: 17.366513
Val Best Loss: 15.936494
Epoch loss: 17.366513
train phase, Epoch 18/20, Loss: 14.956840
val phase, Epoch 18/20, Loss: 16.253455
Val Best Loss: 15.936494
Epoch loss: 16.253455
train phase, Epoch 19/20, Loss: 14.558992
val phase, Epoch 19/20, Loss: 17.483713
Val Best Loss: 15.936494
Epoch loss: 17.483713
train phase, Epoch 20/20, Loss: 14.790700
val phase, Epoch 20/20, Loss: 16.713247
Val Best Loss: 15.936494
Epoch loss: 16.713247
train phase, Epoch 1/20, Loss: 19.664094
val phase, Epoch 1/20, Loss: 17.434475
Val Best Loss: 17.434475
Epoch loss: 17.434475
train phase, Epoch 2/20, Loss: 17.964315
val phase, Epoch 2/20, Loss: 19.243757
Val Best Loss: 17.434475
Epoch loss: 19.243757
train phase, Epoch 3/20, Loss: 17.685143
val phase, Epoch 3/20, Loss: 18.501855
Val Best Loss: 17.434475
Epoch loss: 18.501855
train phase, Epoch 4/20, Loss: 17.268626
val phase, Epoch 4/20, Loss: 16.652045
Val Best Loss: 16.652045
Epoch loss: 16.652045
train phase, Epoch 5/20, Loss: 16.982721
val phase, Epoch 5/20, Loss: 17.306179
Val Best Loss: 16.652045
Epoch loss: 17.306179
train phase, Epoch 6/20, Loss: 16.726535
val phase, Epoch 6/20, Loss: 16.355846
Val Best Loss: 16.355846
Epoch loss: 16.355846
train phase, Epoch 7/20, Loss: 16.645416
val phase, Epoch 7/20, Loss: 16.944194
Val Best Loss: 16.355846
Epoch loss: 16.944194
train phase, Epoch 8/20, Loss: 16.314164
val phase, Epoch 8/20, Loss: 16.020906
Val Best Loss: 16.020906
Epoch loss: 16.020906
train phase, Epoch 9/20, Loss: 16.017414
val phase, Epoch 9/20, Loss: 16.581375
Val Best Loss: 16.020906
Epoch loss: 16.581375
train phase, Epoch 10/20, Loss: 16.299438
val phase, Epoch 10/20, Loss: 16.961573
Val Best Loss: 16.020906
Epoch loss: 16.961573
train phase, Epoch 11/20, Loss: 16.122073
val phase, Epoch 11/20, Loss: 17.878574
Val Best Loss: 16.020906
Epoch loss: 17.878574
train phase, Epoch 12/20, Loss: 16.013262
val phase, Epoch 12/20, Loss: 16.977162
Val Best Loss: 16.020906
Epoch loss: 16.977162
train phase, Epoch 13/20, Loss: 15.758640
val phase, Epoch 13/20, Loss: 16.348249
Val Best Loss: 16.020906
Epoch loss: 16.348249
train phase, Epoch 14/20, Loss: 15.487872
val phase, Epoch 14/20, Loss: 15.897840
Val Best Loss: 15.897840
Epoch loss: 15.897840
train phase, Epoch 15/20, Loss: 15.469661
val phase, Epoch 15/20, Loss: 17.658203
Val Best Loss: 15.897840
Epoch loss: 17.658203
train phase, Epoch 16/20, Loss: 15.092328
val phase, Epoch 16/20, Loss: 16.786674
Val Best Loss: 15.897840
Epoch loss: 16.786674
train phase, Epoch 17/20, Loss: 15.017550
val phase, Epoch 17/20, Loss: 17.972514
Val Best Loss: 15.897840
Epoch loss: 17.972514
train phase, Epoch 18/20, Loss: 15.027299
val phase, Epoch 18/20, Loss: 16.516385
Val Best Loss: 15.897840
Epoch loss: 16.516385
train phase, Epoch 19/20, Loss: 14.409013
val phase, Epoch 19/20, Loss: 16.690409
Val Best Loss: 15.897840
Epoch loss: 16.690409
train phase, Epoch 20/20, Loss: 14.359892
val phase, Epoch 20/20, Loss: 16.091258
Val Best Loss: 15.897840
Epoch loss: 16.091258
train phase, Epoch 1/20, Loss: 19.782291
val phase, Epoch 1/20, Loss: 20.780764
Val Best Loss: 20.780764
Epoch loss: 20.780764
train phase, Epoch 2/20, Loss: 18.058337
val phase, Epoch 2/20, Loss: 17.478492
Val Best Loss: 17.478492
Epoch loss: 17.478492
train phase, Epoch 3/20, Loss: 17.381960
val phase, Epoch 3/20, Loss: 16.614944
Val Best Loss: 16.614944
Epoch loss: 16.614944
train phase, Epoch 4/20, Loss: 17.216910
val phase, Epoch 4/20, Loss: 16.688682
Val Best Loss: 16.614944
Epoch loss: 16.688682
train phase, Epoch 5/20, Loss: 16.762270
val phase, Epoch 5/20, Loss: 17.106270
Val Best Loss: 16.614944
Epoch loss: 17.106270
train phase, Epoch 6/20, Loss: 16.582109
val phase, Epoch 6/20, Loss: 17.459323
Val Best Loss: 16.614944
Epoch loss: 17.459323
train phase, Epoch 7/20, Loss: 16.727282
val phase, Epoch 7/20, Loss: 16.189605
Val Best Loss: 16.189605
Epoch loss: 16.189605
train phase, Epoch 8/20, Loss: 16.366644
val phase, Epoch 8/20, Loss: 16.792063
Val Best Loss: 16.189605
Epoch loss: 16.792063
train phase, Epoch 9/20, Loss: 16.288478
val phase, Epoch 9/20, Loss: 16.601865
Val Best Loss: 16.189605
Epoch loss: 16.601865
train phase, Epoch 10/20, Loss: 16.387931
val phase, Epoch 10/20, Loss: 15.884052
Val Best Loss: 15.884052
Epoch loss: 15.884052
train phase, Epoch 11/20, Loss: 15.832879
val phase, Epoch 11/20, Loss: 16.379061
Val Best Loss: 15.884052
Epoch loss: 16.379061
train phase, Epoch 12/20, Loss: 15.882882
val phase, Epoch 12/20, Loss: 16.407775
Val Best Loss: 15.884052
Epoch loss: 16.407775
train phase, Epoch 13/20, Loss: 15.614069
val phase, Epoch 13/20, Loss: 16.134933
Val Best Loss: 15.884052
Epoch loss: 16.134933
train phase, Epoch 14/20, Loss: 15.385366
val phase, Epoch 14/20, Loss: 17.272458
Val Best Loss: 15.884052
Epoch loss: 17.272458
train phase, Epoch 15/20, Loss: 15.156280
val phase, Epoch 15/20, Loss: 16.715488
Val Best Loss: 15.884052
Epoch loss: 16.715488
train phase, Epoch 16/20, Loss: 14.901346
val phase, Epoch 16/20, Loss: 17.174644
Val Best Loss: 15.884052
Epoch loss: 17.174644
train phase, Epoch 17/20, Loss: 15.149704
val phase, Epoch 17/20, Loss: 16.237959
Val Best Loss: 15.884052
Epoch loss: 16.237959
train phase, Epoch 18/20, Loss: 14.792380
val phase, Epoch 18/20, Loss: 16.780722
Val Best Loss: 15.884052
Epoch loss: 16.780722
train phase, Epoch 19/20, Loss: 14.351194
val phase, Epoch 19/20, Loss: 16.073667
Val Best Loss: 15.884052
Epoch loss: 16.073667
train phase, Epoch 20/20, Loss: 14.179490
val phase, Epoch 20/20, Loss: 16.522744
Val Best Loss: 15.884052
Epoch loss: 16.522744
train phase, Epoch 1/20, Loss: 20.099333
val phase, Epoch 1/20, Loss: 17.157380
Val Best Loss: 17.157380
Epoch loss: 17.157380
train phase, Epoch 2/20, Loss: 18.143549
val phase, Epoch 2/20, Loss: 19.894852
Val Best Loss: 17.157380
Epoch loss: 19.894852
train phase, Epoch 3/20, Loss: 17.726608
val phase, Epoch 3/20, Loss: 16.914489
Val Best Loss: 16.914489
Epoch loss: 16.914489
train phase, Epoch 4/20, Loss: 17.358354
val phase, Epoch 4/20, Loss: 17.055514
Val Best Loss: 16.914489
Epoch loss: 17.055514
train phase, Epoch 5/20, Loss: 17.177744
val phase, Epoch 5/20, Loss: 17.351556
Val Best Loss: 16.914489
Epoch loss: 17.351556
train phase, Epoch 6/20, Loss: 16.994280
val phase, Epoch 6/20, Loss: 17.344672
Val Best Loss: 16.914489
Epoch loss: 17.344672
train phase, Epoch 7/20, Loss: 16.634643
val phase, Epoch 7/20, Loss: 16.071623
Val Best Loss: 16.071623
Epoch loss: 16.071623
train phase, Epoch 8/20, Loss: 16.492864
val phase, Epoch 8/20, Loss: 16.865174
Val Best Loss: 16.071623
Epoch loss: 16.865174
train phase, Epoch 9/20, Loss: 16.383703
val phase, Epoch 9/20, Loss: 17.323985
Val Best Loss: 16.071623
Epoch loss: 17.323985
train phase, Epoch 10/20, Loss: 16.319136
val phase, Epoch 10/20, Loss: 16.211456
Val Best Loss: 16.071623
Epoch loss: 16.211456
train phase, Epoch 11/20, Loss: 15.996843
val phase, Epoch 11/20, Loss: 19.959050
Val Best Loss: 16.071623
Epoch loss: 19.959050
train phase, Epoch 12/20, Loss: 16.091632
val phase, Epoch 12/20, Loss: 16.588085
Val Best Loss: 16.071623
Epoch loss: 16.588085
train phase, Epoch 13/20, Loss: 16.036207
val phase, Epoch 13/20, Loss: 16.400486
Val Best Loss: 16.071623
Epoch loss: 16.400486
train phase, Epoch 14/20, Loss: 15.609528
val phase, Epoch 14/20, Loss: 16.045438
Val Best Loss: 16.045438
Epoch loss: 16.045438
train phase, Epoch 15/20, Loss: 15.295887
val phase, Epoch 15/20, Loss: 18.757852
Val Best Loss: 16.045438
Epoch loss: 18.757852
train phase, Epoch 16/20, Loss: 15.440924
val phase, Epoch 16/20, Loss: 16.078338
Val Best Loss: 16.045438
Epoch loss: 16.078338
train phase, Epoch 17/20, Loss: 14.932149
val phase, Epoch 17/20, Loss: 15.931856
Val Best Loss: 15.931856
Epoch loss: 15.931856
train phase, Epoch 18/20, Loss: 14.833671
val phase, Epoch 18/20, Loss: 15.687922
Val Best Loss: 15.687922
Epoch loss: 15.687922
train phase, Epoch 19/20, Loss: 14.501920
val phase, Epoch 19/20, Loss: 17.268557
Val Best Loss: 15.687922
Epoch loss: 17.268557
train phase, Epoch 20/20, Loss: 14.399022
val phase, Epoch 20/20, Loss: 16.345630
Val Best Loss: 15.687922
Epoch loss: 16.345630
train phase, Epoch 1/20, Loss: 20.679865
val phase, Epoch 1/20, Loss: 17.917320
Val Best Loss: 17.917320
Epoch loss: 17.917320
train phase, Epoch 2/20, Loss: 18.269361
val phase, Epoch 2/20, Loss: 22.233958
Val Best Loss: 17.917320
Epoch loss: 22.233958
train phase, Epoch 3/20, Loss: 17.862046
val phase, Epoch 3/20, Loss: 18.601500
Val Best Loss: 17.917320
Epoch loss: 18.601500
train phase, Epoch 4/20, Loss: 17.042290
val phase, Epoch 4/20, Loss: 16.925259
Val Best Loss: 16.925259
Epoch loss: 16.925259
train phase, Epoch 5/20, Loss: 17.148110
val phase, Epoch 5/20, Loss: 16.750073
Val Best Loss: 16.750073
Epoch loss: 16.750073
train phase, Epoch 6/20, Loss: 16.571032
val phase, Epoch 6/20, Loss: 16.852953
Val Best Loss: 16.750073
Epoch loss: 16.852953
train phase, Epoch 7/20, Loss: 16.911340
val phase, Epoch 7/20, Loss: 16.936487
Val Best Loss: 16.750073
Epoch loss: 16.936487
train phase, Epoch 8/20, Loss: 16.307866
val phase, Epoch 8/20, Loss: 16.199152
Val Best Loss: 16.199152
Epoch loss: 16.199152
train phase, Epoch 9/20, Loss: 16.131393
val phase, Epoch 9/20, Loss: 16.460548
Val Best Loss: 16.199152
Epoch loss: 16.460548
train phase, Epoch 10/20, Loss: 16.282666
val phase, Epoch 10/20, Loss: 16.630600
Val Best Loss: 16.199152
Epoch loss: 16.630600
train phase, Epoch 11/20, Loss: 15.995953
val phase, Epoch 11/20, Loss: 15.964846
Val Best Loss: 15.964846
Epoch loss: 15.964846
train phase, Epoch 12/20, Loss: 15.788144
val phase, Epoch 12/20, Loss: 15.780782
Val Best Loss: 15.780782
Epoch loss: 15.780782
train phase, Epoch 13/20, Loss: 15.437230
val phase, Epoch 13/20, Loss: 17.059374
Val Best Loss: 15.780782
Epoch loss: 17.059374
train phase, Epoch 14/20, Loss: 15.717146
val phase, Epoch 14/20, Loss: 16.472410
Val Best Loss: 15.780782
Epoch loss: 16.472410
train phase, Epoch 15/20, Loss: 15.232921
val phase, Epoch 15/20, Loss: 16.423099
Val Best Loss: 15.780782
Epoch loss: 16.423099
train phase, Epoch 16/20, Loss: 15.242922
val phase, Epoch 16/20, Loss: 16.413070
Val Best Loss: 15.780782
Epoch loss: 16.413070
train phase, Epoch 17/20, Loss: 15.121948
val phase, Epoch 17/20, Loss: 16.373845
Val Best Loss: 15.780782
Epoch loss: 16.373845
train phase, Epoch 18/20, Loss: 14.574301
val phase, Epoch 18/20, Loss: 17.282168
Val Best Loss: 15.780782
Epoch loss: 17.282168
train phase, Epoch 19/20, Loss: 14.352125
val phase, Epoch 19/20, Loss: 16.667861
Val Best Loss: 15.780782
Epoch loss: 16.667861
train phase, Epoch 20/20, Loss: 14.141225
val phase, Epoch 20/20, Loss: 16.507178
Val Best Loss: 15.780782
Epoch loss: 16.507178
train phase, Epoch 1/30, Loss: 34.724509
val phase, Epoch 1/30, Loss: 20.471566
Val Best Loss: 20.471566
Epoch loss: 20.471566
train phase, Epoch 2/30, Loss: 19.442528
val phase, Epoch 2/30, Loss: 20.154844
Val Best Loss: 20.154844
Epoch loss: 20.154844
train phase, Epoch 3/30, Loss: 19.187580
val phase, Epoch 3/30, Loss: 18.423236
Val Best Loss: 18.423236
Epoch loss: 18.423236
train phase, Epoch 4/30, Loss: 18.843765
val phase, Epoch 4/30, Loss: 19.005521
Val Best Loss: 18.423236
Epoch loss: 19.005521
train phase, Epoch 5/30, Loss: 18.772559
val phase, Epoch 5/30, Loss: 25.625569
Val Best Loss: 18.423236
Epoch loss: 25.625569
train phase, Epoch 6/30, Loss: 18.767014
val phase, Epoch 6/30, Loss: 17.951830
Val Best Loss: 17.951830
Epoch loss: 17.951830
train phase, Epoch 7/30, Loss: 18.867748
val phase, Epoch 7/30, Loss: 18.628501
Val Best Loss: 17.951830
Epoch loss: 18.628501
train phase, Epoch 8/30, Loss: 18.580135
val phase, Epoch 8/30, Loss: 18.299915
Val Best Loss: 17.951830
Epoch loss: 18.299915
train phase, Epoch 9/30, Loss: 18.192401
val phase, Epoch 9/30, Loss: 18.111122
Val Best Loss: 17.951830
Epoch loss: 18.111122
train phase, Epoch 10/30, Loss: 18.284898
val phase, Epoch 10/30, Loss: 18.254733
Val Best Loss: 17.951830
Epoch loss: 18.254733
train phase, Epoch 11/30, Loss: 18.275790
val phase, Epoch 11/30, Loss: 18.537353
Val Best Loss: 17.951830
Epoch loss: 18.537353
train phase, Epoch 12/30, Loss: 18.482034
val phase, Epoch 12/30, Loss: 22.990550
Val Best Loss: 17.951830
Epoch loss: 22.990550
train phase, Epoch 13/30, Loss: 17.745697
val phase, Epoch 13/30, Loss: 18.577671
Val Best Loss: 17.951830
Epoch loss: 18.577671
train phase, Epoch 14/30, Loss: 18.048921
val phase, Epoch 14/30, Loss: 19.255030
Val Best Loss: 17.951830
Epoch loss: 19.255030
train phase, Epoch 15/30, Loss: 18.340135
val phase, Epoch 15/30, Loss: 18.540152
Val Best Loss: 17.951830
Epoch loss: 18.540152
train phase, Epoch 16/30, Loss: 17.968216
val phase, Epoch 16/30, Loss: 18.107395
Val Best Loss: 17.951830
Epoch loss: 18.107395
train phase, Epoch 17/30, Loss: 586.846710
val phase, Epoch 17/30, Loss: 57.675120
Val Best Loss: 17.951830
Epoch loss: 57.675120
train phase, Epoch 18/30, Loss: 37.120685
val phase, Epoch 18/30, Loss: 48.970032
Val Best Loss: 17.951830
Epoch loss: 48.970032
train phase, Epoch 19/30, Loss: 28.607968
val phase, Epoch 19/30, Loss: 34.800127
Val Best Loss: 17.951830
Epoch loss: 34.800127
train phase, Epoch 20/30, Loss: 28.894232
val phase, Epoch 20/30, Loss: 85.702590
Val Best Loss: 17.951830
Epoch loss: 85.702590
train phase, Epoch 21/30, Loss: 29.746173
val phase, Epoch 21/30, Loss: 26.524194
Val Best Loss: 17.951830
Epoch loss: 26.524194
train phase, Epoch 22/30, Loss: 24.551042
val phase, Epoch 22/30, Loss: 25.488258
Val Best Loss: 17.951830
Epoch loss: 25.488258
train phase, Epoch 23/30, Loss: 23.976930
val phase, Epoch 23/30, Loss: 34.315563
Val Best Loss: 17.951830
Epoch loss: 34.315563
train phase, Epoch 24/30, Loss: 24.147846
val phase, Epoch 24/30, Loss: 28.083814
Val Best Loss: 17.951830
Epoch loss: 28.083814
train phase, Epoch 25/30, Loss: 24.467289
val phase, Epoch 25/30, Loss: 25.238019
Val Best Loss: 17.951830
Epoch loss: 25.238019
train phase, Epoch 26/30, Loss: 23.152640
val phase, Epoch 26/30, Loss: 24.693651
Val Best Loss: 17.951830
Epoch loss: 24.693651
train phase, Epoch 27/30, Loss: 22.771648
val phase, Epoch 27/30, Loss: 26.464387
Val Best Loss: 17.951830
Epoch loss: 26.464387
train phase, Epoch 28/30, Loss: 21.831349
val phase, Epoch 28/30, Loss: 23.786468
Val Best Loss: 17.951830
Epoch loss: 23.786468
train phase, Epoch 29/30, Loss: 22.117341
val phase, Epoch 29/30, Loss: 23.262338
Val Best Loss: 17.951830
Epoch loss: 23.262338
train phase, Epoch 30/30, Loss: 21.492401
val phase, Epoch 30/30, Loss: 22.862282
Val Best Loss: 17.951830
Epoch loss: 22.862282
train phase, Epoch 1/20, Loss: 20.323697
val phase, Epoch 1/20, Loss: 17.375433
Val Best Loss: 17.375433
Epoch loss: 17.375433
train phase, Epoch 2/20, Loss: 18.300695
val phase, Epoch 2/20, Loss: 19.123852
Val Best Loss: 17.375433
Epoch loss: 19.123852
train phase, Epoch 3/20, Loss: 17.670611
val phase, Epoch 3/20, Loss: 16.671459
Val Best Loss: 16.671459
Epoch loss: 16.671459
train phase, Epoch 4/20, Loss: 17.629113
val phase, Epoch 4/20, Loss: 19.605407
Val Best Loss: 16.671459
Epoch loss: 19.605407
train phase, Epoch 5/20, Loss: 17.209963
val phase, Epoch 5/20, Loss: 19.702770
Val Best Loss: 16.671459
Epoch loss: 19.702770
train phase, Epoch 6/20, Loss: 16.804242
val phase, Epoch 6/20, Loss: 16.211228
Val Best Loss: 16.211228
Epoch loss: 16.211228
train phase, Epoch 7/20, Loss: 16.985363
val phase, Epoch 7/20, Loss: 18.425797
Val Best Loss: 16.211228
Epoch loss: 18.425797
train phase, Epoch 8/20, Loss: 16.828028
val phase, Epoch 8/20, Loss: 16.386907
Val Best Loss: 16.211228
Epoch loss: 16.386907
train phase, Epoch 9/20, Loss: 16.848266
val phase, Epoch 9/20, Loss: 16.365180
Val Best Loss: 16.211228
Epoch loss: 16.365180
train phase, Epoch 10/20, Loss: 16.338912
val phase, Epoch 10/20, Loss: 16.089915
Val Best Loss: 16.089915
Epoch loss: 16.089915
train phase, Epoch 11/20, Loss: 16.463794
val phase, Epoch 11/20, Loss: 16.217009
Val Best Loss: 16.089915
Epoch loss: 16.217009
train phase, Epoch 12/20, Loss: 16.070775
val phase, Epoch 12/20, Loss: 16.905959
Val Best Loss: 16.089915
Epoch loss: 16.905959
train phase, Epoch 13/20, Loss: 15.870386
val phase, Epoch 13/20, Loss: 15.962399
Val Best Loss: 15.962399
Epoch loss: 15.962399
train phase, Epoch 14/20, Loss: 15.855335
val phase, Epoch 14/20, Loss: 15.876901
Val Best Loss: 15.876901
Epoch loss: 15.876901
train phase, Epoch 15/20, Loss: 15.593041
val phase, Epoch 15/20, Loss: 16.342030
Val Best Loss: 15.876901
Epoch loss: 16.342030
train phase, Epoch 16/20, Loss: 15.539317
val phase, Epoch 16/20, Loss: 17.159689
Val Best Loss: 15.876901
Epoch loss: 17.159689
train phase, Epoch 17/20, Loss: 15.445010
val phase, Epoch 17/20, Loss: 16.527780
Val Best Loss: 15.876901
Epoch loss: 16.527780
train phase, Epoch 18/20, Loss: 15.177077
val phase, Epoch 18/20, Loss: 17.626089
Val Best Loss: 15.876901
Epoch loss: 17.626089
train phase, Epoch 19/20, Loss: 14.964046
val phase, Epoch 19/20, Loss: 18.171845
Val Best Loss: 15.876901
Epoch loss: 18.171845
train phase, Epoch 20/20, Loss: 14.715489
val phase, Epoch 20/20, Loss: 16.770579
Val Best Loss: 15.876901
Epoch loss: 16.770579
[Trial 229] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 20.505552
val phase, Epoch 1/30, Loss: 28.405593
Val Best Loss: 28.405593
Epoch loss: 28.405593
train phase, Epoch 2/30, Loss: 18.527449
val phase, Epoch 2/30, Loss: 32.106282
Val Best Loss: 28.405593
Epoch loss: 32.106282
train phase, Epoch 3/30, Loss: 17.585318
val phase, Epoch 3/30, Loss: 31.870375
Val Best Loss: 28.405593
Epoch loss: 31.870375
train phase, Epoch 4/30, Loss: 17.148532
val phase, Epoch 4/30, Loss: 34.426817
Val Best Loss: 28.405593
Epoch loss: 34.426817
train phase, Epoch 5/30, Loss: 17.417101
val phase, Epoch 5/30, Loss: 32.734222
Val Best Loss: 28.405593
Epoch loss: 32.734222
train phase, Epoch 6/30, Loss: 16.679203
val phase, Epoch 6/30, Loss: 40.047158
Val Best Loss: 28.405593
Epoch loss: 40.047158
train phase, Epoch 7/30, Loss: 16.646508
val phase, Epoch 7/30, Loss: 37.032592
Val Best Loss: 28.405593
Epoch loss: 37.032592
train phase, Epoch 8/30, Loss: 16.580432
val phase, Epoch 8/30, Loss: 41.401270
Val Best Loss: 28.405593
Epoch loss: 41.401270
train phase, Epoch 9/30, Loss: 16.473927
val phase, Epoch 9/30, Loss: 51.933557
Val Best Loss: 28.405593
Epoch loss: 51.933557
train phase, Epoch 10/30, Loss: 16.087859
val phase, Epoch 10/30, Loss: 46.180637
Val Best Loss: 28.405593
Epoch loss: 46.180637
train phase, Epoch 11/30, Loss: 16.064083
val phase, Epoch 11/30, Loss: 46.441156
Val Best Loss: 28.405593
Epoch loss: 46.441156
train phase, Epoch 12/30, Loss: 15.874941
val phase, Epoch 12/30, Loss: 59.561591
Val Best Loss: 28.405593
Epoch loss: 59.561591
train phase, Epoch 13/30, Loss: 16.035950
val phase, Epoch 13/30, Loss: 37.392833
Val Best Loss: 28.405593
Epoch loss: 37.392833
train phase, Epoch 14/30, Loss: 15.670865
val phase, Epoch 14/30, Loss: 59.995464
Val Best Loss: 28.405593
Epoch loss: 59.995464
train phase, Epoch 15/30, Loss: 15.565357
val phase, Epoch 15/30, Loss: 68.746341
Val Best Loss: 28.405593
Epoch loss: 68.746341
train phase, Epoch 16/30, Loss: 15.475161
val phase, Epoch 16/30, Loss: 55.640018
Val Best Loss: 28.405593
Epoch loss: 55.640018
train phase, Epoch 17/30, Loss: 15.113763
val phase, Epoch 17/30, Loss: 66.392779
Val Best Loss: 28.405593
Epoch loss: 66.392779
train phase, Epoch 18/30, Loss: 15.257450
val phase, Epoch 18/30, Loss: 54.618274
Val Best Loss: 28.405593
Epoch loss: 54.618274
train phase, Epoch 19/30, Loss: 14.820871
val phase, Epoch 19/30, Loss: 70.223441
Val Best Loss: 28.405593
Epoch loss: 70.223441
train phase, Epoch 20/30, Loss: 14.615691
val phase, Epoch 20/30, Loss: 90.905045
Val Best Loss: 28.405593
Epoch loss: 90.905045
train phase, Epoch 21/30, Loss: 14.297954
val phase, Epoch 21/30, Loss: 90.920883
Val Best Loss: 28.405593
Epoch loss: 90.920883
train phase, Epoch 22/30, Loss: 14.403101
val phase, Epoch 22/30, Loss: 101.164942
Val Best Loss: 28.405593
Epoch loss: 101.164942
train phase, Epoch 23/30, Loss: 13.895039
val phase, Epoch 23/30, Loss: 88.573542
Val Best Loss: 28.405593
Epoch loss: 88.573542
train phase, Epoch 24/30, Loss: 13.517238
val phase, Epoch 24/30, Loss: 76.364833
Val Best Loss: 28.405593
Epoch loss: 76.364833
train phase, Epoch 25/30, Loss: 13.397911
val phase, Epoch 25/30, Loss: 100.028033
Val Best Loss: 28.405593
Epoch loss: 100.028033
train phase, Epoch 26/30, Loss: 12.861096
val phase, Epoch 26/30, Loss: 73.790606
Val Best Loss: 28.405593
Epoch loss: 73.790606
train phase, Epoch 27/30, Loss: 12.664974
val phase, Epoch 27/30, Loss: 93.159233
Val Best Loss: 28.405593
Epoch loss: 93.159233
train phase, Epoch 28/30, Loss: 12.370530
val phase, Epoch 28/30, Loss: 113.676909
Val Best Loss: 28.405593
Epoch loss: 113.676909
train phase, Epoch 29/30, Loss: 11.914261
val phase, Epoch 29/30, Loss: 89.321895
Val Best Loss: 28.405593
Epoch loss: 89.321895
train phase, Epoch 30/30, Loss: 11.487446
val phase, Epoch 30/30, Loss: 80.357039
Val Best Loss: 28.405593
Epoch loss: 80.357039
train phase, Epoch 1/20, Loss: 20.520309
val phase, Epoch 1/20, Loss: 23.351242
Val Best Loss: 23.351242
Epoch loss: 23.351242
train phase, Epoch 2/20, Loss: 17.753719
val phase, Epoch 2/20, Loss: 17.209210
Val Best Loss: 17.209210
Epoch loss: 17.209210
train phase, Epoch 3/20, Loss: 17.440384
val phase, Epoch 3/20, Loss: 17.308000
Val Best Loss: 17.209210
Epoch loss: 17.308000
train phase, Epoch 4/20, Loss: 16.952846
val phase, Epoch 4/20, Loss: 17.058121
Val Best Loss: 17.058121
Epoch loss: 17.058121
train phase, Epoch 5/20, Loss: 17.056031
val phase, Epoch 5/20, Loss: 16.773527
Val Best Loss: 16.773527
Epoch loss: 16.773527
train phase, Epoch 6/20, Loss: 16.657451
val phase, Epoch 6/20, Loss: 16.351480
Val Best Loss: 16.351480
Epoch loss: 16.351480
train phase, Epoch 7/20, Loss: 16.313529
val phase, Epoch 7/20, Loss: 15.863295
Val Best Loss: 15.863295
Epoch loss: 15.863295
train phase, Epoch 8/20, Loss: 16.328260
val phase, Epoch 8/20, Loss: 18.192754
Val Best Loss: 15.863295
Epoch loss: 18.192754
train phase, Epoch 9/20, Loss: 16.071021
val phase, Epoch 9/20, Loss: 16.168317
Val Best Loss: 15.863295
Epoch loss: 16.168317
train phase, Epoch 10/20, Loss: 15.833578
val phase, Epoch 10/20, Loss: 16.273081
Val Best Loss: 15.863295
Epoch loss: 16.273081
train phase, Epoch 11/20, Loss: 15.851252
val phase, Epoch 11/20, Loss: 16.458141
Val Best Loss: 15.863295
Epoch loss: 16.458141
train phase, Epoch 12/20, Loss: 15.526387
val phase, Epoch 12/20, Loss: 16.036450
Val Best Loss: 15.863295
Epoch loss: 16.036450
train phase, Epoch 13/20, Loss: 15.305049
val phase, Epoch 13/20, Loss: 16.502696
Val Best Loss: 15.863295
Epoch loss: 16.502696
train phase, Epoch 14/20, Loss: 15.218527
val phase, Epoch 14/20, Loss: 15.683479
Val Best Loss: 15.683479
Epoch loss: 15.683479
train phase, Epoch 15/20, Loss: 15.108481
val phase, Epoch 15/20, Loss: 16.042626
Val Best Loss: 15.683479
Epoch loss: 16.042626
train phase, Epoch 16/20, Loss: 14.930747
val phase, Epoch 16/20, Loss: 16.331910
Val Best Loss: 15.683479
Epoch loss: 16.331910
train phase, Epoch 17/20, Loss: 14.736491
val phase, Epoch 17/20, Loss: 16.061211
Val Best Loss: 15.683479
Epoch loss: 16.061211
train phase, Epoch 18/20, Loss: 14.280507
val phase, Epoch 18/20, Loss: 16.093589
Val Best Loss: 15.683479
Epoch loss: 16.093589
train phase, Epoch 19/20, Loss: 14.267043
val phase, Epoch 19/20, Loss: 16.783076
Val Best Loss: 15.683479
Epoch loss: 16.783076
train phase, Epoch 20/20, Loss: 13.868583
val phase, Epoch 20/20, Loss: 16.705488
Val Best Loss: 15.683479
Epoch loss: 16.705488
train phase, Epoch 1/20, Loss: 19.713559
val phase, Epoch 1/20, Loss: 19.927280
Val Best Loss: 19.927280
Epoch loss: 19.927280
train phase, Epoch 2/20, Loss: 17.582204
val phase, Epoch 2/20, Loss: 17.128033
Val Best Loss: 17.128033
Epoch loss: 17.128033
train phase, Epoch 3/20, Loss: 17.175359
val phase, Epoch 3/20, Loss: 16.801854
Val Best Loss: 16.801854
Epoch loss: 16.801854
train phase, Epoch 4/20, Loss: 16.982428
val phase, Epoch 4/20, Loss: 17.022429
Val Best Loss: 16.801854
Epoch loss: 17.022429
train phase, Epoch 5/20, Loss: 16.907671
val phase, Epoch 5/20, Loss: 16.578366
Val Best Loss: 16.578366
Epoch loss: 16.578366
train phase, Epoch 6/20, Loss: 16.431602
val phase, Epoch 6/20, Loss: 16.615787
Val Best Loss: 16.578366
Epoch loss: 16.615787
train phase, Epoch 7/20, Loss: 16.351713
val phase, Epoch 7/20, Loss: 17.895575
Val Best Loss: 16.578366
Epoch loss: 17.895575
train phase, Epoch 8/20, Loss: 16.083459
val phase, Epoch 8/20, Loss: 15.818565
Val Best Loss: 15.818565
Epoch loss: 15.818565
train phase, Epoch 9/20, Loss: 15.991879
val phase, Epoch 9/20, Loss: 16.354577
Val Best Loss: 15.818565
Epoch loss: 16.354577
train phase, Epoch 10/20, Loss: 15.783869
val phase, Epoch 10/20, Loss: 15.935033
Val Best Loss: 15.818565
Epoch loss: 15.935033
train phase, Epoch 11/20, Loss: 15.722078
val phase, Epoch 11/20, Loss: 16.029467
Val Best Loss: 15.818565
Epoch loss: 16.029467
train phase, Epoch 12/20, Loss: 15.510920
val phase, Epoch 12/20, Loss: 16.032178
Val Best Loss: 15.818565
Epoch loss: 16.032178
train phase, Epoch 13/20, Loss: 15.177192
val phase, Epoch 13/20, Loss: 16.417176
Val Best Loss: 15.818565
Epoch loss: 16.417176
train phase, Epoch 14/20, Loss: 15.016765
val phase, Epoch 14/20, Loss: 16.570513
Val Best Loss: 15.818565
Epoch loss: 16.570513
train phase, Epoch 15/20, Loss: 15.004332
val phase, Epoch 15/20, Loss: 16.202513
Val Best Loss: 15.818565
Epoch loss: 16.202513
train phase, Epoch 16/20, Loss: 14.573518
val phase, Epoch 16/20, Loss: 15.875645
Val Best Loss: 15.818565
Epoch loss: 15.875645
train phase, Epoch 17/20, Loss: 14.334182
val phase, Epoch 17/20, Loss: 16.329075
Val Best Loss: 15.818565
Epoch loss: 16.329075
train phase, Epoch 18/20, Loss: 13.998606
val phase, Epoch 18/20, Loss: 18.199727
Val Best Loss: 15.818565
Epoch loss: 18.199727
train phase, Epoch 19/20, Loss: 13.849948
val phase, Epoch 19/20, Loss: 24.177315
Val Best Loss: 15.818565
Epoch loss: 24.177315
train phase, Epoch 20/20, Loss: 13.757654
val phase, Epoch 20/20, Loss: 16.295217
Val Best Loss: 15.818565
Epoch loss: 16.295217
train phase, Epoch 1/20, Loss: 20.056979
val phase, Epoch 1/20, Loss: 17.246230
Val Best Loss: 17.246230
Epoch loss: 17.246230
train phase, Epoch 2/20, Loss: 17.757621
val phase, Epoch 2/20, Loss: 16.698126
Val Best Loss: 16.698126
Epoch loss: 16.698126
train phase, Epoch 3/20, Loss: 17.250054
val phase, Epoch 3/20, Loss: 16.580377
Val Best Loss: 16.580377
Epoch loss: 16.580377
train phase, Epoch 4/20, Loss: 16.926724
val phase, Epoch 4/20, Loss: 17.162366
Val Best Loss: 16.580377
Epoch loss: 17.162366
train phase, Epoch 5/20, Loss: 16.804867
val phase, Epoch 5/20, Loss: 18.157033
Val Best Loss: 16.580377
Epoch loss: 18.157033
train phase, Epoch 6/20, Loss: 16.412132
val phase, Epoch 6/20, Loss: 16.011561
Val Best Loss: 16.011561
Epoch loss: 16.011561
train phase, Epoch 7/20, Loss: 16.395016
val phase, Epoch 7/20, Loss: 16.134254
Val Best Loss: 16.011561
Epoch loss: 16.134254
train phase, Epoch 8/20, Loss: 16.231784
val phase, Epoch 8/20, Loss: 15.833759
Val Best Loss: 15.833759
Epoch loss: 15.833759
train phase, Epoch 9/20, Loss: 16.024262
val phase, Epoch 9/20, Loss: 15.977359
Val Best Loss: 15.833759
Epoch loss: 15.977359
train phase, Epoch 10/20, Loss: 16.029343
val phase, Epoch 10/20, Loss: 15.993346
Val Best Loss: 15.833759
Epoch loss: 15.993346
train phase, Epoch 11/20, Loss: 15.584239
val phase, Epoch 11/20, Loss: 17.397032
Val Best Loss: 15.833759
Epoch loss: 17.397032
train phase, Epoch 12/20, Loss: 15.575875
val phase, Epoch 12/20, Loss: 16.025600
Val Best Loss: 15.833759
Epoch loss: 16.025600
train phase, Epoch 13/20, Loss: 15.426681
val phase, Epoch 13/20, Loss: 15.991256
Val Best Loss: 15.833759
Epoch loss: 15.991256
train phase, Epoch 14/20, Loss: 15.249152
val phase, Epoch 14/20, Loss: 15.887751
Val Best Loss: 15.833759
Epoch loss: 15.887751
train phase, Epoch 15/20, Loss: 15.125679
val phase, Epoch 15/20, Loss: 16.638090
Val Best Loss: 15.833759
Epoch loss: 16.638090
train phase, Epoch 16/20, Loss: 14.869481
val phase, Epoch 16/20, Loss: 16.327918
Val Best Loss: 15.833759
Epoch loss: 16.327918
train phase, Epoch 17/20, Loss: 14.469650
val phase, Epoch 17/20, Loss: 16.360995
Val Best Loss: 15.833759
Epoch loss: 16.360995
train phase, Epoch 18/20, Loss: 14.224867
val phase, Epoch 18/20, Loss: 16.542316
Val Best Loss: 15.833759
Epoch loss: 16.542316
train phase, Epoch 19/20, Loss: 13.885871
val phase, Epoch 19/20, Loss: 16.520560
Val Best Loss: 15.833759
Epoch loss: 16.520560
train phase, Epoch 20/20, Loss: 13.860929
val phase, Epoch 20/20, Loss: 16.150077
Val Best Loss: 15.833759
Epoch loss: 16.150077
train phase, Epoch 1/20, Loss: 19.914255
val phase, Epoch 1/20, Loss: 16.790293
Val Best Loss: 16.790293
Epoch loss: 16.790293
train phase, Epoch 2/20, Loss: 17.864274
val phase, Epoch 2/20, Loss: 17.417016
Val Best Loss: 16.790293
Epoch loss: 17.417016
train phase, Epoch 3/20, Loss: 17.627508
val phase, Epoch 3/20, Loss: 19.650181
Val Best Loss: 16.790293
Epoch loss: 19.650181
train phase, Epoch 4/20, Loss: 17.241310
val phase, Epoch 4/20, Loss: 17.036420
Val Best Loss: 16.790293
Epoch loss: 17.036420
train phase, Epoch 5/20, Loss: 17.274331
val phase, Epoch 5/20, Loss: 16.890595
Val Best Loss: 16.790293
Epoch loss: 16.890595
train phase, Epoch 6/20, Loss: 16.830454
val phase, Epoch 6/20, Loss: 16.912422
Val Best Loss: 16.790293
Epoch loss: 16.912422
train phase, Epoch 7/20, Loss: 16.524366
val phase, Epoch 7/20, Loss: 16.428759
Val Best Loss: 16.428759
Epoch loss: 16.428759
train phase, Epoch 8/20, Loss: 16.393419
val phase, Epoch 8/20, Loss: 16.626606
Val Best Loss: 16.428759
Epoch loss: 16.626606
train phase, Epoch 9/20, Loss: 16.421329
val phase, Epoch 9/20, Loss: 16.548206
Val Best Loss: 16.428759
Epoch loss: 16.548206
train phase, Epoch 10/20, Loss: 16.313071
val phase, Epoch 10/20, Loss: 16.899661
Val Best Loss: 16.428759
Epoch loss: 16.899661
train phase, Epoch 11/20, Loss: 15.876999
val phase, Epoch 11/20, Loss: 18.950830
Val Best Loss: 16.428759
Epoch loss: 18.950830
train phase, Epoch 12/20, Loss: 15.987967
val phase, Epoch 12/20, Loss: 17.249344
Val Best Loss: 16.428759
Epoch loss: 17.249344
train phase, Epoch 13/20, Loss: 15.994878
val phase, Epoch 13/20, Loss: 15.812026
Val Best Loss: 15.812026
Epoch loss: 15.812026
train phase, Epoch 14/20, Loss: 15.728239
val phase, Epoch 14/20, Loss: 16.861676
Val Best Loss: 15.812026
Epoch loss: 16.861676
train phase, Epoch 15/20, Loss: 15.422684
val phase, Epoch 15/20, Loss: 16.890505
Val Best Loss: 15.812026
Epoch loss: 16.890505
train phase, Epoch 16/20, Loss: 15.183870
val phase, Epoch 16/20, Loss: 16.124260
Val Best Loss: 15.812026
Epoch loss: 16.124260
train phase, Epoch 17/20, Loss: 15.375520
val phase, Epoch 17/20, Loss: 15.972007
Val Best Loss: 15.812026
Epoch loss: 15.972007
train phase, Epoch 18/20, Loss: 14.799147
val phase, Epoch 18/20, Loss: 16.208164
Val Best Loss: 15.812026
Epoch loss: 16.208164
train phase, Epoch 19/20, Loss: 14.807331
val phase, Epoch 19/20, Loss: 16.743819
Val Best Loss: 15.812026
Epoch loss: 16.743819
train phase, Epoch 20/20, Loss: 14.751246
val phase, Epoch 20/20, Loss: 16.471345
Val Best Loss: 15.812026
Epoch loss: 16.471345
train phase, Epoch 1/20, Loss: 20.500660
val phase, Epoch 1/20, Loss: 17.889793
Val Best Loss: 17.889793
Epoch loss: 17.889793
train phase, Epoch 2/20, Loss: 17.715656
val phase, Epoch 2/20, Loss: 16.762689
Val Best Loss: 16.762689
Epoch loss: 16.762689
train phase, Epoch 3/20, Loss: 17.414033
val phase, Epoch 3/20, Loss: 17.692857
Val Best Loss: 16.762689
Epoch loss: 17.692857
train phase, Epoch 4/20, Loss: 16.903223
val phase, Epoch 4/20, Loss: 16.365181
Val Best Loss: 16.365181
Epoch loss: 16.365181
train phase, Epoch 5/20, Loss: 16.848439
val phase, Epoch 5/20, Loss: 16.174907
Val Best Loss: 16.174907
Epoch loss: 16.174907
train phase, Epoch 6/20, Loss: 16.643643
val phase, Epoch 6/20, Loss: 16.850119
Val Best Loss: 16.174907
Epoch loss: 16.850119
train phase, Epoch 7/20, Loss: 16.301556
val phase, Epoch 7/20, Loss: 15.793637
Val Best Loss: 15.793637
Epoch loss: 15.793637
train phase, Epoch 8/20, Loss: 16.098218
val phase, Epoch 8/20, Loss: 16.027493
Val Best Loss: 15.793637
Epoch loss: 16.027493
train phase, Epoch 9/20, Loss: 16.066252
val phase, Epoch 9/20, Loss: 15.723610
Val Best Loss: 15.723610
Epoch loss: 15.723610
train phase, Epoch 10/20, Loss: 15.823971
val phase, Epoch 10/20, Loss: 16.159031
Val Best Loss: 15.723610
Epoch loss: 16.159031
train phase, Epoch 11/20, Loss: 15.756299
val phase, Epoch 11/20, Loss: 16.419350
Val Best Loss: 15.723610
Epoch loss: 16.419350
train phase, Epoch 12/20, Loss: 15.370076
val phase, Epoch 12/20, Loss: 19.006922
Val Best Loss: 15.723610
Epoch loss: 19.006922
train phase, Epoch 13/20, Loss: 15.480422
val phase, Epoch 13/20, Loss: 15.629217
Val Best Loss: 15.629217
Epoch loss: 15.629217
train phase, Epoch 14/20, Loss: 15.035414
val phase, Epoch 14/20, Loss: 18.149513
Val Best Loss: 15.629217
Epoch loss: 18.149513
train phase, Epoch 15/20, Loss: 14.983813
val phase, Epoch 15/20, Loss: 15.902951
Val Best Loss: 15.629217
Epoch loss: 15.902951
train phase, Epoch 16/20, Loss: 14.659790
val phase, Epoch 16/20, Loss: 15.792802
Val Best Loss: 15.629217
Epoch loss: 15.792802
train phase, Epoch 17/20, Loss: 14.791142
val phase, Epoch 17/20, Loss: 15.734521
Val Best Loss: 15.629217
Epoch loss: 15.734521
train phase, Epoch 18/20, Loss: 14.382205
val phase, Epoch 18/20, Loss: 15.882466
Val Best Loss: 15.629217
Epoch loss: 15.882466
train phase, Epoch 19/20, Loss: 13.923236
val phase, Epoch 19/20, Loss: 16.822214
Val Best Loss: 15.629217
Epoch loss: 16.822214
train phase, Epoch 20/20, Loss: 13.668305
val phase, Epoch 20/20, Loss: 17.354375
Val Best Loss: 15.629217
Epoch loss: 17.354375
train phase, Epoch 1/20, Loss: 19.829588
val phase, Epoch 1/20, Loss: 18.627087
Val Best Loss: 18.627087
Epoch loss: 18.627087
train phase, Epoch 2/20, Loss: 17.894199
val phase, Epoch 2/20, Loss: 18.396099
Val Best Loss: 18.396099
Epoch loss: 18.396099
train phase, Epoch 3/20, Loss: 17.633866
val phase, Epoch 3/20, Loss: 17.671760
Val Best Loss: 17.671760
Epoch loss: 17.671760
train phase, Epoch 4/20, Loss: 17.066431
val phase, Epoch 4/20, Loss: 16.979720
Val Best Loss: 16.979720
Epoch loss: 16.979720
train phase, Epoch 5/20, Loss: 16.922182
val phase, Epoch 5/20, Loss: 16.374408
Val Best Loss: 16.374408
Epoch loss: 16.374408
train phase, Epoch 6/20, Loss: 16.785725
val phase, Epoch 6/20, Loss: 16.158045
Val Best Loss: 16.158045
Epoch loss: 16.158045
train phase, Epoch 7/20, Loss: 16.441120
val phase, Epoch 7/20, Loss: 16.668423
Val Best Loss: 16.158045
Epoch loss: 16.668423
train phase, Epoch 8/20, Loss: 16.306944
val phase, Epoch 8/20, Loss: 16.386415
Val Best Loss: 16.158045
Epoch loss: 16.386415
train phase, Epoch 9/20, Loss: 16.223666
val phase, Epoch 9/20, Loss: 16.444996
Val Best Loss: 16.158045
Epoch loss: 16.444996
train phase, Epoch 10/20, Loss: 16.248983
val phase, Epoch 10/20, Loss: 18.190750
Val Best Loss: 16.158045
Epoch loss: 18.190750
train phase, Epoch 11/20, Loss: 16.188022
val phase, Epoch 11/20, Loss: 16.045248
Val Best Loss: 16.045248
Epoch loss: 16.045248
train phase, Epoch 12/20, Loss: 15.707443
val phase, Epoch 12/20, Loss: 16.269943
Val Best Loss: 16.045248
Epoch loss: 16.269943
train phase, Epoch 13/20, Loss: 15.612028
val phase, Epoch 13/20, Loss: 16.541907
Val Best Loss: 16.045248
Epoch loss: 16.541907
train phase, Epoch 14/20, Loss: 15.588902
val phase, Epoch 14/20, Loss: 16.275903
Val Best Loss: 16.045248
Epoch loss: 16.275903
train phase, Epoch 15/20, Loss: 15.343692
val phase, Epoch 15/20, Loss: 15.870334
Val Best Loss: 15.870334
Epoch loss: 15.870334
train phase, Epoch 16/20, Loss: 15.144385
val phase, Epoch 16/20, Loss: 16.361471
Val Best Loss: 15.870334
Epoch loss: 16.361471
train phase, Epoch 17/20, Loss: 14.828196
val phase, Epoch 17/20, Loss: 16.777150
Val Best Loss: 15.870334
Epoch loss: 16.777150
train phase, Epoch 18/20, Loss: 14.759331
val phase, Epoch 18/20, Loss: 16.713007
Val Best Loss: 15.870334
Epoch loss: 16.713007
train phase, Epoch 19/20, Loss: 14.315711
val phase, Epoch 19/20, Loss: 17.297438
Val Best Loss: 15.870334
Epoch loss: 17.297438
train phase, Epoch 20/20, Loss: 14.243762
val phase, Epoch 20/20, Loss: 17.262643
Val Best Loss: 15.870334
Epoch loss: 17.262643
[Trial 237] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.021479
val phase, Epoch 1/20, Loss: 18.245323
Val Best Loss: 18.245323
Epoch loss: 18.245323
train phase, Epoch 2/20, Loss: 17.570844
val phase, Epoch 2/20, Loss: 16.503943
Val Best Loss: 16.503943
Epoch loss: 16.503943
train phase, Epoch 3/20, Loss: 17.546306
val phase, Epoch 3/20, Loss: 18.025607
Val Best Loss: 16.503943
Epoch loss: 18.025607
train phase, Epoch 4/20, Loss: 16.990412
val phase, Epoch 4/20, Loss: 18.164391
Val Best Loss: 16.503943
Epoch loss: 18.164391
train phase, Epoch 5/20, Loss: 16.778669
val phase, Epoch 5/20, Loss: 16.102809
Val Best Loss: 16.102809
Epoch loss: 16.102809
train phase, Epoch 6/20, Loss: 16.397147
val phase, Epoch 6/20, Loss: 16.478412
Val Best Loss: 16.102809
Epoch loss: 16.478412
train phase, Epoch 7/20, Loss: 16.334149
val phase, Epoch 7/20, Loss: 16.604431
Val Best Loss: 16.102809
Epoch loss: 16.604431
train phase, Epoch 8/20, Loss: 16.286655
val phase, Epoch 8/20, Loss: 16.111577
Val Best Loss: 16.102809
Epoch loss: 16.111577
train phase, Epoch 9/20, Loss: 15.988555
val phase, Epoch 9/20, Loss: 16.552562
Val Best Loss: 16.102809
Epoch loss: 16.552562
train phase, Epoch 10/20, Loss: 15.682136
val phase, Epoch 10/20, Loss: 16.466407
Val Best Loss: 16.102809
Epoch loss: 16.466407
train phase, Epoch 11/20, Loss: 15.529876
val phase, Epoch 11/20, Loss: 15.701213
Val Best Loss: 15.701213
Epoch loss: 15.701213
train phase, Epoch 12/20, Loss: 15.482749
val phase, Epoch 12/20, Loss: 16.244537
Val Best Loss: 15.701213
Epoch loss: 16.244537
train phase, Epoch 13/20, Loss: 15.452836
val phase, Epoch 13/20, Loss: 16.090200
Val Best Loss: 15.701213
Epoch loss: 16.090200
train phase, Epoch 14/20, Loss: 15.323126
val phase, Epoch 14/20, Loss: 17.296788
Val Best Loss: 15.701213
Epoch loss: 17.296788
train phase, Epoch 15/20, Loss: 14.950195
val phase, Epoch 15/20, Loss: 16.471490
Val Best Loss: 15.701213
Epoch loss: 16.471490
train phase, Epoch 16/20, Loss: 14.676678
val phase, Epoch 16/20, Loss: 16.161328
Val Best Loss: 15.701213
Epoch loss: 16.161328
train phase, Epoch 17/20, Loss: 14.506493
val phase, Epoch 17/20, Loss: 16.509606
Val Best Loss: 15.701213
Epoch loss: 16.509606
train phase, Epoch 18/20, Loss: 14.328602
val phase, Epoch 18/20, Loss: 15.864907
Val Best Loss: 15.701213
Epoch loss: 15.864907
train phase, Epoch 19/20, Loss: 14.053487
val phase, Epoch 19/20, Loss: 16.493111
Val Best Loss: 15.701213
Epoch loss: 16.493111
train phase, Epoch 20/20, Loss: 13.651959
val phase, Epoch 20/20, Loss: 16.874322
Val Best Loss: 15.701213
Epoch loss: 16.874322
train phase, Epoch 1/30, Loss: 20.333506
val phase, Epoch 1/30, Loss: 17.522414
Val Best Loss: 17.522414
Epoch loss: 17.522414
train phase, Epoch 2/30, Loss: 17.717932
val phase, Epoch 2/30, Loss: 16.855717
Val Best Loss: 16.855717
Epoch loss: 16.855717
train phase, Epoch 3/30, Loss: 17.254059
val phase, Epoch 3/30, Loss: 16.424354
Val Best Loss: 16.424354
Epoch loss: 16.424354
train phase, Epoch 4/30, Loss: 17.113581
val phase, Epoch 4/30, Loss: 16.387838
Val Best Loss: 16.387838
Epoch loss: 16.387838
train phase, Epoch 5/30, Loss: 16.871422
val phase, Epoch 5/30, Loss: 16.402577
Val Best Loss: 16.387838
Epoch loss: 16.402577
train phase, Epoch 6/30, Loss: 16.432801
val phase, Epoch 6/30, Loss: 16.296733
Val Best Loss: 16.296733
Epoch loss: 16.296733
train phase, Epoch 7/30, Loss: 16.297185
val phase, Epoch 7/30, Loss: 16.351131
Val Best Loss: 16.296733
Epoch loss: 16.351131
train phase, Epoch 8/30, Loss: 16.182556
val phase, Epoch 8/30, Loss: 17.168490
Val Best Loss: 16.296733
Epoch loss: 17.168490
train phase, Epoch 9/30, Loss: 16.205898
val phase, Epoch 9/30, Loss: 16.699502
Val Best Loss: 16.296733
Epoch loss: 16.699502
train phase, Epoch 10/30, Loss: 16.220204
val phase, Epoch 10/30, Loss: 16.197947
Val Best Loss: 16.197947
Epoch loss: 16.197947
train phase, Epoch 11/30, Loss: 15.823372
val phase, Epoch 11/30, Loss: 15.991616
Val Best Loss: 15.991616
Epoch loss: 15.991616
train phase, Epoch 12/30, Loss: 15.514333
val phase, Epoch 12/30, Loss: 16.337991
Val Best Loss: 15.991616
Epoch loss: 16.337991
train phase, Epoch 13/30, Loss: 15.323268
val phase, Epoch 13/30, Loss: 15.966607
Val Best Loss: 15.966607
Epoch loss: 15.966607
train phase, Epoch 14/30, Loss: 15.447703
val phase, Epoch 14/30, Loss: 15.692297
Val Best Loss: 15.692297
Epoch loss: 15.692297
train phase, Epoch 15/30, Loss: 14.845999
val phase, Epoch 15/30, Loss: 16.302634
Val Best Loss: 15.692297
Epoch loss: 16.302634
train phase, Epoch 16/30, Loss: 15.173034
val phase, Epoch 16/30, Loss: 16.190712
Val Best Loss: 15.692297
Epoch loss: 16.190712
train phase, Epoch 17/30, Loss: 14.522528
val phase, Epoch 17/30, Loss: 15.895786
Val Best Loss: 15.692297
Epoch loss: 15.895786
train phase, Epoch 18/30, Loss: 14.602755
val phase, Epoch 18/30, Loss: 16.078100
Val Best Loss: 15.692297
Epoch loss: 16.078100
train phase, Epoch 19/30, Loss: 13.992754
val phase, Epoch 19/30, Loss: 17.111419
Val Best Loss: 15.692297
Epoch loss: 17.111419
train phase, Epoch 20/30, Loss: 13.581101
val phase, Epoch 20/30, Loss: 16.792624
Val Best Loss: 15.692297
Epoch loss: 16.792624
train phase, Epoch 21/30, Loss: 13.378458
val phase, Epoch 21/30, Loss: 16.641056
Val Best Loss: 15.692297
Epoch loss: 16.641056
train phase, Epoch 22/30, Loss: 13.008404
val phase, Epoch 22/30, Loss: 16.936930
Val Best Loss: 15.692297
Epoch loss: 16.936930
train phase, Epoch 23/30, Loss: 12.557201
val phase, Epoch 23/30, Loss: 17.626439
Val Best Loss: 15.692297
Epoch loss: 17.626439
train phase, Epoch 24/30, Loss: 12.389962
val phase, Epoch 24/30, Loss: 16.697056
Val Best Loss: 15.692297
Epoch loss: 16.697056
train phase, Epoch 25/30, Loss: 11.803549
val phase, Epoch 25/30, Loss: 17.512142
Val Best Loss: 15.692297
Epoch loss: 17.512142
train phase, Epoch 26/30, Loss: 11.255460
val phase, Epoch 26/30, Loss: 18.317526
Val Best Loss: 15.692297
Epoch loss: 18.317526
train phase, Epoch 27/30, Loss: 11.061981
val phase, Epoch 27/30, Loss: 17.718981
Val Best Loss: 15.692297
Epoch loss: 17.718981
train phase, Epoch 28/30, Loss: 10.416067
val phase, Epoch 28/30, Loss: 20.715715
Val Best Loss: 15.692297
Epoch loss: 20.715715
train phase, Epoch 29/30, Loss: 9.704519
val phase, Epoch 29/30, Loss: 18.570195
Val Best Loss: 15.692297
Epoch loss: 18.570195
train phase, Epoch 30/30, Loss: 9.478209
val phase, Epoch 30/30, Loss: 19.236499
Val Best Loss: 15.692297
Epoch loss: 19.236499
train phase, Epoch 1/20, Loss: 20.109697
val phase, Epoch 1/20, Loss: 17.813190
Val Best Loss: 17.813190
Epoch loss: 17.813190
train phase, Epoch 2/20, Loss: 17.940354
val phase, Epoch 2/20, Loss: 16.980239
Val Best Loss: 16.980239
Epoch loss: 16.980239
train phase, Epoch 3/20, Loss: 17.284000
val phase, Epoch 3/20, Loss: 19.142422
Val Best Loss: 16.980239
Epoch loss: 19.142422
train phase, Epoch 4/20, Loss: 17.399697
val phase, Epoch 4/20, Loss: 16.454014
Val Best Loss: 16.454014
Epoch loss: 16.454014
train phase, Epoch 5/20, Loss: 17.051461
val phase, Epoch 5/20, Loss: 17.876691
Val Best Loss: 16.454014
Epoch loss: 17.876691
train phase, Epoch 6/20, Loss: 16.462505
val phase, Epoch 6/20, Loss: 16.261796
Val Best Loss: 16.261796
Epoch loss: 16.261796
train phase, Epoch 7/20, Loss: 16.480462
val phase, Epoch 7/20, Loss: 15.884510
Val Best Loss: 15.884510
Epoch loss: 15.884510
train phase, Epoch 8/20, Loss: 16.267230
val phase, Epoch 8/20, Loss: 16.015978
Val Best Loss: 15.884510
Epoch loss: 16.015978
train phase, Epoch 9/20, Loss: 16.311935
val phase, Epoch 9/20, Loss: 16.559879
Val Best Loss: 15.884510
Epoch loss: 16.559879
train phase, Epoch 10/20, Loss: 16.149428
val phase, Epoch 10/20, Loss: 16.600153
Val Best Loss: 15.884510
Epoch loss: 16.600153
train phase, Epoch 11/20, Loss: 15.870694
val phase, Epoch 11/20, Loss: 16.996061
Val Best Loss: 15.884510
Epoch loss: 16.996061
train phase, Epoch 12/20, Loss: 15.582477
val phase, Epoch 12/20, Loss: 16.339173
Val Best Loss: 15.884510
Epoch loss: 16.339173
train phase, Epoch 13/20, Loss: 15.534354
val phase, Epoch 13/20, Loss: 16.435973
Val Best Loss: 15.884510
Epoch loss: 16.435973
train phase, Epoch 14/20, Loss: 15.482876
val phase, Epoch 14/20, Loss: 16.032329
Val Best Loss: 15.884510
Epoch loss: 16.032329
train phase, Epoch 15/20, Loss: 15.215471
val phase, Epoch 15/20, Loss: 16.177018
Val Best Loss: 15.884510
Epoch loss: 16.177018
train phase, Epoch 16/20, Loss: 15.071978
val phase, Epoch 16/20, Loss: 15.766143
Val Best Loss: 15.766143
Epoch loss: 15.766143
train phase, Epoch 17/20, Loss: 14.867294
val phase, Epoch 17/20, Loss: 17.126893
Val Best Loss: 15.766143
Epoch loss: 17.126893
train phase, Epoch 18/20, Loss: 14.378913
val phase, Epoch 18/20, Loss: 17.115296
Val Best Loss: 15.766143
Epoch loss: 17.115296
train phase, Epoch 19/20, Loss: 14.326680
val phase, Epoch 19/20, Loss: 16.272738
Val Best Loss: 15.766143
Epoch loss: 16.272738
train phase, Epoch 20/20, Loss: 14.086049
val phase, Epoch 20/20, Loss: 16.492800
Val Best Loss: 15.766143
Epoch loss: 16.492800
train phase, Epoch 1/20, Loss: 21.263609
val phase, Epoch 1/20, Loss: 17.117591
Val Best Loss: 17.117591
Epoch loss: 17.117591
train phase, Epoch 2/20, Loss: 17.206376
val phase, Epoch 2/20, Loss: 16.821728
Val Best Loss: 16.821728
Epoch loss: 16.821728
train phase, Epoch 3/20, Loss: 16.776809
val phase, Epoch 3/20, Loss: 18.017267
Val Best Loss: 16.821728
Epoch loss: 18.017267
train phase, Epoch 4/20, Loss: 16.613383
val phase, Epoch 4/20, Loss: 16.349230
Val Best Loss: 16.349230
Epoch loss: 16.349230
train phase, Epoch 5/20, Loss: 16.518933
val phase, Epoch 5/20, Loss: 16.468623
Val Best Loss: 16.349230
Epoch loss: 16.468623
train phase, Epoch 6/20, Loss: 16.086905
val phase, Epoch 6/20, Loss: 16.842413
Val Best Loss: 16.349230
Epoch loss: 16.842413
train phase, Epoch 7/20, Loss: 15.935203
val phase, Epoch 7/20, Loss: 16.337094
Val Best Loss: 16.337094
Epoch loss: 16.337094
train phase, Epoch 8/20, Loss: 15.734614
val phase, Epoch 8/20, Loss: 20.640243
Val Best Loss: 16.337094
Epoch loss: 20.640243
train phase, Epoch 9/20, Loss: 15.708085
val phase, Epoch 9/20, Loss: 16.613699
Val Best Loss: 16.337094
Epoch loss: 16.613699
train phase, Epoch 10/20, Loss: 15.058712
val phase, Epoch 10/20, Loss: 16.955429
Val Best Loss: 16.337094
Epoch loss: 16.955429
train phase, Epoch 11/20, Loss: 15.040582
val phase, Epoch 11/20, Loss: 16.947163
Val Best Loss: 16.337094
Epoch loss: 16.947163
train phase, Epoch 12/20, Loss: 14.566246
val phase, Epoch 12/20, Loss: 16.684420
Val Best Loss: 16.337094
Epoch loss: 16.684420
train phase, Epoch 13/20, Loss: 14.151154
val phase, Epoch 13/20, Loss: 16.732905
Val Best Loss: 16.337094
Epoch loss: 16.732905
train phase, Epoch 14/20, Loss: 13.792158
val phase, Epoch 14/20, Loss: 16.715283
Val Best Loss: 16.337094
Epoch loss: 16.715283
train phase, Epoch 15/20, Loss: 13.400537
val phase, Epoch 15/20, Loss: 16.512091
Val Best Loss: 16.337094
Epoch loss: 16.512091
train phase, Epoch 16/20, Loss: 12.869173
val phase, Epoch 16/20, Loss: 17.250346
Val Best Loss: 16.337094
Epoch loss: 17.250346
train phase, Epoch 17/20, Loss: 12.500530
val phase, Epoch 17/20, Loss: 18.737975
Val Best Loss: 16.337094
Epoch loss: 18.737975
train phase, Epoch 18/20, Loss: 12.209788
val phase, Epoch 18/20, Loss: 17.316674
Val Best Loss: 16.337094
Epoch loss: 17.316674
train phase, Epoch 19/20, Loss: 11.670889
val phase, Epoch 19/20, Loss: 18.162610
Val Best Loss: 16.337094
Epoch loss: 18.162610
train phase, Epoch 20/20, Loss: 10.792371
val phase, Epoch 20/20, Loss: 17.594811
Val Best Loss: 16.337094
Epoch loss: 17.594811
train phase, Epoch 1/20, Loss: 20.025815
val phase, Epoch 1/20, Loss: 18.017594
Val Best Loss: 18.017594
Epoch loss: 18.017594
train phase, Epoch 2/20, Loss: 17.555236
val phase, Epoch 2/20, Loss: 24.704254
Val Best Loss: 18.017594
Epoch loss: 24.704254
train phase, Epoch 3/20, Loss: 17.664128
val phase, Epoch 3/20, Loss: 16.903032
Val Best Loss: 16.903032
Epoch loss: 16.903032
train phase, Epoch 4/20, Loss: 16.913027
val phase, Epoch 4/20, Loss: 17.165342
Val Best Loss: 16.903032
Epoch loss: 17.165342
train phase, Epoch 5/20, Loss: 16.710496
val phase, Epoch 5/20, Loss: 16.249341
Val Best Loss: 16.249341
Epoch loss: 16.249341
train phase, Epoch 6/20, Loss: 16.588603
val phase, Epoch 6/20, Loss: 17.292556
Val Best Loss: 16.249341
Epoch loss: 17.292556
train phase, Epoch 7/20, Loss: 16.257723
val phase, Epoch 7/20, Loss: 15.816777
Val Best Loss: 15.816777
Epoch loss: 15.816777
train phase, Epoch 8/20, Loss: 16.176811
val phase, Epoch 8/20, Loss: 17.025925
Val Best Loss: 15.816777
Epoch loss: 17.025925
train phase, Epoch 9/20, Loss: 15.909952
val phase, Epoch 9/20, Loss: 17.027640
Val Best Loss: 15.816777
Epoch loss: 17.027640
train phase, Epoch 10/20, Loss: 15.954295
val phase, Epoch 10/20, Loss: 18.613769
Val Best Loss: 15.816777
Epoch loss: 18.613769
train phase, Epoch 11/20, Loss: 15.569805
val phase, Epoch 11/20, Loss: 16.397151
Val Best Loss: 15.816777
Epoch loss: 16.397151
train phase, Epoch 12/20, Loss: 15.408859
val phase, Epoch 12/20, Loss: 16.601942
Val Best Loss: 15.816777
Epoch loss: 16.601942
train phase, Epoch 13/20, Loss: 15.369799
val phase, Epoch 13/20, Loss: 16.331199
Val Best Loss: 15.816777
Epoch loss: 16.331199
train phase, Epoch 14/20, Loss: 15.059592
val phase, Epoch 14/20, Loss: 16.933973
Val Best Loss: 15.816777
Epoch loss: 16.933973
train phase, Epoch 15/20, Loss: 14.808824
val phase, Epoch 15/20, Loss: 17.486449
Val Best Loss: 15.816777
Epoch loss: 17.486449
train phase, Epoch 16/20, Loss: 14.688708
val phase, Epoch 16/20, Loss: 17.198033
Val Best Loss: 15.816777
Epoch loss: 17.198033
train phase, Epoch 17/20, Loss: 14.554442
val phase, Epoch 17/20, Loss: 16.764462
Val Best Loss: 15.816777
Epoch loss: 16.764462
train phase, Epoch 18/20, Loss: 14.207069
val phase, Epoch 18/20, Loss: 17.047596
Val Best Loss: 15.816777
Epoch loss: 17.047596
train phase, Epoch 19/20, Loss: 13.736449
val phase, Epoch 19/20, Loss: 16.707180
Val Best Loss: 15.816777
Epoch loss: 16.707180
train phase, Epoch 20/20, Loss: 13.654269
val phase, Epoch 20/20, Loss: 17.960782
Val Best Loss: 15.816777
Epoch loss: 17.960782
train phase, Epoch 1/20, Loss: 23.141396
val phase, Epoch 1/20, Loss: 17.219209
Val Best Loss: 17.219209
Epoch loss: 17.219209
train phase, Epoch 2/20, Loss: 17.153897
val phase, Epoch 2/20, Loss: 17.260394
Val Best Loss: 17.219209
Epoch loss: 17.260394
train phase, Epoch 3/20, Loss: 16.720996
val phase, Epoch 3/20, Loss: 16.635474
Val Best Loss: 16.635474
Epoch loss: 16.635474
train phase, Epoch 4/20, Loss: 16.356521
val phase, Epoch 4/20, Loss: 17.155788
Val Best Loss: 16.635474
Epoch loss: 17.155788
train phase, Epoch 5/20, Loss: 16.125727
val phase, Epoch 5/20, Loss: 16.289060
Val Best Loss: 16.289060
Epoch loss: 16.289060
train phase, Epoch 6/20, Loss: 15.787377
val phase, Epoch 6/20, Loss: 17.580613
Val Best Loss: 16.289060
Epoch loss: 17.580613
train phase, Epoch 7/20, Loss: 15.411038
val phase, Epoch 7/20, Loss: 16.173347
Val Best Loss: 16.173347
Epoch loss: 16.173347
train phase, Epoch 8/20, Loss: 15.282606
val phase, Epoch 8/20, Loss: 16.792205
Val Best Loss: 16.173347
Epoch loss: 16.792205
train phase, Epoch 9/20, Loss: 14.886854
val phase, Epoch 9/20, Loss: 17.127153
Val Best Loss: 16.173347
Epoch loss: 17.127153
train phase, Epoch 10/20, Loss: 14.625909
val phase, Epoch 10/20, Loss: 16.107062
Val Best Loss: 16.107062
Epoch loss: 16.107062
train phase, Epoch 11/20, Loss: 14.250121
val phase, Epoch 11/20, Loss: 16.984579
Val Best Loss: 16.107062
Epoch loss: 16.984579
train phase, Epoch 12/20, Loss: 13.902491
val phase, Epoch 12/20, Loss: 17.249585
Val Best Loss: 16.107062
Epoch loss: 17.249585
train phase, Epoch 13/20, Loss: 13.520192
val phase, Epoch 13/20, Loss: 17.373390
Val Best Loss: 16.107062
Epoch loss: 17.373390
train phase, Epoch 14/20, Loss: 13.067549
val phase, Epoch 14/20, Loss: 17.498528
Val Best Loss: 16.107062
Epoch loss: 17.498528
train phase, Epoch 15/20, Loss: 12.608566
val phase, Epoch 15/20, Loss: 18.584925
Val Best Loss: 16.107062
Epoch loss: 18.584925
train phase, Epoch 16/20, Loss: 12.309421
val phase, Epoch 16/20, Loss: 17.318818
Val Best Loss: 16.107062
Epoch loss: 17.318818
train phase, Epoch 17/20, Loss: 11.688334
val phase, Epoch 17/20, Loss: 18.249646
Val Best Loss: 16.107062
Epoch loss: 18.249646
train phase, Epoch 18/20, Loss: 11.195153
val phase, Epoch 18/20, Loss: 17.979031
Val Best Loss: 16.107062
Epoch loss: 17.979031
train phase, Epoch 19/20, Loss: 10.775128
val phase, Epoch 19/20, Loss: 17.959973
Val Best Loss: 16.107062
Epoch loss: 17.959973
train phase, Epoch 20/20, Loss: 10.061446
val phase, Epoch 20/20, Loss: 19.591674
Val Best Loss: 16.107062
Epoch loss: 19.591674
train phase, Epoch 1/20, Loss: 19.692912
val phase, Epoch 1/20, Loss: 16.773139
Val Best Loss: 16.773139
Epoch loss: 16.773139
train phase, Epoch 2/20, Loss: 18.038768
val phase, Epoch 2/20, Loss: 17.384138
Val Best Loss: 16.773139
Epoch loss: 17.384138
train phase, Epoch 3/20, Loss: 17.413217
val phase, Epoch 3/20, Loss: 18.139217
Val Best Loss: 16.773139
Epoch loss: 18.139217
train phase, Epoch 4/20, Loss: 17.287844
val phase, Epoch 4/20, Loss: 17.465080
Val Best Loss: 16.773139
Epoch loss: 17.465080
train phase, Epoch 5/20, Loss: 17.009277
val phase, Epoch 5/20, Loss: 18.351658
Val Best Loss: 16.773139
Epoch loss: 18.351658
train phase, Epoch 6/20, Loss: 16.651362
val phase, Epoch 6/20, Loss: 16.033221
Val Best Loss: 16.033221
Epoch loss: 16.033221
train phase, Epoch 7/20, Loss: 16.906031
val phase, Epoch 7/20, Loss: 16.907233
Val Best Loss: 16.033221
Epoch loss: 16.907233
train phase, Epoch 8/20, Loss: 16.353353
val phase, Epoch 8/20, Loss: 16.536945
Val Best Loss: 16.033221
Epoch loss: 16.536945
train phase, Epoch 9/20, Loss: 16.268766
val phase, Epoch 9/20, Loss: 16.846502
Val Best Loss: 16.033221
Epoch loss: 16.846502
train phase, Epoch 10/20, Loss: 16.216287
val phase, Epoch 10/20, Loss: 16.473196
Val Best Loss: 16.033221
Epoch loss: 16.473196
train phase, Epoch 11/20, Loss: 16.154093
val phase, Epoch 11/20, Loss: 16.167630
Val Best Loss: 16.033221
Epoch loss: 16.167630
train phase, Epoch 12/20, Loss: 15.788723
val phase, Epoch 12/20, Loss: 16.219292
Val Best Loss: 16.033221
Epoch loss: 16.219292
train phase, Epoch 13/20, Loss: 15.661668
val phase, Epoch 13/20, Loss: 15.769825
Val Best Loss: 15.769825
Epoch loss: 15.769825
train phase, Epoch 14/20, Loss: 15.399725
val phase, Epoch 14/20, Loss: 16.265755
Val Best Loss: 15.769825
Epoch loss: 16.265755
train phase, Epoch 15/20, Loss: 15.125929
val phase, Epoch 15/20, Loss: 15.836332
Val Best Loss: 15.769825
Epoch loss: 15.836332
train phase, Epoch 16/20, Loss: 15.026972
val phase, Epoch 16/20, Loss: 15.688272
Val Best Loss: 15.688272
Epoch loss: 15.688272
train phase, Epoch 17/20, Loss: 14.910548
val phase, Epoch 17/20, Loss: 15.646371
Val Best Loss: 15.646371
Epoch loss: 15.646371
train phase, Epoch 18/20, Loss: 14.818665
val phase, Epoch 18/20, Loss: 16.284784
Val Best Loss: 15.646371
Epoch loss: 16.284784
train phase, Epoch 19/20, Loss: 14.628206
val phase, Epoch 19/20, Loss: 16.109104
Val Best Loss: 15.646371
Epoch loss: 16.109104
train phase, Epoch 20/20, Loss: 14.285255
val phase, Epoch 20/20, Loss: 16.346108
Val Best Loss: 15.646371
Epoch loss: 16.346108
train phase, Epoch 1/20, Loss: 20.383207
val phase, Epoch 1/20, Loss: 18.512668
Val Best Loss: 18.512668
Epoch loss: 18.512668
train phase, Epoch 2/20, Loss: 17.791640
val phase, Epoch 2/20, Loss: 17.079013
Val Best Loss: 17.079013
Epoch loss: 17.079013
train phase, Epoch 3/20, Loss: 17.383631
val phase, Epoch 3/20, Loss: 22.990544
Val Best Loss: 17.079013
Epoch loss: 22.990544
train phase, Epoch 4/20, Loss: 17.280528
val phase, Epoch 4/20, Loss: 16.269584
Val Best Loss: 16.269584
Epoch loss: 16.269584
train phase, Epoch 5/20, Loss: 16.933104
val phase, Epoch 5/20, Loss: 16.503506
Val Best Loss: 16.269584
Epoch loss: 16.503506
train phase, Epoch 6/20, Loss: 16.856493
val phase, Epoch 6/20, Loss: 16.560124
Val Best Loss: 16.269584
Epoch loss: 16.560124
train phase, Epoch 7/20, Loss: 16.574371
val phase, Epoch 7/20, Loss: 16.270417
Val Best Loss: 16.269584
Epoch loss: 16.270417
train phase, Epoch 8/20, Loss: 16.327669
val phase, Epoch 8/20, Loss: 15.966082
Val Best Loss: 15.966082
Epoch loss: 15.966082
train phase, Epoch 9/20, Loss: 16.240961
val phase, Epoch 9/20, Loss: 22.255323
Val Best Loss: 15.966082
Epoch loss: 22.255323
train phase, Epoch 10/20, Loss: 16.071197
val phase, Epoch 10/20, Loss: 16.275265
Val Best Loss: 15.966082
Epoch loss: 16.275265
train phase, Epoch 11/20, Loss: 15.972682
val phase, Epoch 11/20, Loss: 18.654639
Val Best Loss: 15.966082
Epoch loss: 18.654639
train phase, Epoch 12/20, Loss: 15.552591
val phase, Epoch 12/20, Loss: 17.175275
Val Best Loss: 15.966082
Epoch loss: 17.175275
train phase, Epoch 13/20, Loss: 15.673050
val phase, Epoch 13/20, Loss: 16.262693
Val Best Loss: 15.966082
Epoch loss: 16.262693
train phase, Epoch 14/20, Loss: 15.517657
val phase, Epoch 14/20, Loss: 15.725180
Val Best Loss: 15.725180
Epoch loss: 15.725180
train phase, Epoch 15/20, Loss: 15.419227
val phase, Epoch 15/20, Loss: 16.805757
Val Best Loss: 15.725180
Epoch loss: 16.805757
train phase, Epoch 16/20, Loss: 15.104657
val phase, Epoch 16/20, Loss: 17.315676
Val Best Loss: 15.725180
Epoch loss: 17.315676
train phase, Epoch 17/20, Loss: 14.986791
val phase, Epoch 17/20, Loss: 16.525983
Val Best Loss: 15.725180
Epoch loss: 16.525983
train phase, Epoch 18/20, Loss: 14.722498
val phase, Epoch 18/20, Loss: 17.118208
Val Best Loss: 15.725180
Epoch loss: 17.118208
train phase, Epoch 19/20, Loss: 14.435072
val phase, Epoch 19/20, Loss: 15.858750
Val Best Loss: 15.725180
Epoch loss: 15.858750
train phase, Epoch 20/20, Loss: 14.219769
val phase, Epoch 20/20, Loss: 16.476664
Val Best Loss: 15.725180
Epoch loss: 16.476664
train phase, Epoch 1/12, Loss: 27.931224
val phase, Epoch 1/12, Loss: 17.486752
Val Best Loss: 17.486752
Epoch loss: 17.486752
train phase, Epoch 2/12, Loss: 17.765458
val phase, Epoch 2/12, Loss: 17.842549
Val Best Loss: 17.486752
Epoch loss: 17.842549
train phase, Epoch 3/12, Loss: 18.323156
val phase, Epoch 3/12, Loss: 17.322678
Val Best Loss: 17.322678
Epoch loss: 17.322678
train phase, Epoch 4/12, Loss: 17.602451
val phase, Epoch 4/12, Loss: 25.420705
Val Best Loss: 17.322678
Epoch loss: 25.420705
train phase, Epoch 5/12, Loss: 17.608868
val phase, Epoch 5/12, Loss: 16.894948
Val Best Loss: 16.894948
Epoch loss: 16.894948
train phase, Epoch 6/12, Loss: 17.177382
val phase, Epoch 6/12, Loss: 17.227351
Val Best Loss: 16.894948
Epoch loss: 17.227351
train phase, Epoch 7/12, Loss: 16.964077
val phase, Epoch 7/12, Loss: 17.611382
Val Best Loss: 16.894948
Epoch loss: 17.611382
train phase, Epoch 8/12, Loss: 16.971189
val phase, Epoch 8/12, Loss: 17.258884
Val Best Loss: 16.894948
Epoch loss: 17.258884
train phase, Epoch 9/12, Loss: 16.619861
val phase, Epoch 9/12, Loss: 17.926298
Val Best Loss: 16.894948
Epoch loss: 17.926298
train phase, Epoch 10/12, Loss: 16.702785
val phase, Epoch 10/12, Loss: 16.945108
Val Best Loss: 16.894948
Epoch loss: 16.945108
train phase, Epoch 11/12, Loss: 16.606466
val phase, Epoch 11/12, Loss: 16.406749
Val Best Loss: 16.406749
Epoch loss: 16.406749
train phase, Epoch 12/12, Loss: 16.338998
val phase, Epoch 12/12, Loss: 16.401521
Val Best Loss: 16.401521
Epoch loss: 16.401521
train phase, Epoch 1/20, Loss: 19.653445
val phase, Epoch 1/20, Loss: 18.515917
Val Best Loss: 18.515917
Epoch loss: 18.515917
train phase, Epoch 2/20, Loss: 18.703963
val phase, Epoch 2/20, Loss: 17.378902
Val Best Loss: 17.378902
Epoch loss: 17.378902
train phase, Epoch 3/20, Loss: 18.148564
val phase, Epoch 3/20, Loss: 17.330584
Val Best Loss: 17.330584
Epoch loss: 17.330584
train phase, Epoch 4/20, Loss: 17.681071
val phase, Epoch 4/20, Loss: 17.844263
Val Best Loss: 17.330584
Epoch loss: 17.844263
train phase, Epoch 5/20, Loss: 17.230443
val phase, Epoch 5/20, Loss: 16.911650
Val Best Loss: 16.911650
Epoch loss: 16.911650
train phase, Epoch 6/20, Loss: 17.045000
val phase, Epoch 6/20, Loss: 18.625257
Val Best Loss: 16.911650
Epoch loss: 18.625257
train phase, Epoch 7/20, Loss: 17.025819
val phase, Epoch 7/20, Loss: 17.768936
Val Best Loss: 16.911650
Epoch loss: 17.768936
train phase, Epoch 8/20, Loss: 16.887067
val phase, Epoch 8/20, Loss: 16.847280
Val Best Loss: 16.847280
Epoch loss: 16.847280
train phase, Epoch 9/20, Loss: 16.747962
val phase, Epoch 9/20, Loss: 16.821663
Val Best Loss: 16.821663
Epoch loss: 16.821663
train phase, Epoch 10/20, Loss: 17.005797
val phase, Epoch 10/20, Loss: 16.065891
Val Best Loss: 16.065891
Epoch loss: 16.065891
train phase, Epoch 11/20, Loss: 16.393952
val phase, Epoch 11/20, Loss: 16.459044
Val Best Loss: 16.065891
Epoch loss: 16.459044
train phase, Epoch 12/20, Loss: 16.245285
val phase, Epoch 12/20, Loss: 16.473359
Val Best Loss: 16.065891
Epoch loss: 16.473359
train phase, Epoch 13/20, Loss: 15.920801
val phase, Epoch 13/20, Loss: 16.651253
Val Best Loss: 16.065891
Epoch loss: 16.651253
train phase, Epoch 14/20, Loss: 15.968799
val phase, Epoch 14/20, Loss: 16.640003
Val Best Loss: 16.065891
Epoch loss: 16.640003
train phase, Epoch 15/20, Loss: 15.662643
val phase, Epoch 15/20, Loss: 15.937278
Val Best Loss: 15.937278
Epoch loss: 15.937278
train phase, Epoch 16/20, Loss: 15.716377
val phase, Epoch 16/20, Loss: 16.160104
Val Best Loss: 15.937278
Epoch loss: 16.160104
train phase, Epoch 17/20, Loss: 15.522291
val phase, Epoch 17/20, Loss: 16.415494
Val Best Loss: 15.937278
Epoch loss: 16.415494
train phase, Epoch 18/20, Loss: 15.492214
val phase, Epoch 18/20, Loss: 16.247256
Val Best Loss: 15.937278
Epoch loss: 16.247256
train phase, Epoch 19/20, Loss: 15.316922
val phase, Epoch 19/20, Loss: 15.854884
Val Best Loss: 15.854884
Epoch loss: 15.854884
train phase, Epoch 20/20, Loss: 15.464659
val phase, Epoch 20/20, Loss: 16.019896
Val Best Loss: 15.854884
Epoch loss: 16.019896
train phase, Epoch 1/20, Loss: 20.244032
val phase, Epoch 1/20, Loss: 17.111012
Val Best Loss: 17.111012
Epoch loss: 17.111012
train phase, Epoch 2/20, Loss: 18.367272
val phase, Epoch 2/20, Loss: 17.129495
Val Best Loss: 17.111012
Epoch loss: 17.129495
train phase, Epoch 3/20, Loss: 17.561839
val phase, Epoch 3/20, Loss: 17.765441
Val Best Loss: 17.111012
Epoch loss: 17.765441
train phase, Epoch 4/20, Loss: 17.563452
val phase, Epoch 4/20, Loss: 16.891260
Val Best Loss: 16.891260
Epoch loss: 16.891260
train phase, Epoch 5/20, Loss: 16.858323
val phase, Epoch 5/20, Loss: 18.683725
Val Best Loss: 16.891260
Epoch loss: 18.683725
train phase, Epoch 6/20, Loss: 16.977248
val phase, Epoch 6/20, Loss: 16.858383
Val Best Loss: 16.858383
Epoch loss: 16.858383
train phase, Epoch 7/20, Loss: 16.510468
val phase, Epoch 7/20, Loss: 16.150545
Val Best Loss: 16.150545
Epoch loss: 16.150545
train phase, Epoch 8/20, Loss: 16.642234
val phase, Epoch 8/20, Loss: 16.321502
Val Best Loss: 16.150545
Epoch loss: 16.321502
train phase, Epoch 9/20, Loss: 16.247515
val phase, Epoch 9/20, Loss: 15.916866
Val Best Loss: 15.916866
Epoch loss: 15.916866
train phase, Epoch 10/20, Loss: 16.266474
val phase, Epoch 10/20, Loss: 16.087661
Val Best Loss: 15.916866
Epoch loss: 16.087661
train phase, Epoch 11/20, Loss: 16.123939
val phase, Epoch 11/20, Loss: 16.335997
Val Best Loss: 15.916866
Epoch loss: 16.335997
train phase, Epoch 12/20, Loss: 16.015288
val phase, Epoch 12/20, Loss: 17.134001
Val Best Loss: 15.916866
Epoch loss: 17.134001
train phase, Epoch 13/20, Loss: 15.793755
val phase, Epoch 13/20, Loss: 15.950372
Val Best Loss: 15.916866
Epoch loss: 15.950372
train phase, Epoch 14/20, Loss: 15.334435
val phase, Epoch 14/20, Loss: 16.422129
Val Best Loss: 15.916866
Epoch loss: 16.422129
train phase, Epoch 15/20, Loss: 15.310641
val phase, Epoch 15/20, Loss: 18.831835
Val Best Loss: 15.916866
Epoch loss: 18.831835
train phase, Epoch 16/20, Loss: 15.186075
val phase, Epoch 16/20, Loss: 16.402931
Val Best Loss: 15.916866
Epoch loss: 16.402931
train phase, Epoch 17/20, Loss: 14.784689
val phase, Epoch 17/20, Loss: 17.235463
Val Best Loss: 15.916866
Epoch loss: 17.235463
train phase, Epoch 18/20, Loss: 14.483812
val phase, Epoch 18/20, Loss: 16.597875
Val Best Loss: 15.916866
Epoch loss: 16.597875
train phase, Epoch 19/20, Loss: 14.258800
val phase, Epoch 19/20, Loss: 16.132312
Val Best Loss: 15.916866
Epoch loss: 16.132312
train phase, Epoch 20/20, Loss: 14.037823
val phase, Epoch 20/20, Loss: 19.307656
Val Best Loss: 15.916866
Epoch loss: 19.307656
train phase, Epoch 1/30, Loss: 21.302763
val phase, Epoch 1/30, Loss: 17.824254
Val Best Loss: 17.824254
Epoch loss: 17.824254
train phase, Epoch 2/30, Loss: 18.401661
val phase, Epoch 2/30, Loss: 17.679372
Val Best Loss: 17.679372
Epoch loss: 17.679372
train phase, Epoch 3/30, Loss: 17.783652
val phase, Epoch 3/30, Loss: 18.256793
Val Best Loss: 17.679372
Epoch loss: 18.256793
train phase, Epoch 4/30, Loss: 17.988629
val phase, Epoch 4/30, Loss: 17.447175
Val Best Loss: 17.447175
Epoch loss: 17.447175
train phase, Epoch 5/30, Loss: 17.377624
val phase, Epoch 5/30, Loss: 18.085891
Val Best Loss: 17.447175
Epoch loss: 18.085891
train phase, Epoch 6/30, Loss: 17.362551
val phase, Epoch 6/30, Loss: 17.003609
Val Best Loss: 17.003609
Epoch loss: 17.003609
train phase, Epoch 7/30, Loss: 16.812412
val phase, Epoch 7/30, Loss: 17.877938
Val Best Loss: 17.003609
Epoch loss: 17.877938
train phase, Epoch 8/30, Loss: 16.679044
val phase, Epoch 8/30, Loss: 17.154599
Val Best Loss: 17.003609
Epoch loss: 17.154599
train phase, Epoch 9/30, Loss: 16.809892
val phase, Epoch 9/30, Loss: 18.078668
Val Best Loss: 17.003609
Epoch loss: 18.078668
train phase, Epoch 10/30, Loss: 16.444485
val phase, Epoch 10/30, Loss: 18.442160
Val Best Loss: 17.003609
Epoch loss: 18.442160
train phase, Epoch 11/30, Loss: 15.917079
val phase, Epoch 11/30, Loss: 16.570136
Val Best Loss: 16.570136
Epoch loss: 16.570136
train phase, Epoch 12/30, Loss: 15.907604
val phase, Epoch 12/30, Loss: 16.610753
Val Best Loss: 16.570136
Epoch loss: 16.610753
train phase, Epoch 13/30, Loss: 15.722467
val phase, Epoch 13/30, Loss: 16.669151
Val Best Loss: 16.570136
Epoch loss: 16.669151
train phase, Epoch 14/30, Loss: 15.541164
val phase, Epoch 14/30, Loss: 16.690404
Val Best Loss: 16.570136
Epoch loss: 16.690404
train phase, Epoch 15/30, Loss: 15.406855
val phase, Epoch 15/30, Loss: 16.465337
Val Best Loss: 16.465337
Epoch loss: 16.465337
train phase, Epoch 16/30, Loss: 14.964342
val phase, Epoch 16/30, Loss: 16.527793
Val Best Loss: 16.465337
Epoch loss: 16.527793
train phase, Epoch 17/30, Loss: 15.013910
val phase, Epoch 17/30, Loss: 16.566930
Val Best Loss: 16.465337
Epoch loss: 16.566930
train phase, Epoch 18/30, Loss: 14.589211
val phase, Epoch 18/30, Loss: 17.930804
Val Best Loss: 16.465337
Epoch loss: 17.930804
train phase, Epoch 19/30, Loss: 14.363750
val phase, Epoch 19/30, Loss: 18.393084
Val Best Loss: 16.465337
Epoch loss: 18.393084
train phase, Epoch 20/30, Loss: 14.429942
val phase, Epoch 20/30, Loss: 17.000188
Val Best Loss: 16.465337
Epoch loss: 17.000188
train phase, Epoch 21/30, Loss: 13.754392
val phase, Epoch 21/30, Loss: 17.296058
Val Best Loss: 16.465337
Epoch loss: 17.296058
train phase, Epoch 22/30, Loss: 13.371522
val phase, Epoch 22/30, Loss: 18.118471
Val Best Loss: 16.465337
Epoch loss: 18.118471
train phase, Epoch 23/30, Loss: 13.302140
val phase, Epoch 23/30, Loss: 17.167788
Val Best Loss: 16.465337
Epoch loss: 17.167788
train phase, Epoch 24/30, Loss: 12.927731
val phase, Epoch 24/30, Loss: 18.037657
Val Best Loss: 16.465337
Epoch loss: 18.037657
train phase, Epoch 25/30, Loss: 12.462816
val phase, Epoch 25/30, Loss: 17.212936
Val Best Loss: 16.465337
Epoch loss: 17.212936
train phase, Epoch 26/30, Loss: 12.064326
val phase, Epoch 26/30, Loss: 17.240433
Val Best Loss: 16.465337
Epoch loss: 17.240433
train phase, Epoch 27/30, Loss: 11.888155
val phase, Epoch 27/30, Loss: 17.263098
Val Best Loss: 16.465337
Epoch loss: 17.263098
train phase, Epoch 28/30, Loss: 11.528083
val phase, Epoch 28/30, Loss: 17.690495
Val Best Loss: 16.465337
Epoch loss: 17.690495
train phase, Epoch 29/30, Loss: 11.078940
val phase, Epoch 29/30, Loss: 18.633429
Val Best Loss: 16.465337
Epoch loss: 18.633429
train phase, Epoch 30/30, Loss: 10.377638
val phase, Epoch 30/30, Loss: 18.673458
Val Best Loss: 16.465337
Epoch loss: 18.673458
[Trial 250] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/25, Loss: 20.130144
val phase, Epoch 1/25, Loss: 17.401731
Val Best Loss: 17.401731
Epoch loss: 17.401731
train phase, Epoch 2/25, Loss: 17.800342
val phase, Epoch 2/25, Loss: 16.845684
Val Best Loss: 16.845684
Epoch loss: 16.845684
train phase, Epoch 3/25, Loss: 17.442800
val phase, Epoch 3/25, Loss: 16.271649
Val Best Loss: 16.271649
Epoch loss: 16.271649
train phase, Epoch 4/25, Loss: 17.139999
val phase, Epoch 4/25, Loss: 17.042431
Val Best Loss: 16.271649
Epoch loss: 17.042431
train phase, Epoch 5/25, Loss: 16.921947
val phase, Epoch 5/25, Loss: 20.035996
Val Best Loss: 16.271649
Epoch loss: 20.035996
train phase, Epoch 6/25, Loss: 16.566294
val phase, Epoch 6/25, Loss: 16.206458
Val Best Loss: 16.206458
Epoch loss: 16.206458
train phase, Epoch 7/25, Loss: 16.443177
val phase, Epoch 7/25, Loss: 15.958485
Val Best Loss: 15.958485
Epoch loss: 15.958485
train phase, Epoch 8/25, Loss: 16.210965
val phase, Epoch 8/25, Loss: 16.221890
Val Best Loss: 15.958485
Epoch loss: 16.221890
train phase, Epoch 9/25, Loss: 16.009527
val phase, Epoch 9/25, Loss: 16.109744
Val Best Loss: 15.958485
Epoch loss: 16.109744
train phase, Epoch 10/25, Loss: 15.900172
val phase, Epoch 10/25, Loss: 17.153960
Val Best Loss: 15.958485
Epoch loss: 17.153960
train phase, Epoch 11/25, Loss: 15.891260
val phase, Epoch 11/25, Loss: 15.994813
Val Best Loss: 15.958485
Epoch loss: 15.994813
train phase, Epoch 12/25, Loss: 15.506466
val phase, Epoch 12/25, Loss: 15.983370
Val Best Loss: 15.958485
Epoch loss: 15.983370
train phase, Epoch 13/25, Loss: 15.212758
val phase, Epoch 13/25, Loss: 16.595270
Val Best Loss: 15.958485
Epoch loss: 16.595270
train phase, Epoch 14/25, Loss: 15.104167
val phase, Epoch 14/25, Loss: 16.340387
Val Best Loss: 15.958485
Epoch loss: 16.340387
train phase, Epoch 15/25, Loss: 14.844332
val phase, Epoch 15/25, Loss: 16.709076
Val Best Loss: 15.958485
Epoch loss: 16.709076
train phase, Epoch 16/25, Loss: 14.764421
val phase, Epoch 16/25, Loss: 16.415360
Val Best Loss: 15.958485
Epoch loss: 16.415360
train phase, Epoch 17/25, Loss: 14.462506
val phase, Epoch 17/25, Loss: 16.858388
Val Best Loss: 15.958485
Epoch loss: 16.858388
train phase, Epoch 18/25, Loss: 14.217562
val phase, Epoch 18/25, Loss: 18.063917
Val Best Loss: 15.958485
Epoch loss: 18.063917
train phase, Epoch 19/25, Loss: 14.042884
val phase, Epoch 19/25, Loss: 16.469938
Val Best Loss: 15.958485
Epoch loss: 16.469938
train phase, Epoch 20/25, Loss: 13.424612
val phase, Epoch 20/25, Loss: 17.057026
Val Best Loss: 15.958485
Epoch loss: 17.057026
train phase, Epoch 21/25, Loss: 13.198049
val phase, Epoch 21/25, Loss: 18.167252
Val Best Loss: 15.958485
Epoch loss: 18.167252
train phase, Epoch 22/25, Loss: 12.668607
val phase, Epoch 22/25, Loss: 17.495245
Val Best Loss: 15.958485
Epoch loss: 17.495245
train phase, Epoch 23/25, Loss: 12.226828
val phase, Epoch 23/25, Loss: 17.085432
Val Best Loss: 15.958485
Epoch loss: 17.085432
train phase, Epoch 24/25, Loss: 11.709366
val phase, Epoch 24/25, Loss: 19.243632
Val Best Loss: 15.958485
Epoch loss: 19.243632
train phase, Epoch 25/25, Loss: 11.733982
val phase, Epoch 25/25, Loss: 18.953873
Val Best Loss: 15.958485
Epoch loss: 18.953873
train phase, Epoch 1/20, Loss: 24.928385
val phase, Epoch 1/20, Loss: 18.301753
Val Best Loss: 18.301753
Epoch loss: 18.301753
train phase, Epoch 2/20, Loss: 18.094038
val phase, Epoch 2/20, Loss: 19.454561
Val Best Loss: 18.301753
Epoch loss: 19.454561
train phase, Epoch 3/20, Loss: 17.748075
val phase, Epoch 3/20, Loss: 19.268137
Val Best Loss: 18.301753
Epoch loss: 19.268137
train phase, Epoch 4/20, Loss: 17.347178
val phase, Epoch 4/20, Loss: 16.819985
Val Best Loss: 16.819985
Epoch loss: 16.819985
train phase, Epoch 5/20, Loss: 16.877222
val phase, Epoch 5/20, Loss: 16.970787
Val Best Loss: 16.819985
Epoch loss: 16.970787
train phase, Epoch 6/20, Loss: 16.630972
val phase, Epoch 6/20, Loss: 16.847526
Val Best Loss: 16.819985
Epoch loss: 16.847526
train phase, Epoch 7/20, Loss: 16.742860
val phase, Epoch 7/20, Loss: 16.589961
Val Best Loss: 16.589961
Epoch loss: 16.589961
train phase, Epoch 8/20, Loss: 16.426425
val phase, Epoch 8/20, Loss: 16.413313
Val Best Loss: 16.413313
Epoch loss: 16.413313
train phase, Epoch 9/20, Loss: 16.339131
val phase, Epoch 9/20, Loss: 17.747009
Val Best Loss: 16.413313
Epoch loss: 17.747009
train phase, Epoch 10/20, Loss: 16.332763
val phase, Epoch 10/20, Loss: 16.330408
Val Best Loss: 16.330408
Epoch loss: 16.330408
train phase, Epoch 11/20, Loss: 16.114142
val phase, Epoch 11/20, Loss: 17.394913
Val Best Loss: 16.330408
Epoch loss: 17.394913
train phase, Epoch 12/20, Loss: 16.133212
val phase, Epoch 12/20, Loss: 16.340069
Val Best Loss: 16.330408
Epoch loss: 16.340069
train phase, Epoch 13/20, Loss: 16.015486
val phase, Epoch 13/20, Loss: 16.375355
Val Best Loss: 16.330408
Epoch loss: 16.375355
train phase, Epoch 14/20, Loss: 15.852894
val phase, Epoch 14/20, Loss: 16.951684
Val Best Loss: 16.330408
Epoch loss: 16.951684
train phase, Epoch 15/20, Loss: 15.904089
val phase, Epoch 15/20, Loss: 16.707647
Val Best Loss: 16.330408
Epoch loss: 16.707647
train phase, Epoch 16/20, Loss: 15.726971
val phase, Epoch 16/20, Loss: 16.186739
Val Best Loss: 16.186739
Epoch loss: 16.186739
train phase, Epoch 17/20, Loss: 15.641481
val phase, Epoch 17/20, Loss: 16.178691
Val Best Loss: 16.178691
Epoch loss: 16.178691
train phase, Epoch 18/20, Loss: 15.503715
val phase, Epoch 18/20, Loss: 16.569397
Val Best Loss: 16.178691
Epoch loss: 16.569397
train phase, Epoch 19/20, Loss: 15.409394
val phase, Epoch 19/20, Loss: 16.452317
Val Best Loss: 16.178691
Epoch loss: 16.452317
train phase, Epoch 20/20, Loss: 15.240586
val phase, Epoch 20/20, Loss: 16.559843
Val Best Loss: 16.178691
Epoch loss: 16.559843
train phase, Epoch 1/5, Loss: 20.648447
val phase, Epoch 1/5, Loss: 18.330311
Val Best Loss: 18.330311
Epoch loss: 18.330311
train phase, Epoch 2/5, Loss: 19.012590
val phase, Epoch 2/5, Loss: 18.572190
Val Best Loss: 18.330311
Epoch loss: 18.572190
train phase, Epoch 3/5, Loss: 18.521268
val phase, Epoch 3/5, Loss: 19.071126
Val Best Loss: 18.330311
Epoch loss: 19.071126
train phase, Epoch 4/5, Loss: 17.999152
val phase, Epoch 4/5, Loss: 16.882256
Val Best Loss: 16.882256
Epoch loss: 16.882256
train phase, Epoch 5/5, Loss: 17.923907
val phase, Epoch 5/5, Loss: 16.655801
Val Best Loss: 16.655801
Epoch loss: 16.655801
train phase, Epoch 1/30, Loss: 20.325184
val phase, Epoch 1/30, Loss: 18.185705
Val Best Loss: 18.185705
Epoch loss: 18.185705
train phase, Epoch 2/30, Loss: 17.884041
val phase, Epoch 2/30, Loss: 17.209167
Val Best Loss: 17.209167
Epoch loss: 17.209167
train phase, Epoch 3/30, Loss: 17.681831
val phase, Epoch 3/30, Loss: 16.625266
Val Best Loss: 16.625266
Epoch loss: 16.625266
train phase, Epoch 4/30, Loss: 17.001624
val phase, Epoch 4/30, Loss: 18.449658
Val Best Loss: 16.625266
Epoch loss: 18.449658
train phase, Epoch 5/30, Loss: 16.992245
val phase, Epoch 5/30, Loss: 16.565576
Val Best Loss: 16.565576
Epoch loss: 16.565576
train phase, Epoch 6/30, Loss: 16.954715
val phase, Epoch 6/30, Loss: 21.499429
Val Best Loss: 16.565576
Epoch loss: 21.499429
train phase, Epoch 7/30, Loss: 16.851367
val phase, Epoch 7/30, Loss: 16.062168
Val Best Loss: 16.062168
Epoch loss: 16.062168
train phase, Epoch 8/30, Loss: 16.466675
val phase, Epoch 8/30, Loss: 16.067572
Val Best Loss: 16.062168
Epoch loss: 16.067572
train phase, Epoch 9/30, Loss: 16.344987
val phase, Epoch 9/30, Loss: 16.233752
Val Best Loss: 16.062168
Epoch loss: 16.233752
train phase, Epoch 10/30, Loss: 16.095657
val phase, Epoch 10/30, Loss: 16.535545
Val Best Loss: 16.062168
Epoch loss: 16.535545
train phase, Epoch 11/30, Loss: 15.926059
val phase, Epoch 11/30, Loss: 15.665087
Val Best Loss: 15.665087
Epoch loss: 15.665087
train phase, Epoch 12/30, Loss: 15.714267
val phase, Epoch 12/30, Loss: 16.531319
Val Best Loss: 15.665087
Epoch loss: 16.531319
train phase, Epoch 13/30, Loss: 15.713019
val phase, Epoch 13/30, Loss: 16.849665
Val Best Loss: 15.665087
Epoch loss: 16.849665
train phase, Epoch 14/30, Loss: 15.674070
val phase, Epoch 14/30, Loss: 15.743554
Val Best Loss: 15.665087
Epoch loss: 15.743554
train phase, Epoch 15/30, Loss: 15.295371
val phase, Epoch 15/30, Loss: 15.951644
Val Best Loss: 15.665087
Epoch loss: 15.951644
train phase, Epoch 16/30, Loss: 15.103666
val phase, Epoch 16/30, Loss: 16.229953
Val Best Loss: 15.665087
Epoch loss: 16.229953
train phase, Epoch 17/30, Loss: 14.817709
val phase, Epoch 17/30, Loss: 16.777011
Val Best Loss: 15.665087
Epoch loss: 16.777011
train phase, Epoch 18/30, Loss: 14.639048
val phase, Epoch 18/30, Loss: 16.325196
Val Best Loss: 15.665087
Epoch loss: 16.325196
train phase, Epoch 19/30, Loss: 14.706084
val phase, Epoch 19/30, Loss: 16.494480
Val Best Loss: 15.665087
Epoch loss: 16.494480
train phase, Epoch 20/30, Loss: 14.215020
val phase, Epoch 20/30, Loss: 16.166736
Val Best Loss: 15.665087
Epoch loss: 16.166736
train phase, Epoch 21/30, Loss: 13.935080
val phase, Epoch 21/30, Loss: 17.034930
Val Best Loss: 15.665087
Epoch loss: 17.034930
train phase, Epoch 22/30, Loss: 13.617801
val phase, Epoch 22/30, Loss: 17.115562
Val Best Loss: 15.665087
Epoch loss: 17.115562
train phase, Epoch 23/30, Loss: 13.225600
val phase, Epoch 23/30, Loss: 18.378517
Val Best Loss: 15.665087
Epoch loss: 18.378517
train phase, Epoch 24/30, Loss: 12.990928
val phase, Epoch 24/30, Loss: 16.919817
Val Best Loss: 15.665087
Epoch loss: 16.919817
train phase, Epoch 25/30, Loss: 12.597526
val phase, Epoch 25/30, Loss: 17.089752
Val Best Loss: 15.665087
Epoch loss: 17.089752
train phase, Epoch 26/30, Loss: 12.260416
val phase, Epoch 26/30, Loss: 17.211422
Val Best Loss: 15.665087
Epoch loss: 17.211422
train phase, Epoch 27/30, Loss: 11.848529
val phase, Epoch 27/30, Loss: 17.241860
Val Best Loss: 15.665087
Epoch loss: 17.241860
train phase, Epoch 28/30, Loss: 11.430186
val phase, Epoch 28/30, Loss: 17.153449
Val Best Loss: 15.665087
Epoch loss: 17.153449
train phase, Epoch 29/30, Loss: 10.894676
val phase, Epoch 29/30, Loss: 17.294253
Val Best Loss: 15.665087
Epoch loss: 17.294253
train phase, Epoch 30/30, Loss: 10.769183
val phase, Epoch 30/30, Loss: 17.770686
Val Best Loss: 15.665087
Epoch loss: 17.770686
train phase, Epoch 1/20, Loss: 19.873153
val phase, Epoch 1/20, Loss: 20.103925
Val Best Loss: 20.103925
Epoch loss: 20.103925
train phase, Epoch 2/20, Loss: 18.221817
val phase, Epoch 2/20, Loss: 18.730954
Val Best Loss: 18.730954
Epoch loss: 18.730954
train phase, Epoch 3/20, Loss: 17.684923
val phase, Epoch 3/20, Loss: 16.535935
Val Best Loss: 16.535935
Epoch loss: 16.535935
train phase, Epoch 4/20, Loss: 17.455724
val phase, Epoch 4/20, Loss: 17.160371
Val Best Loss: 16.535935
Epoch loss: 17.160371
train phase, Epoch 5/20, Loss: 16.887054
val phase, Epoch 5/20, Loss: 17.075268
Val Best Loss: 16.535935
Epoch loss: 17.075268
train phase, Epoch 6/20, Loss: 17.018367
val phase, Epoch 6/20, Loss: 16.690239
Val Best Loss: 16.535935
Epoch loss: 16.690239
train phase, Epoch 7/20, Loss: 16.493861
val phase, Epoch 7/20, Loss: 16.403247
Val Best Loss: 16.403247
Epoch loss: 16.403247
train phase, Epoch 8/20, Loss: 16.606289
val phase, Epoch 8/20, Loss: 16.147613
Val Best Loss: 16.147613
Epoch loss: 16.147613
train phase, Epoch 9/20, Loss: 16.202241
val phase, Epoch 9/20, Loss: 16.584199
Val Best Loss: 16.147613
Epoch loss: 16.584199
train phase, Epoch 10/20, Loss: 16.135257
val phase, Epoch 10/20, Loss: 16.818100
Val Best Loss: 16.147613
Epoch loss: 16.818100
train phase, Epoch 11/20, Loss: 15.926559
val phase, Epoch 11/20, Loss: 16.188454
Val Best Loss: 16.147613
Epoch loss: 16.188454
train phase, Epoch 12/20, Loss: 15.583199
val phase, Epoch 12/20, Loss: 17.212192
Val Best Loss: 16.147613
Epoch loss: 17.212192
train phase, Epoch 13/20, Loss: 15.921851
val phase, Epoch 13/20, Loss: 15.981462
Val Best Loss: 15.981462
Epoch loss: 15.981462
train phase, Epoch 14/20, Loss: 15.574266
val phase, Epoch 14/20, Loss: 17.529738
Val Best Loss: 15.981462
Epoch loss: 17.529738
train phase, Epoch 15/20, Loss: 15.201141
val phase, Epoch 15/20, Loss: 15.890986
Val Best Loss: 15.890986
Epoch loss: 15.890986
train phase, Epoch 16/20, Loss: 15.176135
val phase, Epoch 16/20, Loss: 15.846331
Val Best Loss: 15.846331
Epoch loss: 15.846331
train phase, Epoch 17/20, Loss: 14.773610
val phase, Epoch 17/20, Loss: 17.232124
Val Best Loss: 15.846331
Epoch loss: 17.232124
train phase, Epoch 18/20, Loss: 14.473358
val phase, Epoch 18/20, Loss: 16.091477
Val Best Loss: 15.846331
Epoch loss: 16.091477
train phase, Epoch 19/20, Loss: 14.524513
val phase, Epoch 19/20, Loss: 16.074655
Val Best Loss: 15.846331
Epoch loss: 16.074655
train phase, Epoch 20/20, Loss: 14.260988
val phase, Epoch 20/20, Loss: 16.209485
Val Best Loss: 15.846331
Epoch loss: 16.209485
train phase, Epoch 1/30, Loss: 20.001351
val phase, Epoch 1/30, Loss: 20.189637
Val Best Loss: 20.189637
Epoch loss: 20.189637
train phase, Epoch 2/30, Loss: 17.768347
val phase, Epoch 2/30, Loss: 17.910750
Val Best Loss: 17.910750
Epoch loss: 17.910750
train phase, Epoch 3/30, Loss: 17.565662
val phase, Epoch 3/30, Loss: 16.962303
Val Best Loss: 16.962303
Epoch loss: 16.962303
train phase, Epoch 4/30, Loss: 17.201833
val phase, Epoch 4/30, Loss: 18.417808
Val Best Loss: 16.962303
Epoch loss: 18.417808
train phase, Epoch 5/30, Loss: 16.975213
val phase, Epoch 5/30, Loss: 17.745476
Val Best Loss: 16.962303
Epoch loss: 17.745476
train phase, Epoch 6/30, Loss: 16.731818
val phase, Epoch 6/30, Loss: 16.371062
Val Best Loss: 16.371062
Epoch loss: 16.371062
train phase, Epoch 7/30, Loss: 16.486484
val phase, Epoch 7/30, Loss: 16.265088
Val Best Loss: 16.265088
Epoch loss: 16.265088
train phase, Epoch 8/30, Loss: 16.351372
val phase, Epoch 8/30, Loss: 16.598360
Val Best Loss: 16.265088
Epoch loss: 16.598360
train phase, Epoch 9/30, Loss: 16.263483
val phase, Epoch 9/30, Loss: 16.851077
Val Best Loss: 16.265088
Epoch loss: 16.851077
train phase, Epoch 10/30, Loss: 16.311616
val phase, Epoch 10/30, Loss: 16.136680
Val Best Loss: 16.136680
Epoch loss: 16.136680
train phase, Epoch 11/30, Loss: 15.978491
val phase, Epoch 11/30, Loss: 16.222245
Val Best Loss: 16.136680
Epoch loss: 16.222245
train phase, Epoch 12/30, Loss: 15.722932
val phase, Epoch 12/30, Loss: 16.434806
Val Best Loss: 16.136680
Epoch loss: 16.434806
train phase, Epoch 13/30, Loss: 15.578741
val phase, Epoch 13/30, Loss: 21.474503
Val Best Loss: 16.136680
Epoch loss: 21.474503
train phase, Epoch 14/30, Loss: 15.460654
val phase, Epoch 14/30, Loss: 16.848148
Val Best Loss: 16.136680
Epoch loss: 16.848148
train phase, Epoch 15/30, Loss: 15.380100
val phase, Epoch 15/30, Loss: 16.214965
Val Best Loss: 16.136680
Epoch loss: 16.214965
train phase, Epoch 16/30, Loss: 14.949251
val phase, Epoch 16/30, Loss: 18.136331
Val Best Loss: 16.136680
Epoch loss: 18.136331
train phase, Epoch 17/30, Loss: 15.324252
val phase, Epoch 17/30, Loss: 16.176678
Val Best Loss: 16.136680
Epoch loss: 16.176678
train phase, Epoch 18/30, Loss: 14.676644
val phase, Epoch 18/30, Loss: 17.712919
Val Best Loss: 16.136680
Epoch loss: 17.712919
train phase, Epoch 19/30, Loss: 14.478040
val phase, Epoch 19/30, Loss: 16.262091
Val Best Loss: 16.136680
Epoch loss: 16.262091
train phase, Epoch 20/30, Loss: 13.934649
val phase, Epoch 20/30, Loss: 16.808623
Val Best Loss: 16.136680
Epoch loss: 16.808623
train phase, Epoch 21/30, Loss: 14.249015
val phase, Epoch 21/30, Loss: 17.214767
Val Best Loss: 16.136680
Epoch loss: 17.214767
train phase, Epoch 22/30, Loss: 13.838542
val phase, Epoch 22/30, Loss: 16.533937
Val Best Loss: 16.136680
Epoch loss: 16.533937
train phase, Epoch 23/30, Loss: 13.454982
val phase, Epoch 23/30, Loss: 16.597968
Val Best Loss: 16.136680
Epoch loss: 16.597968
train phase, Epoch 24/30, Loss: 13.088841
val phase, Epoch 24/30, Loss: 17.205870
Val Best Loss: 16.136680
Epoch loss: 17.205870
train phase, Epoch 25/30, Loss: 12.712961
val phase, Epoch 25/30, Loss: 16.843193
Val Best Loss: 16.136680
Epoch loss: 16.843193
train phase, Epoch 26/30, Loss: 12.397133
val phase, Epoch 26/30, Loss: 18.000214
Val Best Loss: 16.136680
Epoch loss: 18.000214
train phase, Epoch 27/30, Loss: 11.776113
val phase, Epoch 27/30, Loss: 17.883135
Val Best Loss: 16.136680
Epoch loss: 17.883135
train phase, Epoch 28/30, Loss: 11.732488
val phase, Epoch 28/30, Loss: 18.594834
Val Best Loss: 16.136680
Epoch loss: 18.594834
train phase, Epoch 29/30, Loss: 11.412137
val phase, Epoch 29/30, Loss: 18.036493
Val Best Loss: 16.136680
Epoch loss: 18.036493
train phase, Epoch 30/30, Loss: 10.820389
val phase, Epoch 30/30, Loss: 18.855445
Val Best Loss: 16.136680
Epoch loss: 18.855445
train phase, Epoch 1/20, Loss: 32.303042
val phase, Epoch 1/20, Loss: 19.456176
Val Best Loss: 19.456176
Epoch loss: 19.456176
train phase, Epoch 2/20, Loss: 20.170734
val phase, Epoch 2/20, Loss: 18.901501
Val Best Loss: 18.901501
Epoch loss: 18.901501
train phase, Epoch 3/20, Loss: 19.149257
val phase, Epoch 3/20, Loss: 18.275395
Val Best Loss: 18.275395
Epoch loss: 18.275395
train phase, Epoch 4/20, Loss: 18.605766
val phase, Epoch 4/20, Loss: 18.672398
Val Best Loss: 18.275395
Epoch loss: 18.672398
train phase, Epoch 5/20, Loss: 18.105315
val phase, Epoch 5/20, Loss: 18.998231
Val Best Loss: 18.275395
Epoch loss: 18.998231
train phase, Epoch 6/20, Loss: 18.197111
val phase, Epoch 6/20, Loss: 17.358651
Val Best Loss: 17.358651
Epoch loss: 17.358651
train phase, Epoch 7/20, Loss: 17.683680
val phase, Epoch 7/20, Loss: 17.196694
Val Best Loss: 17.196694
Epoch loss: 17.196694
train phase, Epoch 8/20, Loss: 17.310730
val phase, Epoch 8/20, Loss: 16.834353
Val Best Loss: 16.834353
Epoch loss: 16.834353
train phase, Epoch 9/20, Loss: 17.241459
val phase, Epoch 9/20, Loss: 17.076451
Val Best Loss: 16.834353
Epoch loss: 17.076451
train phase, Epoch 10/20, Loss: 17.423114
val phase, Epoch 10/20, Loss: 19.790370
Val Best Loss: 16.834353
Epoch loss: 19.790370
train phase, Epoch 11/20, Loss: 17.644453
val phase, Epoch 11/20, Loss: 18.989337
Val Best Loss: 16.834353
Epoch loss: 18.989337
train phase, Epoch 12/20, Loss: 145.530586
val phase, Epoch 12/20, Loss: 26.483469
Val Best Loss: 16.834353
Epoch loss: 26.483469
train phase, Epoch 13/20, Loss: 23.914570
val phase, Epoch 13/20, Loss: 24.674673
Val Best Loss: 16.834353
Epoch loss: 24.674673
train phase, Epoch 14/20, Loss: 21.757352
val phase, Epoch 14/20, Loss: 21.096326
Val Best Loss: 16.834353
Epoch loss: 21.096326
train phase, Epoch 15/20, Loss: 20.797280
val phase, Epoch 15/20, Loss: 20.547748
Val Best Loss: 16.834353
Epoch loss: 20.547748
train phase, Epoch 16/20, Loss: 20.193332
val phase, Epoch 16/20, Loss: 20.055197
Val Best Loss: 16.834353
Epoch loss: 20.055197
train phase, Epoch 17/20, Loss: 19.658926
val phase, Epoch 17/20, Loss: 19.583343
Val Best Loss: 16.834353
Epoch loss: 19.583343
train phase, Epoch 18/20, Loss: 19.270124
val phase, Epoch 18/20, Loss: 20.395437
Val Best Loss: 16.834353
Epoch loss: 20.395437
train phase, Epoch 19/20, Loss: 19.228109
val phase, Epoch 19/20, Loss: 18.623775
Val Best Loss: 16.834353
Epoch loss: 18.623775
train phase, Epoch 20/20, Loss: 18.664938
val phase, Epoch 20/20, Loss: 18.611142
Val Best Loss: 16.834353
Epoch loss: 18.611142
train phase, Epoch 1/10, Loss: 20.125553
val phase, Epoch 1/10, Loss: 18.218199
Val Best Loss: 18.218199
Epoch loss: 18.218199
train phase, Epoch 2/10, Loss: 18.097666
val phase, Epoch 2/10, Loss: 17.535431
Val Best Loss: 17.535431
Epoch loss: 17.535431
train phase, Epoch 3/10, Loss: 17.846090
val phase, Epoch 3/10, Loss: 16.765958
Val Best Loss: 16.765958
Epoch loss: 16.765958
train phase, Epoch 4/10, Loss: 17.248210
val phase, Epoch 4/10, Loss: 16.796142
Val Best Loss: 16.765958
Epoch loss: 16.796142
train phase, Epoch 5/10, Loss: 17.196182
val phase, Epoch 5/10, Loss: 18.137598
Val Best Loss: 16.765958
Epoch loss: 18.137598
train phase, Epoch 6/10, Loss: 16.771559
val phase, Epoch 6/10, Loss: 16.213519
Val Best Loss: 16.213519
Epoch loss: 16.213519
train phase, Epoch 7/10, Loss: 16.760502
val phase, Epoch 7/10, Loss: 17.448685
Val Best Loss: 16.213519
Epoch loss: 17.448685
train phase, Epoch 8/10, Loss: 16.440865
val phase, Epoch 8/10, Loss: 16.462379
Val Best Loss: 16.213519
Epoch loss: 16.462379
train phase, Epoch 9/10, Loss: 16.432816
val phase, Epoch 9/10, Loss: 16.159789
Val Best Loss: 16.159789
Epoch loss: 16.159789
train phase, Epoch 10/10, Loss: 16.246507
val phase, Epoch 10/10, Loss: 17.236812
Val Best Loss: 16.159789
Epoch loss: 17.236812
[Trial 259] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.766441
val phase, Epoch 1/20, Loss: 17.439732
Val Best Loss: 17.439732
Epoch loss: 17.439732
train phase, Epoch 2/20, Loss: 17.967149
val phase, Epoch 2/20, Loss: 17.629707
Val Best Loss: 17.439732
Epoch loss: 17.629707
train phase, Epoch 3/20, Loss: 17.457882
val phase, Epoch 3/20, Loss: 17.251589
Val Best Loss: 17.251589
Epoch loss: 17.251589
train phase, Epoch 4/20, Loss: 17.362510
val phase, Epoch 4/20, Loss: 17.395178
Val Best Loss: 17.251589
Epoch loss: 17.395178
train phase, Epoch 5/20, Loss: 17.021184
val phase, Epoch 5/20, Loss: 16.757143
Val Best Loss: 16.757143
Epoch loss: 16.757143
train phase, Epoch 6/20, Loss: 16.885163
val phase, Epoch 6/20, Loss: 16.606292
Val Best Loss: 16.606292
Epoch loss: 16.606292
train phase, Epoch 7/20, Loss: 16.591805
val phase, Epoch 7/20, Loss: 17.164377
Val Best Loss: 16.606292
Epoch loss: 17.164377
train phase, Epoch 8/20, Loss: 16.395985
val phase, Epoch 8/20, Loss: 16.031130
Val Best Loss: 16.031130
Epoch loss: 16.031130
train phase, Epoch 9/20, Loss: 16.426088
val phase, Epoch 9/20, Loss: 16.750636
Val Best Loss: 16.031130
Epoch loss: 16.750636
train phase, Epoch 10/20, Loss: 16.343853
val phase, Epoch 10/20, Loss: 17.313246
Val Best Loss: 16.031130
Epoch loss: 17.313246
train phase, Epoch 11/20, Loss: 15.926331
val phase, Epoch 11/20, Loss: 19.012677
Val Best Loss: 16.031130
Epoch loss: 19.012677
train phase, Epoch 12/20, Loss: 16.097147
val phase, Epoch 12/20, Loss: 16.877748
Val Best Loss: 16.031130
Epoch loss: 16.877748
train phase, Epoch 13/20, Loss: 15.749097
val phase, Epoch 13/20, Loss: 16.302818
Val Best Loss: 16.031130
Epoch loss: 16.302818
train phase, Epoch 14/20, Loss: 15.792155
val phase, Epoch 14/20, Loss: 15.870785
Val Best Loss: 15.870785
Epoch loss: 15.870785
train phase, Epoch 15/20, Loss: 15.495040
val phase, Epoch 15/20, Loss: 18.602866
Val Best Loss: 15.870785
Epoch loss: 18.602866
train phase, Epoch 16/20, Loss: 15.426675
val phase, Epoch 16/20, Loss: 15.661523
Val Best Loss: 15.661523
Epoch loss: 15.661523
train phase, Epoch 17/20, Loss: 15.266257
val phase, Epoch 17/20, Loss: 16.130966
Val Best Loss: 15.661523
Epoch loss: 16.130966
train phase, Epoch 18/20, Loss: 14.936058
val phase, Epoch 18/20, Loss: 15.961000
Val Best Loss: 15.661523
Epoch loss: 15.961000
train phase, Epoch 19/20, Loss: 14.702730
val phase, Epoch 19/20, Loss: 16.195676
Val Best Loss: 15.661523
Epoch loss: 16.195676
train phase, Epoch 20/20, Loss: 14.412033
val phase, Epoch 20/20, Loss: 16.038914
Val Best Loss: 15.661523
Epoch loss: 16.038914
train phase, Epoch 1/30, Loss: 20.093770
val phase, Epoch 1/30, Loss: 17.194402
Val Best Loss: 17.194402
Epoch loss: 17.194402
train phase, Epoch 2/30, Loss: 18.415146
val phase, Epoch 2/30, Loss: 16.592042
Val Best Loss: 16.592042
Epoch loss: 16.592042
train phase, Epoch 3/30, Loss: 17.740156
val phase, Epoch 3/30, Loss: 20.316413
Val Best Loss: 16.592042
Epoch loss: 20.316413
train phase, Epoch 4/30, Loss: 17.442548
val phase, Epoch 4/30, Loss: 16.414343
Val Best Loss: 16.414343
Epoch loss: 16.414343
train phase, Epoch 5/30, Loss: 17.037930
val phase, Epoch 5/30, Loss: 16.324616
Val Best Loss: 16.324616
Epoch loss: 16.324616
train phase, Epoch 6/30, Loss: 16.551329
val phase, Epoch 6/30, Loss: 16.530517
Val Best Loss: 16.324616
Epoch loss: 16.530517
train phase, Epoch 7/30, Loss: 16.541329
val phase, Epoch 7/30, Loss: 18.079620
Val Best Loss: 16.324616
Epoch loss: 18.079620
train phase, Epoch 8/30, Loss: 16.135735
val phase, Epoch 8/30, Loss: 16.912034
Val Best Loss: 16.324616
Epoch loss: 16.912034
train phase, Epoch 9/30, Loss: 16.054717
val phase, Epoch 9/30, Loss: 20.673983
Val Best Loss: 16.324616
Epoch loss: 20.673983
train phase, Epoch 10/30, Loss: 16.142334
val phase, Epoch 10/30, Loss: 16.875267
Val Best Loss: 16.324616
Epoch loss: 16.875267
train phase, Epoch 11/30, Loss: 16.074749
val phase, Epoch 11/30, Loss: 17.844979
Val Best Loss: 16.324616
Epoch loss: 17.844979
train phase, Epoch 12/30, Loss: 15.759480
val phase, Epoch 12/30, Loss: 16.071113
Val Best Loss: 16.071113
Epoch loss: 16.071113
train phase, Epoch 13/30, Loss: 15.617818
val phase, Epoch 13/30, Loss: 16.565137
Val Best Loss: 16.071113
Epoch loss: 16.565137
train phase, Epoch 14/30, Loss: 15.775990
val phase, Epoch 14/30, Loss: 16.015858
Val Best Loss: 16.015858
Epoch loss: 16.015858
train phase, Epoch 15/30, Loss: 15.179036
val phase, Epoch 15/30, Loss: 16.329278
Val Best Loss: 16.015858
Epoch loss: 16.329278
train phase, Epoch 16/30, Loss: 15.429786
val phase, Epoch 16/30, Loss: 18.101287
Val Best Loss: 16.015858
Epoch loss: 18.101287
train phase, Epoch 17/30, Loss: 15.149509
val phase, Epoch 17/30, Loss: 16.121595
Val Best Loss: 16.015858
Epoch loss: 16.121595
train phase, Epoch 18/30, Loss: 14.601822
val phase, Epoch 18/30, Loss: 16.987806
Val Best Loss: 16.015858
Epoch loss: 16.987806
train phase, Epoch 19/30, Loss: 14.559744
val phase, Epoch 19/30, Loss: 16.069094
Val Best Loss: 16.015858
Epoch loss: 16.069094
train phase, Epoch 20/30, Loss: 14.324911
val phase, Epoch 20/30, Loss: 16.236165
Val Best Loss: 16.015858
Epoch loss: 16.236165
train phase, Epoch 21/30, Loss: 13.909480
val phase, Epoch 21/30, Loss: 16.490517
Val Best Loss: 16.015858
Epoch loss: 16.490517
train phase, Epoch 22/30, Loss: 13.743981
val phase, Epoch 22/30, Loss: 16.445360
Val Best Loss: 16.015858
Epoch loss: 16.445360
train phase, Epoch 23/30, Loss: 13.326807
val phase, Epoch 23/30, Loss: 16.958666
Val Best Loss: 16.015858
Epoch loss: 16.958666
train phase, Epoch 24/30, Loss: 13.118439
val phase, Epoch 24/30, Loss: 17.531339
Val Best Loss: 16.015858
Epoch loss: 17.531339
train phase, Epoch 25/30, Loss: 13.050808
val phase, Epoch 25/30, Loss: 18.480891
Val Best Loss: 16.015858
Epoch loss: 18.480891
train phase, Epoch 26/30, Loss: 12.267039
val phase, Epoch 26/30, Loss: 17.242937
Val Best Loss: 16.015858
Epoch loss: 17.242937
train phase, Epoch 27/30, Loss: 11.973542
val phase, Epoch 27/30, Loss: 17.415205
Val Best Loss: 16.015858
Epoch loss: 17.415205
train phase, Epoch 28/30, Loss: 11.432951
val phase, Epoch 28/30, Loss: 18.450768
Val Best Loss: 16.015858
Epoch loss: 18.450768
train phase, Epoch 29/30, Loss: 11.021665
val phase, Epoch 29/30, Loss: 18.412934
Val Best Loss: 16.015858
Epoch loss: 18.412934
train phase, Epoch 30/30, Loss: 10.488388
val phase, Epoch 30/30, Loss: 17.288834
Val Best Loss: 16.015858
Epoch loss: 17.288834
train phase, Epoch 1/20, Loss: 19.681001
val phase, Epoch 1/20, Loss: 17.950278
Val Best Loss: 17.950278
Epoch loss: 17.950278
train phase, Epoch 2/20, Loss: 17.949238
val phase, Epoch 2/20, Loss: 17.090220
Val Best Loss: 17.090220
Epoch loss: 17.090220
train phase, Epoch 3/20, Loss: 17.282540
val phase, Epoch 3/20, Loss: 17.037866
Val Best Loss: 17.037866
Epoch loss: 17.037866
train phase, Epoch 4/20, Loss: 17.262748
val phase, Epoch 4/20, Loss: 16.763714
Val Best Loss: 16.763714
Epoch loss: 16.763714
train phase, Epoch 5/20, Loss: 16.925551
val phase, Epoch 5/20, Loss: 20.110246
Val Best Loss: 16.763714
Epoch loss: 20.110246
train phase, Epoch 6/20, Loss: 16.779108
val phase, Epoch 6/20, Loss: 15.810443
Val Best Loss: 15.810443
Epoch loss: 15.810443
train phase, Epoch 7/20, Loss: 16.443678
val phase, Epoch 7/20, Loss: 16.013752
Val Best Loss: 15.810443
Epoch loss: 16.013752
train phase, Epoch 8/20, Loss: 16.498823
val phase, Epoch 8/20, Loss: 16.171923
Val Best Loss: 15.810443
Epoch loss: 16.171923
train phase, Epoch 9/20, Loss: 16.228970
val phase, Epoch 9/20, Loss: 16.250748
Val Best Loss: 15.810443
Epoch loss: 16.250748
train phase, Epoch 10/20, Loss: 15.972154
val phase, Epoch 10/20, Loss: 16.206003
Val Best Loss: 15.810443
Epoch loss: 16.206003
train phase, Epoch 11/20, Loss: 15.902502
val phase, Epoch 11/20, Loss: 16.926736
Val Best Loss: 15.810443
Epoch loss: 16.926736
train phase, Epoch 12/20, Loss: 15.801256
val phase, Epoch 12/20, Loss: 16.591098
Val Best Loss: 15.810443
Epoch loss: 16.591098
train phase, Epoch 13/20, Loss: 15.628906
val phase, Epoch 13/20, Loss: 15.865798
Val Best Loss: 15.810443
Epoch loss: 15.865798
train phase, Epoch 14/20, Loss: 15.379288
val phase, Epoch 14/20, Loss: 15.979480
Val Best Loss: 15.810443
Epoch loss: 15.979480
train phase, Epoch 15/20, Loss: 15.412099
val phase, Epoch 15/20, Loss: 15.835022
Val Best Loss: 15.810443
Epoch loss: 15.835022
train phase, Epoch 16/20, Loss: 15.319887
val phase, Epoch 16/20, Loss: 16.041661
Val Best Loss: 15.810443
Epoch loss: 16.041661
train phase, Epoch 17/20, Loss: 14.765034
val phase, Epoch 17/20, Loss: 16.227014
Val Best Loss: 15.810443
Epoch loss: 16.227014
train phase, Epoch 18/20, Loss: 14.800403
val phase, Epoch 18/20, Loss: 16.042773
Val Best Loss: 15.810443
Epoch loss: 16.042773
train phase, Epoch 19/20, Loss: 14.356143
val phase, Epoch 19/20, Loss: 16.325598
Val Best Loss: 15.810443
Epoch loss: 16.325598
train phase, Epoch 20/20, Loss: 14.288250
val phase, Epoch 20/20, Loss: 16.965890
Val Best Loss: 15.810443
Epoch loss: 16.965890
[Trial 263] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
[Trial 264] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 19.598963
val phase, Epoch 1/30, Loss: 27.272278
Val Best Loss: 27.272278
Epoch loss: 27.272278
train phase, Epoch 2/30, Loss: 17.825160
val phase, Epoch 2/30, Loss: 39.560993
Val Best Loss: 27.272278
Epoch loss: 39.560993
train phase, Epoch 3/30, Loss: 17.671111
val phase, Epoch 3/30, Loss: 35.531429
Val Best Loss: 27.272278
Epoch loss: 35.531429
train phase, Epoch 4/30, Loss: 17.048980
val phase, Epoch 4/30, Loss: 36.133614
Val Best Loss: 27.272278
Epoch loss: 36.133614
train phase, Epoch 5/30, Loss: 17.096360
val phase, Epoch 5/30, Loss: 52.857274
Val Best Loss: 27.272278
Epoch loss: 52.857274
train phase, Epoch 6/30, Loss: 16.937451
val phase, Epoch 6/30, Loss: 45.221519
Val Best Loss: 27.272278
Epoch loss: 45.221519
train phase, Epoch 7/30, Loss: 16.541223
val phase, Epoch 7/30, Loss: 38.363260
Val Best Loss: 27.272278
Epoch loss: 38.363260
train phase, Epoch 8/30, Loss: 16.628212
val phase, Epoch 8/30, Loss: 55.866641
Val Best Loss: 27.272278
Epoch loss: 55.866641
train phase, Epoch 9/30, Loss: 16.360802
val phase, Epoch 9/30, Loss: 106.929573
Val Best Loss: 27.272278
Epoch loss: 106.929573
train phase, Epoch 10/30, Loss: 16.101465
val phase, Epoch 10/30, Loss: 49.247477
Val Best Loss: 27.272278
Epoch loss: 49.247477
train phase, Epoch 11/30, Loss: 15.956627
val phase, Epoch 11/30, Loss: 72.295484
Val Best Loss: 27.272278
Epoch loss: 72.295484
train phase, Epoch 12/30, Loss: 16.025946
val phase, Epoch 12/30, Loss: 59.546808
Val Best Loss: 27.272278
Epoch loss: 59.546808
train phase, Epoch 13/30, Loss: 15.753496
val phase, Epoch 13/30, Loss: 59.512750
Val Best Loss: 27.272278
Epoch loss: 59.512750
train phase, Epoch 14/30, Loss: 15.466043
val phase, Epoch 14/30, Loss: 55.596802
Val Best Loss: 27.272278
Epoch loss: 55.596802
train phase, Epoch 15/30, Loss: 15.456625
val phase, Epoch 15/30, Loss: 52.650462
Val Best Loss: 27.272278
Epoch loss: 52.650462
train phase, Epoch 16/30, Loss: 15.008765
val phase, Epoch 16/30, Loss: 70.732934
Val Best Loss: 27.272278
Epoch loss: 70.732934
train phase, Epoch 17/30, Loss: 14.775902
val phase, Epoch 17/30, Loss: 80.077341
Val Best Loss: 27.272278
Epoch loss: 80.077341
train phase, Epoch 18/30, Loss: 14.546951
val phase, Epoch 18/30, Loss: 46.722968
Val Best Loss: 27.272278
Epoch loss: 46.722968
train phase, Epoch 19/30, Loss: 14.418747
val phase, Epoch 19/30, Loss: 59.245548
Val Best Loss: 27.272278
Epoch loss: 59.245548
train phase, Epoch 20/30, Loss: 14.138863
val phase, Epoch 20/30, Loss: 77.911086
Val Best Loss: 27.272278
Epoch loss: 77.911086
train phase, Epoch 21/30, Loss: 14.048354
val phase, Epoch 21/30, Loss: 71.152955
Val Best Loss: 27.272278
Epoch loss: 71.152955
train phase, Epoch 22/30, Loss: 13.748467
val phase, Epoch 22/30, Loss: 79.464846
Val Best Loss: 27.272278
Epoch loss: 79.464846
train phase, Epoch 23/30, Loss: 13.203093
val phase, Epoch 23/30, Loss: 60.471717
Val Best Loss: 27.272278
Epoch loss: 60.471717
train phase, Epoch 24/30, Loss: 12.951884
val phase, Epoch 24/30, Loss: 54.465276
Val Best Loss: 27.272278
Epoch loss: 54.465276
train phase, Epoch 25/30, Loss: 12.515514
val phase, Epoch 25/30, Loss: 87.267432
Val Best Loss: 27.272278
Epoch loss: 87.267432
train phase, Epoch 26/30, Loss: 12.069231
val phase, Epoch 26/30, Loss: 92.500529
Val Best Loss: 27.272278
Epoch loss: 92.500529
train phase, Epoch 27/30, Loss: 11.714555
val phase, Epoch 27/30, Loss: 107.891478
Val Best Loss: 27.272278
Epoch loss: 107.891478
train phase, Epoch 28/30, Loss: 11.587117
val phase, Epoch 28/30, Loss: 69.611026
Val Best Loss: 27.272278
Epoch loss: 69.611026
train phase, Epoch 29/30, Loss: 11.007533
val phase, Epoch 29/30, Loss: 142.399941
Val Best Loss: 27.272278
Epoch loss: 142.399941
train phase, Epoch 30/30, Loss: 10.615239
val phase, Epoch 30/30, Loss: 139.421503
Val Best Loss: 27.272278
Epoch loss: 139.421503
train phase, Epoch 1/20, Loss: 19.849299
val phase, Epoch 1/20, Loss: 19.087242
Val Best Loss: 19.087242
Epoch loss: 19.087242
train phase, Epoch 2/20, Loss: 17.786611
val phase, Epoch 2/20, Loss: 18.082972
Val Best Loss: 18.082972
Epoch loss: 18.082972
train phase, Epoch 3/20, Loss: 17.500343
val phase, Epoch 3/20, Loss: 16.309316
Val Best Loss: 16.309316
Epoch loss: 16.309316
train phase, Epoch 4/20, Loss: 17.226669
val phase, Epoch 4/20, Loss: 16.526708
Val Best Loss: 16.309316
Epoch loss: 16.526708
train phase, Epoch 5/20, Loss: 17.089103
val phase, Epoch 5/20, Loss: 17.143116
Val Best Loss: 16.309316
Epoch loss: 17.143116
train phase, Epoch 6/20, Loss: 16.526861
val phase, Epoch 6/20, Loss: 16.429676
Val Best Loss: 16.309316
Epoch loss: 16.429676
train phase, Epoch 7/20, Loss: 16.778777
val phase, Epoch 7/20, Loss: 15.797480
Val Best Loss: 15.797480
Epoch loss: 15.797480
train phase, Epoch 8/20, Loss: 16.271596
val phase, Epoch 8/20, Loss: 17.234202
Val Best Loss: 15.797480
Epoch loss: 17.234202
train phase, Epoch 9/20, Loss: 16.481379
val phase, Epoch 9/20, Loss: 17.740181
Val Best Loss: 15.797480
Epoch loss: 17.740181
train phase, Epoch 10/20, Loss: 16.071420
val phase, Epoch 10/20, Loss: 16.451377
Val Best Loss: 15.797480
Epoch loss: 16.451377
train phase, Epoch 11/20, Loss: 15.839084
val phase, Epoch 11/20, Loss: 17.037292
Val Best Loss: 15.797480
Epoch loss: 17.037292
train phase, Epoch 12/20, Loss: 15.683747
val phase, Epoch 12/20, Loss: 17.559346
Val Best Loss: 15.797480
Epoch loss: 17.559346
train phase, Epoch 13/20, Loss: 15.564850
val phase, Epoch 13/20, Loss: 15.959338
Val Best Loss: 15.797480
Epoch loss: 15.959338
train phase, Epoch 14/20, Loss: 15.356759
val phase, Epoch 14/20, Loss: 16.955639
Val Best Loss: 15.797480
Epoch loss: 16.955639
train phase, Epoch 15/20, Loss: 15.550388
val phase, Epoch 15/20, Loss: 16.354810
Val Best Loss: 15.797480
Epoch loss: 16.354810
train phase, Epoch 16/20, Loss: 14.999967
val phase, Epoch 16/20, Loss: 15.918867
Val Best Loss: 15.797480
Epoch loss: 15.918867
train phase, Epoch 17/20, Loss: 14.853106
val phase, Epoch 17/20, Loss: 16.432758
Val Best Loss: 15.797480
Epoch loss: 16.432758
train phase, Epoch 18/20, Loss: 14.855931
val phase, Epoch 18/20, Loss: 15.945287
Val Best Loss: 15.797480
Epoch loss: 15.945287
train phase, Epoch 19/20, Loss: 14.491480
val phase, Epoch 19/20, Loss: 16.237671
Val Best Loss: 15.797480
Epoch loss: 16.237671
train phase, Epoch 20/20, Loss: 14.310565
val phase, Epoch 20/20, Loss: 16.337577
Val Best Loss: 15.797480
Epoch loss: 16.337577
train phase, Epoch 1/20, Loss: 20.303609
val phase, Epoch 1/20, Loss: 17.443170
Val Best Loss: 17.443170
Epoch loss: 17.443170
train phase, Epoch 2/20, Loss: 18.245602
val phase, Epoch 2/20, Loss: 17.649443
Val Best Loss: 17.443170
Epoch loss: 17.649443
train phase, Epoch 3/20, Loss: 17.964106
val phase, Epoch 3/20, Loss: 17.005951
Val Best Loss: 17.005951
Epoch loss: 17.005951
train phase, Epoch 4/20, Loss: 17.295029
val phase, Epoch 4/20, Loss: 17.030569
Val Best Loss: 17.005951
Epoch loss: 17.030569
train phase, Epoch 5/20, Loss: 17.074875
val phase, Epoch 5/20, Loss: 17.020441
Val Best Loss: 17.005951
Epoch loss: 17.020441
train phase, Epoch 6/20, Loss: 17.145337
val phase, Epoch 6/20, Loss: 17.337914
Val Best Loss: 17.005951
Epoch loss: 17.337914
train phase, Epoch 7/20, Loss: 16.784500
val phase, Epoch 7/20, Loss: 17.645329
Val Best Loss: 17.005951
Epoch loss: 17.645329
train phase, Epoch 8/20, Loss: 16.625693
val phase, Epoch 8/20, Loss: 16.337222
Val Best Loss: 16.337222
Epoch loss: 16.337222
train phase, Epoch 9/20, Loss: 16.489315
val phase, Epoch 9/20, Loss: 17.537293
Val Best Loss: 16.337222
Epoch loss: 17.537293
train phase, Epoch 10/20, Loss: 16.462816
val phase, Epoch 10/20, Loss: 16.111593
Val Best Loss: 16.111593
Epoch loss: 16.111593
train phase, Epoch 11/20, Loss: 16.508060
val phase, Epoch 11/20, Loss: 17.205414
Val Best Loss: 16.111593
Epoch loss: 17.205414
train phase, Epoch 12/20, Loss: 16.303339
val phase, Epoch 12/20, Loss: 16.740389
Val Best Loss: 16.111593
Epoch loss: 16.740389
train phase, Epoch 13/20, Loss: 15.798630
val phase, Epoch 13/20, Loss: 20.798063
Val Best Loss: 16.111593
Epoch loss: 20.798063
train phase, Epoch 14/20, Loss: 15.889916
val phase, Epoch 14/20, Loss: 16.138972
Val Best Loss: 16.111593
Epoch loss: 16.138972
train phase, Epoch 15/20, Loss: 15.439494
val phase, Epoch 15/20, Loss: 16.183368
Val Best Loss: 16.111593
Epoch loss: 16.183368
train phase, Epoch 16/20, Loss: 15.623611
val phase, Epoch 16/20, Loss: 16.091031
Val Best Loss: 16.091031
Epoch loss: 16.091031
train phase, Epoch 17/20, Loss: 15.274656
val phase, Epoch 17/20, Loss: 16.101077
Val Best Loss: 16.091031
Epoch loss: 16.101077
train phase, Epoch 18/20, Loss: 15.254994
val phase, Epoch 18/20, Loss: 16.349756
Val Best Loss: 16.091031
Epoch loss: 16.349756
train phase, Epoch 19/20, Loss: 15.137651
val phase, Epoch 19/20, Loss: 16.528774
Val Best Loss: 16.091031
Epoch loss: 16.528774
train phase, Epoch 20/20, Loss: 14.855176
val phase, Epoch 20/20, Loss: 17.144115
Val Best Loss: 16.091031
Epoch loss: 17.144115
train phase, Epoch 1/30, Loss: 19.838226
val phase, Epoch 1/30, Loss: 16.764512
Val Best Loss: 16.764512
Epoch loss: 16.764512
train phase, Epoch 2/30, Loss: 17.779590
val phase, Epoch 2/30, Loss: 16.527001
Val Best Loss: 16.527001
Epoch loss: 16.527001
train phase, Epoch 3/30, Loss: 17.232300
val phase, Epoch 3/30, Loss: 16.910046
Val Best Loss: 16.527001
Epoch loss: 16.910046
train phase, Epoch 4/30, Loss: 17.287829
val phase, Epoch 4/30, Loss: 16.136871
Val Best Loss: 16.136871
Epoch loss: 16.136871
train phase, Epoch 5/30, Loss: 16.782835
val phase, Epoch 5/30, Loss: 15.832695
Val Best Loss: 15.832695
Epoch loss: 15.832695
train phase, Epoch 6/30, Loss: 16.723221
val phase, Epoch 6/30, Loss: 17.710651
Val Best Loss: 15.832695
Epoch loss: 17.710651
train phase, Epoch 7/30, Loss: 16.486276
val phase, Epoch 7/30, Loss: 16.152963
Val Best Loss: 15.832695
Epoch loss: 16.152963
train phase, Epoch 8/30, Loss: 16.471540
val phase, Epoch 8/30, Loss: 15.871096
Val Best Loss: 15.832695
Epoch loss: 15.871096
train phase, Epoch 9/30, Loss: 16.267743
val phase, Epoch 9/30, Loss: 16.552373
Val Best Loss: 15.832695
Epoch loss: 16.552373
train phase, Epoch 10/30, Loss: 15.905326
val phase, Epoch 10/30, Loss: 18.325987
Val Best Loss: 15.832695
Epoch loss: 18.325987
train phase, Epoch 11/30, Loss: 16.273899
val phase, Epoch 11/30, Loss: 15.700411
Val Best Loss: 15.700411
Epoch loss: 15.700411
train phase, Epoch 12/30, Loss: 15.651594
val phase, Epoch 12/30, Loss: 16.986132
Val Best Loss: 15.700411
Epoch loss: 16.986132
train phase, Epoch 13/30, Loss: 15.582569
val phase, Epoch 13/30, Loss: 16.679695
Val Best Loss: 15.700411
Epoch loss: 16.679695
train phase, Epoch 14/30, Loss: 15.580686
val phase, Epoch 14/30, Loss: 18.800010
Val Best Loss: 15.700411
Epoch loss: 18.800010
train phase, Epoch 15/30, Loss: 15.445570
val phase, Epoch 15/30, Loss: 15.835254
Val Best Loss: 15.700411
Epoch loss: 15.835254
train phase, Epoch 16/30, Loss: 15.036442
val phase, Epoch 16/30, Loss: 15.781701
Val Best Loss: 15.700411
Epoch loss: 15.781701
train phase, Epoch 17/30, Loss: 14.701251
val phase, Epoch 17/30, Loss: 17.485741
Val Best Loss: 15.700411
Epoch loss: 17.485741
train phase, Epoch 18/30, Loss: 14.738817
val phase, Epoch 18/30, Loss: 15.759863
Val Best Loss: 15.700411
Epoch loss: 15.759863
train phase, Epoch 19/30, Loss: 14.580557
val phase, Epoch 19/30, Loss: 16.027184
Val Best Loss: 15.700411
Epoch loss: 16.027184
train phase, Epoch 20/30, Loss: 14.786376
val phase, Epoch 20/30, Loss: 16.018514
Val Best Loss: 15.700411
Epoch loss: 16.018514
train phase, Epoch 21/30, Loss: 13.867232
val phase, Epoch 21/30, Loss: 16.860186
Val Best Loss: 15.700411
Epoch loss: 16.860186
train phase, Epoch 22/30, Loss: 14.091667
val phase, Epoch 22/30, Loss: 16.237711
Val Best Loss: 15.700411
Epoch loss: 16.237711
train phase, Epoch 23/30, Loss: 13.401208
val phase, Epoch 23/30, Loss: 17.089358
Val Best Loss: 15.700411
Epoch loss: 17.089358
train phase, Epoch 24/30, Loss: 13.402542
val phase, Epoch 24/30, Loss: 16.163394
Val Best Loss: 15.700411
Epoch loss: 16.163394
train phase, Epoch 25/30, Loss: 12.861532
val phase, Epoch 25/30, Loss: 16.317277
Val Best Loss: 15.700411
Epoch loss: 16.317277
train phase, Epoch 26/30, Loss: 12.655713
val phase, Epoch 26/30, Loss: 18.447029
Val Best Loss: 15.700411
Epoch loss: 18.447029
train phase, Epoch 27/30, Loss: 12.223273
val phase, Epoch 27/30, Loss: 17.337248
Val Best Loss: 15.700411
Epoch loss: 17.337248
train phase, Epoch 28/30, Loss: 11.886276
val phase, Epoch 28/30, Loss: 17.458398
Val Best Loss: 15.700411
Epoch loss: 17.458398
train phase, Epoch 29/30, Loss: 11.442189
val phase, Epoch 29/30, Loss: 17.780520
Val Best Loss: 15.700411
Epoch loss: 17.780520
train phase, Epoch 30/30, Loss: 11.025815
val phase, Epoch 30/30, Loss: 17.807899
Val Best Loss: 15.700411
Epoch loss: 17.807899
train phase, Epoch 1/20, Loss: 20.033087
val phase, Epoch 1/20, Loss: 19.622410
Val Best Loss: 19.622410
Epoch loss: 19.622410
train phase, Epoch 2/20, Loss: 17.708137
val phase, Epoch 2/20, Loss: 16.434982
Val Best Loss: 16.434982
Epoch loss: 16.434982
train phase, Epoch 3/20, Loss: 17.113448
val phase, Epoch 3/20, Loss: 17.096491
Val Best Loss: 16.434982
Epoch loss: 17.096491
train phase, Epoch 4/20, Loss: 16.812075
val phase, Epoch 4/20, Loss: 16.254068
Val Best Loss: 16.254068
Epoch loss: 16.254068
train phase, Epoch 5/20, Loss: 16.653414
val phase, Epoch 5/20, Loss: 16.048437
Val Best Loss: 16.048437
Epoch loss: 16.048437
train phase, Epoch 6/20, Loss: 16.466146
val phase, Epoch 6/20, Loss: 17.031707
Val Best Loss: 16.048437
Epoch loss: 17.031707
train phase, Epoch 7/20, Loss: 16.304938
val phase, Epoch 7/20, Loss: 17.727174
Val Best Loss: 16.048437
Epoch loss: 17.727174
train phase, Epoch 8/20, Loss: 16.124717
val phase, Epoch 8/20, Loss: 16.116885
Val Best Loss: 16.048437
Epoch loss: 16.116885
train phase, Epoch 9/20, Loss: 15.917576
val phase, Epoch 9/20, Loss: 16.245739
Val Best Loss: 16.048437
Epoch loss: 16.245739
train phase, Epoch 10/20, Loss: 15.642789
val phase, Epoch 10/20, Loss: 16.756908
Val Best Loss: 16.048437
Epoch loss: 16.756908
train phase, Epoch 11/20, Loss: 15.714998
val phase, Epoch 11/20, Loss: 17.262834
Val Best Loss: 16.048437
Epoch loss: 17.262834
train phase, Epoch 12/20, Loss: 15.385336
val phase, Epoch 12/20, Loss: 16.526295
Val Best Loss: 16.048437
Epoch loss: 16.526295
train phase, Epoch 13/20, Loss: 15.165605
val phase, Epoch 13/20, Loss: 16.258787
Val Best Loss: 16.048437
Epoch loss: 16.258787
train phase, Epoch 14/20, Loss: 14.873327
val phase, Epoch 14/20, Loss: 16.428398
Val Best Loss: 16.048437
Epoch loss: 16.428398
train phase, Epoch 15/20, Loss: 14.803668
val phase, Epoch 15/20, Loss: 17.051214
Val Best Loss: 16.048437
Epoch loss: 17.051214
train phase, Epoch 16/20, Loss: 14.684870
val phase, Epoch 16/20, Loss: 16.360095
Val Best Loss: 16.048437
Epoch loss: 16.360095
train phase, Epoch 17/20, Loss: 14.187146
val phase, Epoch 17/20, Loss: 17.960069
Val Best Loss: 16.048437
Epoch loss: 17.960069
train phase, Epoch 18/20, Loss: 13.942169
val phase, Epoch 18/20, Loss: 17.919632
Val Best Loss: 16.048437
Epoch loss: 17.919632
train phase, Epoch 19/20, Loss: 13.719214
val phase, Epoch 19/20, Loss: 16.892389
Val Best Loss: 16.048437
Epoch loss: 16.892389
train phase, Epoch 20/20, Loss: 13.533555
val phase, Epoch 20/20, Loss: 16.956039
Val Best Loss: 16.048437
Epoch loss: 16.956039
train phase, Epoch 1/20, Loss: 30.395420
val phase, Epoch 1/20, Loss: 18.177971
Val Best Loss: 18.177971
Epoch loss: 18.177971
train phase, Epoch 2/20, Loss: 18.430405
val phase, Epoch 2/20, Loss: 18.267205
Val Best Loss: 18.177971
Epoch loss: 18.267205
train phase, Epoch 3/20, Loss: 18.523289
val phase, Epoch 3/20, Loss: 17.617503
Val Best Loss: 17.617503
Epoch loss: 17.617503
train phase, Epoch 4/20, Loss: 17.627628
val phase, Epoch 4/20, Loss: 17.240967
Val Best Loss: 17.240967
Epoch loss: 17.240967
train phase, Epoch 5/20, Loss: 17.522181
val phase, Epoch 5/20, Loss: 16.986820
Val Best Loss: 16.986820
Epoch loss: 16.986820
train phase, Epoch 6/20, Loss: 17.419381
val phase, Epoch 6/20, Loss: 18.924897
Val Best Loss: 16.986820
Epoch loss: 18.924897
train phase, Epoch 7/20, Loss: 17.335136
val phase, Epoch 7/20, Loss: 17.441497
Val Best Loss: 16.986820
Epoch loss: 17.441497
train phase, Epoch 8/20, Loss: 16.999079
val phase, Epoch 8/20, Loss: 17.543487
Val Best Loss: 16.986820
Epoch loss: 17.543487
train phase, Epoch 9/20, Loss: 16.738574
val phase, Epoch 9/20, Loss: 18.094746
Val Best Loss: 16.986820
Epoch loss: 18.094746
train phase, Epoch 10/20, Loss: 16.675617
val phase, Epoch 10/20, Loss: 16.517380
Val Best Loss: 16.517380
Epoch loss: 16.517380
train phase, Epoch 11/20, Loss: 16.481491
val phase, Epoch 11/20, Loss: 19.858986
Val Best Loss: 16.517380
Epoch loss: 19.858986
train phase, Epoch 12/20, Loss: 17.021443
val phase, Epoch 12/20, Loss: 16.474000
Val Best Loss: 16.474000
Epoch loss: 16.474000
train phase, Epoch 13/20, Loss: 16.450925
val phase, Epoch 13/20, Loss: 19.754919
Val Best Loss: 16.474000
Epoch loss: 19.754919
train phase, Epoch 14/20, Loss: 16.635443
val phase, Epoch 14/20, Loss: 16.444324
Val Best Loss: 16.444324
Epoch loss: 16.444324
train phase, Epoch 15/20, Loss: 16.336156
val phase, Epoch 15/20, Loss: 17.004204
Val Best Loss: 16.444324
Epoch loss: 17.004204
train phase, Epoch 16/20, Loss: 16.248990
val phase, Epoch 16/20, Loss: 16.830394
Val Best Loss: 16.444324
Epoch loss: 16.830394
train phase, Epoch 17/20, Loss: 16.387898
val phase, Epoch 17/20, Loss: 16.646540
Val Best Loss: 16.444324
Epoch loss: 16.646540
train phase, Epoch 18/20, Loss: 15.927961
val phase, Epoch 18/20, Loss: 16.515606
Val Best Loss: 16.444324
Epoch loss: 16.515606
train phase, Epoch 19/20, Loss: 16.246863
val phase, Epoch 19/20, Loss: 16.776982
Val Best Loss: 16.444324
Epoch loss: 16.776982
train phase, Epoch 20/20, Loss: 15.683220
val phase, Epoch 20/20, Loss: 16.811084
Val Best Loss: 16.444324
Epoch loss: 16.811084
train phase, Epoch 1/20, Loss: 19.741942
val phase, Epoch 1/20, Loss: 19.370365
Val Best Loss: 19.370365
Epoch loss: 19.370365
train phase, Epoch 2/20, Loss: 18.398784
val phase, Epoch 2/20, Loss: 16.812859
Val Best Loss: 16.812859
Epoch loss: 16.812859
train phase, Epoch 3/20, Loss: 17.494515
val phase, Epoch 3/20, Loss: 16.562885
Val Best Loss: 16.562885
Epoch loss: 16.562885
train phase, Epoch 4/20, Loss: 17.370735
val phase, Epoch 4/20, Loss: 16.466915
Val Best Loss: 16.466915
Epoch loss: 16.466915
train phase, Epoch 5/20, Loss: 16.910630
val phase, Epoch 5/20, Loss: 16.155983
Val Best Loss: 16.155983
Epoch loss: 16.155983
train phase, Epoch 6/20, Loss: 16.632136
val phase, Epoch 6/20, Loss: 19.208098
Val Best Loss: 16.155983
Epoch loss: 19.208098
train phase, Epoch 7/20, Loss: 16.551352
val phase, Epoch 7/20, Loss: 17.056715
Val Best Loss: 16.155983
Epoch loss: 17.056715
train phase, Epoch 8/20, Loss: 16.503283
val phase, Epoch 8/20, Loss: 17.153928
Val Best Loss: 16.155983
Epoch loss: 17.153928
train phase, Epoch 9/20, Loss: 16.115937
val phase, Epoch 9/20, Loss: 16.386877
Val Best Loss: 16.155983
Epoch loss: 16.386877
train phase, Epoch 10/20, Loss: 16.330252
val phase, Epoch 10/20, Loss: 15.991742
Val Best Loss: 15.991742
Epoch loss: 15.991742
train phase, Epoch 11/20, Loss: 15.772039
val phase, Epoch 11/20, Loss: 16.169951
Val Best Loss: 15.991742
Epoch loss: 16.169951
train phase, Epoch 12/20, Loss: 15.674284
val phase, Epoch 12/20, Loss: 17.318933
Val Best Loss: 15.991742
Epoch loss: 17.318933
train phase, Epoch 13/20, Loss: 15.592973
val phase, Epoch 13/20, Loss: 16.204249
Val Best Loss: 15.991742
Epoch loss: 16.204249
train phase, Epoch 14/20, Loss: 15.433484
val phase, Epoch 14/20, Loss: 18.691153
Val Best Loss: 15.991742
Epoch loss: 18.691153
train phase, Epoch 15/20, Loss: 15.012515
val phase, Epoch 15/20, Loss: 16.287972
Val Best Loss: 15.991742
Epoch loss: 16.287972
train phase, Epoch 16/20, Loss: 14.918435
val phase, Epoch 16/20, Loss: 18.508226
Val Best Loss: 15.991742
Epoch loss: 18.508226
train phase, Epoch 17/20, Loss: 14.950075
val phase, Epoch 17/20, Loss: 17.225774
Val Best Loss: 15.991742
Epoch loss: 17.225774
train phase, Epoch 18/20, Loss: 14.722999
val phase, Epoch 18/20, Loss: 17.089939
Val Best Loss: 15.991742
Epoch loss: 17.089939
train phase, Epoch 19/20, Loss: 14.298644
val phase, Epoch 19/20, Loss: 16.468852
Val Best Loss: 15.991742
Epoch loss: 16.468852
train phase, Epoch 20/20, Loss: 13.993127
val phase, Epoch 20/20, Loss: 18.133950
Val Best Loss: 15.991742
Epoch loss: 18.133950
train phase, Epoch 1/15, Loss: 20.575692
val phase, Epoch 1/15, Loss: 18.183524
Val Best Loss: 18.183524
Epoch loss: 18.183524
train phase, Epoch 2/15, Loss: 17.198809
val phase, Epoch 2/15, Loss: 16.676178
Val Best Loss: 16.676178
Epoch loss: 16.676178
train phase, Epoch 3/15, Loss: 17.250687
val phase, Epoch 3/15, Loss: 17.920533
Val Best Loss: 16.676178
Epoch loss: 17.920533
train phase, Epoch 4/15, Loss: 16.926867
val phase, Epoch 4/15, Loss: 19.962708
Val Best Loss: 16.676178
Epoch loss: 19.962708
train phase, Epoch 5/15, Loss: 16.282640
val phase, Epoch 5/15, Loss: 17.048147
Val Best Loss: 16.676178
Epoch loss: 17.048147
train phase, Epoch 6/15, Loss: 16.442586
val phase, Epoch 6/15, Loss: 18.541596
Val Best Loss: 16.676178
Epoch loss: 18.541596
train phase, Epoch 7/15, Loss: 16.190142
val phase, Epoch 7/15, Loss: 16.420531
Val Best Loss: 16.420531
Epoch loss: 16.420531
train phase, Epoch 8/15, Loss: 16.092235
val phase, Epoch 8/15, Loss: 16.301459
Val Best Loss: 16.301459
Epoch loss: 16.301459
train phase, Epoch 9/15, Loss: 15.782851
val phase, Epoch 9/15, Loss: 16.917030
Val Best Loss: 16.301459
Epoch loss: 16.917030
train phase, Epoch 10/15, Loss: 15.802177
val phase, Epoch 10/15, Loss: 16.257064
Val Best Loss: 16.257064
Epoch loss: 16.257064
train phase, Epoch 11/15, Loss: 15.716551
val phase, Epoch 11/15, Loss: 16.769153
Val Best Loss: 16.257064
Epoch loss: 16.769153
train phase, Epoch 12/15, Loss: 15.389605
val phase, Epoch 12/15, Loss: 16.604578
Val Best Loss: 16.257064
Epoch loss: 16.604578
train phase, Epoch 13/15, Loss: 14.978397
val phase, Epoch 13/15, Loss: 17.311766
Val Best Loss: 16.257064
Epoch loss: 17.311766
train phase, Epoch 14/15, Loss: 14.773562
val phase, Epoch 14/15, Loss: 16.122459
Val Best Loss: 16.122459
Epoch loss: 16.122459
train phase, Epoch 15/15, Loss: 14.701340
val phase, Epoch 15/15, Loss: 16.052033
Val Best Loss: 16.052033
Epoch loss: 16.052033
[Trial 273] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.632773
val phase, Epoch 1/20, Loss: 17.080184
Val Best Loss: 17.080184
Epoch loss: 17.080184
train phase, Epoch 2/20, Loss: 17.617334
val phase, Epoch 2/20, Loss: 16.626188
Val Best Loss: 16.626188
Epoch loss: 16.626188
train phase, Epoch 3/20, Loss: 17.322548
val phase, Epoch 3/20, Loss: 16.543834
Val Best Loss: 16.543834
Epoch loss: 16.543834
train phase, Epoch 4/20, Loss: 17.096006
val phase, Epoch 4/20, Loss: 16.270934
Val Best Loss: 16.270934
Epoch loss: 16.270934
train phase, Epoch 5/20, Loss: 16.641085
val phase, Epoch 5/20, Loss: 16.685469
Val Best Loss: 16.270934
Epoch loss: 16.685469
train phase, Epoch 6/20, Loss: 16.466321
val phase, Epoch 6/20, Loss: 16.423638
Val Best Loss: 16.270934
Epoch loss: 16.423638
train phase, Epoch 7/20, Loss: 16.335113
val phase, Epoch 7/20, Loss: 16.935997
Val Best Loss: 16.270934
Epoch loss: 16.935997
train phase, Epoch 8/20, Loss: 16.314229
val phase, Epoch 8/20, Loss: 19.234251
Val Best Loss: 16.270934
Epoch loss: 19.234251
train phase, Epoch 9/20, Loss: 16.137018
val phase, Epoch 9/20, Loss: 18.456792
Val Best Loss: 16.270934
Epoch loss: 18.456792
train phase, Epoch 10/20, Loss: 16.220812
val phase, Epoch 10/20, Loss: 15.905771
Val Best Loss: 15.905771
Epoch loss: 15.905771
train phase, Epoch 11/20, Loss: 15.731699
val phase, Epoch 11/20, Loss: 16.541623
Val Best Loss: 15.905771
Epoch loss: 16.541623
train phase, Epoch 12/20, Loss: 15.829943
val phase, Epoch 12/20, Loss: 16.216751
Val Best Loss: 15.905771
Epoch loss: 16.216751
train phase, Epoch 13/20, Loss: 15.233853
val phase, Epoch 13/20, Loss: 17.304199
Val Best Loss: 15.905771
Epoch loss: 17.304199
train phase, Epoch 14/20, Loss: 15.189873
val phase, Epoch 14/20, Loss: 15.995605
Val Best Loss: 15.905771
Epoch loss: 15.995605
train phase, Epoch 15/20, Loss: 14.948496
val phase, Epoch 15/20, Loss: 16.488458
Val Best Loss: 15.905771
Epoch loss: 16.488458
train phase, Epoch 16/20, Loss: 14.752353
val phase, Epoch 16/20, Loss: 16.403785
Val Best Loss: 15.905771
Epoch loss: 16.403785
train phase, Epoch 17/20, Loss: 14.626342
val phase, Epoch 17/20, Loss: 16.235381
Val Best Loss: 15.905771
Epoch loss: 16.235381
train phase, Epoch 18/20, Loss: 14.139664
val phase, Epoch 18/20, Loss: 16.431057
Val Best Loss: 15.905771
Epoch loss: 16.431057
train phase, Epoch 19/20, Loss: 13.943287
val phase, Epoch 19/20, Loss: 17.372405
Val Best Loss: 15.905771
Epoch loss: 17.372405
train phase, Epoch 20/20, Loss: 13.867005
val phase, Epoch 20/20, Loss: 17.474395
Val Best Loss: 15.905771
Epoch loss: 17.474395
train phase, Epoch 1/20, Loss: 19.813035
val phase, Epoch 1/20, Loss: 17.418540
Val Best Loss: 17.418540
Epoch loss: 17.418540
train phase, Epoch 2/20, Loss: 17.741526
val phase, Epoch 2/20, Loss: 20.100191
Val Best Loss: 17.418540
Epoch loss: 20.100191
train phase, Epoch 3/20, Loss: 17.168834
val phase, Epoch 3/20, Loss: 16.406937
Val Best Loss: 16.406937
Epoch loss: 16.406937
train phase, Epoch 4/20, Loss: 17.158438
val phase, Epoch 4/20, Loss: 18.733413
Val Best Loss: 16.406937
Epoch loss: 18.733413
train phase, Epoch 5/20, Loss: 16.811440
val phase, Epoch 5/20, Loss: 17.088911
Val Best Loss: 16.406937
Epoch loss: 17.088911
train phase, Epoch 6/20, Loss: 16.371465
val phase, Epoch 6/20, Loss: 16.102440
Val Best Loss: 16.102440
Epoch loss: 16.102440
train phase, Epoch 7/20, Loss: 16.365754
val phase, Epoch 7/20, Loss: 23.440484
Val Best Loss: 16.102440
Epoch loss: 23.440484
train phase, Epoch 8/20, Loss: 16.530171
val phase, Epoch 8/20, Loss: 16.504900
Val Best Loss: 16.102440
Epoch loss: 16.504900
train phase, Epoch 9/20, Loss: 16.439263
val phase, Epoch 9/20, Loss: 15.747032
Val Best Loss: 15.747032
Epoch loss: 15.747032
train phase, Epoch 10/20, Loss: 15.730667
val phase, Epoch 10/20, Loss: 16.906578
Val Best Loss: 15.747032
Epoch loss: 16.906578
train phase, Epoch 11/20, Loss: 15.653770
val phase, Epoch 11/20, Loss: 16.093401
Val Best Loss: 15.747032
Epoch loss: 16.093401
train phase, Epoch 12/20, Loss: 15.478620
val phase, Epoch 12/20, Loss: 16.550114
Val Best Loss: 15.747032
Epoch loss: 16.550114
train phase, Epoch 13/20, Loss: 15.311369
val phase, Epoch 13/20, Loss: 15.998988
Val Best Loss: 15.747032
Epoch loss: 15.998988
train phase, Epoch 14/20, Loss: 15.171475
val phase, Epoch 14/20, Loss: 16.096801
Val Best Loss: 15.747032
Epoch loss: 16.096801
train phase, Epoch 15/20, Loss: 14.826995
val phase, Epoch 15/20, Loss: 15.909777
Val Best Loss: 15.747032
Epoch loss: 15.909777
train phase, Epoch 16/20, Loss: 14.774334
val phase, Epoch 16/20, Loss: 16.488735
Val Best Loss: 15.747032
Epoch loss: 16.488735
train phase, Epoch 17/20, Loss: 14.582483
val phase, Epoch 17/20, Loss: 16.475809
Val Best Loss: 15.747032
Epoch loss: 16.475809
train phase, Epoch 18/20, Loss: 14.379996
val phase, Epoch 18/20, Loss: 17.558062
Val Best Loss: 15.747032
Epoch loss: 17.558062
train phase, Epoch 19/20, Loss: 13.829071
val phase, Epoch 19/20, Loss: 16.263921
Val Best Loss: 15.747032
Epoch loss: 16.263921
train phase, Epoch 20/20, Loss: 13.593014
val phase, Epoch 20/20, Loss: 16.738253
Val Best Loss: 15.747032
Epoch loss: 16.738253
train phase, Epoch 1/12, Loss: 20.749644
val phase, Epoch 1/12, Loss: 22.260749
Val Best Loss: 22.260749
Epoch loss: 22.260749
train phase, Epoch 2/12, Loss: 18.748152
val phase, Epoch 2/12, Loss: 17.709496
Val Best Loss: 17.709496
Epoch loss: 17.709496
train phase, Epoch 3/12, Loss: 18.239616
val phase, Epoch 3/12, Loss: 18.616779
Val Best Loss: 17.709496
Epoch loss: 18.616779
train phase, Epoch 4/12, Loss: 17.851538
val phase, Epoch 4/12, Loss: 17.150538
Val Best Loss: 17.150538
Epoch loss: 17.150538
train phase, Epoch 5/12, Loss: 17.671795
val phase, Epoch 5/12, Loss: 19.181753
Val Best Loss: 17.150538
Epoch loss: 19.181753
train phase, Epoch 6/12, Loss: 17.374136
val phase, Epoch 6/12, Loss: 17.387353
Val Best Loss: 17.150538
Epoch loss: 17.387353
train phase, Epoch 7/12, Loss: 17.197183
val phase, Epoch 7/12, Loss: 17.225177
Val Best Loss: 17.150538
Epoch loss: 17.225177
train phase, Epoch 8/12, Loss: 17.004250
val phase, Epoch 8/12, Loss: 17.310262
Val Best Loss: 17.150538
Epoch loss: 17.310262
train phase, Epoch 9/12, Loss: 16.671363
val phase, Epoch 9/12, Loss: 16.754616
Val Best Loss: 16.754616
Epoch loss: 16.754616
train phase, Epoch 10/12, Loss: 16.700554
val phase, Epoch 10/12, Loss: 17.349775
Val Best Loss: 16.754616
Epoch loss: 17.349775
train phase, Epoch 11/12, Loss: 16.503870
val phase, Epoch 11/12, Loss: 16.624437
Val Best Loss: 16.624437
Epoch loss: 16.624437
train phase, Epoch 12/12, Loss: 16.270098
val phase, Epoch 12/12, Loss: 16.763420
Val Best Loss: 16.624437
Epoch loss: 16.763420
[Trial 277] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 19.927768
val phase, Epoch 1/30, Loss: 16.872117
Val Best Loss: 16.872117
Epoch loss: 16.872117
train phase, Epoch 2/30, Loss: 17.478218
val phase, Epoch 2/30, Loss: 17.257166
Val Best Loss: 16.872117
Epoch loss: 17.257166
train phase, Epoch 3/30, Loss: 17.179277
val phase, Epoch 3/30, Loss: 16.278661
Val Best Loss: 16.278661
Epoch loss: 16.278661
train phase, Epoch 4/30, Loss: 16.925957
val phase, Epoch 4/30, Loss: 16.423462
Val Best Loss: 16.278661
Epoch loss: 16.423462
train phase, Epoch 5/30, Loss: 16.774348
val phase, Epoch 5/30, Loss: 16.181314
Val Best Loss: 16.181314
Epoch loss: 16.181314
train phase, Epoch 6/30, Loss: 16.358514
val phase, Epoch 6/30, Loss: 16.413731
Val Best Loss: 16.181314
Epoch loss: 16.413731
train phase, Epoch 7/30, Loss: 16.139863
val phase, Epoch 7/30, Loss: 16.382214
Val Best Loss: 16.181314
Epoch loss: 16.382214
train phase, Epoch 8/30, Loss: 15.888832
val phase, Epoch 8/30, Loss: 17.413567
Val Best Loss: 16.181314
Epoch loss: 17.413567
train phase, Epoch 9/30, Loss: 15.865367
val phase, Epoch 9/30, Loss: 15.885773
Val Best Loss: 15.885773
Epoch loss: 15.885773
train phase, Epoch 10/30, Loss: 15.748631
val phase, Epoch 10/30, Loss: 16.291709
Val Best Loss: 15.885773
Epoch loss: 16.291709
train phase, Epoch 11/30, Loss: 15.643591
val phase, Epoch 11/30, Loss: 16.597997
Val Best Loss: 15.885773
Epoch loss: 16.597997
train phase, Epoch 12/30, Loss: 15.383318
val phase, Epoch 12/30, Loss: 16.192787
Val Best Loss: 15.885773
Epoch loss: 16.192787
train phase, Epoch 13/30, Loss: 15.103628
val phase, Epoch 13/30, Loss: 17.011957
Val Best Loss: 15.885773
Epoch loss: 17.011957
train phase, Epoch 14/30, Loss: 15.105609
val phase, Epoch 14/30, Loss: 16.403249
Val Best Loss: 15.885773
Epoch loss: 16.403249
train phase, Epoch 15/30, Loss: 14.816450
val phase, Epoch 15/30, Loss: 17.100252
Val Best Loss: 15.885773
Epoch loss: 17.100252
train phase, Epoch 16/30, Loss: 14.448519
val phase, Epoch 16/30, Loss: 15.857632
Val Best Loss: 15.857632
Epoch loss: 15.857632
train phase, Epoch 17/30, Loss: 14.293433
val phase, Epoch 17/30, Loss: 16.240611
Val Best Loss: 15.857632
Epoch loss: 16.240611
train phase, Epoch 18/30, Loss: 13.975723
val phase, Epoch 18/30, Loss: 17.233118
Val Best Loss: 15.857632
Epoch loss: 17.233118
train phase, Epoch 19/30, Loss: 13.713268
val phase, Epoch 19/30, Loss: 16.561213
Val Best Loss: 15.857632
Epoch loss: 16.561213
train phase, Epoch 20/30, Loss: 13.343475
val phase, Epoch 20/30, Loss: 17.014795
Val Best Loss: 15.857632
Epoch loss: 17.014795
train phase, Epoch 21/30, Loss: 13.021915
val phase, Epoch 21/30, Loss: 17.583982
Val Best Loss: 15.857632
Epoch loss: 17.583982
train phase, Epoch 22/30, Loss: 12.628439
val phase, Epoch 22/30, Loss: 17.065464
Val Best Loss: 15.857632
Epoch loss: 17.065464
train phase, Epoch 23/30, Loss: 12.245360
val phase, Epoch 23/30, Loss: 19.553853
Val Best Loss: 15.857632
Epoch loss: 19.553853
train phase, Epoch 24/30, Loss: 11.840472
val phase, Epoch 24/30, Loss: 17.008762
Val Best Loss: 15.857632
Epoch loss: 17.008762
train phase, Epoch 25/30, Loss: 11.190793
val phase, Epoch 25/30, Loss: 18.011208
Val Best Loss: 15.857632
Epoch loss: 18.011208
train phase, Epoch 26/30, Loss: 10.770266
val phase, Epoch 26/30, Loss: 18.553993
Val Best Loss: 15.857632
Epoch loss: 18.553993
train phase, Epoch 27/30, Loss: 10.133830
val phase, Epoch 27/30, Loss: 19.811879
Val Best Loss: 15.857632
Epoch loss: 19.811879
train phase, Epoch 28/30, Loss: 9.730005
val phase, Epoch 28/30, Loss: 18.042631
Val Best Loss: 15.857632
Epoch loss: 18.042631
train phase, Epoch 29/30, Loss: 9.174953
val phase, Epoch 29/30, Loss: 18.813870
Val Best Loss: 15.857632
Epoch loss: 18.813870
train phase, Epoch 30/30, Loss: 8.779002
val phase, Epoch 30/30, Loss: 20.259507
Val Best Loss: 15.857632
Epoch loss: 20.259507
train phase, Epoch 1/20, Loss: 20.586271
val phase, Epoch 1/20, Loss: 17.542834
Val Best Loss: 17.542834
Epoch loss: 17.542834
train phase, Epoch 2/20, Loss: 18.093916
val phase, Epoch 2/20, Loss: 18.306539
Val Best Loss: 17.542834
Epoch loss: 18.306539
train phase, Epoch 3/20, Loss: 17.756141
val phase, Epoch 3/20, Loss: 16.838238
Val Best Loss: 16.838238
Epoch loss: 16.838238
train phase, Epoch 4/20, Loss: 17.133731
val phase, Epoch 4/20, Loss: 16.900595
Val Best Loss: 16.838238
Epoch loss: 16.900595
train phase, Epoch 5/20, Loss: 17.342989
val phase, Epoch 5/20, Loss: 18.563157
Val Best Loss: 16.838238
Epoch loss: 18.563157
train phase, Epoch 6/20, Loss: 16.855660
val phase, Epoch 6/20, Loss: 18.546342
Val Best Loss: 16.838238
Epoch loss: 18.546342
train phase, Epoch 7/20, Loss: 16.755500
val phase, Epoch 7/20, Loss: 16.954803
Val Best Loss: 16.838238
Epoch loss: 16.954803
train phase, Epoch 8/20, Loss: 16.597929
val phase, Epoch 8/20, Loss: 16.066909
Val Best Loss: 16.066909
Epoch loss: 16.066909
train phase, Epoch 9/20, Loss: 16.231554
val phase, Epoch 9/20, Loss: 16.232584
Val Best Loss: 16.066909
Epoch loss: 16.232584
train phase, Epoch 10/20, Loss: 16.143044
val phase, Epoch 10/20, Loss: 17.695859
Val Best Loss: 16.066909
Epoch loss: 17.695859
train phase, Epoch 11/20, Loss: 15.854781
val phase, Epoch 11/20, Loss: 16.447630
Val Best Loss: 16.066909
Epoch loss: 16.447630
train phase, Epoch 12/20, Loss: 15.968246
val phase, Epoch 12/20, Loss: 21.047851
Val Best Loss: 16.066909
Epoch loss: 21.047851
train phase, Epoch 13/20, Loss: 16.105762
val phase, Epoch 13/20, Loss: 16.463226
Val Best Loss: 16.066909
Epoch loss: 16.463226
train phase, Epoch 14/20, Loss: 15.812605
val phase, Epoch 14/20, Loss: 17.602403
Val Best Loss: 16.066909
Epoch loss: 17.602403
train phase, Epoch 15/20, Loss: 15.423406
val phase, Epoch 15/20, Loss: 17.040412
Val Best Loss: 16.066909
Epoch loss: 17.040412
train phase, Epoch 16/20, Loss: 15.195615
val phase, Epoch 16/20, Loss: 16.662140
Val Best Loss: 16.066909
Epoch loss: 16.662140
train phase, Epoch 17/20, Loss: 15.219841
val phase, Epoch 17/20, Loss: 16.107627
Val Best Loss: 16.066909
Epoch loss: 16.107627
train phase, Epoch 18/20, Loss: 14.720173
val phase, Epoch 18/20, Loss: 16.094965
Val Best Loss: 16.066909
Epoch loss: 16.094965
train phase, Epoch 19/20, Loss: 14.569558
val phase, Epoch 19/20, Loss: 16.359368
Val Best Loss: 16.066909
Epoch loss: 16.359368
train phase, Epoch 20/20, Loss: 14.264346
val phase, Epoch 20/20, Loss: 17.721057
Val Best Loss: 16.066909
Epoch loss: 17.721057
train phase, Epoch 1/20, Loss: 20.733202
val phase, Epoch 1/20, Loss: 17.094284
Val Best Loss: 17.094284
Epoch loss: 17.094284
train phase, Epoch 2/20, Loss: 17.998647
val phase, Epoch 2/20, Loss: 20.900820
Val Best Loss: 17.094284
Epoch loss: 20.900820
train phase, Epoch 3/20, Loss: 17.667178
val phase, Epoch 3/20, Loss: 17.773842
Val Best Loss: 17.094284
Epoch loss: 17.773842
train phase, Epoch 4/20, Loss: 17.093682
val phase, Epoch 4/20, Loss: 16.338375
Val Best Loss: 16.338375
Epoch loss: 16.338375
train phase, Epoch 5/20, Loss: 17.094401
val phase, Epoch 5/20, Loss: 19.761119
Val Best Loss: 16.338375
Epoch loss: 19.761119
train phase, Epoch 6/20, Loss: 16.587098
val phase, Epoch 6/20, Loss: 17.039531
Val Best Loss: 16.338375
Epoch loss: 17.039531
train phase, Epoch 7/20, Loss: 16.729287
val phase, Epoch 7/20, Loss: 17.203529
Val Best Loss: 16.338375
Epoch loss: 17.203529
train phase, Epoch 8/20, Loss: 16.338799
val phase, Epoch 8/20, Loss: 16.827430
Val Best Loss: 16.338375
Epoch loss: 16.827430
train phase, Epoch 9/20, Loss: 16.267544
val phase, Epoch 9/20, Loss: 16.394355
Val Best Loss: 16.338375
Epoch loss: 16.394355
train phase, Epoch 10/20, Loss: 16.052913
val phase, Epoch 10/20, Loss: 16.241356
Val Best Loss: 16.241356
Epoch loss: 16.241356
train phase, Epoch 11/20, Loss: 15.889709
val phase, Epoch 11/20, Loss: 16.308615
Val Best Loss: 16.241356
Epoch loss: 16.308615
train phase, Epoch 12/20, Loss: 15.650268
val phase, Epoch 12/20, Loss: 18.391054
Val Best Loss: 16.241356
Epoch loss: 18.391054
train phase, Epoch 13/20, Loss: 15.497059
val phase, Epoch 13/20, Loss: 15.822431
Val Best Loss: 15.822431
Epoch loss: 15.822431
train phase, Epoch 14/20, Loss: 15.438243
val phase, Epoch 14/20, Loss: 19.703728
Val Best Loss: 15.822431
Epoch loss: 19.703728
train phase, Epoch 15/20, Loss: 15.383613
val phase, Epoch 15/20, Loss: 15.932103
Val Best Loss: 15.822431
Epoch loss: 15.932103
train phase, Epoch 16/20, Loss: 15.134073
val phase, Epoch 16/20, Loss: 15.931368
Val Best Loss: 15.822431
Epoch loss: 15.931368
train phase, Epoch 17/20, Loss: 14.702039
val phase, Epoch 17/20, Loss: 19.926520
Val Best Loss: 15.822431
Epoch loss: 19.926520
train phase, Epoch 18/20, Loss: 14.504698
val phase, Epoch 18/20, Loss: 17.378067
Val Best Loss: 15.822431
Epoch loss: 17.378067
train phase, Epoch 19/20, Loss: 14.322217
val phase, Epoch 19/20, Loss: 17.852887
Val Best Loss: 15.822431
Epoch loss: 17.852887
train phase, Epoch 20/20, Loss: 14.104877
val phase, Epoch 20/20, Loss: 17.530422
Val Best Loss: 15.822431
Epoch loss: 17.530422
[Trial 281] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/25, Loss: 19.778407
val phase, Epoch 1/25, Loss: 17.567078
Val Best Loss: 17.567078
Epoch loss: 17.567078
train phase, Epoch 2/25, Loss: 17.803062
val phase, Epoch 2/25, Loss: 16.679352
Val Best Loss: 16.679352
Epoch loss: 16.679352
train phase, Epoch 3/25, Loss: 17.202499
val phase, Epoch 3/25, Loss: 17.523962
Val Best Loss: 16.679352
Epoch loss: 17.523962
train phase, Epoch 4/25, Loss: 17.080955
val phase, Epoch 4/25, Loss: 16.345831
Val Best Loss: 16.345831
Epoch loss: 16.345831
train phase, Epoch 5/25, Loss: 16.975688
val phase, Epoch 5/25, Loss: 20.371124
Val Best Loss: 16.345831
Epoch loss: 20.371124
train phase, Epoch 6/25, Loss: 16.599784
val phase, Epoch 6/25, Loss: 16.284005
Val Best Loss: 16.284005
Epoch loss: 16.284005
train phase, Epoch 7/25, Loss: 16.443385
val phase, Epoch 7/25, Loss: 16.045168
Val Best Loss: 16.045168
Epoch loss: 16.045168
train phase, Epoch 8/25, Loss: 16.242472
val phase, Epoch 8/25, Loss: 16.507526
Val Best Loss: 16.045168
Epoch loss: 16.507526
train phase, Epoch 9/25, Loss: 16.105450
val phase, Epoch 9/25, Loss: 16.143970
Val Best Loss: 16.045168
Epoch loss: 16.143970
train phase, Epoch 10/25, Loss: 15.973114
val phase, Epoch 10/25, Loss: 15.870966
Val Best Loss: 15.870966
Epoch loss: 15.870966
train phase, Epoch 11/25, Loss: 15.672349
val phase, Epoch 11/25, Loss: 16.642818
Val Best Loss: 15.870966
Epoch loss: 16.642818
train phase, Epoch 12/25, Loss: 15.594692
val phase, Epoch 12/25, Loss: 16.621062
Val Best Loss: 15.870966
Epoch loss: 16.621062
train phase, Epoch 13/25, Loss: 15.690637
val phase, Epoch 13/25, Loss: 15.858585
Val Best Loss: 15.858585
Epoch loss: 15.858585
train phase, Epoch 14/25, Loss: 15.439906
val phase, Epoch 14/25, Loss: 16.419334
Val Best Loss: 15.858585
Epoch loss: 16.419334
train phase, Epoch 15/25, Loss: 14.923888
val phase, Epoch 15/25, Loss: 17.321179
Val Best Loss: 15.858585
Epoch loss: 17.321179
train phase, Epoch 16/25, Loss: 14.718800
val phase, Epoch 16/25, Loss: 16.624119
Val Best Loss: 15.858585
Epoch loss: 16.624119
train phase, Epoch 17/25, Loss: 14.318736
val phase, Epoch 17/25, Loss: 16.658619
Val Best Loss: 15.858585
Epoch loss: 16.658619
train phase, Epoch 18/25, Loss: 14.034336
val phase, Epoch 18/25, Loss: 19.162323
Val Best Loss: 15.858585
Epoch loss: 19.162323
train phase, Epoch 19/25, Loss: 14.362922
val phase, Epoch 19/25, Loss: 17.331016
Val Best Loss: 15.858585
Epoch loss: 17.331016
train phase, Epoch 20/25, Loss: 13.751828
val phase, Epoch 20/25, Loss: 16.284150
Val Best Loss: 15.858585
Epoch loss: 16.284150
train phase, Epoch 21/25, Loss: 13.295477
val phase, Epoch 21/25, Loss: 17.855599
Val Best Loss: 15.858585
Epoch loss: 17.855599
train phase, Epoch 22/25, Loss: 12.929400
val phase, Epoch 22/25, Loss: 16.722326
Val Best Loss: 15.858585
Epoch loss: 16.722326
train phase, Epoch 23/25, Loss: 12.423361
val phase, Epoch 23/25, Loss: 17.593527
Val Best Loss: 15.858585
Epoch loss: 17.593527
train phase, Epoch 24/25, Loss: 11.976068
val phase, Epoch 24/25, Loss: 17.662805
Val Best Loss: 15.858585
Epoch loss: 17.662805
train phase, Epoch 25/25, Loss: 11.625499
val phase, Epoch 25/25, Loss: 17.452501
Val Best Loss: 15.858585
Epoch loss: 17.452501
train phase, Epoch 1/30, Loss: 20.365875
val phase, Epoch 1/30, Loss: 17.259093
Val Best Loss: 17.259093
Epoch loss: 17.259093
train phase, Epoch 2/30, Loss: 18.075500
val phase, Epoch 2/30, Loss: 18.170746
Val Best Loss: 17.259093
Epoch loss: 18.170746
train phase, Epoch 3/30, Loss: 17.494437
val phase, Epoch 3/30, Loss: 16.652222
Val Best Loss: 16.652222
Epoch loss: 16.652222
train phase, Epoch 4/30, Loss: 17.506787
val phase, Epoch 4/30, Loss: 18.535150
Val Best Loss: 16.652222
Epoch loss: 18.535150
train phase, Epoch 5/30, Loss: 17.376041
val phase, Epoch 5/30, Loss: 17.404041
Val Best Loss: 16.652222
Epoch loss: 17.404041
train phase, Epoch 6/30, Loss: 16.736536
val phase, Epoch 6/30, Loss: 16.596240
Val Best Loss: 16.596240
Epoch loss: 16.596240
train phase, Epoch 7/30, Loss: 16.758284
val phase, Epoch 7/30, Loss: 16.818405
Val Best Loss: 16.596240
Epoch loss: 16.818405
train phase, Epoch 8/30, Loss: 16.421410
val phase, Epoch 8/30, Loss: 15.969378
Val Best Loss: 15.969378
Epoch loss: 15.969378
train phase, Epoch 9/30, Loss: 16.363178
val phase, Epoch 9/30, Loss: 17.329151
Val Best Loss: 15.969378
Epoch loss: 17.329151
train phase, Epoch 10/30, Loss: 16.415277
val phase, Epoch 10/30, Loss: 16.287495
Val Best Loss: 15.969378
Epoch loss: 16.287495
train phase, Epoch 11/30, Loss: 15.980439
val phase, Epoch 11/30, Loss: 16.621704
Val Best Loss: 15.969378
Epoch loss: 16.621704
train phase, Epoch 12/30, Loss: 15.923745
val phase, Epoch 12/30, Loss: 16.353396
Val Best Loss: 15.969378
Epoch loss: 16.353396
train phase, Epoch 13/30, Loss: 15.664553
val phase, Epoch 13/30, Loss: 15.932104
Val Best Loss: 15.932104
Epoch loss: 15.932104
train phase, Epoch 14/30, Loss: 15.481067
val phase, Epoch 14/30, Loss: 17.019445
Val Best Loss: 15.932104
Epoch loss: 17.019445
train phase, Epoch 15/30, Loss: 15.340168
val phase, Epoch 15/30, Loss: 19.708736
Val Best Loss: 15.932104
Epoch loss: 19.708736
train phase, Epoch 16/30, Loss: 15.199837
val phase, Epoch 16/30, Loss: 16.467798
Val Best Loss: 15.932104
Epoch loss: 16.467798
train phase, Epoch 17/30, Loss: 15.019455
val phase, Epoch 17/30, Loss: 16.997133
Val Best Loss: 15.932104
Epoch loss: 16.997133
train phase, Epoch 18/30, Loss: 15.109167
val phase, Epoch 18/30, Loss: 15.890722
Val Best Loss: 15.890722
Epoch loss: 15.890722
train phase, Epoch 19/30, Loss: 14.784190
val phase, Epoch 19/30, Loss: 16.338848
Val Best Loss: 15.890722
Epoch loss: 16.338848
train phase, Epoch 20/30, Loss: 14.679382
val phase, Epoch 20/30, Loss: 16.465716
Val Best Loss: 15.890722
Epoch loss: 16.465716
train phase, Epoch 21/30, Loss: 14.200825
val phase, Epoch 21/30, Loss: 16.761846
Val Best Loss: 15.890722
Epoch loss: 16.761846
train phase, Epoch 22/30, Loss: 13.915038
val phase, Epoch 22/30, Loss: 16.664753
Val Best Loss: 15.890722
Epoch loss: 16.664753
train phase, Epoch 23/30, Loss: 13.817490
val phase, Epoch 23/30, Loss: 16.774479
Val Best Loss: 15.890722
Epoch loss: 16.774479
train phase, Epoch 24/30, Loss: 13.331105
val phase, Epoch 24/30, Loss: 16.809563
Val Best Loss: 15.890722
Epoch loss: 16.809563
train phase, Epoch 25/30, Loss: 12.946240
val phase, Epoch 25/30, Loss: 16.898188
Val Best Loss: 15.890722
Epoch loss: 16.898188
train phase, Epoch 26/30, Loss: 12.648032
val phase, Epoch 26/30, Loss: 16.848934
Val Best Loss: 15.890722
Epoch loss: 16.848934
train phase, Epoch 27/30, Loss: 12.437675
val phase, Epoch 27/30, Loss: 17.549955
Val Best Loss: 15.890722
Epoch loss: 17.549955
train phase, Epoch 28/30, Loss: 11.870553
val phase, Epoch 28/30, Loss: 18.138082
Val Best Loss: 15.890722
Epoch loss: 18.138082
train phase, Epoch 29/30, Loss: 11.693006
val phase, Epoch 29/30, Loss: 17.744476
Val Best Loss: 15.890722
Epoch loss: 17.744476
train phase, Epoch 30/30, Loss: 11.356084
val phase, Epoch 30/30, Loss: 18.073753
Val Best Loss: 15.890722
Epoch loss: 18.073753
train phase, Epoch 1/5, Loss: 20.263175
val phase, Epoch 1/5, Loss: 19.281989
Val Best Loss: 19.281989
Epoch loss: 19.281989
train phase, Epoch 2/5, Loss: 18.479422
val phase, Epoch 2/5, Loss: 17.274107
Val Best Loss: 17.274107
Epoch loss: 17.274107
train phase, Epoch 3/5, Loss: 17.262695
val phase, Epoch 3/5, Loss: 16.621890
Val Best Loss: 16.621890
Epoch loss: 16.621890
train phase, Epoch 4/5, Loss: 16.943647
val phase, Epoch 4/5, Loss: 19.619284
Val Best Loss: 16.621890
Epoch loss: 19.619284
train phase, Epoch 5/5, Loss: 17.147243
val phase, Epoch 5/5, Loss: 16.156720
Val Best Loss: 16.156720
Epoch loss: 16.156720
train phase, Epoch 1/20, Loss: 20.105058
val phase, Epoch 1/20, Loss: 17.698951
Val Best Loss: 17.698951
Epoch loss: 17.698951
train phase, Epoch 2/20, Loss: 17.647987
val phase, Epoch 2/20, Loss: 17.019611
Val Best Loss: 17.019611
Epoch loss: 17.019611
train phase, Epoch 3/20, Loss: 17.439393
val phase, Epoch 3/20, Loss: 17.081794
Val Best Loss: 17.019611
Epoch loss: 17.081794
train phase, Epoch 4/20, Loss: 17.208517
val phase, Epoch 4/20, Loss: 18.223012
Val Best Loss: 17.019611
Epoch loss: 18.223012
train phase, Epoch 5/20, Loss: 16.826475
val phase, Epoch 5/20, Loss: 16.159823
Val Best Loss: 16.159823
Epoch loss: 16.159823
train phase, Epoch 6/20, Loss: 16.543259
val phase, Epoch 6/20, Loss: 16.680409
Val Best Loss: 16.159823
Epoch loss: 16.680409
train phase, Epoch 7/20, Loss: 16.453960
val phase, Epoch 7/20, Loss: 16.574298
Val Best Loss: 16.159823
Epoch loss: 16.574298
train phase, Epoch 8/20, Loss: 16.173319
val phase, Epoch 8/20, Loss: 16.165839
Val Best Loss: 16.159823
Epoch loss: 16.165839
train phase, Epoch 9/20, Loss: 16.178765
val phase, Epoch 9/20, Loss: 16.500208
Val Best Loss: 16.159823
Epoch loss: 16.500208
train phase, Epoch 10/20, Loss: 15.896079
val phase, Epoch 10/20, Loss: 17.110208
Val Best Loss: 16.159823
Epoch loss: 17.110208
train phase, Epoch 11/20, Loss: 15.701311
val phase, Epoch 11/20, Loss: 16.531236
Val Best Loss: 16.159823
Epoch loss: 16.531236
train phase, Epoch 12/20, Loss: 15.608826
val phase, Epoch 12/20, Loss: 16.372308
Val Best Loss: 16.159823
Epoch loss: 16.372308
train phase, Epoch 13/20, Loss: 15.299703
val phase, Epoch 13/20, Loss: 15.899797
Val Best Loss: 15.899797
Epoch loss: 15.899797
train phase, Epoch 14/20, Loss: 15.318699
val phase, Epoch 14/20, Loss: 16.492214
Val Best Loss: 15.899797
Epoch loss: 16.492214
train phase, Epoch 15/20, Loss: 15.019616
val phase, Epoch 15/20, Loss: 16.290613
Val Best Loss: 15.899797
Epoch loss: 16.290613
train phase, Epoch 16/20, Loss: 14.888074
val phase, Epoch 16/20, Loss: 16.197279
Val Best Loss: 15.899797
Epoch loss: 16.197279
train phase, Epoch 17/20, Loss: 14.599996
val phase, Epoch 17/20, Loss: 15.601050
Val Best Loss: 15.601050
Epoch loss: 15.601050
train phase, Epoch 18/20, Loss: 14.414877
val phase, Epoch 18/20, Loss: 17.523575
Val Best Loss: 15.601050
Epoch loss: 17.523575
train phase, Epoch 19/20, Loss: 14.542376
val phase, Epoch 19/20, Loss: 16.704743
Val Best Loss: 15.601050
Epoch loss: 16.704743
train phase, Epoch 20/20, Loss: 13.968765
val phase, Epoch 20/20, Loss: 16.205063
Val Best Loss: 15.601050
Epoch loss: 16.205063
train phase, Epoch 1/20, Loss: 20.265404
val phase, Epoch 1/20, Loss: 19.679690
Val Best Loss: 19.679690
Epoch loss: 19.679690
train phase, Epoch 2/20, Loss: 17.821556
val phase, Epoch 2/20, Loss: 17.075648
Val Best Loss: 17.075648
Epoch loss: 17.075648
train phase, Epoch 3/20, Loss: 17.333487
val phase, Epoch 3/20, Loss: 18.347151
Val Best Loss: 17.075648
Epoch loss: 18.347151
train phase, Epoch 4/20, Loss: 17.192086
val phase, Epoch 4/20, Loss: 16.225095
Val Best Loss: 16.225095
Epoch loss: 16.225095
train phase, Epoch 5/20, Loss: 16.700160
val phase, Epoch 5/20, Loss: 16.423705
Val Best Loss: 16.225095
Epoch loss: 16.423705
train phase, Epoch 6/20, Loss: 16.702026
val phase, Epoch 6/20, Loss: 16.454806
Val Best Loss: 16.225095
Epoch loss: 16.454806
train phase, Epoch 7/20, Loss: 16.280695
val phase, Epoch 7/20, Loss: 16.272804
Val Best Loss: 16.225095
Epoch loss: 16.272804
train phase, Epoch 8/20, Loss: 16.185106
val phase, Epoch 8/20, Loss: 16.959525
Val Best Loss: 16.225095
Epoch loss: 16.959525
train phase, Epoch 9/20, Loss: 16.218247
val phase, Epoch 9/20, Loss: 18.363264
Val Best Loss: 16.225095
Epoch loss: 18.363264
train phase, Epoch 10/20, Loss: 15.671931
val phase, Epoch 10/20, Loss: 15.893646
Val Best Loss: 15.893646
Epoch loss: 15.893646
train phase, Epoch 11/20, Loss: 15.525114
val phase, Epoch 11/20, Loss: 16.371391
Val Best Loss: 15.893646
Epoch loss: 16.371391
train phase, Epoch 12/20, Loss: 15.628780
val phase, Epoch 12/20, Loss: 16.988907
Val Best Loss: 15.893646
Epoch loss: 16.988907
train phase, Epoch 13/20, Loss: 15.288175
val phase, Epoch 13/20, Loss: 15.869714
Val Best Loss: 15.869714
Epoch loss: 15.869714
train phase, Epoch 14/20, Loss: 15.052847
val phase, Epoch 14/20, Loss: 15.753393
Val Best Loss: 15.753393
Epoch loss: 15.753393
train phase, Epoch 15/20, Loss: 14.789536
val phase, Epoch 15/20, Loss: 16.496861
Val Best Loss: 15.753393
Epoch loss: 16.496861
train phase, Epoch 16/20, Loss: 14.710284
val phase, Epoch 16/20, Loss: 16.287270
Val Best Loss: 15.753393
Epoch loss: 16.287270
train phase, Epoch 17/20, Loss: 14.349335
val phase, Epoch 17/20, Loss: 15.952930
Val Best Loss: 15.753393
Epoch loss: 15.952930
train phase, Epoch 18/20, Loss: 13.876281
val phase, Epoch 18/20, Loss: 16.907794
Val Best Loss: 15.753393
Epoch loss: 16.907794
train phase, Epoch 19/20, Loss: 13.678953
val phase, Epoch 19/20, Loss: 17.624019
Val Best Loss: 15.753393
Epoch loss: 17.624019
train phase, Epoch 20/20, Loss: 13.414752
val phase, Epoch 20/20, Loss: 17.702530
Val Best Loss: 15.753393
Epoch loss: 17.702530
[Trial 287] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.669971
val phase, Epoch 1/20, Loss: 17.136881
Val Best Loss: 17.136881
Epoch loss: 17.136881
train phase, Epoch 2/20, Loss: 17.769942
val phase, Epoch 2/20, Loss: 17.176982
Val Best Loss: 17.136881
Epoch loss: 17.176982
train phase, Epoch 3/20, Loss: 17.816337
val phase, Epoch 3/20, Loss: 16.364972
Val Best Loss: 16.364972
Epoch loss: 16.364972
train phase, Epoch 4/20, Loss: 17.125480
val phase, Epoch 4/20, Loss: 17.395873
Val Best Loss: 16.364972
Epoch loss: 17.395873
train phase, Epoch 5/20, Loss: 17.188565
val phase, Epoch 5/20, Loss: 16.378230
Val Best Loss: 16.364972
Epoch loss: 16.378230
train phase, Epoch 6/20, Loss: 17.212449
val phase, Epoch 6/20, Loss: 16.053354
Val Best Loss: 16.053354
Epoch loss: 16.053354
train phase, Epoch 7/20, Loss: 16.427017
val phase, Epoch 7/20, Loss: 16.591657
Val Best Loss: 16.053354
Epoch loss: 16.591657
train phase, Epoch 8/20, Loss: 16.465787
val phase, Epoch 8/20, Loss: 16.959302
Val Best Loss: 16.053354
Epoch loss: 16.959302
train phase, Epoch 9/20, Loss: 16.306563
val phase, Epoch 9/20, Loss: 17.615338
Val Best Loss: 16.053354
Epoch loss: 17.615338
train phase, Epoch 10/20, Loss: 16.164737
val phase, Epoch 10/20, Loss: 18.862729
Val Best Loss: 16.053354
Epoch loss: 18.862729
train phase, Epoch 11/20, Loss: 16.213477
val phase, Epoch 11/20, Loss: 15.978312
Val Best Loss: 15.978312
Epoch loss: 15.978312
train phase, Epoch 12/20, Loss: 15.685432
val phase, Epoch 12/20, Loss: 15.660730
Val Best Loss: 15.660730
Epoch loss: 15.660730
train phase, Epoch 13/20, Loss: 15.709378
val phase, Epoch 13/20, Loss: 16.718775
Val Best Loss: 15.660730
Epoch loss: 16.718775
train phase, Epoch 14/20, Loss: 15.346061
val phase, Epoch 14/20, Loss: 16.193778
Val Best Loss: 15.660730
Epoch loss: 16.193778
train phase, Epoch 15/20, Loss: 15.210034
val phase, Epoch 15/20, Loss: 17.624695
Val Best Loss: 15.660730
Epoch loss: 17.624695
train phase, Epoch 16/20, Loss: 15.317272
val phase, Epoch 16/20, Loss: 16.904102
Val Best Loss: 15.660730
Epoch loss: 16.904102
train phase, Epoch 17/20, Loss: 14.779746
val phase, Epoch 17/20, Loss: 16.599012
Val Best Loss: 15.660730
Epoch loss: 16.599012
train phase, Epoch 18/20, Loss: 14.572959
val phase, Epoch 18/20, Loss: 16.288632
Val Best Loss: 15.660730
Epoch loss: 16.288632
train phase, Epoch 19/20, Loss: 14.239422
val phase, Epoch 19/20, Loss: 17.372581
Val Best Loss: 15.660730
Epoch loss: 17.372581
train phase, Epoch 20/20, Loss: 14.021011
val phase, Epoch 20/20, Loss: 17.835181
Val Best Loss: 15.660730
Epoch loss: 17.835181
train phase, Epoch 1/30, Loss: 20.041470
val phase, Epoch 1/30, Loss: 17.221180
Val Best Loss: 17.221180
Epoch loss: 17.221180
train phase, Epoch 2/30, Loss: 18.033093
val phase, Epoch 2/30, Loss: 17.999183
Val Best Loss: 17.221180
Epoch loss: 17.999183
train phase, Epoch 3/30, Loss: 17.465132
val phase, Epoch 3/30, Loss: 16.592654
Val Best Loss: 16.592654
Epoch loss: 16.592654
train phase, Epoch 4/30, Loss: 17.555820
val phase, Epoch 4/30, Loss: 16.752788
Val Best Loss: 16.592654
Epoch loss: 16.752788
train phase, Epoch 5/30, Loss: 17.456615
val phase, Epoch 5/30, Loss: 17.350907
Val Best Loss: 16.592654
Epoch loss: 17.350907
train phase, Epoch 6/30, Loss: 16.857506
val phase, Epoch 6/30, Loss: 16.322579
Val Best Loss: 16.322579
Epoch loss: 16.322579
train phase, Epoch 7/30, Loss: 16.837988
val phase, Epoch 7/30, Loss: 16.857968
Val Best Loss: 16.322579
Epoch loss: 16.857968
train phase, Epoch 8/30, Loss: 16.467224
val phase, Epoch 8/30, Loss: 16.411986
Val Best Loss: 16.322579
Epoch loss: 16.411986
train phase, Epoch 9/30, Loss: 16.628305
val phase, Epoch 9/30, Loss: 15.985960
Val Best Loss: 15.985960
Epoch loss: 15.985960
train phase, Epoch 10/30, Loss: 16.211659
val phase, Epoch 10/30, Loss: 17.801047
Val Best Loss: 15.985960
Epoch loss: 17.801047
train phase, Epoch 11/30, Loss: 16.086408
val phase, Epoch 11/30, Loss: 20.091555
Val Best Loss: 15.985960
Epoch loss: 20.091555
train phase, Epoch 12/30, Loss: 16.172651
val phase, Epoch 12/30, Loss: 16.794437
Val Best Loss: 15.985960
Epoch loss: 16.794437
train phase, Epoch 13/30, Loss: 16.022440
val phase, Epoch 13/30, Loss: 16.151860
Val Best Loss: 15.985960
Epoch loss: 16.151860
train phase, Epoch 14/30, Loss: 15.777172
val phase, Epoch 14/30, Loss: 15.952120
Val Best Loss: 15.952120
Epoch loss: 15.952120
train phase, Epoch 15/30, Loss: 15.639009
val phase, Epoch 15/30, Loss: 16.071620
Val Best Loss: 15.952120
Epoch loss: 16.071620
train phase, Epoch 16/30, Loss: 15.201431
val phase, Epoch 16/30, Loss: 15.875023
Val Best Loss: 15.875023
Epoch loss: 15.875023
train phase, Epoch 17/30, Loss: 15.098748
val phase, Epoch 17/30, Loss: 16.829840
Val Best Loss: 15.875023
Epoch loss: 16.829840
train phase, Epoch 18/30, Loss: 14.871960
val phase, Epoch 18/30, Loss: 16.520175
Val Best Loss: 15.875023
Epoch loss: 16.520175
train phase, Epoch 19/30, Loss: 14.878527
val phase, Epoch 19/30, Loss: 16.951706
Val Best Loss: 15.875023
Epoch loss: 16.951706
train phase, Epoch 20/30, Loss: 14.571291
val phase, Epoch 20/30, Loss: 15.991569
Val Best Loss: 15.875023
Epoch loss: 15.991569
train phase, Epoch 21/30, Loss: 14.187379
val phase, Epoch 21/30, Loss: 16.359572
Val Best Loss: 15.875023
Epoch loss: 16.359572
train phase, Epoch 22/30, Loss: 13.954308
val phase, Epoch 22/30, Loss: 16.765352
Val Best Loss: 15.875023
Epoch loss: 16.765352
train phase, Epoch 23/30, Loss: 13.599877
val phase, Epoch 23/30, Loss: 16.276275
Val Best Loss: 15.875023
Epoch loss: 16.276275
train phase, Epoch 24/30, Loss: 13.152165
val phase, Epoch 24/30, Loss: 17.929572
Val Best Loss: 15.875023
Epoch loss: 17.929572
train phase, Epoch 25/30, Loss: 13.034785
val phase, Epoch 25/30, Loss: 16.705691
Val Best Loss: 15.875023
Epoch loss: 16.705691
train phase, Epoch 26/30, Loss: 12.625346
val phase, Epoch 26/30, Loss: 17.308804
Val Best Loss: 15.875023
Epoch loss: 17.308804
train phase, Epoch 27/30, Loss: 12.138937
val phase, Epoch 27/30, Loss: 16.825486
Val Best Loss: 15.875023
Epoch loss: 16.825486
train phase, Epoch 28/30, Loss: 11.709225
val phase, Epoch 28/30, Loss: 17.400530
Val Best Loss: 15.875023
Epoch loss: 17.400530
train phase, Epoch 29/30, Loss: 11.134351
val phase, Epoch 29/30, Loss: 18.352899
Val Best Loss: 15.875023
Epoch loss: 18.352899
train phase, Epoch 30/30, Loss: 10.706349
val phase, Epoch 30/30, Loss: 18.298762
Val Best Loss: 15.875023
Epoch loss: 18.298762
train phase, Epoch 1/20, Loss: 20.866724
val phase, Epoch 1/20, Loss: 22.564765
Val Best Loss: 22.564765
Epoch loss: 22.564765
train phase, Epoch 2/20, Loss: 18.857974
val phase, Epoch 2/20, Loss: 20.272368
Val Best Loss: 20.272368
Epoch loss: 20.272368
train phase, Epoch 3/20, Loss: 18.626565
val phase, Epoch 3/20, Loss: 18.868075
Val Best Loss: 18.868075
Epoch loss: 18.868075
train phase, Epoch 4/20, Loss: 18.311339
val phase, Epoch 4/20, Loss: 17.995231
Val Best Loss: 17.995231
Epoch loss: 17.995231
train phase, Epoch 5/20, Loss: 17.705369
val phase, Epoch 5/20, Loss: 20.013714
Val Best Loss: 17.995231
Epoch loss: 20.013714
train phase, Epoch 6/20, Loss: 17.938968
val phase, Epoch 6/20, Loss: 17.994441
Val Best Loss: 17.994441
Epoch loss: 17.994441
train phase, Epoch 7/20, Loss: 17.433397
val phase, Epoch 7/20, Loss: 18.001985
Val Best Loss: 17.994441
Epoch loss: 18.001985
train phase, Epoch 8/20, Loss: 17.476782
val phase, Epoch 8/20, Loss: 18.672020
Val Best Loss: 17.994441
Epoch loss: 18.672020
train phase, Epoch 9/20, Loss: 17.617821
val phase, Epoch 9/20, Loss: 23.224823
Val Best Loss: 17.994441
Epoch loss: 23.224823
train phase, Epoch 10/20, Loss: 16.960569
val phase, Epoch 10/20, Loss: 17.120640
Val Best Loss: 17.120640
Epoch loss: 17.120640
train phase, Epoch 11/20, Loss: 16.977500
val phase, Epoch 11/20, Loss: 17.644953
Val Best Loss: 17.120640
Epoch loss: 17.644953
train phase, Epoch 12/20, Loss: 16.650884
val phase, Epoch 12/20, Loss: 17.826314
Val Best Loss: 17.120640
Epoch loss: 17.826314
train phase, Epoch 13/20, Loss: 16.637579
val phase, Epoch 13/20, Loss: 17.337062
Val Best Loss: 17.120640
Epoch loss: 17.337062
train phase, Epoch 14/20, Loss: 16.547248
val phase, Epoch 14/20, Loss: 17.162700
Val Best Loss: 17.120640
Epoch loss: 17.162700
train phase, Epoch 15/20, Loss: 16.402780
val phase, Epoch 15/20, Loss: 17.684429
Val Best Loss: 17.120640
Epoch loss: 17.684429
train phase, Epoch 16/20, Loss: 16.313645
val phase, Epoch 16/20, Loss: 16.895800
Val Best Loss: 16.895800
Epoch loss: 16.895800
train phase, Epoch 17/20, Loss: 16.354460
val phase, Epoch 17/20, Loss: 17.131597
Val Best Loss: 16.895800
Epoch loss: 17.131597
train phase, Epoch 18/20, Loss: 16.145455
val phase, Epoch 18/20, Loss: 16.992295
Val Best Loss: 16.895800
Epoch loss: 16.992295
train phase, Epoch 19/20, Loss: 15.944018
val phase, Epoch 19/20, Loss: 17.542359
Val Best Loss: 16.895800
Epoch loss: 17.542359
train phase, Epoch 20/20, Loss: 16.026394
val phase, Epoch 20/20, Loss: 16.765736
Val Best Loss: 16.765736
Epoch loss: 16.765736
train phase, Epoch 1/20, Loss: 29.066347
val phase, Epoch 1/20, Loss: 18.014286
Val Best Loss: 18.014286
Epoch loss: 18.014286
train phase, Epoch 2/20, Loss: 18.399365
val phase, Epoch 2/20, Loss: 17.746669
Val Best Loss: 17.746669
Epoch loss: 17.746669
train phase, Epoch 3/20, Loss: 17.837324
val phase, Epoch 3/20, Loss: 17.534134
Val Best Loss: 17.534134
Epoch loss: 17.534134
train phase, Epoch 4/20, Loss: 17.572614
val phase, Epoch 4/20, Loss: 16.879975
Val Best Loss: 16.879975
Epoch loss: 16.879975
train phase, Epoch 5/20, Loss: 17.163080
val phase, Epoch 5/20, Loss: 16.727722
Val Best Loss: 16.727722
Epoch loss: 16.727722
train phase, Epoch 6/20, Loss: 17.141125
val phase, Epoch 6/20, Loss: 16.630714
Val Best Loss: 16.630714
Epoch loss: 16.630714
train phase, Epoch 7/20, Loss: 17.331053
val phase, Epoch 7/20, Loss: 16.939202
Val Best Loss: 16.630714
Epoch loss: 16.939202
train phase, Epoch 8/20, Loss: 16.895075
val phase, Epoch 8/20, Loss: 16.333487
Val Best Loss: 16.333487
Epoch loss: 16.333487
train phase, Epoch 9/20, Loss: 16.629929
val phase, Epoch 9/20, Loss: 17.230774
Val Best Loss: 16.333487
Epoch loss: 17.230774
train phase, Epoch 10/20, Loss: 16.552975
val phase, Epoch 10/20, Loss: 16.459360
Val Best Loss: 16.333487
Epoch loss: 16.459360
train phase, Epoch 11/20, Loss: 16.446769
val phase, Epoch 11/20, Loss: 16.619690
Val Best Loss: 16.333487
Epoch loss: 16.619690
train phase, Epoch 12/20, Loss: 16.216789
val phase, Epoch 12/20, Loss: 16.532175
Val Best Loss: 16.333487
Epoch loss: 16.532175
train phase, Epoch 13/20, Loss: 16.073082
val phase, Epoch 13/20, Loss: 16.257673
Val Best Loss: 16.257673
Epoch loss: 16.257673
train phase, Epoch 14/20, Loss: 16.234912
val phase, Epoch 14/20, Loss: 16.280910
Val Best Loss: 16.257673
Epoch loss: 16.280910
train phase, Epoch 15/20, Loss: 15.998412
val phase, Epoch 15/20, Loss: 16.542974
Val Best Loss: 16.257673
Epoch loss: 16.542974
train phase, Epoch 16/20, Loss: 15.967581
val phase, Epoch 16/20, Loss: 17.448777
Val Best Loss: 16.257673
Epoch loss: 17.448777
train phase, Epoch 17/20, Loss: 15.863600
val phase, Epoch 17/20, Loss: 16.981526
Val Best Loss: 16.257673
Epoch loss: 16.981526
train phase, Epoch 18/20, Loss: 15.660121
val phase, Epoch 18/20, Loss: 17.617919
Val Best Loss: 16.257673
Epoch loss: 17.617919
train phase, Epoch 19/20, Loss: 15.810600
val phase, Epoch 19/20, Loss: 16.049676
Val Best Loss: 16.049676
Epoch loss: 16.049676
train phase, Epoch 20/20, Loss: 15.456782
val phase, Epoch 20/20, Loss: 17.134680
Val Best Loss: 16.049676
Epoch loss: 17.134680
train phase, Epoch 1/20, Loss: 19.985697
val phase, Epoch 1/20, Loss: 17.503171
Val Best Loss: 17.503171
Epoch loss: 17.503171
train phase, Epoch 2/20, Loss: 18.732659
val phase, Epoch 2/20, Loss: 20.474620
Val Best Loss: 17.503171
Epoch loss: 20.474620
train phase, Epoch 3/20, Loss: 17.978090
val phase, Epoch 3/20, Loss: 16.914239
Val Best Loss: 16.914239
Epoch loss: 16.914239
train phase, Epoch 4/20, Loss: 17.490864
val phase, Epoch 4/20, Loss: 17.776319
Val Best Loss: 16.914239
Epoch loss: 17.776319
train phase, Epoch 5/20, Loss: 17.388888
val phase, Epoch 5/20, Loss: 16.532380
Val Best Loss: 16.532380
Epoch loss: 16.532380
train phase, Epoch 6/20, Loss: 17.251754
val phase, Epoch 6/20, Loss: 17.240495
Val Best Loss: 16.532380
Epoch loss: 17.240495
train phase, Epoch 7/20, Loss: 16.992984
val phase, Epoch 7/20, Loss: 17.219476
Val Best Loss: 16.532380
Epoch loss: 17.219476
train phase, Epoch 8/20, Loss: 16.730782
val phase, Epoch 8/20, Loss: 16.430184
Val Best Loss: 16.430184
Epoch loss: 16.430184
train phase, Epoch 9/20, Loss: 16.688629
val phase, Epoch 9/20, Loss: 16.906015
Val Best Loss: 16.430184
Epoch loss: 16.906015
train phase, Epoch 10/20, Loss: 16.393216
val phase, Epoch 10/20, Loss: 17.160393
Val Best Loss: 16.430184
Epoch loss: 17.160393
train phase, Epoch 11/20, Loss: 16.367529
val phase, Epoch 11/20, Loss: 18.162646
Val Best Loss: 16.430184
Epoch loss: 18.162646
train phase, Epoch 12/20, Loss: 16.194694
val phase, Epoch 12/20, Loss: 16.983897
Val Best Loss: 16.430184
Epoch loss: 16.983897
train phase, Epoch 13/20, Loss: 15.846067
val phase, Epoch 13/20, Loss: 18.467372
Val Best Loss: 16.430184
Epoch loss: 18.467372
train phase, Epoch 14/20, Loss: 16.235130
val phase, Epoch 14/20, Loss: 16.300233
Val Best Loss: 16.300233
Epoch loss: 16.300233
train phase, Epoch 15/20, Loss: 15.663440
val phase, Epoch 15/20, Loss: 16.420759
Val Best Loss: 16.300233
Epoch loss: 16.420759
train phase, Epoch 16/20, Loss: 15.486566
val phase, Epoch 16/20, Loss: 18.616895
Val Best Loss: 16.300233
Epoch loss: 18.616895
train phase, Epoch 17/20, Loss: 15.483525
val phase, Epoch 17/20, Loss: 16.542393
Val Best Loss: 16.300233
Epoch loss: 16.542393
train phase, Epoch 18/20, Loss: 15.429618
val phase, Epoch 18/20, Loss: 16.621714
Val Best Loss: 16.300233
Epoch loss: 16.621714
train phase, Epoch 19/20, Loss: 14.921517
val phase, Epoch 19/20, Loss: 16.559502
Val Best Loss: 16.300233
Epoch loss: 16.559502
train phase, Epoch 20/20, Loss: 14.713494
val phase, Epoch 20/20, Loss: 16.227530
Val Best Loss: 16.227530
Epoch loss: 16.227530
train phase, Epoch 1/30, Loss: 19.671024
val phase, Epoch 1/30, Loss: 29.401428
Val Best Loss: 29.401428
Epoch loss: 29.401428
train phase, Epoch 2/30, Loss: 17.496788
val phase, Epoch 2/30, Loss: 30.440589
Val Best Loss: 29.401428
Epoch loss: 30.440589
train phase, Epoch 3/30, Loss: 17.219401
val phase, Epoch 3/30, Loss: 29.997920
Val Best Loss: 29.401428
Epoch loss: 29.997920
train phase, Epoch 4/30, Loss: 17.121838
val phase, Epoch 4/30, Loss: 30.089873
Val Best Loss: 29.401428
Epoch loss: 30.089873
train phase, Epoch 5/30, Loss: 17.096935
val phase, Epoch 5/30, Loss: 36.133244
Val Best Loss: 29.401428
Epoch loss: 36.133244
train phase, Epoch 6/30, Loss: 16.531059
val phase, Epoch 6/30, Loss: 34.332549
Val Best Loss: 29.401428
Epoch loss: 34.332549
train phase, Epoch 7/30, Loss: 16.540220
val phase, Epoch 7/30, Loss: 37.060266
Val Best Loss: 29.401428
Epoch loss: 37.060266
train phase, Epoch 8/30, Loss: 16.311305
val phase, Epoch 8/30, Loss: 38.406476
Val Best Loss: 29.401428
Epoch loss: 38.406476
train phase, Epoch 9/30, Loss: 16.270702
val phase, Epoch 9/30, Loss: 37.593510
Val Best Loss: 29.401428
Epoch loss: 37.593510
train phase, Epoch 10/30, Loss: 15.962445
val phase, Epoch 10/30, Loss: 35.391400
Val Best Loss: 29.401428
Epoch loss: 35.391400
train phase, Epoch 11/30, Loss: 15.760263
val phase, Epoch 11/30, Loss: 43.716984
Val Best Loss: 29.401428
Epoch loss: 43.716984
train phase, Epoch 12/30, Loss: 15.762880
val phase, Epoch 12/30, Loss: 50.621840
Val Best Loss: 29.401428
Epoch loss: 50.621840
train phase, Epoch 13/30, Loss: 15.484920
val phase, Epoch 13/30, Loss: 42.925468
Val Best Loss: 29.401428
Epoch loss: 42.925468
train phase, Epoch 14/30, Loss: 15.137053
val phase, Epoch 14/30, Loss: 73.659595
Val Best Loss: 29.401428
Epoch loss: 73.659595
train phase, Epoch 15/30, Loss: 15.016270
val phase, Epoch 15/30, Loss: 61.545178
Val Best Loss: 29.401428
Epoch loss: 61.545178
train phase, Epoch 16/30, Loss: 14.591643
val phase, Epoch 16/30, Loss: 35.649306
Val Best Loss: 29.401428
Epoch loss: 35.649306
train phase, Epoch 17/30, Loss: 14.686424
val phase, Epoch 17/30, Loss: 49.115221
Val Best Loss: 29.401428
Epoch loss: 49.115221
train phase, Epoch 18/30, Loss: 14.094128
val phase, Epoch 18/30, Loss: 72.719376
Val Best Loss: 29.401428
Epoch loss: 72.719376
train phase, Epoch 19/30, Loss: 13.996340
val phase, Epoch 19/30, Loss: 58.885139
Val Best Loss: 29.401428
Epoch loss: 58.885139
train phase, Epoch 20/30, Loss: 13.460426
val phase, Epoch 20/30, Loss: 77.263856
Val Best Loss: 29.401428
Epoch loss: 77.263856
train phase, Epoch 21/30, Loss: 13.242994
val phase, Epoch 21/30, Loss: 46.733929
Val Best Loss: 29.401428
Epoch loss: 46.733929
train phase, Epoch 22/30, Loss: 13.076618
val phase, Epoch 22/30, Loss: 66.098675
Val Best Loss: 29.401428
Epoch loss: 66.098675
train phase, Epoch 23/30, Loss: 12.485082
val phase, Epoch 23/30, Loss: 74.507985
Val Best Loss: 29.401428
Epoch loss: 74.507985
train phase, Epoch 24/30, Loss: 11.977173
val phase, Epoch 24/30, Loss: 64.288821
Val Best Loss: 29.401428
Epoch loss: 64.288821
train phase, Epoch 25/30, Loss: 11.475857
val phase, Epoch 25/30, Loss: 73.850011
Val Best Loss: 29.401428
Epoch loss: 73.850011
train phase, Epoch 26/30, Loss: 10.918427
val phase, Epoch 26/30, Loss: 130.512918
Val Best Loss: 29.401428
Epoch loss: 130.512918
train phase, Epoch 27/30, Loss: 10.549589
val phase, Epoch 27/30, Loss: 75.821317
Val Best Loss: 29.401428
Epoch loss: 75.821317
train phase, Epoch 28/30, Loss: 9.994612
val phase, Epoch 28/30, Loss: 88.812204
Val Best Loss: 29.401428
Epoch loss: 88.812204
train phase, Epoch 29/30, Loss: 9.554850
val phase, Epoch 29/30, Loss: 126.885794
Val Best Loss: 29.401428
Epoch loss: 126.885794
train phase, Epoch 30/30, Loss: 8.961308
val phase, Epoch 30/30, Loss: 119.773853
Val Best Loss: 29.401428
Epoch loss: 119.773853
train phase, Epoch 1/20, Loss: 20.495681
val phase, Epoch 1/20, Loss: 23.437277
Val Best Loss: 23.437277
Epoch loss: 23.437277
train phase, Epoch 2/20, Loss: 18.083926
val phase, Epoch 2/20, Loss: 17.276499
Val Best Loss: 17.276499
Epoch loss: 17.276499
train phase, Epoch 3/20, Loss: 17.866516
val phase, Epoch 3/20, Loss: 22.566182
Val Best Loss: 17.276499
Epoch loss: 22.566182
train phase, Epoch 4/20, Loss: 17.554668
val phase, Epoch 4/20, Loss: 16.534351
Val Best Loss: 16.534351
Epoch loss: 16.534351
train phase, Epoch 5/20, Loss: 17.030302
val phase, Epoch 5/20, Loss: 16.443887
Val Best Loss: 16.443887
Epoch loss: 16.443887
train phase, Epoch 6/20, Loss: 17.102135
val phase, Epoch 6/20, Loss: 16.787333
Val Best Loss: 16.443887
Epoch loss: 16.787333
train phase, Epoch 7/20, Loss: 16.778307
val phase, Epoch 7/20, Loss: 16.086943
Val Best Loss: 16.086943
Epoch loss: 16.086943
train phase, Epoch 8/20, Loss: 16.395648
val phase, Epoch 8/20, Loss: 16.319049
Val Best Loss: 16.086943
Epoch loss: 16.319049
train phase, Epoch 9/20, Loss: 16.219482
val phase, Epoch 9/20, Loss: 16.773586
Val Best Loss: 16.086943
Epoch loss: 16.773586
train phase, Epoch 10/20, Loss: 16.632509
val phase, Epoch 10/20, Loss: 16.492166
Val Best Loss: 16.086943
Epoch loss: 16.492166
train phase, Epoch 11/20, Loss: 15.976381
val phase, Epoch 11/20, Loss: 16.025980
Val Best Loss: 16.025980
Epoch loss: 16.025980
train phase, Epoch 12/20, Loss: 16.003077
val phase, Epoch 12/20, Loss: 19.657083
Val Best Loss: 16.025980
Epoch loss: 19.657083
train phase, Epoch 13/20, Loss: 15.953076
val phase, Epoch 13/20, Loss: 16.281563
Val Best Loss: 16.025980
Epoch loss: 16.281563
train phase, Epoch 14/20, Loss: 15.590614
val phase, Epoch 14/20, Loss: 16.317654
Val Best Loss: 16.025980
Epoch loss: 16.317654
train phase, Epoch 15/20, Loss: 15.392201
val phase, Epoch 15/20, Loss: 17.182472
Val Best Loss: 16.025980
Epoch loss: 17.182472
train phase, Epoch 16/20, Loss: 15.331550
val phase, Epoch 16/20, Loss: 15.917397
Val Best Loss: 15.917397
Epoch loss: 15.917397
train phase, Epoch 17/20, Loss: 15.060272
val phase, Epoch 17/20, Loss: 16.318982
Val Best Loss: 15.917397
Epoch loss: 16.318982
train phase, Epoch 18/20, Loss: 14.977420
val phase, Epoch 18/20, Loss: 16.212811
Val Best Loss: 15.917397
Epoch loss: 16.212811
train phase, Epoch 19/20, Loss: 14.686504
val phase, Epoch 19/20, Loss: 18.186665
Val Best Loss: 15.917397
Epoch loss: 18.186665
train phase, Epoch 20/20, Loss: 14.730286
val phase, Epoch 20/20, Loss: 17.253718
Val Best Loss: 15.917397
Epoch loss: 17.253718
train phase, Epoch 1/20, Loss: 19.829474
val phase, Epoch 1/20, Loss: 16.992257
Val Best Loss: 16.992257
Epoch loss: 16.992257
train phase, Epoch 2/20, Loss: 17.547773
val phase, Epoch 2/20, Loss: 18.156991
Val Best Loss: 16.992257
Epoch loss: 18.156991
train phase, Epoch 3/20, Loss: 17.244519
val phase, Epoch 3/20, Loss: 16.772351
Val Best Loss: 16.772351
Epoch loss: 16.772351
train phase, Epoch 4/20, Loss: 16.846046
val phase, Epoch 4/20, Loss: 16.512017
Val Best Loss: 16.512017
Epoch loss: 16.512017
train phase, Epoch 5/20, Loss: 16.925968
val phase, Epoch 5/20, Loss: 17.202888
Val Best Loss: 16.512017
Epoch loss: 17.202888
train phase, Epoch 6/20, Loss: 16.368629
val phase, Epoch 6/20, Loss: 16.653965
Val Best Loss: 16.512017
Epoch loss: 16.653965
train phase, Epoch 7/20, Loss: 16.275400
val phase, Epoch 7/20, Loss: 16.249282
Val Best Loss: 16.249282
Epoch loss: 16.249282
train phase, Epoch 8/20, Loss: 15.951652
val phase, Epoch 8/20, Loss: 17.058929
Val Best Loss: 16.249282
Epoch loss: 17.058929
train phase, Epoch 9/20, Loss: 15.741278
val phase, Epoch 9/20, Loss: 17.611565
Val Best Loss: 16.249282
Epoch loss: 17.611565
train phase, Epoch 10/20, Loss: 15.907693
val phase, Epoch 10/20, Loss: 15.962814
Val Best Loss: 15.962814
Epoch loss: 15.962814
train phase, Epoch 11/20, Loss: 15.496774
val phase, Epoch 11/20, Loss: 15.932075
Val Best Loss: 15.932075
Epoch loss: 15.932075
train phase, Epoch 12/20, Loss: 15.261918
val phase, Epoch 12/20, Loss: 16.984828
Val Best Loss: 15.932075
Epoch loss: 16.984828
train phase, Epoch 13/20, Loss: 15.159830
val phase, Epoch 13/20, Loss: 16.520501
Val Best Loss: 15.932075
Epoch loss: 16.520501
train phase, Epoch 14/20, Loss: 14.649316
val phase, Epoch 14/20, Loss: 16.070687
Val Best Loss: 15.932075
Epoch loss: 16.070687
train phase, Epoch 15/20, Loss: 14.587294
val phase, Epoch 15/20, Loss: 16.400950
Val Best Loss: 15.932075
Epoch loss: 16.400950
train phase, Epoch 16/20, Loss: 14.358041
val phase, Epoch 16/20, Loss: 16.359619
Val Best Loss: 15.932075
Epoch loss: 16.359619
train phase, Epoch 17/20, Loss: 14.039159
val phase, Epoch 17/20, Loss: 16.259308
Val Best Loss: 15.932075
Epoch loss: 16.259308
train phase, Epoch 18/20, Loss: 13.763252
val phase, Epoch 18/20, Loss: 18.076541
Val Best Loss: 15.932075
Epoch loss: 18.076541
train phase, Epoch 19/20, Loss: 13.406456
val phase, Epoch 19/20, Loss: 16.474426
Val Best Loss: 15.932075
Epoch loss: 16.474426
train phase, Epoch 20/20, Loss: 12.877123
val phase, Epoch 20/20, Loss: 18.342668
Val Best Loss: 15.932075
Epoch loss: 18.342668
[Trial 296] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 20.024426
val phase, Epoch 1/30, Loss: 18.231529
Val Best Loss: 18.231529
Epoch loss: 18.231529
train phase, Epoch 2/30, Loss: 18.100370
val phase, Epoch 2/30, Loss: 17.492756
Val Best Loss: 17.492756
Epoch loss: 17.492756
train phase, Epoch 3/30, Loss: 17.420062
val phase, Epoch 3/30, Loss: 19.935273
Val Best Loss: 17.492756
Epoch loss: 19.935273
train phase, Epoch 4/30, Loss: 17.272704
val phase, Epoch 4/30, Loss: 17.066048
Val Best Loss: 17.066048
Epoch loss: 17.066048
train phase, Epoch 5/30, Loss: 17.014228
val phase, Epoch 5/30, Loss: 16.520971
Val Best Loss: 16.520971
Epoch loss: 16.520971
train phase, Epoch 6/30, Loss: 16.900417
val phase, Epoch 6/30, Loss: 18.949737
Val Best Loss: 16.520971
Epoch loss: 18.949737
train phase, Epoch 7/30, Loss: 16.543374
val phase, Epoch 7/30, Loss: 15.999567
Val Best Loss: 15.999567
Epoch loss: 15.999567
train phase, Epoch 8/30, Loss: 16.280199
val phase, Epoch 8/30, Loss: 17.631056
Val Best Loss: 15.999567
Epoch loss: 17.631056
train phase, Epoch 9/30, Loss: 16.454726
val phase, Epoch 9/30, Loss: 16.166121
Val Best Loss: 15.999567
Epoch loss: 16.166121
train phase, Epoch 10/30, Loss: 16.188576
val phase, Epoch 10/30, Loss: 16.176476
Val Best Loss: 15.999567
Epoch loss: 16.176476
train phase, Epoch 11/30, Loss: 15.891359
val phase, Epoch 11/30, Loss: 16.068207
Val Best Loss: 15.999567
Epoch loss: 16.068207
train phase, Epoch 12/30, Loss: 15.663062
val phase, Epoch 12/30, Loss: 15.783264
Val Best Loss: 15.783264
Epoch loss: 15.783264
train phase, Epoch 13/30, Loss: 15.658457
val phase, Epoch 13/30, Loss: 15.777549
Val Best Loss: 15.777549
Epoch loss: 15.777549
train phase, Epoch 14/30, Loss: 15.363058
val phase, Epoch 14/30, Loss: 16.375867
Val Best Loss: 15.777549
Epoch loss: 16.375867
train phase, Epoch 15/30, Loss: 15.524298
val phase, Epoch 15/30, Loss: 15.717968
Val Best Loss: 15.717968
Epoch loss: 15.717968
train phase, Epoch 16/30, Loss: 15.120569
val phase, Epoch 16/30, Loss: 16.435789
Val Best Loss: 15.717968
Epoch loss: 16.435789
train phase, Epoch 17/30, Loss: 14.874661
val phase, Epoch 17/30, Loss: 15.762746
Val Best Loss: 15.717968
Epoch loss: 15.762746
train phase, Epoch 18/30, Loss: 14.780648
val phase, Epoch 18/30, Loss: 15.604998
Val Best Loss: 15.604998
Epoch loss: 15.604998
train phase, Epoch 19/30, Loss: 14.540807
val phase, Epoch 19/30, Loss: 18.380736
Val Best Loss: 15.604998
Epoch loss: 18.380736
train phase, Epoch 20/30, Loss: 14.214630
val phase, Epoch 20/30, Loss: 16.938118
Val Best Loss: 15.604998
Epoch loss: 16.938118
train phase, Epoch 21/30, Loss: 13.916859
val phase, Epoch 21/30, Loss: 16.317724
Val Best Loss: 15.604998
Epoch loss: 16.317724
train phase, Epoch 22/30, Loss: 13.773629
val phase, Epoch 22/30, Loss: 16.475897
Val Best Loss: 15.604998
Epoch loss: 16.475897
train phase, Epoch 23/30, Loss: 13.656141
val phase, Epoch 23/30, Loss: 16.587678
Val Best Loss: 15.604998
Epoch loss: 16.587678
train phase, Epoch 24/30, Loss: 13.274468
val phase, Epoch 24/30, Loss: 17.593173
Val Best Loss: 15.604998
Epoch loss: 17.593173
train phase, Epoch 25/30, Loss: 12.545250
val phase, Epoch 25/30, Loss: 16.957097
Val Best Loss: 15.604998
Epoch loss: 16.957097
train phase, Epoch 26/30, Loss: 12.303193
val phase, Epoch 26/30, Loss: 16.998915
Val Best Loss: 15.604998
Epoch loss: 16.998915
train phase, Epoch 27/30, Loss: 11.790103
val phase, Epoch 27/30, Loss: 17.791064
Val Best Loss: 15.604998
Epoch loss: 17.791064
train phase, Epoch 28/30, Loss: 11.461482
val phase, Epoch 28/30, Loss: 18.141831
Val Best Loss: 15.604998
Epoch loss: 18.141831
train phase, Epoch 29/30, Loss: 10.912664
val phase, Epoch 29/30, Loss: 17.749823
Val Best Loss: 15.604998
Epoch loss: 17.749823
train phase, Epoch 30/30, Loss: 10.580708
val phase, Epoch 30/30, Loss: 17.369692
Val Best Loss: 15.604998
Epoch loss: 17.369692
[Trial 298] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 20.218246
val phase, Epoch 1/30, Loss: 17.510724
Val Best Loss: 17.510724
Epoch loss: 17.510724
train phase, Epoch 2/30, Loss: 17.888100
val phase, Epoch 2/30, Loss: 16.745127
Val Best Loss: 16.745127
Epoch loss: 16.745127
train phase, Epoch 3/30, Loss: 17.511428
val phase, Epoch 3/30, Loss: 16.833083
Val Best Loss: 16.745127
Epoch loss: 16.833083
train phase, Epoch 4/30, Loss: 17.201579
val phase, Epoch 4/30, Loss: 17.946060
Val Best Loss: 16.745127
Epoch loss: 17.946060
train phase, Epoch 5/30, Loss: 17.047655
val phase, Epoch 5/30, Loss: 19.909372
Val Best Loss: 16.745127
Epoch loss: 19.909372
train phase, Epoch 6/30, Loss: 17.305746
val phase, Epoch 6/30, Loss: 17.061365
Val Best Loss: 16.745127
Epoch loss: 17.061365
train phase, Epoch 7/30, Loss: 16.834894
val phase, Epoch 7/30, Loss: 21.572981
Val Best Loss: 16.745127
Epoch loss: 21.572981
train phase, Epoch 8/30, Loss: 16.271134
val phase, Epoch 8/30, Loss: 16.173379
Val Best Loss: 16.173379
Epoch loss: 16.173379
train phase, Epoch 9/30, Loss: 16.349954
val phase, Epoch 9/30, Loss: 17.481575
Val Best Loss: 16.173379
Epoch loss: 17.481575
train phase, Epoch 10/30, Loss: 15.976431
val phase, Epoch 10/30, Loss: 16.356534
Val Best Loss: 16.173379
Epoch loss: 16.356534
train phase, Epoch 11/30, Loss: 16.104593
val phase, Epoch 11/30, Loss: 16.803773
Val Best Loss: 16.173379
Epoch loss: 16.803773
train phase, Epoch 12/30, Loss: 15.966266
val phase, Epoch 12/30, Loss: 16.054882
Val Best Loss: 16.054882
Epoch loss: 16.054882
train phase, Epoch 13/30, Loss: 15.847251
val phase, Epoch 13/30, Loss: 18.946260
Val Best Loss: 16.054882
Epoch loss: 18.946260
train phase, Epoch 14/30, Loss: 15.527622
val phase, Epoch 14/30, Loss: 15.950764
Val Best Loss: 15.950764
Epoch loss: 15.950764
train phase, Epoch 15/30, Loss: 15.437584
val phase, Epoch 15/30, Loss: 16.502487
Val Best Loss: 15.950764
Epoch loss: 16.502487
train phase, Epoch 16/30, Loss: 15.030331
val phase, Epoch 16/30, Loss: 15.800066
Val Best Loss: 15.800066
Epoch loss: 15.800066
train phase, Epoch 17/30, Loss: 14.907200
val phase, Epoch 17/30, Loss: 16.134940
Val Best Loss: 15.800066
Epoch loss: 16.134940
train phase, Epoch 18/30, Loss: 14.632585
val phase, Epoch 18/30, Loss: 16.036601
Val Best Loss: 15.800066
Epoch loss: 16.036601
train phase, Epoch 19/30, Loss: 14.597517
val phase, Epoch 19/30, Loss: 16.041138
Val Best Loss: 15.800066
Epoch loss: 16.041138
train phase, Epoch 20/30, Loss: 14.197562
val phase, Epoch 20/30, Loss: 15.912955
Val Best Loss: 15.800066
Epoch loss: 15.912955
train phase, Epoch 21/30, Loss: 14.069410
val phase, Epoch 21/30, Loss: 16.233883
Val Best Loss: 15.800066
Epoch loss: 16.233883
train phase, Epoch 22/30, Loss: 13.817667
val phase, Epoch 22/30, Loss: 16.023977
Val Best Loss: 15.800066
Epoch loss: 16.023977
train phase, Epoch 23/30, Loss: 13.392289
val phase, Epoch 23/30, Loss: 16.506103
Val Best Loss: 15.800066
Epoch loss: 16.506103
train phase, Epoch 24/30, Loss: 12.988040
val phase, Epoch 24/30, Loss: 17.011893
Val Best Loss: 15.800066
Epoch loss: 17.011893
train phase, Epoch 25/30, Loss: 12.595260
val phase, Epoch 25/30, Loss: 17.246435
Val Best Loss: 15.800066
Epoch loss: 17.246435
train phase, Epoch 26/30, Loss: 12.244612
val phase, Epoch 26/30, Loss: 16.861548
Val Best Loss: 15.800066
Epoch loss: 16.861548
train phase, Epoch 27/30, Loss: 11.978051
val phase, Epoch 27/30, Loss: 17.727840
Val Best Loss: 15.800066
Epoch loss: 17.727840
train phase, Epoch 28/30, Loss: 11.750945
val phase, Epoch 28/30, Loss: 17.386993
Val Best Loss: 15.800066
Epoch loss: 17.386993
train phase, Epoch 29/30, Loss: 11.125199
val phase, Epoch 29/30, Loss: 18.395097
Val Best Loss: 15.800066
Epoch loss: 18.395097
train phase, Epoch 30/30, Loss: 10.979583
val phase, Epoch 30/30, Loss: 18.340741
Val Best Loss: 15.800066
Epoch loss: 18.340741
train phase, Epoch 1/30, Loss: 20.251466
val phase, Epoch 1/30, Loss: 29.124880
Val Best Loss: 29.124880
Epoch loss: 29.124880
train phase, Epoch 2/30, Loss: 18.500163
val phase, Epoch 2/30, Loss: 16.970503
Val Best Loss: 16.970503
Epoch loss: 16.970503
train phase, Epoch 3/30, Loss: 17.828356
val phase, Epoch 3/30, Loss: 20.985544
Val Best Loss: 16.970503
Epoch loss: 20.985544
train phase, Epoch 4/30, Loss: 17.900242
val phase, Epoch 4/30, Loss: 16.186264
Val Best Loss: 16.186264
Epoch loss: 16.186264
train phase, Epoch 5/30, Loss: 17.177076
val phase, Epoch 5/30, Loss: 16.936063
Val Best Loss: 16.186264
Epoch loss: 16.936063
train phase, Epoch 6/30, Loss: 17.266928
val phase, Epoch 6/30, Loss: 16.751213
Val Best Loss: 16.186264
Epoch loss: 16.751213
train phase, Epoch 7/30, Loss: 16.942308
val phase, Epoch 7/30, Loss: 16.817782
Val Best Loss: 16.186264
Epoch loss: 16.817782
train phase, Epoch 8/30, Loss: 16.569425
val phase, Epoch 8/30, Loss: 17.599368
Val Best Loss: 16.186264
Epoch loss: 17.599368
train phase, Epoch 9/30, Loss: 16.649621
val phase, Epoch 9/30, Loss: 17.372506
Val Best Loss: 16.186264
Epoch loss: 17.372506
train phase, Epoch 10/30, Loss: 16.478327
val phase, Epoch 10/30, Loss: 17.843069
Val Best Loss: 16.186264
Epoch loss: 17.843069
train phase, Epoch 11/30, Loss: 16.287123
val phase, Epoch 11/30, Loss: 16.037807
Val Best Loss: 16.037807
Epoch loss: 16.037807
train phase, Epoch 12/30, Loss: 15.962311
val phase, Epoch 12/30, Loss: 16.347260
Val Best Loss: 16.037807
Epoch loss: 16.347260
train phase, Epoch 13/30, Loss: 15.785052
val phase, Epoch 13/30, Loss: 16.054893
Val Best Loss: 16.037807
Epoch loss: 16.054893
train phase, Epoch 14/30, Loss: 15.694611
val phase, Epoch 14/30, Loss: 16.245249
Val Best Loss: 16.037807
Epoch loss: 16.245249
train phase, Epoch 15/30, Loss: 15.389149
val phase, Epoch 15/30, Loss: 18.010438
Val Best Loss: 16.037807
Epoch loss: 18.010438
train phase, Epoch 16/30, Loss: 15.438916
val phase, Epoch 16/30, Loss: 16.282455
Val Best Loss: 16.037807
Epoch loss: 16.282455
train phase, Epoch 17/30, Loss: 15.023276
val phase, Epoch 17/30, Loss: 15.882814
Val Best Loss: 15.882814
Epoch loss: 15.882814
train phase, Epoch 18/30, Loss: 14.937130
val phase, Epoch 18/30, Loss: 16.187082
Val Best Loss: 15.882814
Epoch loss: 16.187082
train phase, Epoch 19/30, Loss: 14.648287
val phase, Epoch 19/30, Loss: 16.120557
Val Best Loss: 15.882814
Epoch loss: 16.120557
train phase, Epoch 20/30, Loss: 14.425212
val phase, Epoch 20/30, Loss: 16.666107
Val Best Loss: 15.882814
Epoch loss: 16.666107
train phase, Epoch 21/30, Loss: 14.264529
val phase, Epoch 21/30, Loss: 16.448653
Val Best Loss: 15.882814
Epoch loss: 16.448653
train phase, Epoch 22/30, Loss: 13.901555
val phase, Epoch 22/30, Loss: 17.667630
Val Best Loss: 15.882814
Epoch loss: 17.667630
train phase, Epoch 23/30, Loss: 13.542071
val phase, Epoch 23/30, Loss: 17.356495
Val Best Loss: 15.882814
Epoch loss: 17.356495
train phase, Epoch 24/30, Loss: 13.221355
val phase, Epoch 24/30, Loss: 18.071793
Val Best Loss: 15.882814
Epoch loss: 18.071793
train phase, Epoch 25/30, Loss: 13.002406
val phase, Epoch 25/30, Loss: 18.435607
Val Best Loss: 15.882814
Epoch loss: 18.435607
train phase, Epoch 26/30, Loss: 12.542307
val phase, Epoch 26/30, Loss: 16.932607
Val Best Loss: 15.882814
Epoch loss: 16.932607
train phase, Epoch 27/30, Loss: 12.489189
val phase, Epoch 27/30, Loss: 18.145616
Val Best Loss: 15.882814
Epoch loss: 18.145616
train phase, Epoch 28/30, Loss: 11.851490
val phase, Epoch 28/30, Loss: 17.700527
Val Best Loss: 15.882814
Epoch loss: 17.700527
train phase, Epoch 29/30, Loss: 11.658097
val phase, Epoch 29/30, Loss: 16.932884
Val Best Loss: 15.882814
Epoch loss: 16.932884
train phase, Epoch 30/30, Loss: 11.214669
val phase, Epoch 30/30, Loss: 17.390835
Val Best Loss: 15.882814
Epoch loss: 17.390835
train phase, Epoch 1/30, Loss: 20.911924
val phase, Epoch 1/30, Loss: 17.982855
Val Best Loss: 17.982855
Epoch loss: 17.982855
train phase, Epoch 2/30, Loss: 17.715280
val phase, Epoch 2/30, Loss: 16.574473
Val Best Loss: 16.574473
Epoch loss: 16.574473
train phase, Epoch 3/30, Loss: 17.534949
val phase, Epoch 3/30, Loss: 17.633167
Val Best Loss: 16.574473
Epoch loss: 17.633167
train phase, Epoch 4/30, Loss: 17.266569
val phase, Epoch 4/30, Loss: 17.020553
Val Best Loss: 16.574473
Epoch loss: 17.020553
train phase, Epoch 5/30, Loss: 17.245918
val phase, Epoch 5/30, Loss: 17.726163
Val Best Loss: 16.574473
Epoch loss: 17.726163
train phase, Epoch 6/30, Loss: 16.810664
val phase, Epoch 6/30, Loss: 16.437884
Val Best Loss: 16.437884
Epoch loss: 16.437884
train phase, Epoch 7/30, Loss: 16.316778
val phase, Epoch 7/30, Loss: 16.525840
Val Best Loss: 16.437884
Epoch loss: 16.525840
train phase, Epoch 8/30, Loss: 16.384785
val phase, Epoch 8/30, Loss: 18.065787
Val Best Loss: 16.437884
Epoch loss: 18.065787
train phase, Epoch 9/30, Loss: 16.079278
val phase, Epoch 9/30, Loss: 15.813082
Val Best Loss: 15.813082
Epoch loss: 15.813082
train phase, Epoch 10/30, Loss: 16.115230
val phase, Epoch 10/30, Loss: 16.087428
Val Best Loss: 15.813082
Epoch loss: 16.087428
train phase, Epoch 11/30, Loss: 15.967256
val phase, Epoch 11/30, Loss: 15.993972
Val Best Loss: 15.813082
Epoch loss: 15.993972
train phase, Epoch 12/30, Loss: 15.661163
val phase, Epoch 12/30, Loss: 15.950935
Val Best Loss: 15.813082
Epoch loss: 15.950935
train phase, Epoch 13/30, Loss: 15.499946
val phase, Epoch 13/30, Loss: 15.963137
Val Best Loss: 15.813082
Epoch loss: 15.963137
train phase, Epoch 14/30, Loss: 15.258740
val phase, Epoch 14/30, Loss: 16.292489
Val Best Loss: 15.813082
Epoch loss: 16.292489
train phase, Epoch 15/30, Loss: 15.397089
val phase, Epoch 15/30, Loss: 16.207378
Val Best Loss: 15.813082
Epoch loss: 16.207378
train phase, Epoch 16/30, Loss: 15.037613
val phase, Epoch 16/30, Loss: 16.246738
Val Best Loss: 15.813082
Epoch loss: 16.246738
train phase, Epoch 17/30, Loss: 14.651210
val phase, Epoch 17/30, Loss: 16.868496
Val Best Loss: 15.813082
Epoch loss: 16.868496
train phase, Epoch 18/30, Loss: 14.417142
val phase, Epoch 18/30, Loss: 16.951313
Val Best Loss: 15.813082
Epoch loss: 16.951313
train phase, Epoch 19/30, Loss: 14.384518
val phase, Epoch 19/30, Loss: 16.887538
Val Best Loss: 15.813082
Epoch loss: 16.887538
train phase, Epoch 20/30, Loss: 13.830980
val phase, Epoch 20/30, Loss: 15.998643
Val Best Loss: 15.813082
Epoch loss: 15.998643
train phase, Epoch 21/30, Loss: 13.619820
val phase, Epoch 21/30, Loss: 19.191242
Val Best Loss: 15.813082
Epoch loss: 19.191242
train phase, Epoch 22/30, Loss: 13.664789
val phase, Epoch 22/30, Loss: 17.226149
Val Best Loss: 15.813082
Epoch loss: 17.226149
train phase, Epoch 23/30, Loss: 13.367754
val phase, Epoch 23/30, Loss: 17.025683
Val Best Loss: 15.813082
Epoch loss: 17.025683
train phase, Epoch 24/30, Loss: 12.676573
val phase, Epoch 24/30, Loss: 17.132301
Val Best Loss: 15.813082
Epoch loss: 17.132301
train phase, Epoch 25/30, Loss: 12.252660
val phase, Epoch 25/30, Loss: 18.698693
Val Best Loss: 15.813082
Epoch loss: 18.698693
train phase, Epoch 26/30, Loss: 11.859447
val phase, Epoch 26/30, Loss: 17.433327
Val Best Loss: 15.813082
Epoch loss: 17.433327
train phase, Epoch 27/30, Loss: 11.522763
val phase, Epoch 27/30, Loss: 17.632214
Val Best Loss: 15.813082
Epoch loss: 17.632214
train phase, Epoch 28/30, Loss: 11.123278
val phase, Epoch 28/30, Loss: 17.801837
Val Best Loss: 15.813082
Epoch loss: 17.801837
train phase, Epoch 29/30, Loss: 10.439745
val phase, Epoch 29/30, Loss: 18.723437
Val Best Loss: 15.813082
Epoch loss: 18.723437
train phase, Epoch 30/30, Loss: 10.177634
val phase, Epoch 30/30, Loss: 18.075590
Val Best Loss: 15.813082
Epoch loss: 18.075590
train phase, Epoch 1/30, Loss: 21.514752
val phase, Epoch 1/30, Loss: 17.448256
Val Best Loss: 17.448256
Epoch loss: 17.448256
train phase, Epoch 2/30, Loss: 17.875676
val phase, Epoch 2/30, Loss: 16.910563
Val Best Loss: 16.910563
Epoch loss: 16.910563
train phase, Epoch 3/30, Loss: 17.385836
val phase, Epoch 3/30, Loss: 17.563364
Val Best Loss: 16.910563
Epoch loss: 17.563364
train phase, Epoch 4/30, Loss: 17.177528
val phase, Epoch 4/30, Loss: 16.490255
Val Best Loss: 16.490255
Epoch loss: 16.490255
train phase, Epoch 5/30, Loss: 16.947564
val phase, Epoch 5/30, Loss: 16.111905
Val Best Loss: 16.111905
Epoch loss: 16.111905
train phase, Epoch 6/30, Loss: 16.805248
val phase, Epoch 6/30, Loss: 16.779512
Val Best Loss: 16.111905
Epoch loss: 16.779512
train phase, Epoch 7/30, Loss: 16.910002
val phase, Epoch 7/30, Loss: 16.316068
Val Best Loss: 16.111905
Epoch loss: 16.316068
train phase, Epoch 8/30, Loss: 16.343302
val phase, Epoch 8/30, Loss: 16.362345
Val Best Loss: 16.111905
Epoch loss: 16.362345
train phase, Epoch 9/30, Loss: 16.434041
val phase, Epoch 9/30, Loss: 17.938445
Val Best Loss: 16.111905
Epoch loss: 17.938445
train phase, Epoch 10/30, Loss: 16.203875
val phase, Epoch 10/30, Loss: 15.696824
Val Best Loss: 15.696824
Epoch loss: 15.696824
train phase, Epoch 11/30, Loss: 15.885682
val phase, Epoch 11/30, Loss: 16.474000
Val Best Loss: 15.696824
Epoch loss: 16.474000
train phase, Epoch 12/30, Loss: 15.725547
val phase, Epoch 12/30, Loss: 17.341178
Val Best Loss: 15.696824
Epoch loss: 17.341178
train phase, Epoch 13/30, Loss: 15.401856
val phase, Epoch 13/30, Loss: 15.785380
Val Best Loss: 15.696824
Epoch loss: 15.785380
train phase, Epoch 14/30, Loss: 15.287372
val phase, Epoch 14/30, Loss: 16.962060
Val Best Loss: 15.696824
Epoch loss: 16.962060
train phase, Epoch 15/30, Loss: 15.379126
val phase, Epoch 15/30, Loss: 15.704752
Val Best Loss: 15.696824
Epoch loss: 15.704752
train phase, Epoch 16/30, Loss: 14.911839
val phase, Epoch 16/30, Loss: 15.824132
Val Best Loss: 15.696824
Epoch loss: 15.824132
train phase, Epoch 17/30, Loss: 14.876824
val phase, Epoch 17/30, Loss: 16.933584
Val Best Loss: 15.696824
Epoch loss: 16.933584
train phase, Epoch 18/30, Loss: 14.502790
val phase, Epoch 18/30, Loss: 16.119480
Val Best Loss: 15.696824
Epoch loss: 16.119480
train phase, Epoch 19/30, Loss: 14.426367
val phase, Epoch 19/30, Loss: 16.473835
Val Best Loss: 15.696824
Epoch loss: 16.473835
train phase, Epoch 20/30, Loss: 14.175303
val phase, Epoch 20/30, Loss: 17.293688
Val Best Loss: 15.696824
Epoch loss: 17.293688
train phase, Epoch 21/30, Loss: 13.683760
val phase, Epoch 21/30, Loss: 16.879274
Val Best Loss: 15.696824
Epoch loss: 16.879274
train phase, Epoch 22/30, Loss: 13.204394
val phase, Epoch 22/30, Loss: 19.092724
Val Best Loss: 15.696824
Epoch loss: 19.092724
train phase, Epoch 23/30, Loss: 13.038323
val phase, Epoch 23/30, Loss: 17.504442
Val Best Loss: 15.696824
Epoch loss: 17.504442
train phase, Epoch 24/30, Loss: 12.799782
val phase, Epoch 24/30, Loss: 16.743286
Val Best Loss: 15.696824
Epoch loss: 16.743286
train phase, Epoch 25/30, Loss: 12.313051
val phase, Epoch 25/30, Loss: 17.814323
Val Best Loss: 15.696824
Epoch loss: 17.814323
train phase, Epoch 26/30, Loss: 11.874690
val phase, Epoch 26/30, Loss: 17.587590
Val Best Loss: 15.696824
Epoch loss: 17.587590
train phase, Epoch 27/30, Loss: 11.627425
val phase, Epoch 27/30, Loss: 17.734887
Val Best Loss: 15.696824
Epoch loss: 17.734887
train phase, Epoch 28/30, Loss: 11.105865
val phase, Epoch 28/30, Loss: 18.498464
Val Best Loss: 15.696824
Epoch loss: 18.498464
train phase, Epoch 29/30, Loss: 11.141027
val phase, Epoch 29/30, Loss: 17.340805
Val Best Loss: 15.696824
Epoch loss: 17.340805
train phase, Epoch 30/30, Loss: 10.473903
val phase, Epoch 30/30, Loss: 18.502170
Val Best Loss: 15.696824
Epoch loss: 18.502170
[Trial 303] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/15, Loss: 19.766250
val phase, Epoch 1/15, Loss: 18.218799
Val Best Loss: 18.218799
Epoch loss: 18.218799
train phase, Epoch 2/15, Loss: 18.354127
val phase, Epoch 2/15, Loss: 20.134222
Val Best Loss: 18.218799
Epoch loss: 20.134222
train phase, Epoch 3/15, Loss: 17.402477
val phase, Epoch 3/15, Loss: 19.320010
Val Best Loss: 18.218799
Epoch loss: 19.320010
train phase, Epoch 4/15, Loss: 17.192149
val phase, Epoch 4/15, Loss: 18.585538
Val Best Loss: 18.218799
Epoch loss: 18.585538
train phase, Epoch 5/15, Loss: 16.972980
val phase, Epoch 5/15, Loss: 18.073020
Val Best Loss: 18.073020
Epoch loss: 18.073020
train phase, Epoch 6/15, Loss: 16.811828
val phase, Epoch 6/15, Loss: 18.316277
Val Best Loss: 18.073020
Epoch loss: 18.316277
train phase, Epoch 7/15, Loss: 16.652794
val phase, Epoch 7/15, Loss: 16.671394
Val Best Loss: 16.671394
Epoch loss: 16.671394
train phase, Epoch 8/15, Loss: 16.539279
val phase, Epoch 8/15, Loss: 16.769901
Val Best Loss: 16.671394
Epoch loss: 16.769901
train phase, Epoch 9/15, Loss: 16.374601
val phase, Epoch 9/15, Loss: 15.954303
Val Best Loss: 15.954303
Epoch loss: 15.954303
train phase, Epoch 10/15, Loss: 16.213518
val phase, Epoch 10/15, Loss: 15.919112
Val Best Loss: 15.919112
Epoch loss: 15.919112
train phase, Epoch 11/15, Loss: 16.036048
val phase, Epoch 11/15, Loss: 16.250508
Val Best Loss: 15.919112
Epoch loss: 16.250508
train phase, Epoch 12/15, Loss: 15.686652
val phase, Epoch 12/15, Loss: 16.649870
Val Best Loss: 15.919112
Epoch loss: 16.649870
train phase, Epoch 13/15, Loss: 15.732730
val phase, Epoch 13/15, Loss: 16.149510
Val Best Loss: 15.919112
Epoch loss: 16.149510
train phase, Epoch 14/15, Loss: 15.554008
val phase, Epoch 14/15, Loss: 15.977170
Val Best Loss: 15.919112
Epoch loss: 15.977170
train phase, Epoch 15/15, Loss: 15.593264
val phase, Epoch 15/15, Loss: 15.918473
Val Best Loss: 15.918473
Epoch loss: 15.918473
train phase, Epoch 1/30, Loss: 21.792967
val phase, Epoch 1/30, Loss: 18.259986
Val Best Loss: 18.259986
Epoch loss: 18.259986
train phase, Epoch 2/30, Loss: 18.771672
val phase, Epoch 2/30, Loss: 18.699861
Val Best Loss: 18.259986
Epoch loss: 18.699861
train phase, Epoch 3/30, Loss: 18.353660
val phase, Epoch 3/30, Loss: 17.444619
Val Best Loss: 17.444619
Epoch loss: 17.444619
train phase, Epoch 4/30, Loss: 18.229272
val phase, Epoch 4/30, Loss: 19.788654
Val Best Loss: 17.444619
Epoch loss: 19.788654
train phase, Epoch 5/30, Loss: 17.601165
val phase, Epoch 5/30, Loss: 17.433433
Val Best Loss: 17.433433
Epoch loss: 17.433433
train phase, Epoch 6/30, Loss: 17.493067
val phase, Epoch 6/30, Loss: 16.933089
Val Best Loss: 16.933089
Epoch loss: 16.933089
train phase, Epoch 7/30, Loss: 17.146059
val phase, Epoch 7/30, Loss: 18.314698
Val Best Loss: 16.933089
Epoch loss: 18.314698
train phase, Epoch 8/30, Loss: 17.095236
val phase, Epoch 8/30, Loss: 16.761750
Val Best Loss: 16.761750
Epoch loss: 16.761750
train phase, Epoch 9/30, Loss: 16.855388
val phase, Epoch 9/30, Loss: 17.949978
Val Best Loss: 16.761750
Epoch loss: 17.949978
train phase, Epoch 10/30, Loss: 16.775661
val phase, Epoch 10/30, Loss: 16.600135
Val Best Loss: 16.600135
Epoch loss: 16.600135
train phase, Epoch 11/30, Loss: 16.595106
val phase, Epoch 11/30, Loss: 16.282937
Val Best Loss: 16.282937
Epoch loss: 16.282937
train phase, Epoch 12/30, Loss: 16.655313
val phase, Epoch 12/30, Loss: 16.578257
Val Best Loss: 16.282937
Epoch loss: 16.578257
train phase, Epoch 13/30, Loss: 16.301972
val phase, Epoch 13/30, Loss: 16.182677
Val Best Loss: 16.182677
Epoch loss: 16.182677
train phase, Epoch 14/30, Loss: 16.217587
val phase, Epoch 14/30, Loss: 17.120827
Val Best Loss: 16.182677
Epoch loss: 17.120827
train phase, Epoch 15/30, Loss: 16.013372
val phase, Epoch 15/30, Loss: 16.322908
Val Best Loss: 16.182677
Epoch loss: 16.322908
train phase, Epoch 16/30, Loss: 15.989775
val phase, Epoch 16/30, Loss: 16.783531
Val Best Loss: 16.182677
Epoch loss: 16.783531
train phase, Epoch 17/30, Loss: 15.723734
val phase, Epoch 17/30, Loss: 16.294938
Val Best Loss: 16.182677
Epoch loss: 16.294938
train phase, Epoch 18/30, Loss: 15.511163
val phase, Epoch 18/30, Loss: 19.801795
Val Best Loss: 16.182677
Epoch loss: 19.801795
train phase, Epoch 19/30, Loss: 15.753787
val phase, Epoch 19/30, Loss: 16.250361
Val Best Loss: 16.182677
Epoch loss: 16.250361
train phase, Epoch 20/30, Loss: 15.336342
val phase, Epoch 20/30, Loss: 16.451107
Val Best Loss: 16.182677
Epoch loss: 16.451107
train phase, Epoch 21/30, Loss: 14.925255
val phase, Epoch 21/30, Loss: 16.083976
Val Best Loss: 16.083976
Epoch loss: 16.083976
train phase, Epoch 22/30, Loss: 14.776589
val phase, Epoch 22/30, Loss: 18.461131
Val Best Loss: 16.083976
Epoch loss: 18.461131
train phase, Epoch 23/30, Loss: 14.690626
val phase, Epoch 23/30, Loss: 17.543842
Val Best Loss: 16.083976
Epoch loss: 17.543842
train phase, Epoch 24/30, Loss: 14.351709
val phase, Epoch 24/30, Loss: 18.241275
Val Best Loss: 16.083976
Epoch loss: 18.241275
train phase, Epoch 25/30, Loss: 14.064987
val phase, Epoch 25/30, Loss: 16.742817
Val Best Loss: 16.083976
Epoch loss: 16.742817
train phase, Epoch 26/30, Loss: 13.651258
val phase, Epoch 26/30, Loss: 17.124832
Val Best Loss: 16.083976
Epoch loss: 17.124832
train phase, Epoch 27/30, Loss: 13.570879
val phase, Epoch 27/30, Loss: 17.653128
Val Best Loss: 16.083976
Epoch loss: 17.653128
train phase, Epoch 28/30, Loss: 13.305037
val phase, Epoch 28/30, Loss: 17.387192
Val Best Loss: 16.083976
Epoch loss: 17.387192
train phase, Epoch 29/30, Loss: 13.105230
val phase, Epoch 29/30, Loss: 17.677488
Val Best Loss: 16.083976
Epoch loss: 17.677488
train phase, Epoch 30/30, Loss: 12.564880
val phase, Epoch 30/30, Loss: 20.131599
Val Best Loss: 16.083976
Epoch loss: 20.131599
train phase, Epoch 1/20, Loss: 20.898730
val phase, Epoch 1/20, Loss: 19.020645
Val Best Loss: 19.020645
Epoch loss: 19.020645
train phase, Epoch 2/20, Loss: 17.309876
val phase, Epoch 2/20, Loss: 18.332295
Val Best Loss: 18.332295
Epoch loss: 18.332295
train phase, Epoch 3/20, Loss: 17.117513
val phase, Epoch 3/20, Loss: 16.937184
Val Best Loss: 16.937184
Epoch loss: 16.937184
train phase, Epoch 4/20, Loss: 16.659758
val phase, Epoch 4/20, Loss: 17.304073
Val Best Loss: 16.937184
Epoch loss: 17.304073
train phase, Epoch 5/20, Loss: 16.410355
val phase, Epoch 5/20, Loss: 17.925909
Val Best Loss: 16.937184
Epoch loss: 17.925909
train phase, Epoch 6/20, Loss: 16.308352
val phase, Epoch 6/20, Loss: 16.955070
Val Best Loss: 16.937184
Epoch loss: 16.955070
train phase, Epoch 7/20, Loss: 15.996457
val phase, Epoch 7/20, Loss: 17.507973
Val Best Loss: 16.937184
Epoch loss: 17.507973
train phase, Epoch 8/20, Loss: 15.833723
val phase, Epoch 8/20, Loss: 17.603806
Val Best Loss: 16.937184
Epoch loss: 17.603806
train phase, Epoch 9/20, Loss: 15.604794
val phase, Epoch 9/20, Loss: 17.111950
Val Best Loss: 16.937184
Epoch loss: 17.111950
train phase, Epoch 10/20, Loss: 15.434391
val phase, Epoch 10/20, Loss: 17.812014
Val Best Loss: 16.937184
Epoch loss: 17.812014
train phase, Epoch 11/20, Loss: 15.274548
val phase, Epoch 11/20, Loss: 16.168663
Val Best Loss: 16.168663
Epoch loss: 16.168663
train phase, Epoch 12/20, Loss: 14.992397
val phase, Epoch 12/20, Loss: 18.750006
Val Best Loss: 16.168663
Epoch loss: 18.750006
train phase, Epoch 13/20, Loss: 14.739541
val phase, Epoch 13/20, Loss: 19.425576
Val Best Loss: 16.168663
Epoch loss: 19.425576
train phase, Epoch 14/20, Loss: 14.720709
val phase, Epoch 14/20, Loss: 16.202289
Val Best Loss: 16.168663
Epoch loss: 16.202289
train phase, Epoch 15/20, Loss: 14.090800
val phase, Epoch 15/20, Loss: 16.282744
Val Best Loss: 16.168663
Epoch loss: 16.282744
train phase, Epoch 16/20, Loss: 13.907220
val phase, Epoch 16/20, Loss: 18.436450
Val Best Loss: 16.168663
Epoch loss: 18.436450
train phase, Epoch 17/20, Loss: 13.525684
val phase, Epoch 17/20, Loss: 16.429810
Val Best Loss: 16.168663
Epoch loss: 16.429810
train phase, Epoch 18/20, Loss: 13.186749
val phase, Epoch 18/20, Loss: 18.064941
Val Best Loss: 16.168663
Epoch loss: 18.064941
train phase, Epoch 19/20, Loss: 12.883166
val phase, Epoch 19/20, Loss: 17.341537
Val Best Loss: 16.168663
Epoch loss: 17.341537
train phase, Epoch 20/20, Loss: 12.480151
val phase, Epoch 20/20, Loss: 16.972256
Val Best Loss: 16.168663
Epoch loss: 16.972256
train phase, Epoch 1/12, Loss: 20.127168
val phase, Epoch 1/12, Loss: 18.504597
Val Best Loss: 18.504597
Epoch loss: 18.504597
train phase, Epoch 2/12, Loss: 17.974400
val phase, Epoch 2/12, Loss: 16.721185
Val Best Loss: 16.721185
Epoch loss: 16.721185
train phase, Epoch 3/12, Loss: 17.712371
val phase, Epoch 3/12, Loss: 16.384609
Val Best Loss: 16.384609
Epoch loss: 16.384609
train phase, Epoch 4/12, Loss: 17.087139
val phase, Epoch 4/12, Loss: 16.342019
Val Best Loss: 16.342019
Epoch loss: 16.342019
train phase, Epoch 5/12, Loss: 17.026232
val phase, Epoch 5/12, Loss: 17.038540
Val Best Loss: 16.342019
Epoch loss: 17.038540
train phase, Epoch 6/12, Loss: 16.676742
val phase, Epoch 6/12, Loss: 17.941316
Val Best Loss: 16.342019
Epoch loss: 17.941316
train phase, Epoch 7/12, Loss: 16.618001
val phase, Epoch 7/12, Loss: 16.083596
Val Best Loss: 16.083596
Epoch loss: 16.083596
train phase, Epoch 8/12, Loss: 16.413772
val phase, Epoch 8/12, Loss: 16.129545
Val Best Loss: 16.083596
Epoch loss: 16.129545
train phase, Epoch 9/12, Loss: 16.447997
val phase, Epoch 9/12, Loss: 17.149669
Val Best Loss: 16.083596
Epoch loss: 17.149669
train phase, Epoch 10/12, Loss: 16.288832
val phase, Epoch 10/12, Loss: 16.122018
Val Best Loss: 16.083596
Epoch loss: 16.122018
train phase, Epoch 11/12, Loss: 15.979530
val phase, Epoch 11/12, Loss: 19.618762
Val Best Loss: 16.083596
Epoch loss: 19.618762
train phase, Epoch 12/12, Loss: 16.075413
val phase, Epoch 12/12, Loss: 16.557149
Val Best Loss: 16.083596
Epoch loss: 16.557149
train phase, Epoch 1/20, Loss: 20.691090
val phase, Epoch 1/20, Loss: 19.156723
Val Best Loss: 19.156723
Epoch loss: 19.156723
train phase, Epoch 2/20, Loss: 18.856790
val phase, Epoch 2/20, Loss: 23.971792
Val Best Loss: 19.156723
Epoch loss: 23.971792
train phase, Epoch 3/20, Loss: 18.162949
val phase, Epoch 3/20, Loss: 19.089926
Val Best Loss: 19.089926
Epoch loss: 19.089926
train phase, Epoch 4/20, Loss: 18.209703
val phase, Epoch 4/20, Loss: 19.166807
Val Best Loss: 19.089926
Epoch loss: 19.166807
train phase, Epoch 5/20, Loss: 17.685825
val phase, Epoch 5/20, Loss: 16.508498
Val Best Loss: 16.508498
Epoch loss: 16.508498
train phase, Epoch 6/20, Loss: 17.412920
val phase, Epoch 6/20, Loss: 16.873632
Val Best Loss: 16.508498
Epoch loss: 16.873632
train phase, Epoch 7/20, Loss: 17.088846
val phase, Epoch 7/20, Loss: 17.322811
Val Best Loss: 16.508498
Epoch loss: 17.322811
train phase, Epoch 8/20, Loss: 17.228141
val phase, Epoch 8/20, Loss: 16.489117
Val Best Loss: 16.489117
Epoch loss: 16.489117
train phase, Epoch 9/20, Loss: 16.927149
val phase, Epoch 9/20, Loss: 16.317045
Val Best Loss: 16.317045
Epoch loss: 16.317045
train phase, Epoch 10/20, Loss: 16.656858
val phase, Epoch 10/20, Loss: 19.268918
Val Best Loss: 16.317045
Epoch loss: 19.268918
train phase, Epoch 11/20, Loss: 16.691726
val phase, Epoch 11/20, Loss: 16.182292
Val Best Loss: 16.182292
Epoch loss: 16.182292
train phase, Epoch 12/20, Loss: 16.617955
val phase, Epoch 12/20, Loss: 17.103920
Val Best Loss: 16.182292
Epoch loss: 17.103920
train phase, Epoch 13/20, Loss: 16.425668
val phase, Epoch 13/20, Loss: 17.303423
Val Best Loss: 16.182292
Epoch loss: 17.303423
train phase, Epoch 14/20, Loss: 16.413951
val phase, Epoch 14/20, Loss: 17.619556
Val Best Loss: 16.182292
Epoch loss: 17.619556
train phase, Epoch 15/20, Loss: 16.110103
val phase, Epoch 15/20, Loss: 16.741105
Val Best Loss: 16.182292
Epoch loss: 16.741105
train phase, Epoch 16/20, Loss: 16.197581
val phase, Epoch 16/20, Loss: 16.291729
Val Best Loss: 16.182292
Epoch loss: 16.291729
train phase, Epoch 17/20, Loss: 15.904458
val phase, Epoch 17/20, Loss: 16.090941
Val Best Loss: 16.090941
Epoch loss: 16.090941
train phase, Epoch 18/20, Loss: 15.862217
val phase, Epoch 18/20, Loss: 15.755435
Val Best Loss: 15.755435
Epoch loss: 15.755435
train phase, Epoch 19/20, Loss: 15.581233
val phase, Epoch 19/20, Loss: 15.895426
Val Best Loss: 15.755435
Epoch loss: 15.895426
train phase, Epoch 20/20, Loss: 15.398671
val phase, Epoch 20/20, Loss: 16.191024
Val Best Loss: 15.755435
Epoch loss: 16.191024
train phase, Epoch 1/30, Loss: 19.852889
val phase, Epoch 1/30, Loss: 17.428283
Val Best Loss: 17.428283
Epoch loss: 17.428283
train phase, Epoch 2/30, Loss: 18.117199
val phase, Epoch 2/30, Loss: 19.384389
Val Best Loss: 17.428283
Epoch loss: 19.384389
train phase, Epoch 3/30, Loss: 18.035407
val phase, Epoch 3/30, Loss: 16.872732
Val Best Loss: 16.872732
Epoch loss: 16.872732
train phase, Epoch 4/30, Loss: 17.139049
val phase, Epoch 4/30, Loss: 16.400957
Val Best Loss: 16.400957
Epoch loss: 16.400957
train phase, Epoch 5/30, Loss: 16.931720
val phase, Epoch 5/30, Loss: 17.800413
Val Best Loss: 16.400957
Epoch loss: 17.800413
train phase, Epoch 6/30, Loss: 17.242525
val phase, Epoch 6/30, Loss: 16.561510
Val Best Loss: 16.400957
Epoch loss: 16.561510
train phase, Epoch 7/30, Loss: 16.747738
val phase, Epoch 7/30, Loss: 16.637254
Val Best Loss: 16.400957
Epoch loss: 16.637254
train phase, Epoch 8/30, Loss: 16.446297
val phase, Epoch 8/30, Loss: 19.576040
Val Best Loss: 16.400957
Epoch loss: 19.576040
train phase, Epoch 9/30, Loss: 16.176174
val phase, Epoch 9/30, Loss: 18.534266
Val Best Loss: 16.400957
Epoch loss: 18.534266
train phase, Epoch 10/30, Loss: 16.180028
val phase, Epoch 10/30, Loss: 16.395417
Val Best Loss: 16.395417
Epoch loss: 16.395417
train phase, Epoch 11/30, Loss: 15.980515
val phase, Epoch 11/30, Loss: 17.048106
Val Best Loss: 16.395417
Epoch loss: 17.048106
train phase, Epoch 12/30, Loss: 16.048407
val phase, Epoch 12/30, Loss: 16.929839
Val Best Loss: 16.395417
Epoch loss: 16.929839
train phase, Epoch 13/30, Loss: 15.745502
val phase, Epoch 13/30, Loss: 17.307495
Val Best Loss: 16.395417
Epoch loss: 17.307495
train phase, Epoch 14/30, Loss: 15.769212
val phase, Epoch 14/30, Loss: 16.074031
Val Best Loss: 16.074031
Epoch loss: 16.074031
train phase, Epoch 15/30, Loss: 15.465856
val phase, Epoch 15/30, Loss: 17.834010
Val Best Loss: 16.074031
Epoch loss: 17.834010
train phase, Epoch 16/30, Loss: 15.102632
val phase, Epoch 16/30, Loss: 16.337347
Val Best Loss: 16.074031
Epoch loss: 16.337347
train phase, Epoch 17/30, Loss: 15.058087
val phase, Epoch 17/30, Loss: 16.473278
Val Best Loss: 16.074031
Epoch loss: 16.473278
train phase, Epoch 18/30, Loss: 14.824022
val phase, Epoch 18/30, Loss: 16.410862
Val Best Loss: 16.074031
Epoch loss: 16.410862
train phase, Epoch 19/30, Loss: 14.668053
val phase, Epoch 19/30, Loss: 17.052006
Val Best Loss: 16.074031
Epoch loss: 17.052006
train phase, Epoch 20/30, Loss: 14.449095
val phase, Epoch 20/30, Loss: 16.367280
Val Best Loss: 16.074031
Epoch loss: 16.367280
train phase, Epoch 21/30, Loss: 14.007996
val phase, Epoch 21/30, Loss: 16.337719
Val Best Loss: 16.074031
Epoch loss: 16.337719
train phase, Epoch 22/30, Loss: 13.874489
val phase, Epoch 22/30, Loss: 17.694106
Val Best Loss: 16.074031
Epoch loss: 17.694106
train phase, Epoch 23/30, Loss: 13.368952
val phase, Epoch 23/30, Loss: 16.614672
Val Best Loss: 16.074031
Epoch loss: 16.614672
train phase, Epoch 24/30, Loss: 13.038026
val phase, Epoch 24/30, Loss: 17.956268
Val Best Loss: 16.074031
Epoch loss: 17.956268
train phase, Epoch 25/30, Loss: 12.626146
val phase, Epoch 25/30, Loss: 17.365374
Val Best Loss: 16.074031
Epoch loss: 17.365374
train phase, Epoch 26/30, Loss: 12.226137
val phase, Epoch 26/30, Loss: 17.835995
Val Best Loss: 16.074031
Epoch loss: 17.835995
train phase, Epoch 27/30, Loss: 11.883353
val phase, Epoch 27/30, Loss: 18.014975
Val Best Loss: 16.074031
Epoch loss: 18.014975
train phase, Epoch 28/30, Loss: 11.254370
val phase, Epoch 28/30, Loss: 21.018038
Val Best Loss: 16.074031
Epoch loss: 21.018038
train phase, Epoch 29/30, Loss: 10.865868
val phase, Epoch 29/30, Loss: 18.564347
Val Best Loss: 16.074031
Epoch loss: 18.564347
train phase, Epoch 30/30, Loss: 10.513615
val phase, Epoch 30/30, Loss: 18.373437
Val Best Loss: 16.074031
Epoch loss: 18.373437
train phase, Epoch 1/20, Loss: 20.267636
val phase, Epoch 1/20, Loss: 17.426211
Val Best Loss: 17.426211
Epoch loss: 17.426211
train phase, Epoch 2/20, Loss: 17.931633
val phase, Epoch 2/20, Loss: 18.253479
Val Best Loss: 17.426211
Epoch loss: 18.253479
train phase, Epoch 3/20, Loss: 17.610935
val phase, Epoch 3/20, Loss: 17.520480
Val Best Loss: 17.426211
Epoch loss: 17.520480
train phase, Epoch 4/20, Loss: 17.392178
val phase, Epoch 4/20, Loss: 16.505885
Val Best Loss: 16.505885
Epoch loss: 16.505885
train phase, Epoch 5/20, Loss: 17.088581
val phase, Epoch 5/20, Loss: 16.604746
Val Best Loss: 16.505885
Epoch loss: 16.604746
train phase, Epoch 6/20, Loss: 16.712173
val phase, Epoch 6/20, Loss: 16.221453
Val Best Loss: 16.221453
Epoch loss: 16.221453
train phase, Epoch 7/20, Loss: 16.497295
val phase, Epoch 7/20, Loss: 16.846799
Val Best Loss: 16.221453
Epoch loss: 16.846799
train phase, Epoch 8/20, Loss: 16.313119
val phase, Epoch 8/20, Loss: 16.725370
Val Best Loss: 16.221453
Epoch loss: 16.725370
train phase, Epoch 9/20, Loss: 16.304197
val phase, Epoch 9/20, Loss: 16.382985
Val Best Loss: 16.221453
Epoch loss: 16.382985
train phase, Epoch 10/20, Loss: 16.070930
val phase, Epoch 10/20, Loss: 18.346550
Val Best Loss: 16.221453
Epoch loss: 18.346550
train phase, Epoch 11/20, Loss: 16.110997
val phase, Epoch 11/20, Loss: 21.109164
Val Best Loss: 16.221453
Epoch loss: 21.109164
train phase, Epoch 12/20, Loss: 16.207778
val phase, Epoch 12/20, Loss: 16.047496
Val Best Loss: 16.047496
Epoch loss: 16.047496
train phase, Epoch 13/20, Loss: 15.545313
val phase, Epoch 13/20, Loss: 16.770093
Val Best Loss: 16.047496
Epoch loss: 16.770093
train phase, Epoch 14/20, Loss: 15.504412
val phase, Epoch 14/20, Loss: 15.768568
Val Best Loss: 15.768568
Epoch loss: 15.768568
train phase, Epoch 15/20, Loss: 15.308969
val phase, Epoch 15/20, Loss: 17.892797
Val Best Loss: 15.768568
Epoch loss: 17.892797
train phase, Epoch 16/20, Loss: 15.127771
val phase, Epoch 16/20, Loss: 16.537334
Val Best Loss: 15.768568
Epoch loss: 16.537334
train phase, Epoch 17/20, Loss: 15.011014
val phase, Epoch 17/20, Loss: 16.769212
Val Best Loss: 15.768568
Epoch loss: 16.769212
train phase, Epoch 18/20, Loss: 14.706197
val phase, Epoch 18/20, Loss: 19.650127
Val Best Loss: 15.768568
Epoch loss: 19.650127
train phase, Epoch 19/20, Loss: 14.570779
val phase, Epoch 19/20, Loss: 16.171226
Val Best Loss: 15.768568
Epoch loss: 16.171226
train phase, Epoch 20/20, Loss: 14.618873
val phase, Epoch 20/20, Loss: 16.762448
Val Best Loss: 15.768568
Epoch loss: 16.762448
[Trial 311] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 19.962193
val phase, Epoch 1/30, Loss: 17.966176
Val Best Loss: 17.966176
Epoch loss: 17.966176
train phase, Epoch 2/30, Loss: 17.671621
val phase, Epoch 2/30, Loss: 16.535494
Val Best Loss: 16.535494
Epoch loss: 16.535494
train phase, Epoch 3/30, Loss: 17.296198
val phase, Epoch 3/30, Loss: 16.620326
Val Best Loss: 16.535494
Epoch loss: 16.620326
train phase, Epoch 4/30, Loss: 17.475867
val phase, Epoch 4/30, Loss: 16.372999
Val Best Loss: 16.372999
Epoch loss: 16.372999
train phase, Epoch 5/30, Loss: 16.850215
val phase, Epoch 5/30, Loss: 16.415703
Val Best Loss: 16.372999
Epoch loss: 16.415703
train phase, Epoch 6/30, Loss: 16.599777
val phase, Epoch 6/30, Loss: 16.262005
Val Best Loss: 16.262005
Epoch loss: 16.262005
train phase, Epoch 7/30, Loss: 16.356818
val phase, Epoch 7/30, Loss: 16.398098
Val Best Loss: 16.262005
Epoch loss: 16.398098
train phase, Epoch 8/30, Loss: 16.558778
val phase, Epoch 8/30, Loss: 17.675785
Val Best Loss: 16.262005
Epoch loss: 17.675785
train phase, Epoch 9/30, Loss: 16.134171
val phase, Epoch 9/30, Loss: 15.834387
Val Best Loss: 15.834387
Epoch loss: 15.834387
train phase, Epoch 10/30, Loss: 16.117864
val phase, Epoch 10/30, Loss: 16.004088
Val Best Loss: 15.834387
Epoch loss: 16.004088
train phase, Epoch 11/30, Loss: 15.715416
val phase, Epoch 11/30, Loss: 16.091072
Val Best Loss: 15.834387
Epoch loss: 16.091072
train phase, Epoch 12/30, Loss: 15.920312
val phase, Epoch 12/30, Loss: 15.883937
Val Best Loss: 15.834387
Epoch loss: 15.883937
train phase, Epoch 13/30, Loss: 15.507535
val phase, Epoch 13/30, Loss: 18.309163
Val Best Loss: 15.834387
Epoch loss: 18.309163
train phase, Epoch 14/30, Loss: 15.448625
val phase, Epoch 14/30, Loss: 15.686632
Val Best Loss: 15.686632
Epoch loss: 15.686632
train phase, Epoch 15/30, Loss: 15.093380
val phase, Epoch 15/30, Loss: 17.873820
Val Best Loss: 15.686632
Epoch loss: 17.873820
train phase, Epoch 16/30, Loss: 15.034699
val phase, Epoch 16/30, Loss: 16.397769
Val Best Loss: 15.686632
Epoch loss: 16.397769
train phase, Epoch 17/30, Loss: 14.731525
val phase, Epoch 17/30, Loss: 16.504792
Val Best Loss: 15.686632
Epoch loss: 16.504792
train phase, Epoch 18/30, Loss: 14.425357
val phase, Epoch 18/30, Loss: 16.476738
Val Best Loss: 15.686632
Epoch loss: 16.476738
train phase, Epoch 19/30, Loss: 14.341339
val phase, Epoch 19/30, Loss: 16.092560
Val Best Loss: 15.686632
Epoch loss: 16.092560
train phase, Epoch 20/30, Loss: 14.238591
val phase, Epoch 20/30, Loss: 18.370667
Val Best Loss: 15.686632
Epoch loss: 18.370667
train phase, Epoch 21/30, Loss: 13.801388
val phase, Epoch 21/30, Loss: 16.055854
Val Best Loss: 15.686632
Epoch loss: 16.055854
train phase, Epoch 22/30, Loss: 13.570855
val phase, Epoch 22/30, Loss: 16.450248
Val Best Loss: 15.686632
Epoch loss: 16.450248
train phase, Epoch 23/30, Loss: 13.194162
val phase, Epoch 23/30, Loss: 16.790502
Val Best Loss: 15.686632
Epoch loss: 16.790502
train phase, Epoch 24/30, Loss: 13.022843
val phase, Epoch 24/30, Loss: 17.908486
Val Best Loss: 15.686632
Epoch loss: 17.908486
train phase, Epoch 25/30, Loss: 12.485949
val phase, Epoch 25/30, Loss: 17.555264
Val Best Loss: 15.686632
Epoch loss: 17.555264
train phase, Epoch 26/30, Loss: 12.200572
val phase, Epoch 26/30, Loss: 18.462017
Val Best Loss: 15.686632
Epoch loss: 18.462017
train phase, Epoch 27/30, Loss: 11.767276
val phase, Epoch 27/30, Loss: 17.312782
Val Best Loss: 15.686632
Epoch loss: 17.312782
train phase, Epoch 28/30, Loss: 11.330548
val phase, Epoch 28/30, Loss: 17.550968
Val Best Loss: 15.686632
Epoch loss: 17.550968
train phase, Epoch 29/30, Loss: 10.990107
val phase, Epoch 29/30, Loss: 18.565630
Val Best Loss: 15.686632
Epoch loss: 18.565630
train phase, Epoch 30/30, Loss: 11.046743
val phase, Epoch 30/30, Loss: 17.007163
Val Best Loss: 15.686632
Epoch loss: 17.007163
train phase, Epoch 1/20, Loss: 20.514277
val phase, Epoch 1/20, Loss: 17.580607
Val Best Loss: 17.580607
Epoch loss: 17.580607
train phase, Epoch 2/20, Loss: 18.165521
val phase, Epoch 2/20, Loss: 17.100815
Val Best Loss: 17.100815
Epoch loss: 17.100815
train phase, Epoch 3/20, Loss: 18.071018
val phase, Epoch 3/20, Loss: 17.126697
Val Best Loss: 17.100815
Epoch loss: 17.126697
train phase, Epoch 4/20, Loss: 17.267941
val phase, Epoch 4/20, Loss: 16.830503
Val Best Loss: 16.830503
Epoch loss: 16.830503
train phase, Epoch 5/20, Loss: 17.320652
val phase, Epoch 5/20, Loss: 16.674252
Val Best Loss: 16.674252
Epoch loss: 16.674252
train phase, Epoch 6/20, Loss: 17.174588
val phase, Epoch 6/20, Loss: 17.578375
Val Best Loss: 16.674252
Epoch loss: 17.578375
train phase, Epoch 7/20, Loss: 17.009660
val phase, Epoch 7/20, Loss: 16.648390
Val Best Loss: 16.648390
Epoch loss: 16.648390
train phase, Epoch 8/20, Loss: 16.771482
val phase, Epoch 8/20, Loss: 16.332102
Val Best Loss: 16.332102
Epoch loss: 16.332102
train phase, Epoch 9/20, Loss: 16.730073
val phase, Epoch 9/20, Loss: 16.320509
Val Best Loss: 16.320509
Epoch loss: 16.320509
train phase, Epoch 10/20, Loss: 16.303288
val phase, Epoch 10/20, Loss: 16.004450
Val Best Loss: 16.004450
Epoch loss: 16.004450
train phase, Epoch 11/20, Loss: 16.694715
val phase, Epoch 11/20, Loss: 17.122195
Val Best Loss: 16.004450
Epoch loss: 17.122195
train phase, Epoch 12/20, Loss: 16.240545
val phase, Epoch 12/20, Loss: 16.589923
Val Best Loss: 16.004450
Epoch loss: 16.589923
train phase, Epoch 13/20, Loss: 15.913050
val phase, Epoch 13/20, Loss: 15.901132
Val Best Loss: 15.901132
Epoch loss: 15.901132
train phase, Epoch 14/20, Loss: 15.837921
val phase, Epoch 14/20, Loss: 16.208779
Val Best Loss: 15.901132
Epoch loss: 16.208779
train phase, Epoch 15/20, Loss: 16.101232
val phase, Epoch 15/20, Loss: 15.955774
Val Best Loss: 15.901132
Epoch loss: 15.955774
train phase, Epoch 16/20, Loss: 15.980724
val phase, Epoch 16/20, Loss: 16.737886
Val Best Loss: 15.901132
Epoch loss: 16.737886
train phase, Epoch 17/20, Loss: 15.517934
val phase, Epoch 17/20, Loss: 16.633080
Val Best Loss: 15.901132
Epoch loss: 16.633080
train phase, Epoch 18/20, Loss: 15.482752
val phase, Epoch 18/20, Loss: 19.137536
Val Best Loss: 15.901132
Epoch loss: 19.137536
train phase, Epoch 19/20, Loss: 15.518013
val phase, Epoch 19/20, Loss: 16.510226
Val Best Loss: 15.901132
Epoch loss: 16.510226
train phase, Epoch 20/20, Loss: 15.209657
val phase, Epoch 20/20, Loss: 16.548007
Val Best Loss: 15.901132
Epoch loss: 16.548007
train phase, Epoch 1/20, Loss: 20.127364
val phase, Epoch 1/20, Loss: 18.096652
Val Best Loss: 18.096652
Epoch loss: 18.096652
train phase, Epoch 2/20, Loss: 17.768891
val phase, Epoch 2/20, Loss: 17.474728
Val Best Loss: 17.474728
Epoch loss: 17.474728
train phase, Epoch 3/20, Loss: 17.391945
val phase, Epoch 3/20, Loss: 17.063051
Val Best Loss: 17.063051
Epoch loss: 17.063051
train phase, Epoch 4/20, Loss: 17.224766
val phase, Epoch 4/20, Loss: 16.066247
Val Best Loss: 16.066247
Epoch loss: 16.066247
train phase, Epoch 5/20, Loss: 16.770835
val phase, Epoch 5/20, Loss: 16.539657
Val Best Loss: 16.066247
Epoch loss: 16.539657
train phase, Epoch 6/20, Loss: 16.586118
val phase, Epoch 6/20, Loss: 16.459726
Val Best Loss: 16.066247
Epoch loss: 16.459726
train phase, Epoch 7/20, Loss: 16.497185
val phase, Epoch 7/20, Loss: 16.704859
Val Best Loss: 16.066247
Epoch loss: 16.704859
train phase, Epoch 8/20, Loss: 16.491511
val phase, Epoch 8/20, Loss: 17.346695
Val Best Loss: 16.066247
Epoch loss: 17.346695
train phase, Epoch 9/20, Loss: 16.031205
val phase, Epoch 9/20, Loss: 16.150480
Val Best Loss: 16.066247
Epoch loss: 16.150480
train phase, Epoch 10/20, Loss: 15.983265
val phase, Epoch 10/20, Loss: 15.986900
Val Best Loss: 15.986900
Epoch loss: 15.986900
train phase, Epoch 11/20, Loss: 15.783572
val phase, Epoch 11/20, Loss: 16.132511
Val Best Loss: 15.986900
Epoch loss: 16.132511
train phase, Epoch 12/20, Loss: 15.421259
val phase, Epoch 12/20, Loss: 16.600313
Val Best Loss: 15.986900
Epoch loss: 16.600313
train phase, Epoch 13/20, Loss: 15.430385
val phase, Epoch 13/20, Loss: 16.606249
Val Best Loss: 15.986900
Epoch loss: 16.606249
train phase, Epoch 14/20, Loss: 15.498431
val phase, Epoch 14/20, Loss: 15.817329
Val Best Loss: 15.817329
Epoch loss: 15.817329
train phase, Epoch 15/20, Loss: 15.275688
val phase, Epoch 15/20, Loss: 15.817118
Val Best Loss: 15.817118
Epoch loss: 15.817118
train phase, Epoch 16/20, Loss: 15.071695
val phase, Epoch 16/20, Loss: 17.040376
Val Best Loss: 15.817118
Epoch loss: 17.040376
train phase, Epoch 17/20, Loss: 14.739219
val phase, Epoch 17/20, Loss: 16.312889
Val Best Loss: 15.817118
Epoch loss: 16.312889
train phase, Epoch 18/20, Loss: 14.208031
val phase, Epoch 18/20, Loss: 16.305572
Val Best Loss: 15.817118
Epoch loss: 16.305572
train phase, Epoch 19/20, Loss: 14.261144
val phase, Epoch 19/20, Loss: 15.826748
Val Best Loss: 15.817118
Epoch loss: 15.826748
train phase, Epoch 20/20, Loss: 13.762122
val phase, Epoch 20/20, Loss: 16.119975
Val Best Loss: 15.817118
Epoch loss: 16.119975
train phase, Epoch 1/5, Loss: 19.563378
val phase, Epoch 1/5, Loss: 16.936600
Val Best Loss: 16.936600
Epoch loss: 16.936600
train phase, Epoch 2/5, Loss: 17.585846
val phase, Epoch 2/5, Loss: 16.921554
Val Best Loss: 16.921554
Epoch loss: 16.921554
train phase, Epoch 3/5, Loss: 17.404838
val phase, Epoch 3/5, Loss: 16.275409
Val Best Loss: 16.275409
Epoch loss: 16.275409
train phase, Epoch 4/5, Loss: 17.292164
val phase, Epoch 4/5, Loss: 16.447114
Val Best Loss: 16.275409
Epoch loss: 16.447114
train phase, Epoch 5/5, Loss: 16.698990
val phase, Epoch 5/5, Loss: 16.497087
Val Best Loss: 16.275409
Epoch loss: 16.497087
train phase, Epoch 1/25, Loss: 32.070625
val phase, Epoch 1/25, Loss: 19.382439
Val Best Loss: 19.382439
Epoch loss: 19.382439
train phase, Epoch 2/25, Loss: 19.611903
val phase, Epoch 2/25, Loss: 18.596688
Val Best Loss: 18.596688
Epoch loss: 18.596688
train phase, Epoch 3/25, Loss: 19.618505
val phase, Epoch 3/25, Loss: 18.703789
Val Best Loss: 18.596688
Epoch loss: 18.703789
train phase, Epoch 4/25, Loss: 18.584760
val phase, Epoch 4/25, Loss: 18.223811
Val Best Loss: 18.223811
Epoch loss: 18.223811
train phase, Epoch 5/25, Loss: 18.648486
val phase, Epoch 5/25, Loss: 17.945939
Val Best Loss: 17.945939
Epoch loss: 17.945939
train phase, Epoch 6/25, Loss: 18.834234
val phase, Epoch 6/25, Loss: 18.679766
Val Best Loss: 17.945939
Epoch loss: 18.679766
train phase, Epoch 7/25, Loss: 18.151408
val phase, Epoch 7/25, Loss: 25.172608
Val Best Loss: 17.945939
Epoch loss: 25.172608
train phase, Epoch 8/25, Loss: 17.965651
val phase, Epoch 8/25, Loss: 19.090795
Val Best Loss: 17.945939
Epoch loss: 19.090795
train phase, Epoch 9/25, Loss: 18.144898
val phase, Epoch 9/25, Loss: 20.989663
Val Best Loss: 17.945939
Epoch loss: 20.989663
train phase, Epoch 10/25, Loss: 18.336697
val phase, Epoch 10/25, Loss: 24.874062
Val Best Loss: 17.945939
Epoch loss: 24.874062
train phase, Epoch 11/25, Loss: 17.741198
val phase, Epoch 11/25, Loss: 20.420074
Val Best Loss: 17.945939
Epoch loss: 20.420074
train phase, Epoch 12/25, Loss: 17.596646
val phase, Epoch 12/25, Loss: 18.316663
Val Best Loss: 17.945939
Epoch loss: 18.316663
train phase, Epoch 13/25, Loss: 17.270393
val phase, Epoch 13/25, Loss: 22.865123
Val Best Loss: 17.945939
Epoch loss: 22.865123
train phase, Epoch 14/25, Loss: 17.241591
val phase, Epoch 14/25, Loss: 17.556277
Val Best Loss: 17.556277
Epoch loss: 17.556277
train phase, Epoch 15/25, Loss: 17.048834
val phase, Epoch 15/25, Loss: 20.757388
Val Best Loss: 17.556277
Epoch loss: 20.757388
train phase, Epoch 16/25, Loss: 17.113885
val phase, Epoch 16/25, Loss: 19.000250
Val Best Loss: 17.556277
Epoch loss: 19.000250
train phase, Epoch 17/25, Loss: 16.826518
val phase, Epoch 17/25, Loss: 17.634657
Val Best Loss: 17.556277
Epoch loss: 17.634657
train phase, Epoch 18/25, Loss: 16.848222
val phase, Epoch 18/25, Loss: 17.856250
Val Best Loss: 17.556277
Epoch loss: 17.856250
train phase, Epoch 19/25, Loss: 16.641993
val phase, Epoch 19/25, Loss: 17.764081
Val Best Loss: 17.556277
Epoch loss: 17.764081
train phase, Epoch 20/25, Loss: 16.527496
val phase, Epoch 20/25, Loss: 22.994707
Val Best Loss: 17.556277
Epoch loss: 22.994707
train phase, Epoch 21/25, Loss: 16.494443
val phase, Epoch 21/25, Loss: 17.687501
Val Best Loss: 17.556277
Epoch loss: 17.687501
train phase, Epoch 22/25, Loss: 16.345240
val phase, Epoch 22/25, Loss: 17.671649
Val Best Loss: 17.556277
Epoch loss: 17.671649
train phase, Epoch 23/25, Loss: 16.094351
val phase, Epoch 23/25, Loss: 20.459809
Val Best Loss: 17.556277
Epoch loss: 20.459809
train phase, Epoch 24/25, Loss: 16.372087
val phase, Epoch 24/25, Loss: 21.387684
Val Best Loss: 17.556277
Epoch loss: 21.387684
train phase, Epoch 25/25, Loss: 16.407505
val phase, Epoch 25/25, Loss: 17.703124
Val Best Loss: 17.556277
Epoch loss: 17.703124
train phase, Epoch 1/20, Loss: 20.807994
val phase, Epoch 1/20, Loss: 20.924446
Val Best Loss: 20.924446
Epoch loss: 20.924446
train phase, Epoch 2/20, Loss: 18.686534
val phase, Epoch 2/20, Loss: 18.026078
Val Best Loss: 18.026078
Epoch loss: 18.026078
train phase, Epoch 3/20, Loss: 18.159672
val phase, Epoch 3/20, Loss: 17.438733
Val Best Loss: 17.438733
Epoch loss: 17.438733
train phase, Epoch 4/20, Loss: 17.837766
val phase, Epoch 4/20, Loss: 18.556437
Val Best Loss: 17.438733
Epoch loss: 18.556437
train phase, Epoch 5/20, Loss: 17.400552
val phase, Epoch 5/20, Loss: 16.766422
Val Best Loss: 16.766422
Epoch loss: 16.766422
train phase, Epoch 6/20, Loss: 17.359762
val phase, Epoch 6/20, Loss: 17.167222
Val Best Loss: 16.766422
Epoch loss: 17.167222
train phase, Epoch 7/20, Loss: 17.195997
val phase, Epoch 7/20, Loss: 17.121376
Val Best Loss: 16.766422
Epoch loss: 17.121376
train phase, Epoch 8/20, Loss: 16.803910
val phase, Epoch 8/20, Loss: 19.509346
Val Best Loss: 16.766422
Epoch loss: 19.509346
train phase, Epoch 9/20, Loss: 16.788377
val phase, Epoch 9/20, Loss: 17.548539
Val Best Loss: 16.766422
Epoch loss: 17.548539
train phase, Epoch 10/20, Loss: 16.578281
val phase, Epoch 10/20, Loss: 21.543607
Val Best Loss: 16.766422
Epoch loss: 21.543607
train phase, Epoch 11/20, Loss: 16.582756
val phase, Epoch 11/20, Loss: 16.660632
Val Best Loss: 16.660632
Epoch loss: 16.660632
train phase, Epoch 12/20, Loss: 16.349603
val phase, Epoch 12/20, Loss: 18.916555
Val Best Loss: 16.660632
Epoch loss: 18.916555
train phase, Epoch 13/20, Loss: 16.088650
val phase, Epoch 13/20, Loss: 17.750808
Val Best Loss: 16.660632
Epoch loss: 17.750808
train phase, Epoch 14/20, Loss: 16.070615
val phase, Epoch 14/20, Loss: 16.588041
Val Best Loss: 16.588041
Epoch loss: 16.588041
train phase, Epoch 15/20, Loss: 15.750682
val phase, Epoch 15/20, Loss: 18.101159
Val Best Loss: 16.588041
Epoch loss: 18.101159
train phase, Epoch 16/20, Loss: 15.420176
val phase, Epoch 16/20, Loss: 16.707993
Val Best Loss: 16.588041
Epoch loss: 16.707993
train phase, Epoch 17/20, Loss: 15.344297
val phase, Epoch 17/20, Loss: 16.996129
Val Best Loss: 16.588041
Epoch loss: 16.996129
train phase, Epoch 18/20, Loss: 14.960283
val phase, Epoch 18/20, Loss: 16.748399
Val Best Loss: 16.588041
Epoch loss: 16.748399
train phase, Epoch 19/20, Loss: 14.859030
val phase, Epoch 19/20, Loss: 17.479903
Val Best Loss: 16.588041
Epoch loss: 17.479903
train phase, Epoch 20/20, Loss: 14.453249
val phase, Epoch 20/20, Loss: 18.438251
Val Best Loss: 16.588041
Epoch loss: 18.438251
train phase, Epoch 1/30, Loss: 20.009178
val phase, Epoch 1/30, Loss: 19.297650
Val Best Loss: 19.297650
Epoch loss: 19.297650
train phase, Epoch 2/30, Loss: 17.843893
val phase, Epoch 2/30, Loss: 16.780497
Val Best Loss: 16.780497
Epoch loss: 16.780497
train phase, Epoch 3/30, Loss: 17.468499
val phase, Epoch 3/30, Loss: 18.342708
Val Best Loss: 16.780497
Epoch loss: 18.342708
train phase, Epoch 4/30, Loss: 17.356963
val phase, Epoch 4/30, Loss: 16.226983
Val Best Loss: 16.226983
Epoch loss: 16.226983
train phase, Epoch 5/30, Loss: 16.781278
val phase, Epoch 5/30, Loss: 17.474920
Val Best Loss: 16.226983
Epoch loss: 17.474920
train phase, Epoch 6/30, Loss: 16.643801
val phase, Epoch 6/30, Loss: 17.193792
Val Best Loss: 16.226983
Epoch loss: 17.193792
train phase, Epoch 7/30, Loss: 16.419207
val phase, Epoch 7/30, Loss: 16.396545
Val Best Loss: 16.226983
Epoch loss: 16.396545
train phase, Epoch 8/30, Loss: 16.186457
val phase, Epoch 8/30, Loss: 16.367724
Val Best Loss: 16.226983
Epoch loss: 16.367724
train phase, Epoch 9/30, Loss: 16.557073
val phase, Epoch 9/30, Loss: 17.596226
Val Best Loss: 16.226983
Epoch loss: 17.596226
train phase, Epoch 10/30, Loss: 16.247892
val phase, Epoch 10/30, Loss: 17.520536
Val Best Loss: 16.226983
Epoch loss: 17.520536
train phase, Epoch 11/30, Loss: 15.811599
val phase, Epoch 11/30, Loss: 16.115136
Val Best Loss: 16.115136
Epoch loss: 16.115136
train phase, Epoch 12/30, Loss: 15.832954
val phase, Epoch 12/30, Loss: 16.142719
Val Best Loss: 16.115136
Epoch loss: 16.142719
train phase, Epoch 13/30, Loss: 15.449787
val phase, Epoch 13/30, Loss: 15.799287
Val Best Loss: 15.799287
Epoch loss: 15.799287
train phase, Epoch 14/30, Loss: 15.367241
val phase, Epoch 14/30, Loss: 15.958900
Val Best Loss: 15.799287
Epoch loss: 15.958900
train phase, Epoch 15/30, Loss: 15.091280
val phase, Epoch 15/30, Loss: 16.754756
Val Best Loss: 15.799287
Epoch loss: 16.754756
train phase, Epoch 16/30, Loss: 15.163119
val phase, Epoch 16/30, Loss: 17.089838
Val Best Loss: 15.799287
Epoch loss: 17.089838
train phase, Epoch 17/30, Loss: 14.729283
val phase, Epoch 17/30, Loss: 15.988753
Val Best Loss: 15.799287
Epoch loss: 15.988753
train phase, Epoch 18/30, Loss: 14.471540
val phase, Epoch 18/30, Loss: 16.612419
Val Best Loss: 15.799287
Epoch loss: 16.612419
train phase, Epoch 19/30, Loss: 14.249081
val phase, Epoch 19/30, Loss: 17.223079
Val Best Loss: 15.799287
Epoch loss: 17.223079
train phase, Epoch 20/30, Loss: 14.100200
val phase, Epoch 20/30, Loss: 16.036634
Val Best Loss: 15.799287
Epoch loss: 16.036634
train phase, Epoch 21/30, Loss: 13.695332
val phase, Epoch 21/30, Loss: 16.286510
Val Best Loss: 15.799287
Epoch loss: 16.286510
train phase, Epoch 22/30, Loss: 13.432635
val phase, Epoch 22/30, Loss: 17.878024
Val Best Loss: 15.799287
Epoch loss: 17.878024
train phase, Epoch 23/30, Loss: 13.177229
val phase, Epoch 23/30, Loss: 16.606579
Val Best Loss: 15.799287
Epoch loss: 16.606579
train phase, Epoch 24/30, Loss: 12.962559
val phase, Epoch 24/30, Loss: 16.848702
Val Best Loss: 15.799287
Epoch loss: 16.848702
train phase, Epoch 25/30, Loss: 12.565728
val phase, Epoch 25/30, Loss: 17.796873
Val Best Loss: 15.799287
Epoch loss: 17.796873
train phase, Epoch 26/30, Loss: 12.124320
val phase, Epoch 26/30, Loss: 18.123884
Val Best Loss: 15.799287
Epoch loss: 18.123884
train phase, Epoch 27/30, Loss: 11.687697
val phase, Epoch 27/30, Loss: 17.585337
Val Best Loss: 15.799287
Epoch loss: 17.585337
train phase, Epoch 28/30, Loss: 11.141105
val phase, Epoch 28/30, Loss: 17.868805
Val Best Loss: 15.799287
Epoch loss: 17.868805
train phase, Epoch 29/30, Loss: 10.799971
val phase, Epoch 29/30, Loss: 18.376332
Val Best Loss: 15.799287
Epoch loss: 18.376332
train phase, Epoch 30/30, Loss: 10.453833
val phase, Epoch 30/30, Loss: 18.554687
Val Best Loss: 15.799287
Epoch loss: 18.554687
[Trial 319] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
[Trial 320] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.951544
val phase, Epoch 1/20, Loss: 16.950466
Val Best Loss: 16.950466
Epoch loss: 16.950466
train phase, Epoch 2/20, Loss: 17.961264
val phase, Epoch 2/20, Loss: 17.403245
Val Best Loss: 16.950466
Epoch loss: 17.403245
train phase, Epoch 3/20, Loss: 17.147217
val phase, Epoch 3/20, Loss: 16.159107
Val Best Loss: 16.159107
Epoch loss: 16.159107
train phase, Epoch 4/20, Loss: 16.810458
val phase, Epoch 4/20, Loss: 17.180104
Val Best Loss: 16.159107
Epoch loss: 17.180104
train phase, Epoch 5/20, Loss: 16.882262
val phase, Epoch 5/20, Loss: 17.645757
Val Best Loss: 16.159107
Epoch loss: 17.645757
train phase, Epoch 6/20, Loss: 16.718121
val phase, Epoch 6/20, Loss: 16.661618
Val Best Loss: 16.159107
Epoch loss: 16.661618
train phase, Epoch 7/20, Loss: 16.433301
val phase, Epoch 7/20, Loss: 16.089122
Val Best Loss: 16.089122
Epoch loss: 16.089122
train phase, Epoch 8/20, Loss: 16.240591
val phase, Epoch 8/20, Loss: 16.618803
Val Best Loss: 16.089122
Epoch loss: 16.618803
train phase, Epoch 9/20, Loss: 15.928516
val phase, Epoch 9/20, Loss: 16.297165
Val Best Loss: 16.089122
Epoch loss: 16.297165
train phase, Epoch 10/20, Loss: 15.706702
val phase, Epoch 10/20, Loss: 17.115548
Val Best Loss: 16.089122
Epoch loss: 17.115548
train phase, Epoch 11/20, Loss: 15.552795
val phase, Epoch 11/20, Loss: 16.424466
Val Best Loss: 16.089122
Epoch loss: 16.424466
train phase, Epoch 12/20, Loss: 15.525796
val phase, Epoch 12/20, Loss: 16.570052
Val Best Loss: 16.089122
Epoch loss: 16.570052
train phase, Epoch 13/20, Loss: 15.330891
val phase, Epoch 13/20, Loss: 16.330138
Val Best Loss: 16.089122
Epoch loss: 16.330138
train phase, Epoch 14/20, Loss: 15.289812
val phase, Epoch 14/20, Loss: 16.496815
Val Best Loss: 16.089122
Epoch loss: 16.496815
train phase, Epoch 15/20, Loss: 15.197989
val phase, Epoch 15/20, Loss: 21.460077
Val Best Loss: 16.089122
Epoch loss: 21.460077
train phase, Epoch 16/20, Loss: 14.723653
val phase, Epoch 16/20, Loss: 16.584666
Val Best Loss: 16.089122
Epoch loss: 16.584666
train phase, Epoch 17/20, Loss: 14.474332
val phase, Epoch 17/20, Loss: 17.244643
Val Best Loss: 16.089122
Epoch loss: 17.244643
train phase, Epoch 18/20, Loss: 14.279451
val phase, Epoch 18/20, Loss: 16.301767
Val Best Loss: 16.089122
Epoch loss: 16.301767
train phase, Epoch 19/20, Loss: 13.941135
val phase, Epoch 19/20, Loss: 16.612678
Val Best Loss: 16.089122
Epoch loss: 16.612678
train phase, Epoch 20/20, Loss: 13.669770
val phase, Epoch 20/20, Loss: 16.432325
Val Best Loss: 16.089122
Epoch loss: 16.432325
train phase, Epoch 1/30, Loss: 20.126461
val phase, Epoch 1/30, Loss: 18.690232
Val Best Loss: 18.690232
Epoch loss: 18.690232
train phase, Epoch 2/30, Loss: 17.702212
val phase, Epoch 2/30, Loss: 16.939213
Val Best Loss: 16.939213
Epoch loss: 16.939213
train phase, Epoch 3/30, Loss: 17.414726
val phase, Epoch 3/30, Loss: 17.344449
Val Best Loss: 16.939213
Epoch loss: 17.344449
train phase, Epoch 4/30, Loss: 17.370083
val phase, Epoch 4/30, Loss: 19.300272
Val Best Loss: 16.939213
Epoch loss: 19.300272
train phase, Epoch 5/30, Loss: 16.942446
val phase, Epoch 5/30, Loss: 16.294946
Val Best Loss: 16.294946
Epoch loss: 16.294946
train phase, Epoch 6/30, Loss: 16.707667
val phase, Epoch 6/30, Loss: 16.526258
Val Best Loss: 16.294946
Epoch loss: 16.526258
train phase, Epoch 7/30, Loss: 16.680515
val phase, Epoch 7/30, Loss: 17.764325
Val Best Loss: 16.294946
Epoch loss: 17.764325
train phase, Epoch 8/30, Loss: 16.461880
val phase, Epoch 8/30, Loss: 16.856193
Val Best Loss: 16.294946
Epoch loss: 16.856193
train phase, Epoch 9/30, Loss: 16.639222
val phase, Epoch 9/30, Loss: 17.010699
Val Best Loss: 16.294946
Epoch loss: 17.010699
train phase, Epoch 10/30, Loss: 16.098795
val phase, Epoch 10/30, Loss: 16.218686
Val Best Loss: 16.218686
Epoch loss: 16.218686
train phase, Epoch 11/30, Loss: 16.003598
val phase, Epoch 11/30, Loss: 15.989353
Val Best Loss: 15.989353
Epoch loss: 15.989353
train phase, Epoch 12/30, Loss: 15.802756
val phase, Epoch 12/30, Loss: 16.840654
Val Best Loss: 15.989353
Epoch loss: 16.840654
train phase, Epoch 13/30, Loss: 15.727992
val phase, Epoch 13/30, Loss: 15.781671
Val Best Loss: 15.781671
Epoch loss: 15.781671
train phase, Epoch 14/30, Loss: 15.543383
val phase, Epoch 14/30, Loss: 16.459874
Val Best Loss: 15.781671
Epoch loss: 16.459874
train phase, Epoch 15/30, Loss: 15.303496
val phase, Epoch 15/30, Loss: 16.507662
Val Best Loss: 15.781671
Epoch loss: 16.507662
train phase, Epoch 16/30, Loss: 15.149804
val phase, Epoch 16/30, Loss: 16.229978
Val Best Loss: 15.781671
Epoch loss: 16.229978
train phase, Epoch 17/30, Loss: 15.000712
val phase, Epoch 17/30, Loss: 16.145406
Val Best Loss: 15.781671
Epoch loss: 16.145406
train phase, Epoch 18/30, Loss: 14.935750
val phase, Epoch 18/30, Loss: 16.018048
Val Best Loss: 15.781671
Epoch loss: 16.018048
train phase, Epoch 19/30, Loss: 14.627163
val phase, Epoch 19/30, Loss: 16.633457
Val Best Loss: 15.781671
Epoch loss: 16.633457
train phase, Epoch 20/30, Loss: 14.246535
val phase, Epoch 20/30, Loss: 16.560387
Val Best Loss: 15.781671
Epoch loss: 16.560387
train phase, Epoch 21/30, Loss: 14.125780
val phase, Epoch 21/30, Loss: 16.866324
Val Best Loss: 15.781671
Epoch loss: 16.866324
train phase, Epoch 22/30, Loss: 13.714513
val phase, Epoch 22/30, Loss: 16.244712
Val Best Loss: 15.781671
Epoch loss: 16.244712
train phase, Epoch 23/30, Loss: 13.160490
val phase, Epoch 23/30, Loss: 17.869317
Val Best Loss: 15.781671
Epoch loss: 17.869317
train phase, Epoch 24/30, Loss: 13.166195
val phase, Epoch 24/30, Loss: 18.835491
Val Best Loss: 15.781671
Epoch loss: 18.835491
train phase, Epoch 25/30, Loss: 12.854500
val phase, Epoch 25/30, Loss: 17.309495
Val Best Loss: 15.781671
Epoch loss: 17.309495
train phase, Epoch 26/30, Loss: 12.441164
val phase, Epoch 26/30, Loss: 17.542387
Val Best Loss: 15.781671
Epoch loss: 17.542387
train phase, Epoch 27/30, Loss: 11.901773
val phase, Epoch 27/30, Loss: 17.541627
Val Best Loss: 15.781671
Epoch loss: 17.541627
train phase, Epoch 28/30, Loss: 11.383694
val phase, Epoch 28/30, Loss: 17.359982
Val Best Loss: 15.781671
Epoch loss: 17.359982
train phase, Epoch 29/30, Loss: 11.109748
val phase, Epoch 29/30, Loss: 17.876856
Val Best Loss: 15.781671
Epoch loss: 17.876856
train phase, Epoch 30/30, Loss: 10.631982
val phase, Epoch 30/30, Loss: 17.970108
Val Best Loss: 15.781671
Epoch loss: 17.970108
[Trial 323] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/20, Loss: 24.050493
val phase, Epoch 1/20, Loss: 17.334826
Val Best Loss: 17.334826
Epoch loss: 17.334826
train phase, Epoch 2/20, Loss: 17.238288
val phase, Epoch 2/20, Loss: 16.978898
Val Best Loss: 16.978898
Epoch loss: 16.978898
train phase, Epoch 3/20, Loss: 16.812416
val phase, Epoch 3/20, Loss: 16.683008
Val Best Loss: 16.683008
Epoch loss: 16.683008
train phase, Epoch 4/20, Loss: 16.329576
val phase, Epoch 4/20, Loss: 16.365385
Val Best Loss: 16.365385
Epoch loss: 16.365385
train phase, Epoch 5/20, Loss: 16.063771
val phase, Epoch 5/20, Loss: 16.544194
Val Best Loss: 16.365385
Epoch loss: 16.544194
train phase, Epoch 6/20, Loss: 15.752769
val phase, Epoch 6/20, Loss: 16.480073
Val Best Loss: 16.365385
Epoch loss: 16.480073
train phase, Epoch 7/20, Loss: 15.341587
val phase, Epoch 7/20, Loss: 18.130596
Val Best Loss: 16.365385
Epoch loss: 18.130596
train phase, Epoch 8/20, Loss: 15.051571
val phase, Epoch 8/20, Loss: 16.725714
Val Best Loss: 16.365385
Epoch loss: 16.725714
train phase, Epoch 9/20, Loss: 14.581747
val phase, Epoch 9/20, Loss: 16.511220
Val Best Loss: 16.365385
Epoch loss: 16.511220
train phase, Epoch 10/20, Loss: 14.206429
val phase, Epoch 10/20, Loss: 16.554184
Val Best Loss: 16.365385
Epoch loss: 16.554184
train phase, Epoch 11/20, Loss: 13.958041
val phase, Epoch 11/20, Loss: 16.381588
Val Best Loss: 16.365385
Epoch loss: 16.381588
train phase, Epoch 12/20, Loss: 13.298906
val phase, Epoch 12/20, Loss: 17.295797
Val Best Loss: 16.365385
Epoch loss: 17.295797
train phase, Epoch 13/20, Loss: 13.016098
val phase, Epoch 13/20, Loss: 17.215694
Val Best Loss: 16.365385
Epoch loss: 17.215694
train phase, Epoch 14/20, Loss: 12.278952
val phase, Epoch 14/20, Loss: 16.497752
Val Best Loss: 16.365385
Epoch loss: 16.497752
train phase, Epoch 15/20, Loss: 11.714929
val phase, Epoch 15/20, Loss: 17.884422
Val Best Loss: 16.365385
Epoch loss: 17.884422
train phase, Epoch 16/20, Loss: 11.172231
val phase, Epoch 16/20, Loss: 22.245116
Val Best Loss: 16.365385
Epoch loss: 22.245116
train phase, Epoch 17/20, Loss: 10.543733
val phase, Epoch 17/20, Loss: 17.893077
Val Best Loss: 16.365385
Epoch loss: 17.893077
train phase, Epoch 18/20, Loss: 10.272402
val phase, Epoch 18/20, Loss: 18.233962
Val Best Loss: 16.365385
Epoch loss: 18.233962
train phase, Epoch 19/20, Loss: 9.375174
val phase, Epoch 19/20, Loss: 17.768418
Val Best Loss: 16.365385
Epoch loss: 17.768418
train phase, Epoch 20/20, Loss: 8.912155
val phase, Epoch 20/20, Loss: 20.459242
Val Best Loss: 16.365385
Epoch loss: 20.459242
train phase, Epoch 1/20, Loss: 20.100247
val phase, Epoch 1/20, Loss: 19.248241
Val Best Loss: 19.248241
Epoch loss: 19.248241
train phase, Epoch 2/20, Loss: 17.938177
val phase, Epoch 2/20, Loss: 16.654811
Val Best Loss: 16.654811
Epoch loss: 16.654811
train phase, Epoch 3/20, Loss: 17.333507
val phase, Epoch 3/20, Loss: 18.682990
Val Best Loss: 16.654811
Epoch loss: 18.682990
train phase, Epoch 4/20, Loss: 17.210974
val phase, Epoch 4/20, Loss: 16.337850
Val Best Loss: 16.337850
Epoch loss: 16.337850
train phase, Epoch 5/20, Loss: 16.881325
val phase, Epoch 5/20, Loss: 16.550978
Val Best Loss: 16.337850
Epoch loss: 16.550978
train phase, Epoch 6/20, Loss: 16.553565
val phase, Epoch 6/20, Loss: 16.145888
Val Best Loss: 16.145888
Epoch loss: 16.145888
train phase, Epoch 7/20, Loss: 16.517387
val phase, Epoch 7/20, Loss: 17.325508
Val Best Loss: 16.145888
Epoch loss: 17.325508
train phase, Epoch 8/20, Loss: 16.741409
val phase, Epoch 8/20, Loss: 17.638579
Val Best Loss: 16.145888
Epoch loss: 17.638579
train phase, Epoch 9/20, Loss: 16.462651
val phase, Epoch 9/20, Loss: 16.725594
Val Best Loss: 16.145888
Epoch loss: 16.725594
train phase, Epoch 10/20, Loss: 16.194873
val phase, Epoch 10/20, Loss: 16.119333
Val Best Loss: 16.119333
Epoch loss: 16.119333
train phase, Epoch 11/20, Loss: 16.005489
val phase, Epoch 11/20, Loss: 16.041024
Val Best Loss: 16.041024
Epoch loss: 16.041024
train phase, Epoch 12/20, Loss: 16.222932
val phase, Epoch 12/20, Loss: 15.921487
Val Best Loss: 15.921487
Epoch loss: 15.921487
train phase, Epoch 13/20, Loss: 15.632772
val phase, Epoch 13/20, Loss: 16.318124
Val Best Loss: 15.921487
Epoch loss: 16.318124
train phase, Epoch 14/20, Loss: 15.579003
val phase, Epoch 14/20, Loss: 15.752925
Val Best Loss: 15.752925
Epoch loss: 15.752925
train phase, Epoch 15/20, Loss: 15.168296
val phase, Epoch 15/20, Loss: 16.155123
Val Best Loss: 15.752925
Epoch loss: 16.155123
train phase, Epoch 16/20, Loss: 15.057957
val phase, Epoch 16/20, Loss: 15.816560
Val Best Loss: 15.752925
Epoch loss: 15.816560
train phase, Epoch 17/20, Loss: 15.126748
val phase, Epoch 17/20, Loss: 15.987441
Val Best Loss: 15.752925
Epoch loss: 15.987441
train phase, Epoch 18/20, Loss: 15.065588
val phase, Epoch 18/20, Loss: 16.010049
Val Best Loss: 15.752925
Epoch loss: 16.010049
train phase, Epoch 19/20, Loss: 14.481686
val phase, Epoch 19/20, Loss: 16.042718
Val Best Loss: 15.752925
Epoch loss: 16.042718
train phase, Epoch 20/20, Loss: 14.465431
val phase, Epoch 20/20, Loss: 16.136959
Val Best Loss: 15.752925
Epoch loss: 16.136959
train phase, Epoch 1/30, Loss: 21.247375
val phase, Epoch 1/30, Loss: 16.973258
Val Best Loss: 16.973258
Epoch loss: 16.973258
train phase, Epoch 2/30, Loss: 18.104015
val phase, Epoch 2/30, Loss: 16.339358
Val Best Loss: 16.339358
Epoch loss: 16.339358
train phase, Epoch 3/30, Loss: 17.740214
val phase, Epoch 3/30, Loss: 16.800179
Val Best Loss: 16.339358
Epoch loss: 16.800179
train phase, Epoch 4/30, Loss: 17.282221
val phase, Epoch 4/30, Loss: 16.853881
Val Best Loss: 16.339358
Epoch loss: 16.853881
train phase, Epoch 5/30, Loss: 17.102514
val phase, Epoch 5/30, Loss: 16.838501
Val Best Loss: 16.339358
Epoch loss: 16.838501
train phase, Epoch 6/30, Loss: 16.968098
val phase, Epoch 6/30, Loss: 21.055834
Val Best Loss: 16.339358
Epoch loss: 21.055834
train phase, Epoch 7/30, Loss: 16.921072
val phase, Epoch 7/30, Loss: 17.188505
Val Best Loss: 16.339358
Epoch loss: 17.188505
train phase, Epoch 8/30, Loss: 16.430415
val phase, Epoch 8/30, Loss: 16.168930
Val Best Loss: 16.168930
Epoch loss: 16.168930
train phase, Epoch 9/30, Loss: 16.521519
val phase, Epoch 9/30, Loss: 17.246268
Val Best Loss: 16.168930
Epoch loss: 17.246268
train phase, Epoch 10/30, Loss: 16.660826
val phase, Epoch 10/30, Loss: 19.844482
Val Best Loss: 16.168930
Epoch loss: 19.844482
train phase, Epoch 11/30, Loss: 16.143403
val phase, Epoch 11/30, Loss: 15.900408
Val Best Loss: 15.900408
Epoch loss: 15.900408
train phase, Epoch 12/30, Loss: 16.065247
val phase, Epoch 12/30, Loss: 17.054992
Val Best Loss: 15.900408
Epoch loss: 17.054992
train phase, Epoch 13/30, Loss: 16.023228
val phase, Epoch 13/30, Loss: 19.450495
Val Best Loss: 15.900408
Epoch loss: 19.450495
train phase, Epoch 14/30, Loss: 15.437129
val phase, Epoch 14/30, Loss: 16.178503
Val Best Loss: 15.900408
Epoch loss: 16.178503
train phase, Epoch 15/30, Loss: 15.498940
val phase, Epoch 15/30, Loss: 16.882092
Val Best Loss: 15.900408
Epoch loss: 16.882092
train phase, Epoch 16/30, Loss: 15.458422
val phase, Epoch 16/30, Loss: 15.791769
Val Best Loss: 15.791769
Epoch loss: 15.791769
train phase, Epoch 17/30, Loss: 15.316476
val phase, Epoch 17/30, Loss: 17.176017
Val Best Loss: 15.791769
Epoch loss: 17.176017
train phase, Epoch 18/30, Loss: 14.962937
val phase, Epoch 18/30, Loss: 17.100801
Val Best Loss: 15.791769
Epoch loss: 17.100801
train phase, Epoch 19/30, Loss: 14.707836
val phase, Epoch 19/30, Loss: 17.321082
Val Best Loss: 15.791769
Epoch loss: 17.321082
train phase, Epoch 20/30, Loss: 14.695317
val phase, Epoch 20/30, Loss: 16.637879
Val Best Loss: 15.791769
Epoch loss: 16.637879
train phase, Epoch 21/30, Loss: 14.219437
val phase, Epoch 21/30, Loss: 16.323485
Val Best Loss: 15.791769
Epoch loss: 16.323485
train phase, Epoch 22/30, Loss: 14.002684
val phase, Epoch 22/30, Loss: 18.975988
Val Best Loss: 15.791769
Epoch loss: 18.975988
train phase, Epoch 23/30, Loss: 13.671277
val phase, Epoch 23/30, Loss: 16.694506
Val Best Loss: 15.791769
Epoch loss: 16.694506
train phase, Epoch 24/30, Loss: 13.481174
val phase, Epoch 24/30, Loss: 16.775664
Val Best Loss: 15.791769
Epoch loss: 16.775664
train phase, Epoch 25/30, Loss: 13.090143
val phase, Epoch 25/30, Loss: 16.908331
Val Best Loss: 15.791769
Epoch loss: 16.908331
train phase, Epoch 26/30, Loss: 12.508732
val phase, Epoch 26/30, Loss: 16.798395
Val Best Loss: 15.791769
Epoch loss: 16.798395
train phase, Epoch 27/30, Loss: 12.320352
val phase, Epoch 27/30, Loss: 16.518837
Val Best Loss: 15.791769
Epoch loss: 16.518837
train phase, Epoch 28/30, Loss: 11.789514
val phase, Epoch 28/30, Loss: 17.071626
Val Best Loss: 15.791769
Epoch loss: 17.071626
train phase, Epoch 29/30, Loss: 11.359455
val phase, Epoch 29/30, Loss: 19.560220
Val Best Loss: 15.791769
Epoch loss: 19.560220
train phase, Epoch 30/30, Loss: 11.222907
val phase, Epoch 30/30, Loss: 18.212037
Val Best Loss: 15.791769
Epoch loss: 18.212037
train phase, Epoch 1/20, Loss: 20.186427
val phase, Epoch 1/20, Loss: 17.898948
Val Best Loss: 17.898948
Epoch loss: 17.898948
train phase, Epoch 2/20, Loss: 17.890508
val phase, Epoch 2/20, Loss: 17.758918
Val Best Loss: 17.758918
Epoch loss: 17.758918
train phase, Epoch 3/20, Loss: 17.496538
val phase, Epoch 3/20, Loss: 16.517118
Val Best Loss: 16.517118
Epoch loss: 16.517118
train phase, Epoch 4/20, Loss: 17.049703
val phase, Epoch 4/20, Loss: 16.819700
Val Best Loss: 16.517118
Epoch loss: 16.819700
train phase, Epoch 5/20, Loss: 16.893406
val phase, Epoch 5/20, Loss: 16.179735
Val Best Loss: 16.179735
Epoch loss: 16.179735
train phase, Epoch 6/20, Loss: 16.635995
val phase, Epoch 6/20, Loss: 17.083714
Val Best Loss: 16.179735
Epoch loss: 17.083714
train phase, Epoch 7/20, Loss: 16.326643
val phase, Epoch 7/20, Loss: 16.614450
Val Best Loss: 16.179735
Epoch loss: 16.614450
train phase, Epoch 8/20, Loss: 16.123939
val phase, Epoch 8/20, Loss: 16.991577
Val Best Loss: 16.179735
Epoch loss: 16.991577
train phase, Epoch 9/20, Loss: 16.028814
val phase, Epoch 9/20, Loss: 16.150275
Val Best Loss: 16.150275
Epoch loss: 16.150275
train phase, Epoch 10/20, Loss: 15.688338
val phase, Epoch 10/20, Loss: 16.165823
Val Best Loss: 16.150275
Epoch loss: 16.165823
train phase, Epoch 11/20, Loss: 15.715696
val phase, Epoch 11/20, Loss: 16.389034
Val Best Loss: 16.150275
Epoch loss: 16.389034
train phase, Epoch 12/20, Loss: 15.666403
val phase, Epoch 12/20, Loss: 16.992222
Val Best Loss: 16.150275
Epoch loss: 16.992222
train phase, Epoch 13/20, Loss: 15.482431
val phase, Epoch 13/20, Loss: 16.263372
Val Best Loss: 16.150275
Epoch loss: 16.263372
train phase, Epoch 14/20, Loss: 15.402105
val phase, Epoch 14/20, Loss: 16.164535
Val Best Loss: 16.150275
Epoch loss: 16.164535
train phase, Epoch 15/20, Loss: 15.086254
val phase, Epoch 15/20, Loss: 15.790208
Val Best Loss: 15.790208
Epoch loss: 15.790208
train phase, Epoch 16/20, Loss: 14.627109
val phase, Epoch 16/20, Loss: 17.150992
Val Best Loss: 15.790208
Epoch loss: 17.150992
train phase, Epoch 17/20, Loss: 14.649989
val phase, Epoch 17/20, Loss: 16.660117
Val Best Loss: 15.790208
Epoch loss: 16.660117
train phase, Epoch 18/20, Loss: 14.418381
val phase, Epoch 18/20, Loss: 16.685004
Val Best Loss: 15.790208
Epoch loss: 16.685004
train phase, Epoch 19/20, Loss: 14.085650
val phase, Epoch 19/20, Loss: 16.786764
Val Best Loss: 15.790208
Epoch loss: 16.786764
train phase, Epoch 20/20, Loss: 13.842454
val phase, Epoch 20/20, Loss: 17.298941
Val Best Loss: 15.790208
Epoch loss: 17.298941
train phase, Epoch 1/20, Loss: 20.063106
val phase, Epoch 1/20, Loss: 18.856089
Val Best Loss: 18.856089
Epoch loss: 18.856089
train phase, Epoch 2/20, Loss: 17.710731
val phase, Epoch 2/20, Loss: 16.697720
Val Best Loss: 16.697720
Epoch loss: 16.697720
train phase, Epoch 3/20, Loss: 17.632455
val phase, Epoch 3/20, Loss: 16.515008
Val Best Loss: 16.515008
Epoch loss: 16.515008
train phase, Epoch 4/20, Loss: 16.897869
val phase, Epoch 4/20, Loss: 16.270859
Val Best Loss: 16.270859
Epoch loss: 16.270859
train phase, Epoch 5/20, Loss: 16.674951
val phase, Epoch 5/20, Loss: 16.109269
Val Best Loss: 16.109269
Epoch loss: 16.109269
train phase, Epoch 6/20, Loss: 16.561980
val phase, Epoch 6/20, Loss: 16.356450
Val Best Loss: 16.109269
Epoch loss: 16.356450
train phase, Epoch 7/20, Loss: 16.701841
val phase, Epoch 7/20, Loss: 20.008281
Val Best Loss: 16.109269
Epoch loss: 20.008281
train phase, Epoch 8/20, Loss: 16.169599
val phase, Epoch 8/20, Loss: 16.003727
Val Best Loss: 16.003727
Epoch loss: 16.003727
train phase, Epoch 9/20, Loss: 16.056066
val phase, Epoch 9/20, Loss: 15.811367
Val Best Loss: 15.811367
Epoch loss: 15.811367
train phase, Epoch 10/20, Loss: 15.861868
val phase, Epoch 10/20, Loss: 16.392271
Val Best Loss: 15.811367
Epoch loss: 16.392271
train phase, Epoch 11/20, Loss: 15.872970
val phase, Epoch 11/20, Loss: 15.748369
Val Best Loss: 15.748369
Epoch loss: 15.748369
train phase, Epoch 12/20, Loss: 15.449453
val phase, Epoch 12/20, Loss: 16.572544
Val Best Loss: 15.748369
Epoch loss: 16.572544
train phase, Epoch 13/20, Loss: 15.386198
val phase, Epoch 13/20, Loss: 16.308702
Val Best Loss: 15.748369
Epoch loss: 16.308702
train phase, Epoch 14/20, Loss: 15.281830
val phase, Epoch 14/20, Loss: 16.541304
Val Best Loss: 15.748369
Epoch loss: 16.541304
train phase, Epoch 15/20, Loss: 14.903442
val phase, Epoch 15/20, Loss: 17.440441
Val Best Loss: 15.748369
Epoch loss: 17.440441
train phase, Epoch 16/20, Loss: 14.942683
val phase, Epoch 16/20, Loss: 16.385772
Val Best Loss: 15.748369
Epoch loss: 16.385772
train phase, Epoch 17/20, Loss: 14.620904
val phase, Epoch 17/20, Loss: 17.317101
Val Best Loss: 15.748369
Epoch loss: 17.317101
train phase, Epoch 18/20, Loss: 14.074298
val phase, Epoch 18/20, Loss: 16.271193
Val Best Loss: 15.748369
Epoch loss: 16.271193
train phase, Epoch 19/20, Loss: 13.821749
val phase, Epoch 19/20, Loss: 16.993790
Val Best Loss: 15.748369
Epoch loss: 16.993790
train phase, Epoch 20/20, Loss: 13.700975
val phase, Epoch 20/20, Loss: 19.430593
Val Best Loss: 15.748369
Epoch loss: 19.430593
train phase, Epoch 1/30, Loss: 20.589453
val phase, Epoch 1/30, Loss: 20.284743
Val Best Loss: 20.284743
Epoch loss: 20.284743
train phase, Epoch 2/30, Loss: 17.827339
val phase, Epoch 2/30, Loss: 19.410569
Val Best Loss: 19.410569
Epoch loss: 19.410569
train phase, Epoch 3/30, Loss: 17.224217
val phase, Epoch 3/30, Loss: 17.716056
Val Best Loss: 17.716056
Epoch loss: 17.716056
train phase, Epoch 4/30, Loss: 17.328281
val phase, Epoch 4/30, Loss: 16.280994
Val Best Loss: 16.280994
Epoch loss: 16.280994
train phase, Epoch 5/30, Loss: 16.935227
val phase, Epoch 5/30, Loss: 16.670616
Val Best Loss: 16.280994
Epoch loss: 16.670616
train phase, Epoch 6/30, Loss: 16.943791
val phase, Epoch 6/30, Loss: 16.651295
Val Best Loss: 16.280994
Epoch loss: 16.651295
train phase, Epoch 7/30, Loss: 16.575181
val phase, Epoch 7/30, Loss: 16.130332
Val Best Loss: 16.130332
Epoch loss: 16.130332
train phase, Epoch 8/30, Loss: 16.481742
val phase, Epoch 8/30, Loss: 18.259850
Val Best Loss: 16.130332
Epoch loss: 18.259850
train phase, Epoch 9/30, Loss: 16.433137
val phase, Epoch 9/30, Loss: 15.881895
Val Best Loss: 15.881895
Epoch loss: 15.881895
train phase, Epoch 10/30, Loss: 15.922722
val phase, Epoch 10/30, Loss: 16.376253
Val Best Loss: 15.881895
Epoch loss: 16.376253
train phase, Epoch 11/30, Loss: 16.183548
val phase, Epoch 11/30, Loss: 17.471057
Val Best Loss: 15.881895
Epoch loss: 17.471057
train phase, Epoch 12/30, Loss: 16.104308
val phase, Epoch 12/30, Loss: 16.403619
Val Best Loss: 15.881895
Epoch loss: 16.403619
train phase, Epoch 13/30, Loss: 15.558779
val phase, Epoch 13/30, Loss: 17.131163
Val Best Loss: 15.881895
Epoch loss: 17.131163
train phase, Epoch 14/30, Loss: 15.370692
val phase, Epoch 14/30, Loss: 15.839941
Val Best Loss: 15.839941
Epoch loss: 15.839941
train phase, Epoch 15/30, Loss: 15.392637
val phase, Epoch 15/30, Loss: 15.806572
Val Best Loss: 15.806572
Epoch loss: 15.806572
train phase, Epoch 16/30, Loss: 15.008375
val phase, Epoch 16/30, Loss: 16.111173
Val Best Loss: 15.806572
Epoch loss: 16.111173
train phase, Epoch 17/30, Loss: 15.228763
val phase, Epoch 17/30, Loss: 16.346667
Val Best Loss: 15.806572
Epoch loss: 16.346667
train phase, Epoch 18/30, Loss: 14.835817
val phase, Epoch 18/30, Loss: 16.262703
Val Best Loss: 15.806572
Epoch loss: 16.262703
train phase, Epoch 19/30, Loss: 14.366847
val phase, Epoch 19/30, Loss: 16.282227
Val Best Loss: 15.806572
Epoch loss: 16.282227
train phase, Epoch 20/30, Loss: 14.273367
val phase, Epoch 20/30, Loss: 16.616724
Val Best Loss: 15.806572
Epoch loss: 16.616724
train phase, Epoch 21/30, Loss: 14.021349
val phase, Epoch 21/30, Loss: 16.341945
Val Best Loss: 15.806572
Epoch loss: 16.341945
train phase, Epoch 22/30, Loss: 13.930312
val phase, Epoch 22/30, Loss: 17.288194
Val Best Loss: 15.806572
Epoch loss: 17.288194
train phase, Epoch 23/30, Loss: 13.620987
val phase, Epoch 23/30, Loss: 17.130596
Val Best Loss: 15.806572
Epoch loss: 17.130596
train phase, Epoch 24/30, Loss: 13.047907
val phase, Epoch 24/30, Loss: 18.189526
Val Best Loss: 15.806572
Epoch loss: 18.189526
train phase, Epoch 25/30, Loss: 12.853902
val phase, Epoch 25/30, Loss: 18.211911
Val Best Loss: 15.806572
Epoch loss: 18.211911
train phase, Epoch 26/30, Loss: 12.509200
val phase, Epoch 26/30, Loss: 16.837377
Val Best Loss: 15.806572
Epoch loss: 16.837377
train phase, Epoch 27/30, Loss: 11.895713
val phase, Epoch 27/30, Loss: 17.498996
Val Best Loss: 15.806572
Epoch loss: 17.498996
train phase, Epoch 28/30, Loss: 11.680940
val phase, Epoch 28/30, Loss: 17.848310
Val Best Loss: 15.806572
Epoch loss: 17.848310
train phase, Epoch 29/30, Loss: 11.616480
val phase, Epoch 29/30, Loss: 17.916826
Val Best Loss: 15.806572
Epoch loss: 17.916826
train phase, Epoch 30/30, Loss: 11.295968
val phase, Epoch 30/30, Loss: 18.027937
Val Best Loss: 15.806572
Epoch loss: 18.027937
train phase, Epoch 1/20, Loss: nan
val phase, Epoch 1/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/20, Loss: nan
val phase, Epoch 2/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/20, Loss: nan
val phase, Epoch 3/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/20, Loss: nan
val phase, Epoch 4/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/20, Loss: nan
val phase, Epoch 5/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/20, Loss: nan
val phase, Epoch 6/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/20, Loss: nan
val phase, Epoch 7/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/20, Loss: nan
val phase, Epoch 8/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/20, Loss: nan
val phase, Epoch 9/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/20, Loss: nan
val phase, Epoch 10/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 11/20, Loss: nan
val phase, Epoch 11/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 12/20, Loss: nan
val phase, Epoch 12/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 13/20, Loss: nan
val phase, Epoch 13/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 14/20, Loss: nan
val phase, Epoch 14/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 15/20, Loss: nan
val phase, Epoch 15/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 16/20, Loss: nan
val phase, Epoch 16/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 17/20, Loss: nan
val phase, Epoch 17/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 18/20, Loss: nan
val phase, Epoch 18/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 19/20, Loss: nan
val phase, Epoch 19/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 20/20, Loss: nan
val phase, Epoch 20/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 1/20, Loss: 20.866386
val phase, Epoch 1/20, Loss: 17.696653
Val Best Loss: 17.696653
Epoch loss: 17.696653
train phase, Epoch 2/20, Loss: 18.599399
val phase, Epoch 2/20, Loss: 19.196299
Val Best Loss: 17.696653
Epoch loss: 19.196299
train phase, Epoch 3/20, Loss: 18.024459
val phase, Epoch 3/20, Loss: 16.980634
Val Best Loss: 16.980634
Epoch loss: 16.980634
train phase, Epoch 4/20, Loss: 17.770895
val phase, Epoch 4/20, Loss: 17.149794
Val Best Loss: 16.980634
Epoch loss: 17.149794
train phase, Epoch 5/20, Loss: 17.342905
val phase, Epoch 5/20, Loss: 20.383830
Val Best Loss: 16.980634
Epoch loss: 20.383830
train phase, Epoch 6/20, Loss: 17.367925
val phase, Epoch 6/20, Loss: 17.246556
Val Best Loss: 16.980634
Epoch loss: 17.246556
train phase, Epoch 7/20, Loss: 17.054915
val phase, Epoch 7/20, Loss: 16.893737
Val Best Loss: 16.893737
Epoch loss: 16.893737
train phase, Epoch 8/20, Loss: 16.740869
val phase, Epoch 8/20, Loss: 17.886231
Val Best Loss: 16.893737
Epoch loss: 17.886231
train phase, Epoch 9/20, Loss: 16.536303
val phase, Epoch 9/20, Loss: 17.274624
Val Best Loss: 16.893737
Epoch loss: 17.274624
train phase, Epoch 10/20, Loss: 16.244059
val phase, Epoch 10/20, Loss: 16.707899
Val Best Loss: 16.707899
Epoch loss: 16.707899
train phase, Epoch 11/20, Loss: 16.280519
val phase, Epoch 11/20, Loss: 16.715374
Val Best Loss: 16.707899
Epoch loss: 16.715374
train phase, Epoch 12/20, Loss: 15.947947
val phase, Epoch 12/20, Loss: 16.490705
Val Best Loss: 16.490705
Epoch loss: 16.490705
train phase, Epoch 13/20, Loss: 16.025048
val phase, Epoch 13/20, Loss: 16.277601
Val Best Loss: 16.277601
Epoch loss: 16.277601
train phase, Epoch 14/20, Loss: 15.693020
val phase, Epoch 14/20, Loss: 17.071683
Val Best Loss: 16.277601
Epoch loss: 17.071683
train phase, Epoch 15/20, Loss: 15.394404
val phase, Epoch 15/20, Loss: 16.673333
Val Best Loss: 16.277601
Epoch loss: 16.673333
train phase, Epoch 16/20, Loss: 15.138664
val phase, Epoch 16/20, Loss: 16.714344
Val Best Loss: 16.277601
Epoch loss: 16.714344
train phase, Epoch 17/20, Loss: 14.947968
val phase, Epoch 17/20, Loss: 16.571027
Val Best Loss: 16.277601
Epoch loss: 16.571027
train phase, Epoch 18/20, Loss: 14.768915
val phase, Epoch 18/20, Loss: 16.903811
Val Best Loss: 16.277601
Epoch loss: 16.903811
train phase, Epoch 19/20, Loss: 14.327523
val phase, Epoch 19/20, Loss: 16.537770
Val Best Loss: 16.277601
Epoch loss: 16.537770
train phase, Epoch 20/20, Loss: 14.403048
val phase, Epoch 20/20, Loss: 16.682322
Val Best Loss: 16.277601
Epoch loss: 16.682322
train phase, Epoch 1/15, Loss: 20.350761
val phase, Epoch 1/15, Loss: 18.211967
Val Best Loss: 18.211967
Epoch loss: 18.211967
train phase, Epoch 2/15, Loss: 17.679913
val phase, Epoch 2/15, Loss: 18.072133
Val Best Loss: 18.072133
Epoch loss: 18.072133
train phase, Epoch 3/15, Loss: 17.010698
val phase, Epoch 3/15, Loss: 16.704326
Val Best Loss: 16.704326
Epoch loss: 16.704326
train phase, Epoch 4/15, Loss: 17.044658
val phase, Epoch 4/15, Loss: 17.016623
Val Best Loss: 16.704326
Epoch loss: 17.016623
train phase, Epoch 5/15, Loss: 17.243972
val phase, Epoch 5/15, Loss: 17.322968
Val Best Loss: 16.704326
Epoch loss: 17.322968
train phase, Epoch 6/15, Loss: 16.596425
val phase, Epoch 6/15, Loss: 17.423775
Val Best Loss: 16.704326
Epoch loss: 17.423775
train phase, Epoch 7/15, Loss: 16.340376
val phase, Epoch 7/15, Loss: 16.062488
Val Best Loss: 16.062488
Epoch loss: 16.062488
train phase, Epoch 8/15, Loss: 16.508626
val phase, Epoch 8/15, Loss: 16.623030
Val Best Loss: 16.062488
Epoch loss: 16.623030
train phase, Epoch 9/15, Loss: 15.889067
val phase, Epoch 9/15, Loss: 17.214632
Val Best Loss: 16.062488
Epoch loss: 17.214632
train phase, Epoch 10/15, Loss: 16.101630
val phase, Epoch 10/15, Loss: 16.405147
Val Best Loss: 16.062488
Epoch loss: 16.405147
train phase, Epoch 11/15, Loss: 15.711474
val phase, Epoch 11/15, Loss: 16.353914
Val Best Loss: 16.062488
Epoch loss: 16.353914
train phase, Epoch 12/15, Loss: 15.575297
val phase, Epoch 12/15, Loss: 18.088338
Val Best Loss: 16.062488
Epoch loss: 18.088338
train phase, Epoch 13/15, Loss: 15.427996
val phase, Epoch 13/15, Loss: 16.338667
Val Best Loss: 16.062488
Epoch loss: 16.338667
train phase, Epoch 14/15, Loss: 15.171817
val phase, Epoch 14/15, Loss: 15.907998
Val Best Loss: 15.907998
Epoch loss: 15.907998
train phase, Epoch 15/15, Loss: 14.962776
val phase, Epoch 15/15, Loss: 17.019760
Val Best Loss: 15.907998
Epoch loss: 17.019760
[Trial 333] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 20.833889
val phase, Epoch 1/30, Loss: 18.110760
Val Best Loss: 18.110760
Epoch loss: 18.110760
train phase, Epoch 2/30, Loss: 18.975240
val phase, Epoch 2/30, Loss: 31.500696
Val Best Loss: 18.110760
Epoch loss: 31.500696
train phase, Epoch 3/30, Loss: 18.413045
val phase, Epoch 3/30, Loss: 17.097973
Val Best Loss: 17.097973
Epoch loss: 17.097973
train phase, Epoch 4/30, Loss: 17.806038
val phase, Epoch 4/30, Loss: 16.598110
Val Best Loss: 16.598110
Epoch loss: 16.598110
train phase, Epoch 5/30, Loss: 17.693054
val phase, Epoch 5/30, Loss: 18.477800
Val Best Loss: 16.598110
Epoch loss: 18.477800
train phase, Epoch 6/30, Loss: 17.453043
val phase, Epoch 6/30, Loss: 20.029117
Val Best Loss: 16.598110
Epoch loss: 20.029117
train phase, Epoch 7/30, Loss: 17.256540
val phase, Epoch 7/30, Loss: 16.252343
Val Best Loss: 16.252343
Epoch loss: 16.252343
train phase, Epoch 8/30, Loss: 16.910387
val phase, Epoch 8/30, Loss: 18.411624
Val Best Loss: 16.252343
Epoch loss: 18.411624
train phase, Epoch 9/30, Loss: 16.935056
val phase, Epoch 9/30, Loss: 16.220697
Val Best Loss: 16.220697
Epoch loss: 16.220697
train phase, Epoch 10/30, Loss: 16.714503
val phase, Epoch 10/30, Loss: 16.785217
Val Best Loss: 16.220697
Epoch loss: 16.785217
train phase, Epoch 11/30, Loss: 16.562805
val phase, Epoch 11/30, Loss: 17.273826
Val Best Loss: 16.220697
Epoch loss: 17.273826
train phase, Epoch 12/30, Loss: 16.307858
val phase, Epoch 12/30, Loss: 16.004571
Val Best Loss: 16.004571
Epoch loss: 16.004571
train phase, Epoch 13/30, Loss: 16.309087
val phase, Epoch 13/30, Loss: 15.936558
Val Best Loss: 15.936558
Epoch loss: 15.936558
train phase, Epoch 14/30, Loss: 16.269029
val phase, Epoch 14/30, Loss: 16.991243
Val Best Loss: 15.936558
Epoch loss: 16.991243
train phase, Epoch 15/30, Loss: 15.996972
val phase, Epoch 15/30, Loss: 17.248981
Val Best Loss: 15.936558
Epoch loss: 17.248981
train phase, Epoch 16/30, Loss: 15.949149
val phase, Epoch 16/30, Loss: 16.122303
Val Best Loss: 15.936558
Epoch loss: 16.122303
train phase, Epoch 17/30, Loss: 15.757134
val phase, Epoch 17/30, Loss: 16.549925
Val Best Loss: 15.936558
Epoch loss: 16.549925
train phase, Epoch 18/30, Loss: 15.428308
val phase, Epoch 18/30, Loss: 16.179508
Val Best Loss: 15.936558
Epoch loss: 16.179508
train phase, Epoch 19/30, Loss: 15.408501
val phase, Epoch 19/30, Loss: 15.940945
Val Best Loss: 15.936558
Epoch loss: 15.940945
train phase, Epoch 20/30, Loss: 15.086132
val phase, Epoch 20/30, Loss: 16.161335
Val Best Loss: 15.936558
Epoch loss: 16.161335
train phase, Epoch 21/30, Loss: 15.036947
val phase, Epoch 21/30, Loss: 16.686075
Val Best Loss: 15.936558
Epoch loss: 16.686075
train phase, Epoch 22/30, Loss: 14.720103
val phase, Epoch 22/30, Loss: 18.139008
Val Best Loss: 15.936558
Epoch loss: 18.139008
train phase, Epoch 23/30, Loss: 14.587833
val phase, Epoch 23/30, Loss: 16.066687
Val Best Loss: 15.936558
Epoch loss: 16.066687
train phase, Epoch 24/30, Loss: 14.330359
val phase, Epoch 24/30, Loss: 17.903635
Val Best Loss: 15.936558
Epoch loss: 17.903635
train phase, Epoch 25/30, Loss: 14.184352
val phase, Epoch 25/30, Loss: 16.816471
Val Best Loss: 15.936558
Epoch loss: 16.816471
train phase, Epoch 26/30, Loss: 14.026707
val phase, Epoch 26/30, Loss: 16.582540
Val Best Loss: 15.936558
Epoch loss: 16.582540
train phase, Epoch 27/30, Loss: 13.619835
val phase, Epoch 27/30, Loss: 17.221378
Val Best Loss: 15.936558
Epoch loss: 17.221378
train phase, Epoch 28/30, Loss: 13.263522
val phase, Epoch 28/30, Loss: 17.441317
Val Best Loss: 15.936558
Epoch loss: 17.441317
train phase, Epoch 29/30, Loss: 12.755630
val phase, Epoch 29/30, Loss: 17.034974
Val Best Loss: 15.936558
Epoch loss: 17.034974
train phase, Epoch 30/30, Loss: 12.749977
val phase, Epoch 30/30, Loss: 17.379171
Val Best Loss: 15.936558
Epoch loss: 17.379171
train phase, Epoch 1/20, Loss: 20.911979
val phase, Epoch 1/20, Loss: 17.993544
Val Best Loss: 17.993544
Epoch loss: 17.993544
train phase, Epoch 2/20, Loss: 18.115804
val phase, Epoch 2/20, Loss: 17.270607
Val Best Loss: 17.270607
Epoch loss: 17.270607
train phase, Epoch 3/20, Loss: 17.493489
val phase, Epoch 3/20, Loss: 16.653296
Val Best Loss: 16.653296
Epoch loss: 16.653296
train phase, Epoch 4/20, Loss: 17.425056
val phase, Epoch 4/20, Loss: 17.675423
Val Best Loss: 16.653296
Epoch loss: 17.675423
train phase, Epoch 5/20, Loss: 17.187905
val phase, Epoch 5/20, Loss: 18.962180
Val Best Loss: 16.653296
Epoch loss: 18.962180
train phase, Epoch 6/20, Loss: 16.753486
val phase, Epoch 6/20, Loss: 16.158301
Val Best Loss: 16.158301
Epoch loss: 16.158301
train phase, Epoch 7/20, Loss: 16.720246
val phase, Epoch 7/20, Loss: 16.304254
Val Best Loss: 16.158301
Epoch loss: 16.304254
train phase, Epoch 8/20, Loss: 16.295944
val phase, Epoch 8/20, Loss: 16.022247
Val Best Loss: 16.022247
Epoch loss: 16.022247
train phase, Epoch 9/20, Loss: 16.270935
val phase, Epoch 9/20, Loss: 19.396297
Val Best Loss: 16.022247
Epoch loss: 19.396297
train phase, Epoch 10/20, Loss: 16.297729
val phase, Epoch 10/20, Loss: 17.946277
Val Best Loss: 16.022247
Epoch loss: 17.946277
train phase, Epoch 11/20, Loss: 16.276332
val phase, Epoch 11/20, Loss: 16.858018
Val Best Loss: 16.022247
Epoch loss: 16.858018
train phase, Epoch 12/20, Loss: 15.792003
val phase, Epoch 12/20, Loss: 16.610273
Val Best Loss: 16.022247
Epoch loss: 16.610273
train phase, Epoch 13/20, Loss: 15.726025
val phase, Epoch 13/20, Loss: 17.418783
Val Best Loss: 16.022247
Epoch loss: 17.418783
train phase, Epoch 14/20, Loss: 16.012379
val phase, Epoch 14/20, Loss: 19.247797
Val Best Loss: 16.022247
Epoch loss: 19.247797
train phase, Epoch 15/20, Loss: 15.885767
val phase, Epoch 15/20, Loss: 17.291750
Val Best Loss: 16.022247
Epoch loss: 17.291750
train phase, Epoch 16/20, Loss: 15.309390
val phase, Epoch 16/20, Loss: 16.425911
Val Best Loss: 16.022247
Epoch loss: 16.425911
train phase, Epoch 17/20, Loss: 15.337045
val phase, Epoch 17/20, Loss: 16.469363
Val Best Loss: 16.022247
Epoch loss: 16.469363
train phase, Epoch 18/20, Loss: 15.114005
val phase, Epoch 18/20, Loss: 19.145153
Val Best Loss: 16.022247
Epoch loss: 19.145153
train phase, Epoch 19/20, Loss: 14.820726
val phase, Epoch 19/20, Loss: 16.627045
Val Best Loss: 16.022247
Epoch loss: 16.627045
train phase, Epoch 20/20, Loss: 14.513141
val phase, Epoch 20/20, Loss: 16.234576
Val Best Loss: 16.022247
Epoch loss: 16.234576
train phase, Epoch 1/20, Loss: 27.950005
val phase, Epoch 1/20, Loss: 19.129002
Val Best Loss: 19.129002
Epoch loss: 19.129002
train phase, Epoch 2/20, Loss: 19.424751
val phase, Epoch 2/20, Loss: 18.732702
Val Best Loss: 18.732702
Epoch loss: 18.732702
train phase, Epoch 3/20, Loss: 18.775756
val phase, Epoch 3/20, Loss: 21.024817
Val Best Loss: 18.732702
Epoch loss: 21.024817
train phase, Epoch 4/20, Loss: 18.647452
val phase, Epoch 4/20, Loss: 23.643107
Val Best Loss: 18.732702
Epoch loss: 23.643107
train phase, Epoch 5/20, Loss: 17.900487
val phase, Epoch 5/20, Loss: 18.243581
Val Best Loss: 18.243581
Epoch loss: 18.243581
train phase, Epoch 6/20, Loss: 17.683309
val phase, Epoch 6/20, Loss: 23.000038
Val Best Loss: 18.243581
Epoch loss: 23.000038
train phase, Epoch 7/20, Loss: 17.446490
val phase, Epoch 7/20, Loss: 18.492529
Val Best Loss: 18.243581
Epoch loss: 18.492529
train phase, Epoch 8/20, Loss: 17.759026
val phase, Epoch 8/20, Loss: 17.592103
Val Best Loss: 17.592103
Epoch loss: 17.592103
train phase, Epoch 9/20, Loss: 17.053574
val phase, Epoch 9/20, Loss: 17.333445
Val Best Loss: 17.333445
Epoch loss: 17.333445
train phase, Epoch 10/20, Loss: 16.908732
val phase, Epoch 10/20, Loss: 19.477587
Val Best Loss: 17.333445
Epoch loss: 19.477587
train phase, Epoch 11/20, Loss: 16.738764
val phase, Epoch 11/20, Loss: 17.096290
Val Best Loss: 17.096290
Epoch loss: 17.096290
train phase, Epoch 12/20, Loss: 17.105012
val phase, Epoch 12/20, Loss: 16.520468
Val Best Loss: 16.520468
Epoch loss: 16.520468
train phase, Epoch 13/20, Loss: 16.683222
val phase, Epoch 13/20, Loss: 16.755989
Val Best Loss: 16.520468
Epoch loss: 16.755989
train phase, Epoch 14/20, Loss: 16.320719
val phase, Epoch 14/20, Loss: 17.023580
Val Best Loss: 16.520468
Epoch loss: 17.023580
train phase, Epoch 15/20, Loss: 16.482912
val phase, Epoch 15/20, Loss: 20.016733
Val Best Loss: 16.520468
Epoch loss: 20.016733
train phase, Epoch 16/20, Loss: 16.437026
val phase, Epoch 16/20, Loss: 17.822331
Val Best Loss: 16.520468
Epoch loss: 17.822331
train phase, Epoch 17/20, Loss: 16.268567
val phase, Epoch 17/20, Loss: 16.813559
Val Best Loss: 16.520468
Epoch loss: 16.813559
train phase, Epoch 18/20, Loss: 15.902362
val phase, Epoch 18/20, Loss: 18.085423
Val Best Loss: 16.520468
Epoch loss: 18.085423
train phase, Epoch 19/20, Loss: 15.990823
val phase, Epoch 19/20, Loss: 18.101518
Val Best Loss: 16.520468
Epoch loss: 18.101518
train phase, Epoch 20/20, Loss: 18.280684
val phase, Epoch 20/20, Loss: 19.362500
Val Best Loss: 16.520468
Epoch loss: 19.362500
train phase, Epoch 1/12, Loss: 21.044471
val phase, Epoch 1/12, Loss: 17.716177
Val Best Loss: 17.716177
Epoch loss: 17.716177
train phase, Epoch 2/12, Loss: 18.617373
val phase, Epoch 2/12, Loss: 17.274764
Val Best Loss: 17.274764
Epoch loss: 17.274764
train phase, Epoch 3/12, Loss: 18.431979
val phase, Epoch 3/12, Loss: 19.430481
Val Best Loss: 17.274764
Epoch loss: 19.430481
train phase, Epoch 4/12, Loss: 18.225558
val phase, Epoch 4/12, Loss: 17.481707
Val Best Loss: 17.274764
Epoch loss: 17.481707
train phase, Epoch 5/12, Loss: 17.674477
val phase, Epoch 5/12, Loss: 17.355492
Val Best Loss: 17.274764
Epoch loss: 17.355492
train phase, Epoch 6/12, Loss: 17.635703
val phase, Epoch 6/12, Loss: 17.306501
Val Best Loss: 17.274764
Epoch loss: 17.306501
train phase, Epoch 7/12, Loss: 17.251345
val phase, Epoch 7/12, Loss: 17.434663
Val Best Loss: 17.274764
Epoch loss: 17.434663
train phase, Epoch 8/12, Loss: 17.119449
val phase, Epoch 8/12, Loss: 16.890969
Val Best Loss: 16.890969
Epoch loss: 16.890969
train phase, Epoch 9/12, Loss: 17.187952
val phase, Epoch 9/12, Loss: 16.995321
Val Best Loss: 16.890969
Epoch loss: 16.995321
train phase, Epoch 10/12, Loss: 17.188502
val phase, Epoch 10/12, Loss: 19.126871
Val Best Loss: 16.890969
Epoch loss: 19.126871
train phase, Epoch 11/12, Loss: 17.066015
val phase, Epoch 11/12, Loss: 16.561002
Val Best Loss: 16.561002
Epoch loss: 16.561002
train phase, Epoch 12/12, Loss: 16.795413
val phase, Epoch 12/12, Loss: 17.402791
Val Best Loss: 16.561002
Epoch loss: 17.402791
train phase, Epoch 1/30, Loss: 20.316200
val phase, Epoch 1/30, Loss: 18.712167
Val Best Loss: 18.712167
Epoch loss: 18.712167
train phase, Epoch 2/30, Loss: 18.121719
val phase, Epoch 2/30, Loss: 16.790876
Val Best Loss: 16.790876
Epoch loss: 16.790876
train phase, Epoch 3/30, Loss: 17.620511
val phase, Epoch 3/30, Loss: 21.338553
Val Best Loss: 16.790876
Epoch loss: 21.338553
train phase, Epoch 4/30, Loss: 17.409925
val phase, Epoch 4/30, Loss: 16.869747
Val Best Loss: 16.790876
Epoch loss: 16.869747
train phase, Epoch 5/30, Loss: 17.107958
val phase, Epoch 5/30, Loss: 18.042123
Val Best Loss: 16.790876
Epoch loss: 18.042123
train phase, Epoch 6/30, Loss: 17.004890
val phase, Epoch 6/30, Loss: 16.597306
Val Best Loss: 16.597306
Epoch loss: 16.597306
train phase, Epoch 7/30, Loss: 16.628994
val phase, Epoch 7/30, Loss: 16.671438
Val Best Loss: 16.597306
Epoch loss: 16.671438
train phase, Epoch 8/30, Loss: 16.284219
val phase, Epoch 8/30, Loss: 20.884326
Val Best Loss: 16.597306
Epoch loss: 20.884326
train phase, Epoch 9/30, Loss: 16.289610
val phase, Epoch 9/30, Loss: 16.506656
Val Best Loss: 16.506656
Epoch loss: 16.506656
train phase, Epoch 10/30, Loss: 15.974961
val phase, Epoch 10/30, Loss: 16.349917
Val Best Loss: 16.349917
Epoch loss: 16.349917
train phase, Epoch 11/30, Loss: 16.129614
val phase, Epoch 11/30, Loss: 16.060237
Val Best Loss: 16.060237
Epoch loss: 16.060237
train phase, Epoch 12/30, Loss: 15.604214
val phase, Epoch 12/30, Loss: 16.045585
Val Best Loss: 16.045585
Epoch loss: 16.045585
train phase, Epoch 13/30, Loss: 16.277853
val phase, Epoch 13/30, Loss: 16.014197
Val Best Loss: 16.014197
Epoch loss: 16.014197
train phase, Epoch 14/30, Loss: 15.476620
val phase, Epoch 14/30, Loss: 16.265567
Val Best Loss: 16.014197
Epoch loss: 16.265567
train phase, Epoch 15/30, Loss: 15.329655
val phase, Epoch 15/30, Loss: 15.940763
Val Best Loss: 15.940763
Epoch loss: 15.940763
train phase, Epoch 16/30, Loss: 14.966496
val phase, Epoch 16/30, Loss: 16.582420
Val Best Loss: 15.940763
Epoch loss: 16.582420
train phase, Epoch 17/30, Loss: 14.637425
val phase, Epoch 17/30, Loss: 16.841509
Val Best Loss: 15.940763
Epoch loss: 16.841509
train phase, Epoch 18/30, Loss: 14.570439
val phase, Epoch 18/30, Loss: 16.262918
Val Best Loss: 15.940763
Epoch loss: 16.262918
train phase, Epoch 19/30, Loss: 14.313256
val phase, Epoch 19/30, Loss: 15.951834
Val Best Loss: 15.940763
Epoch loss: 15.951834
train phase, Epoch 20/30, Loss: 14.082491
val phase, Epoch 20/30, Loss: 17.032725
Val Best Loss: 15.940763
Epoch loss: 17.032725
train phase, Epoch 21/30, Loss: 13.787937
val phase, Epoch 21/30, Loss: 16.457925
Val Best Loss: 15.940763
Epoch loss: 16.457925
train phase, Epoch 22/30, Loss: 13.407727
val phase, Epoch 22/30, Loss: 18.522379
Val Best Loss: 15.940763
Epoch loss: 18.522379
train phase, Epoch 23/30, Loss: 13.342123
val phase, Epoch 23/30, Loss: 16.851374
Val Best Loss: 15.940763
Epoch loss: 16.851374
train phase, Epoch 24/30, Loss: 12.723825
val phase, Epoch 24/30, Loss: 18.378271
Val Best Loss: 15.940763
Epoch loss: 18.378271
train phase, Epoch 25/30, Loss: 12.687785
val phase, Epoch 25/30, Loss: 17.246176
Val Best Loss: 15.940763
Epoch loss: 17.246176
train phase, Epoch 26/30, Loss: 12.199881
val phase, Epoch 26/30, Loss: 21.530978
Val Best Loss: 15.940763
Epoch loss: 21.530978
train phase, Epoch 27/30, Loss: 11.955039
val phase, Epoch 27/30, Loss: 17.236335
Val Best Loss: 15.940763
Epoch loss: 17.236335
train phase, Epoch 28/30, Loss: 11.357866
val phase, Epoch 28/30, Loss: 17.735801
Val Best Loss: 15.940763
Epoch loss: 17.735801
train phase, Epoch 29/30, Loss: 10.748948
val phase, Epoch 29/30, Loss: 17.914272
Val Best Loss: 15.940763
Epoch loss: 17.914272
train phase, Epoch 30/30, Loss: 10.511733
val phase, Epoch 30/30, Loss: 17.731120
Val Best Loss: 15.940763
Epoch loss: 17.731120
train phase, Epoch 1/20, Loss: 19.913493
val phase, Epoch 1/20, Loss: 18.069877
Val Best Loss: 18.069877
Epoch loss: 18.069877
train phase, Epoch 2/20, Loss: 17.890453
val phase, Epoch 2/20, Loss: 18.223611
Val Best Loss: 18.069877
Epoch loss: 18.223611
train phase, Epoch 3/20, Loss: 17.661519
val phase, Epoch 3/20, Loss: 16.978291
Val Best Loss: 16.978291
Epoch loss: 16.978291
train phase, Epoch 4/20, Loss: 17.236510
val phase, Epoch 4/20, Loss: 16.810110
Val Best Loss: 16.810110
Epoch loss: 16.810110
train phase, Epoch 5/20, Loss: 17.381410
val phase, Epoch 5/20, Loss: 16.493018
Val Best Loss: 16.493018
Epoch loss: 16.493018
train phase, Epoch 6/20, Loss: 16.821014
val phase, Epoch 6/20, Loss: 18.396505
Val Best Loss: 16.493018
Epoch loss: 18.396505
train phase, Epoch 7/20, Loss: 16.666407
val phase, Epoch 7/20, Loss: 16.438793
Val Best Loss: 16.438793
Epoch loss: 16.438793
train phase, Epoch 8/20, Loss: 16.628758
val phase, Epoch 8/20, Loss: 16.376946
Val Best Loss: 16.376946
Epoch loss: 16.376946
train phase, Epoch 9/20, Loss: 16.299372
val phase, Epoch 9/20, Loss: 16.925479
Val Best Loss: 16.376946
Epoch loss: 16.925479
train phase, Epoch 10/20, Loss: 16.335302
val phase, Epoch 10/20, Loss: 16.151019
Val Best Loss: 16.151019
Epoch loss: 16.151019
train phase, Epoch 11/20, Loss: 16.202985
val phase, Epoch 11/20, Loss: 17.163383
Val Best Loss: 16.151019
Epoch loss: 17.163383
train phase, Epoch 12/20, Loss: 15.838259
val phase, Epoch 12/20, Loss: 16.034113
Val Best Loss: 16.034113
Epoch loss: 16.034113
train phase, Epoch 13/20, Loss: 15.947997
val phase, Epoch 13/20, Loss: 16.834199
Val Best Loss: 16.034113
Epoch loss: 16.834199
train phase, Epoch 14/20, Loss: 15.870483
val phase, Epoch 14/20, Loss: 17.095698
Val Best Loss: 16.034113
Epoch loss: 17.095698
train phase, Epoch 15/20, Loss: 15.657980
val phase, Epoch 15/20, Loss: 15.989591
Val Best Loss: 15.989591
Epoch loss: 15.989591
train phase, Epoch 16/20, Loss: 15.399891
val phase, Epoch 16/20, Loss: 19.348404
Val Best Loss: 15.989591
Epoch loss: 19.348404
train phase, Epoch 17/20, Loss: 15.618254
val phase, Epoch 17/20, Loss: 16.578259
Val Best Loss: 15.989591
Epoch loss: 16.578259
train phase, Epoch 18/20, Loss: 15.470794
val phase, Epoch 18/20, Loss: 16.027085
Val Best Loss: 15.989591
Epoch loss: 16.027085
train phase, Epoch 19/20, Loss: 15.066246
val phase, Epoch 19/20, Loss: 16.898979
Val Best Loss: 15.989591
Epoch loss: 16.898979
train phase, Epoch 20/20, Loss: 14.889756
val phase, Epoch 20/20, Loss: 15.996102
Val Best Loss: 15.989591
Epoch loss: 15.996102
train phase, Epoch 1/20, Loss: 20.575898
val phase, Epoch 1/20, Loss: 18.126083
Val Best Loss: 18.126083
Epoch loss: 18.126083
train phase, Epoch 2/20, Loss: 17.410304
val phase, Epoch 2/20, Loss: 16.562657
Val Best Loss: 16.562657
Epoch loss: 16.562657
train phase, Epoch 3/20, Loss: 16.964708
val phase, Epoch 3/20, Loss: 16.440771
Val Best Loss: 16.440771
Epoch loss: 16.440771
train phase, Epoch 4/20, Loss: 16.737811
val phase, Epoch 4/20, Loss: 16.478306
Val Best Loss: 16.440771
Epoch loss: 16.478306
train phase, Epoch 5/20, Loss: 16.486377
val phase, Epoch 5/20, Loss: 16.330637
Val Best Loss: 16.330637
Epoch loss: 16.330637
train phase, Epoch 6/20, Loss: 16.354656
val phase, Epoch 6/20, Loss: 16.445860
Val Best Loss: 16.330637
Epoch loss: 16.445860
train phase, Epoch 7/20, Loss: 16.020890
val phase, Epoch 7/20, Loss: 16.717764
Val Best Loss: 16.330637
Epoch loss: 16.717764
train phase, Epoch 8/20, Loss: 16.102762
val phase, Epoch 8/20, Loss: 16.279804
Val Best Loss: 16.279804
Epoch loss: 16.279804
train phase, Epoch 9/20, Loss: 15.818073
val phase, Epoch 9/20, Loss: 17.475307
Val Best Loss: 16.279804
Epoch loss: 17.475307
train phase, Epoch 10/20, Loss: 15.558608
val phase, Epoch 10/20, Loss: 16.108892
Val Best Loss: 16.108892
Epoch loss: 16.108892
train phase, Epoch 11/20, Loss: 15.367467
val phase, Epoch 11/20, Loss: 16.461197
Val Best Loss: 16.108892
Epoch loss: 16.461197
train phase, Epoch 12/20, Loss: 15.267294
val phase, Epoch 12/20, Loss: 16.512869
Val Best Loss: 16.108892
Epoch loss: 16.512869
train phase, Epoch 13/20, Loss: 15.468656
val phase, Epoch 13/20, Loss: 16.212537
Val Best Loss: 16.108892
Epoch loss: 16.212537
train phase, Epoch 14/20, Loss: 14.844835
val phase, Epoch 14/20, Loss: 15.753067
Val Best Loss: 15.753067
Epoch loss: 15.753067
train phase, Epoch 15/20, Loss: 14.699790
val phase, Epoch 15/20, Loss: 16.355219
Val Best Loss: 15.753067
Epoch loss: 16.355219
train phase, Epoch 16/20, Loss: 14.422190
val phase, Epoch 16/20, Loss: 16.288881
Val Best Loss: 15.753067
Epoch loss: 16.288881
train phase, Epoch 17/20, Loss: 14.386207
val phase, Epoch 17/20, Loss: 16.869361
Val Best Loss: 15.753067
Epoch loss: 16.869361
train phase, Epoch 18/20, Loss: 13.979620
val phase, Epoch 18/20, Loss: 16.878769
Val Best Loss: 15.753067
Epoch loss: 16.878769
train phase, Epoch 19/20, Loss: 13.903816
val phase, Epoch 19/20, Loss: 16.401069
Val Best Loss: 15.753067
Epoch loss: 16.401069
train phase, Epoch 20/20, Loss: 13.372952
val phase, Epoch 20/20, Loss: 16.228622
Val Best Loss: 15.753067
Epoch loss: 16.228622
[Trial 341] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
[Trial 342] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 21.163802
val phase, Epoch 1/20, Loss: 18.734295
Val Best Loss: 18.734295
Epoch loss: 18.734295
train phase, Epoch 2/20, Loss: 18.650812
val phase, Epoch 2/20, Loss: 17.673786
Val Best Loss: 17.673786
Epoch loss: 17.673786
train phase, Epoch 3/20, Loss: 18.653273
val phase, Epoch 3/20, Loss: 18.721933
Val Best Loss: 17.673786
Epoch loss: 18.721933
train phase, Epoch 4/20, Loss: 18.299064
val phase, Epoch 4/20, Loss: 23.605366
Val Best Loss: 17.673786
Epoch loss: 23.605366
train phase, Epoch 5/20, Loss: 18.327881
val phase, Epoch 5/20, Loss: 17.096010
Val Best Loss: 17.096010
Epoch loss: 17.096010
train phase, Epoch 6/20, Loss: 17.583212
val phase, Epoch 6/20, Loss: 17.269694
Val Best Loss: 17.096010
Epoch loss: 17.269694
train phase, Epoch 7/20, Loss: 17.335875
val phase, Epoch 7/20, Loss: 17.880167
Val Best Loss: 17.096010
Epoch loss: 17.880167
train phase, Epoch 8/20, Loss: 17.481479
val phase, Epoch 8/20, Loss: 17.303933
Val Best Loss: 17.096010
Epoch loss: 17.303933
train phase, Epoch 9/20, Loss: 17.335863
val phase, Epoch 9/20, Loss: 16.824501
Val Best Loss: 16.824501
Epoch loss: 16.824501
train phase, Epoch 10/20, Loss: 16.921210
val phase, Epoch 10/20, Loss: 17.398255
Val Best Loss: 16.824501
Epoch loss: 17.398255
train phase, Epoch 11/20, Loss: 16.685282
val phase, Epoch 11/20, Loss: 17.879829
Val Best Loss: 16.824501
Epoch loss: 17.879829
train phase, Epoch 12/20, Loss: 16.852405
val phase, Epoch 12/20, Loss: 18.012816
Val Best Loss: 16.824501
Epoch loss: 18.012816
train phase, Epoch 13/20, Loss: 16.359144
val phase, Epoch 13/20, Loss: 16.957021
Val Best Loss: 16.824501
Epoch loss: 16.957021
train phase, Epoch 14/20, Loss: 16.500393
val phase, Epoch 14/20, Loss: 19.697081
Val Best Loss: 16.824501
Epoch loss: 19.697081
train phase, Epoch 15/20, Loss: 16.373100
val phase, Epoch 15/20, Loss: 18.180149
Val Best Loss: 16.824501
Epoch loss: 18.180149
train phase, Epoch 16/20, Loss: 16.212510
val phase, Epoch 16/20, Loss: 17.482850
Val Best Loss: 16.824501
Epoch loss: 17.482850
train phase, Epoch 17/20, Loss: 15.916034
val phase, Epoch 17/20, Loss: 17.096982
Val Best Loss: 16.824501
Epoch loss: 17.096982
train phase, Epoch 18/20, Loss: 15.877072
val phase, Epoch 18/20, Loss: 16.813962
Val Best Loss: 16.813962
Epoch loss: 16.813962
train phase, Epoch 19/20, Loss: 15.718248
val phase, Epoch 19/20, Loss: 16.640011
Val Best Loss: 16.640011
Epoch loss: 16.640011
train phase, Epoch 20/20, Loss: 15.629098
val phase, Epoch 20/20, Loss: 16.682775
Val Best Loss: 16.640011
Epoch loss: 16.682775
train phase, Epoch 1/5, Loss: 19.817944
val phase, Epoch 1/5, Loss: 18.756823
Val Best Loss: 18.756823
Epoch loss: 18.756823
train phase, Epoch 2/5, Loss: 17.898227
val phase, Epoch 2/5, Loss: 16.529266
Val Best Loss: 16.529266
Epoch loss: 16.529266
train phase, Epoch 3/5, Loss: 17.355532
val phase, Epoch 3/5, Loss: 16.983059
Val Best Loss: 16.529266
Epoch loss: 16.983059
train phase, Epoch 4/5, Loss: 17.189047
val phase, Epoch 4/5, Loss: 16.689539
Val Best Loss: 16.529266
Epoch loss: 16.689539
train phase, Epoch 5/5, Loss: 16.798853
val phase, Epoch 5/5, Loss: 22.046282
Val Best Loss: 16.529266
Epoch loss: 22.046282
train phase, Epoch 1/20, Loss: 19.981758
val phase, Epoch 1/20, Loss: 17.406081
Val Best Loss: 17.406081
Epoch loss: 17.406081
train phase, Epoch 2/20, Loss: 17.977351
val phase, Epoch 2/20, Loss: 17.247728
Val Best Loss: 17.247728
Epoch loss: 17.247728
train phase, Epoch 3/20, Loss: 17.458031
val phase, Epoch 3/20, Loss: 16.934041
Val Best Loss: 16.934041
Epoch loss: 16.934041
train phase, Epoch 4/20, Loss: 17.238190
val phase, Epoch 4/20, Loss: 17.090872
Val Best Loss: 16.934041
Epoch loss: 17.090872
train phase, Epoch 5/20, Loss: 17.112686
val phase, Epoch 5/20, Loss: 16.213071
Val Best Loss: 16.213071
Epoch loss: 16.213071
train phase, Epoch 6/20, Loss: 16.731448
val phase, Epoch 6/20, Loss: 17.168434
Val Best Loss: 16.213071
Epoch loss: 17.168434
train phase, Epoch 7/20, Loss: 16.743027
val phase, Epoch 7/20, Loss: 19.384538
Val Best Loss: 16.213071
Epoch loss: 19.384538
train phase, Epoch 8/20, Loss: 16.544621
val phase, Epoch 8/20, Loss: 16.893658
Val Best Loss: 16.213071
Epoch loss: 16.893658
train phase, Epoch 9/20, Loss: 16.398926
val phase, Epoch 9/20, Loss: 16.067544
Val Best Loss: 16.067544
Epoch loss: 16.067544
train phase, Epoch 10/20, Loss: 16.235664
val phase, Epoch 10/20, Loss: 16.601938
Val Best Loss: 16.067544
Epoch loss: 16.601938
train phase, Epoch 11/20, Loss: 16.140076
val phase, Epoch 11/20, Loss: 16.700006
Val Best Loss: 16.067544
Epoch loss: 16.700006
train phase, Epoch 12/20, Loss: 15.885802
val phase, Epoch 12/20, Loss: 17.725128
Val Best Loss: 16.067544
Epoch loss: 17.725128
train phase, Epoch 13/20, Loss: 15.476187
val phase, Epoch 13/20, Loss: 16.883696
Val Best Loss: 16.067544
Epoch loss: 16.883696
train phase, Epoch 14/20, Loss: 15.533584
val phase, Epoch 14/20, Loss: 17.127328
Val Best Loss: 16.067544
Epoch loss: 17.127328
train phase, Epoch 15/20, Loss: 15.395075
val phase, Epoch 15/20, Loss: 15.992981
Val Best Loss: 15.992981
Epoch loss: 15.992981
train phase, Epoch 16/20, Loss: 15.170810
val phase, Epoch 16/20, Loss: 15.921864
Val Best Loss: 15.921864
Epoch loss: 15.921864
train phase, Epoch 17/20, Loss: 14.979745
val phase, Epoch 17/20, Loss: 17.799701
Val Best Loss: 15.921864
Epoch loss: 17.799701
train phase, Epoch 18/20, Loss: 14.937426
val phase, Epoch 18/20, Loss: 16.824375
Val Best Loss: 15.921864
Epoch loss: 16.824375
train phase, Epoch 19/20, Loss: 14.522715
val phase, Epoch 19/20, Loss: 17.276193
Val Best Loss: 15.921864
Epoch loss: 17.276193
train phase, Epoch 20/20, Loss: 14.235743
val phase, Epoch 20/20, Loss: 16.793960
Val Best Loss: 15.921864
Epoch loss: 16.793960
train phase, Epoch 1/20, Loss: 20.005564
val phase, Epoch 1/20, Loss: 28.871897
Val Best Loss: 28.871897
Epoch loss: 28.871897
train phase, Epoch 2/20, Loss: 17.992832
val phase, Epoch 2/20, Loss: 28.573206
Val Best Loss: 28.573206
Epoch loss: 28.573206
train phase, Epoch 3/20, Loss: 17.186256
val phase, Epoch 3/20, Loss: 26.835888
Val Best Loss: 26.835888
Epoch loss: 26.835888
train phase, Epoch 4/20, Loss: 16.853807
val phase, Epoch 4/20, Loss: 30.949860
Val Best Loss: 26.835888
Epoch loss: 30.949860
train phase, Epoch 5/20, Loss: 16.925285
val phase, Epoch 5/20, Loss: 30.384130
Val Best Loss: 26.835888
Epoch loss: 30.384130
train phase, Epoch 6/20, Loss: 16.545113
val phase, Epoch 6/20, Loss: 29.077910
Val Best Loss: 26.835888
Epoch loss: 29.077910
train phase, Epoch 7/20, Loss: 16.510108
val phase, Epoch 7/20, Loss: 31.751862
Val Best Loss: 26.835888
Epoch loss: 31.751862
train phase, Epoch 8/20, Loss: 16.281037
val phase, Epoch 8/20, Loss: 29.664323
Val Best Loss: 26.835888
Epoch loss: 29.664323
train phase, Epoch 9/20, Loss: 15.981925
val phase, Epoch 9/20, Loss: 32.027747
Val Best Loss: 26.835888
Epoch loss: 32.027747
train phase, Epoch 10/20, Loss: 15.735760
val phase, Epoch 10/20, Loss: 30.838892
Val Best Loss: 26.835888
Epoch loss: 30.838892
train phase, Epoch 11/20, Loss: 15.762365
val phase, Epoch 11/20, Loss: 33.446591
Val Best Loss: 26.835888
Epoch loss: 33.446591
train phase, Epoch 12/20, Loss: 15.378484
val phase, Epoch 12/20, Loss: 29.183430
Val Best Loss: 26.835888
Epoch loss: 29.183430
train phase, Epoch 13/20, Loss: 15.251150
val phase, Epoch 13/20, Loss: 33.125414
Val Best Loss: 26.835888
Epoch loss: 33.125414
train phase, Epoch 14/20, Loss: 15.049289
val phase, Epoch 14/20, Loss: 32.474323
Val Best Loss: 26.835888
Epoch loss: 32.474323
train phase, Epoch 15/20, Loss: 14.849501
val phase, Epoch 15/20, Loss: 40.536616
Val Best Loss: 26.835888
Epoch loss: 40.536616
train phase, Epoch 16/20, Loss: 14.689550
val phase, Epoch 16/20, Loss: 30.676170
Val Best Loss: 26.835888
Epoch loss: 30.676170
train phase, Epoch 17/20, Loss: 14.318751
val phase, Epoch 17/20, Loss: 36.557606
Val Best Loss: 26.835888
Epoch loss: 36.557606
train phase, Epoch 18/20, Loss: 13.942639
val phase, Epoch 18/20, Loss: 40.924906
Val Best Loss: 26.835888
Epoch loss: 40.924906
train phase, Epoch 19/20, Loss: 13.841528
val phase, Epoch 19/20, Loss: 36.363658
Val Best Loss: 26.835888
Epoch loss: 36.363658
train phase, Epoch 20/20, Loss: 13.549724
val phase, Epoch 20/20, Loss: 38.457217
Val Best Loss: 26.835888
Epoch loss: 38.457217
train phase, Epoch 1/30, Loss: 22.594416
val phase, Epoch 1/30, Loss: 19.592753
Val Best Loss: 19.592753
Epoch loss: 19.592753
train phase, Epoch 2/30, Loss: 17.423305
val phase, Epoch 2/30, Loss: 17.571980
Val Best Loss: 17.571980
Epoch loss: 17.571980
train phase, Epoch 3/30, Loss: 16.915042
val phase, Epoch 3/30, Loss: 16.629147
Val Best Loss: 16.629147
Epoch loss: 16.629147
train phase, Epoch 4/30, Loss: 16.609127
val phase, Epoch 4/30, Loss: 16.444509
Val Best Loss: 16.444509
Epoch loss: 16.444509
train phase, Epoch 5/30, Loss: 16.331757
val phase, Epoch 5/30, Loss: 16.833570
Val Best Loss: 16.444509
Epoch loss: 16.833570
train phase, Epoch 6/30, Loss: 16.082813
val phase, Epoch 6/30, Loss: 16.730061
Val Best Loss: 16.444509
Epoch loss: 16.730061
train phase, Epoch 7/30, Loss: 15.701963
val phase, Epoch 7/30, Loss: 16.568230
Val Best Loss: 16.444509
Epoch loss: 16.568230
train phase, Epoch 8/30, Loss: 15.482909
val phase, Epoch 8/30, Loss: 17.992071
Val Best Loss: 16.444509
Epoch loss: 17.992071
train phase, Epoch 9/30, Loss: 15.173192
val phase, Epoch 9/30, Loss: 16.588664
Val Best Loss: 16.444509
Epoch loss: 16.588664
train phase, Epoch 10/30, Loss: 14.825681
val phase, Epoch 10/30, Loss: 17.272940
Val Best Loss: 16.444509
Epoch loss: 17.272940
train phase, Epoch 11/30, Loss: 14.594727
val phase, Epoch 11/30, Loss: 17.733118
Val Best Loss: 16.444509
Epoch loss: 17.733118
train phase, Epoch 12/30, Loss: 14.300435
val phase, Epoch 12/30, Loss: 17.279317
Val Best Loss: 16.444509
Epoch loss: 17.279317
train phase, Epoch 13/30, Loss: 13.836950
val phase, Epoch 13/30, Loss: 17.229360
Val Best Loss: 16.444509
Epoch loss: 17.229360
train phase, Epoch 14/30, Loss: 13.426061
val phase, Epoch 14/30, Loss: 17.563770
Val Best Loss: 16.444509
Epoch loss: 17.563770
train phase, Epoch 15/30, Loss: 13.003310
val phase, Epoch 15/30, Loss: 16.813699
Val Best Loss: 16.444509
Epoch loss: 16.813699
train phase, Epoch 16/30, Loss: 12.536948
val phase, Epoch 16/30, Loss: 18.030446
Val Best Loss: 16.444509
Epoch loss: 18.030446
train phase, Epoch 17/30, Loss: 12.435904
val phase, Epoch 17/30, Loss: 17.375428
Val Best Loss: 16.444509
Epoch loss: 17.375428
train phase, Epoch 18/30, Loss: 11.662313
val phase, Epoch 18/30, Loss: 18.357796
Val Best Loss: 16.444509
Epoch loss: 18.357796
train phase, Epoch 19/30, Loss: 11.117434
val phase, Epoch 19/30, Loss: 18.490881
Val Best Loss: 16.444509
Epoch loss: 18.490881
train phase, Epoch 20/30, Loss: 10.751327
val phase, Epoch 20/30, Loss: 18.206909
Val Best Loss: 16.444509
Epoch loss: 18.206909
train phase, Epoch 21/30, Loss: 10.303522
val phase, Epoch 21/30, Loss: 18.295384
Val Best Loss: 16.444509
Epoch loss: 18.295384
train phase, Epoch 22/30, Loss: 9.581165
val phase, Epoch 22/30, Loss: 19.931022
Val Best Loss: 16.444509
Epoch loss: 19.931022
train phase, Epoch 23/30, Loss: 9.424375
val phase, Epoch 23/30, Loss: 20.732391
Val Best Loss: 16.444509
Epoch loss: 20.732391
train phase, Epoch 24/30, Loss: 8.884553
val phase, Epoch 24/30, Loss: 20.060289
Val Best Loss: 16.444509
Epoch loss: 20.060289
train phase, Epoch 25/30, Loss: 7.980532
val phase, Epoch 25/30, Loss: 19.935110
Val Best Loss: 16.444509
Epoch loss: 19.935110
train phase, Epoch 26/30, Loss: 7.464554
val phase, Epoch 26/30, Loss: 20.209845
Val Best Loss: 16.444509
Epoch loss: 20.209845
train phase, Epoch 27/30, Loss: 7.095614
val phase, Epoch 27/30, Loss: 21.583510
Val Best Loss: 16.444509
Epoch loss: 21.583510
train phase, Epoch 28/30, Loss: 6.779460
val phase, Epoch 28/30, Loss: 20.727452
Val Best Loss: 16.444509
Epoch loss: 20.727452
train phase, Epoch 29/30, Loss: 6.819996
val phase, Epoch 29/30, Loss: 19.934463
Val Best Loss: 16.444509
Epoch loss: 19.934463
train phase, Epoch 30/30, Loss: 6.222822
val phase, Epoch 30/30, Loss: 19.649113
Val Best Loss: 16.444509
Epoch loss: 19.649113
train phase, Epoch 1/20, Loss: 19.874715
val phase, Epoch 1/20, Loss: 16.994034
Val Best Loss: 16.994034
Epoch loss: 16.994034
train phase, Epoch 2/20, Loss: 18.205576
val phase, Epoch 2/20, Loss: 16.772422
Val Best Loss: 16.772422
Epoch loss: 16.772422
train phase, Epoch 3/20, Loss: 17.683521
val phase, Epoch 3/20, Loss: 17.089672
Val Best Loss: 16.772422
Epoch loss: 17.089672
train phase, Epoch 4/20, Loss: 17.549824
val phase, Epoch 4/20, Loss: 17.916774
Val Best Loss: 16.772422
Epoch loss: 17.916774
train phase, Epoch 5/20, Loss: 17.335821
val phase, Epoch 5/20, Loss: 16.217555
Val Best Loss: 16.217555
Epoch loss: 16.217555
train phase, Epoch 6/20, Loss: 16.828343
val phase, Epoch 6/20, Loss: 16.646539
Val Best Loss: 16.217555
Epoch loss: 16.646539
train phase, Epoch 7/20, Loss: 16.912158
val phase, Epoch 7/20, Loss: 16.463216
Val Best Loss: 16.217555
Epoch loss: 16.463216
train phase, Epoch 8/20, Loss: 16.724075
val phase, Epoch 8/20, Loss: 18.193085
Val Best Loss: 16.217555
Epoch loss: 18.193085
train phase, Epoch 9/20, Loss: 16.468304
val phase, Epoch 9/20, Loss: 18.098762
Val Best Loss: 16.217555
Epoch loss: 18.098762
train phase, Epoch 10/20, Loss: 16.333546
val phase, Epoch 10/20, Loss: 16.330839
Val Best Loss: 16.217555
Epoch loss: 16.330839
train phase, Epoch 11/20, Loss: 15.976166
val phase, Epoch 11/20, Loss: 16.584970
Val Best Loss: 16.217555
Epoch loss: 16.584970
train phase, Epoch 12/20, Loss: 15.755013
val phase, Epoch 12/20, Loss: 16.198545
Val Best Loss: 16.198545
Epoch loss: 16.198545
train phase, Epoch 13/20, Loss: 15.691411
val phase, Epoch 13/20, Loss: 16.572437
Val Best Loss: 16.198545
Epoch loss: 16.572437
train phase, Epoch 14/20, Loss: 15.486553
val phase, Epoch 14/20, Loss: 16.525556
Val Best Loss: 16.198545
Epoch loss: 16.525556
train phase, Epoch 15/20, Loss: 15.336628
val phase, Epoch 15/20, Loss: 17.354994
Val Best Loss: 16.198545
Epoch loss: 17.354994
train phase, Epoch 16/20, Loss: 15.180740
val phase, Epoch 16/20, Loss: 16.168503
Val Best Loss: 16.168503
Epoch loss: 16.168503
train phase, Epoch 17/20, Loss: 14.889356
val phase, Epoch 17/20, Loss: 16.165222
Val Best Loss: 16.165222
Epoch loss: 16.165222
train phase, Epoch 18/20, Loss: 14.528728
val phase, Epoch 18/20, Loss: 16.245397
Val Best Loss: 16.165222
Epoch loss: 16.245397
train phase, Epoch 19/20, Loss: 14.510959
val phase, Epoch 19/20, Loss: 17.392049
Val Best Loss: 16.165222
Epoch loss: 17.392049
train phase, Epoch 20/20, Loss: 14.127184
val phase, Epoch 20/20, Loss: 16.571862
Val Best Loss: 16.165222
Epoch loss: 16.571862
train phase, Epoch 1/10, Loss: nan
val phase, Epoch 1/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/10, Loss: nan
val phase, Epoch 2/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/10, Loss: nan
val phase, Epoch 3/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/10, Loss: nan
val phase, Epoch 4/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/10, Loss: nan
val phase, Epoch 5/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/10, Loss: nan
val phase, Epoch 6/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/10, Loss: nan
val phase, Epoch 7/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/10, Loss: nan
val phase, Epoch 8/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/10, Loss: nan
val phase, Epoch 9/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/10, Loss: nan
val phase, Epoch 10/10, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 1/20, Loss: 20.248476
val phase, Epoch 1/20, Loss: 17.614556
Val Best Loss: 17.614556
Epoch loss: 17.614556
train phase, Epoch 2/20, Loss: 18.060665
val phase, Epoch 2/20, Loss: 17.207042
Val Best Loss: 17.207042
Epoch loss: 17.207042
train phase, Epoch 3/20, Loss: 17.459731
val phase, Epoch 3/20, Loss: 16.631234
Val Best Loss: 16.631234
Epoch loss: 16.631234
train phase, Epoch 4/20, Loss: 17.353137
val phase, Epoch 4/20, Loss: 16.296517
Val Best Loss: 16.296517
Epoch loss: 16.296517
train phase, Epoch 5/20, Loss: 16.973060
val phase, Epoch 5/20, Loss: 16.528186
Val Best Loss: 16.296517
Epoch loss: 16.528186
train phase, Epoch 6/20, Loss: 16.736584
val phase, Epoch 6/20, Loss: 16.257205
Val Best Loss: 16.257205
Epoch loss: 16.257205
train phase, Epoch 7/20, Loss: 16.828439
val phase, Epoch 7/20, Loss: 16.186871
Val Best Loss: 16.186871
Epoch loss: 16.186871
train phase, Epoch 8/20, Loss: 16.497815
val phase, Epoch 8/20, Loss: 15.882424
Val Best Loss: 15.882424
Epoch loss: 15.882424
train phase, Epoch 9/20, Loss: 16.154621
val phase, Epoch 9/20, Loss: 18.524020
Val Best Loss: 15.882424
Epoch loss: 18.524020
train phase, Epoch 10/20, Loss: 16.125361
val phase, Epoch 10/20, Loss: 18.700136
Val Best Loss: 15.882424
Epoch loss: 18.700136
train phase, Epoch 11/20, Loss: 16.275953
val phase, Epoch 11/20, Loss: 16.060454
Val Best Loss: 15.882424
Epoch loss: 16.060454
train phase, Epoch 12/20, Loss: 15.755618
val phase, Epoch 12/20, Loss: 16.425460
Val Best Loss: 15.882424
Epoch loss: 16.425460
train phase, Epoch 13/20, Loss: 15.548231
val phase, Epoch 13/20, Loss: 16.903249
Val Best Loss: 15.882424
Epoch loss: 16.903249
train phase, Epoch 14/20, Loss: 15.499859
val phase, Epoch 14/20, Loss: 16.731920
Val Best Loss: 15.882424
Epoch loss: 16.731920
train phase, Epoch 15/20, Loss: 15.211184
val phase, Epoch 15/20, Loss: 17.905290
Val Best Loss: 15.882424
Epoch loss: 17.905290
train phase, Epoch 16/20, Loss: 15.270043
val phase, Epoch 16/20, Loss: 15.993878
Val Best Loss: 15.882424
Epoch loss: 15.993878
train phase, Epoch 17/20, Loss: 15.116802
val phase, Epoch 17/20, Loss: 16.572793
Val Best Loss: 15.882424
Epoch loss: 16.572793
train phase, Epoch 18/20, Loss: 14.694165
val phase, Epoch 18/20, Loss: 16.487616
Val Best Loss: 15.882424
Epoch loss: 16.487616
train phase, Epoch 19/20, Loss: 14.514082
val phase, Epoch 19/20, Loss: 16.338198
Val Best Loss: 15.882424
Epoch loss: 16.338198
train phase, Epoch 20/20, Loss: 14.411664
val phase, Epoch 20/20, Loss: 17.906482
Val Best Loss: 15.882424
Epoch loss: 17.906482
train phase, Epoch 1/30, Loss: 19.712962
val phase, Epoch 1/30, Loss: 17.379875
Val Best Loss: 17.379875
Epoch loss: 17.379875
train phase, Epoch 2/30, Loss: 17.839691
val phase, Epoch 2/30, Loss: 16.697642
Val Best Loss: 16.697642
Epoch loss: 16.697642
train phase, Epoch 3/30, Loss: 17.652524
val phase, Epoch 3/30, Loss: 16.808894
Val Best Loss: 16.697642
Epoch loss: 16.808894
train phase, Epoch 4/30, Loss: 17.223447
val phase, Epoch 4/30, Loss: 16.376150
Val Best Loss: 16.376150
Epoch loss: 16.376150
train phase, Epoch 5/30, Loss: 17.014206
val phase, Epoch 5/30, Loss: 16.378833
Val Best Loss: 16.376150
Epoch loss: 16.378833
train phase, Epoch 6/30, Loss: 16.709958
val phase, Epoch 6/30, Loss: 16.172895
Val Best Loss: 16.172895
Epoch loss: 16.172895
train phase, Epoch 7/30, Loss: 16.751938
val phase, Epoch 7/30, Loss: 18.259627
Val Best Loss: 16.172895
Epoch loss: 18.259627
train phase, Epoch 8/30, Loss: 16.332723
val phase, Epoch 8/30, Loss: 16.317228
Val Best Loss: 16.172895
Epoch loss: 16.317228
train phase, Epoch 9/30, Loss: 16.177804
val phase, Epoch 9/30, Loss: 16.794568
Val Best Loss: 16.172895
Epoch loss: 16.794568
train phase, Epoch 10/30, Loss: 16.164843
val phase, Epoch 10/30, Loss: 15.820484
Val Best Loss: 15.820484
Epoch loss: 15.820484
train phase, Epoch 11/30, Loss: 15.805135
val phase, Epoch 11/30, Loss: 16.681424
Val Best Loss: 15.820484
Epoch loss: 16.681424
train phase, Epoch 12/30, Loss: 15.789893
val phase, Epoch 12/30, Loss: 17.179956
Val Best Loss: 15.820484
Epoch loss: 17.179956
train phase, Epoch 13/30, Loss: 15.618085
val phase, Epoch 13/30, Loss: 16.274640
Val Best Loss: 15.820484
Epoch loss: 16.274640
train phase, Epoch 14/30, Loss: 15.376955
val phase, Epoch 14/30, Loss: 16.331368
Val Best Loss: 15.820484
Epoch loss: 16.331368
train phase, Epoch 15/30, Loss: 15.242781
val phase, Epoch 15/30, Loss: 16.210410
Val Best Loss: 15.820484
Epoch loss: 16.210410
train phase, Epoch 16/30, Loss: 15.097677
val phase, Epoch 16/30, Loss: 16.102495
Val Best Loss: 15.820484
Epoch loss: 16.102495
train phase, Epoch 17/30, Loss: 14.903709
val phase, Epoch 17/30, Loss: 16.442312
Val Best Loss: 15.820484
Epoch loss: 16.442312
train phase, Epoch 18/30, Loss: 14.878893
val phase, Epoch 18/30, Loss: 17.669922
Val Best Loss: 15.820484
Epoch loss: 17.669922
train phase, Epoch 19/30, Loss: 14.576962
val phase, Epoch 19/30, Loss: 15.972510
Val Best Loss: 15.820484
Epoch loss: 15.972510
train phase, Epoch 20/30, Loss: 14.219849
val phase, Epoch 20/30, Loss: 16.469190
Val Best Loss: 15.820484
Epoch loss: 16.469190
train phase, Epoch 21/30, Loss: 13.829961
val phase, Epoch 21/30, Loss: 17.702107
Val Best Loss: 15.820484
Epoch loss: 17.702107
train phase, Epoch 22/30, Loss: 13.664503
val phase, Epoch 22/30, Loss: 16.642260
Val Best Loss: 15.820484
Epoch loss: 16.642260
train phase, Epoch 23/30, Loss: 13.164509
val phase, Epoch 23/30, Loss: 16.437554
Val Best Loss: 15.820484
Epoch loss: 16.437554
train phase, Epoch 24/30, Loss: 12.903087
val phase, Epoch 24/30, Loss: 16.276388
Val Best Loss: 15.820484
Epoch loss: 16.276388
train phase, Epoch 25/30, Loss: 12.500889
val phase, Epoch 25/30, Loss: 16.638753
Val Best Loss: 15.820484
Epoch loss: 16.638753
train phase, Epoch 26/30, Loss: 12.437592
val phase, Epoch 26/30, Loss: 17.061163
Val Best Loss: 15.820484
Epoch loss: 17.061163
train phase, Epoch 27/30, Loss: 11.553334
val phase, Epoch 27/30, Loss: 18.526363
Val Best Loss: 15.820484
Epoch loss: 18.526363
train phase, Epoch 28/30, Loss: 11.119616
val phase, Epoch 28/30, Loss: 18.207175
Val Best Loss: 15.820484
Epoch loss: 18.207175
train phase, Epoch 29/30, Loss: 10.930408
val phase, Epoch 29/30, Loss: 18.148190
Val Best Loss: 15.820484
Epoch loss: 18.148190
train phase, Epoch 30/30, Loss: 10.254073
val phase, Epoch 30/30, Loss: 19.370425
Val Best Loss: 15.820484
Epoch loss: 19.370425
train phase, Epoch 1/20, Loss: 20.013590
val phase, Epoch 1/20, Loss: 17.047122
Val Best Loss: 17.047122
Epoch loss: 17.047122
train phase, Epoch 2/20, Loss: 18.057358
val phase, Epoch 2/20, Loss: 19.330582
Val Best Loss: 17.047122
Epoch loss: 19.330582
train phase, Epoch 3/20, Loss: 17.953394
val phase, Epoch 3/20, Loss: 19.180613
Val Best Loss: 17.047122
Epoch loss: 19.180613
train phase, Epoch 4/20, Loss: 17.132366
val phase, Epoch 4/20, Loss: 16.844490
Val Best Loss: 16.844490
Epoch loss: 16.844490
train phase, Epoch 5/20, Loss: 17.271952
val phase, Epoch 5/20, Loss: 19.683376
Val Best Loss: 16.844490
Epoch loss: 19.683376
train phase, Epoch 6/20, Loss: 17.102212
val phase, Epoch 6/20, Loss: 16.146451
Val Best Loss: 16.146451
Epoch loss: 16.146451
train phase, Epoch 7/20, Loss: 16.507639
val phase, Epoch 7/20, Loss: 19.689952
Val Best Loss: 16.146451
Epoch loss: 19.689952
train phase, Epoch 8/20, Loss: 16.557277
val phase, Epoch 8/20, Loss: 16.007567
Val Best Loss: 16.007567
Epoch loss: 16.007567
train phase, Epoch 9/20, Loss: 16.270591
val phase, Epoch 9/20, Loss: 17.515182
Val Best Loss: 16.007567
Epoch loss: 17.515182
train phase, Epoch 10/20, Loss: 16.322876
val phase, Epoch 10/20, Loss: 16.173179
Val Best Loss: 16.007567
Epoch loss: 16.173179
train phase, Epoch 11/20, Loss: 15.943843
val phase, Epoch 11/20, Loss: 17.351187
Val Best Loss: 16.007567
Epoch loss: 17.351187
train phase, Epoch 12/20, Loss: 15.934799
val phase, Epoch 12/20, Loss: 16.207910
Val Best Loss: 16.007567
Epoch loss: 16.207910
train phase, Epoch 13/20, Loss: 15.613721
val phase, Epoch 13/20, Loss: 17.498408
Val Best Loss: 16.007567
Epoch loss: 17.498408
train phase, Epoch 14/20, Loss: 15.553858
val phase, Epoch 14/20, Loss: 16.748828
Val Best Loss: 16.007567
Epoch loss: 16.748828
train phase, Epoch 15/20, Loss: 15.462008
val phase, Epoch 15/20, Loss: 18.712089
Val Best Loss: 16.007567
Epoch loss: 18.712089
train phase, Epoch 16/20, Loss: 15.134267
val phase, Epoch 16/20, Loss: 16.575262
Val Best Loss: 16.007567
Epoch loss: 16.575262
train phase, Epoch 17/20, Loss: 15.197395
val phase, Epoch 17/20, Loss: 16.019432
Val Best Loss: 16.007567
Epoch loss: 16.019432
train phase, Epoch 18/20, Loss: 14.818036
val phase, Epoch 18/20, Loss: 16.504626
Val Best Loss: 16.007567
Epoch loss: 16.504626
train phase, Epoch 19/20, Loss: 14.735103
val phase, Epoch 19/20, Loss: 16.073647
Val Best Loss: 16.007567
Epoch loss: 16.073647
train phase, Epoch 20/20, Loss: 14.370121
val phase, Epoch 20/20, Loss: 16.729216
Val Best Loss: 16.007567
Epoch loss: 16.729216
train phase, Epoch 1/20, Loss: 20.058453
val phase, Epoch 1/20, Loss: 17.380080
Val Best Loss: 17.380080
Epoch loss: 17.380080
train phase, Epoch 2/20, Loss: 18.296450
val phase, Epoch 2/20, Loss: 19.951936
Val Best Loss: 17.380080
Epoch loss: 19.951936
train phase, Epoch 3/20, Loss: 17.519153
val phase, Epoch 3/20, Loss: 16.226415
Val Best Loss: 16.226415
Epoch loss: 16.226415
train phase, Epoch 4/20, Loss: 17.089554
val phase, Epoch 4/20, Loss: 16.750259
Val Best Loss: 16.226415
Epoch loss: 16.750259
train phase, Epoch 5/20, Loss: 17.172703
val phase, Epoch 5/20, Loss: 16.631675
Val Best Loss: 16.226415
Epoch loss: 16.631675
train phase, Epoch 6/20, Loss: 16.739510
val phase, Epoch 6/20, Loss: 16.180188
Val Best Loss: 16.180188
Epoch loss: 16.180188
train phase, Epoch 7/20, Loss: 16.399072
val phase, Epoch 7/20, Loss: 16.163325
Val Best Loss: 16.163325
Epoch loss: 16.163325
train phase, Epoch 8/20, Loss: 16.277549
val phase, Epoch 8/20, Loss: 19.668181
Val Best Loss: 16.163325
Epoch loss: 19.668181
train phase, Epoch 9/20, Loss: 16.291185
val phase, Epoch 9/20, Loss: 16.192353
Val Best Loss: 16.163325
Epoch loss: 16.192353
train phase, Epoch 10/20, Loss: 15.978177
val phase, Epoch 10/20, Loss: 18.212087
Val Best Loss: 16.163325
Epoch loss: 18.212087
train phase, Epoch 11/20, Loss: 16.030117
val phase, Epoch 11/20, Loss: 15.788440
Val Best Loss: 15.788440
Epoch loss: 15.788440
train phase, Epoch 12/20, Loss: 15.824633
val phase, Epoch 12/20, Loss: 15.718509
Val Best Loss: 15.718509
Epoch loss: 15.718509
train phase, Epoch 13/20, Loss: 15.559775
val phase, Epoch 13/20, Loss: 16.253871
Val Best Loss: 15.718509
Epoch loss: 16.253871
train phase, Epoch 14/20, Loss: 15.298059
val phase, Epoch 14/20, Loss: 16.183756
Val Best Loss: 15.718509
Epoch loss: 16.183756
train phase, Epoch 15/20, Loss: 15.340997
val phase, Epoch 15/20, Loss: 15.562366
Val Best Loss: 15.562366
Epoch loss: 15.562366
train phase, Epoch 16/20, Loss: 15.061530
val phase, Epoch 16/20, Loss: 15.838475
Val Best Loss: 15.562366
Epoch loss: 15.838475
train phase, Epoch 17/20, Loss: 14.932262
val phase, Epoch 17/20, Loss: 16.192950
Val Best Loss: 15.562366
Epoch loss: 16.192950
train phase, Epoch 18/20, Loss: 14.587035
val phase, Epoch 18/20, Loss: 17.604167
Val Best Loss: 15.562366
Epoch loss: 17.604167
train phase, Epoch 19/20, Loss: 14.341994
val phase, Epoch 19/20, Loss: 16.697165
Val Best Loss: 15.562366
Epoch loss: 16.697165
train phase, Epoch 20/20, Loss: 14.366276
val phase, Epoch 20/20, Loss: 16.430967
Val Best Loss: 15.562366
Epoch loss: 16.430967
train phase, Epoch 1/20, Loss: 20.107222
val phase, Epoch 1/20, Loss: 17.471760
Val Best Loss: 17.471760
Epoch loss: 17.471760
train phase, Epoch 2/20, Loss: 17.887537
val phase, Epoch 2/20, Loss: 16.813649
Val Best Loss: 16.813649
Epoch loss: 16.813649
train phase, Epoch 3/20, Loss: 17.463617
val phase, Epoch 3/20, Loss: 16.433199
Val Best Loss: 16.433199
Epoch loss: 16.433199
train phase, Epoch 4/20, Loss: 17.068473
val phase, Epoch 4/20, Loss: 16.312626
Val Best Loss: 16.312626
Epoch loss: 16.312626
train phase, Epoch 5/20, Loss: 16.859613
val phase, Epoch 5/20, Loss: 16.334183
Val Best Loss: 16.312626
Epoch loss: 16.334183
train phase, Epoch 6/20, Loss: 16.721374
val phase, Epoch 6/20, Loss: 16.430132
Val Best Loss: 16.312626
Epoch loss: 16.430132
train phase, Epoch 7/20, Loss: 16.473092
val phase, Epoch 7/20, Loss: 16.055974
Val Best Loss: 16.055974
Epoch loss: 16.055974
train phase, Epoch 8/20, Loss: 16.436139
val phase, Epoch 8/20, Loss: 16.466991
Val Best Loss: 16.055974
Epoch loss: 16.466991
train phase, Epoch 9/20, Loss: 16.369572
val phase, Epoch 9/20, Loss: 18.044316
Val Best Loss: 16.055974
Epoch loss: 18.044316
train phase, Epoch 10/20, Loss: 16.175160
val phase, Epoch 10/20, Loss: 17.287802
Val Best Loss: 16.055974
Epoch loss: 17.287802
train phase, Epoch 11/20, Loss: 15.837426
val phase, Epoch 11/20, Loss: 16.224137
Val Best Loss: 16.055974
Epoch loss: 16.224137
train phase, Epoch 12/20, Loss: 15.595127
val phase, Epoch 12/20, Loss: 16.483220
Val Best Loss: 16.055974
Epoch loss: 16.483220
train phase, Epoch 13/20, Loss: 15.507972
val phase, Epoch 13/20, Loss: 15.911879
Val Best Loss: 15.911879
Epoch loss: 15.911879
train phase, Epoch 14/20, Loss: 15.565995
val phase, Epoch 14/20, Loss: 17.777043
Val Best Loss: 15.911879
Epoch loss: 17.777043
train phase, Epoch 15/20, Loss: 15.262625
val phase, Epoch 15/20, Loss: 16.986847
Val Best Loss: 15.911879
Epoch loss: 16.986847
train phase, Epoch 16/20, Loss: 14.895898
val phase, Epoch 16/20, Loss: 16.944324
Val Best Loss: 15.911879
Epoch loss: 16.944324
train phase, Epoch 17/20, Loss: 14.635322
val phase, Epoch 17/20, Loss: 16.352818
Val Best Loss: 15.911879
Epoch loss: 16.352818
train phase, Epoch 18/20, Loss: 14.496176
val phase, Epoch 18/20, Loss: 18.477539
Val Best Loss: 15.911879
Epoch loss: 18.477539
train phase, Epoch 19/20, Loss: 13.983940
val phase, Epoch 19/20, Loss: 17.403673
Val Best Loss: 15.911879
Epoch loss: 17.403673
train phase, Epoch 20/20, Loss: 13.676787
val phase, Epoch 20/20, Loss: 17.058877
Val Best Loss: 15.911879
Epoch loss: 17.058877
[Trial 355] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.827916
val phase, Epoch 1/20, Loss: 21.598002
Val Best Loss: 21.598002
Epoch loss: 21.598002
train phase, Epoch 2/20, Loss: 17.736564
val phase, Epoch 2/20, Loss: 17.225866
Val Best Loss: 17.225866
Epoch loss: 17.225866
train phase, Epoch 3/20, Loss: 17.356994
val phase, Epoch 3/20, Loss: 19.159697
Val Best Loss: 17.225866
Epoch loss: 19.159697
train phase, Epoch 4/20, Loss: 17.266758
val phase, Epoch 4/20, Loss: 16.846351
Val Best Loss: 16.846351
Epoch loss: 16.846351
train phase, Epoch 5/20, Loss: 16.873598
val phase, Epoch 5/20, Loss: 16.787767
Val Best Loss: 16.787767
Epoch loss: 16.787767
train phase, Epoch 6/20, Loss: 16.819498
val phase, Epoch 6/20, Loss: 16.506729
Val Best Loss: 16.506729
Epoch loss: 16.506729
train phase, Epoch 7/20, Loss: 16.488451
val phase, Epoch 7/20, Loss: 16.270361
Val Best Loss: 16.270361
Epoch loss: 16.270361
train phase, Epoch 8/20, Loss: 16.401672
val phase, Epoch 8/20, Loss: 16.136656
Val Best Loss: 16.136656
Epoch loss: 16.136656
train phase, Epoch 9/20, Loss: 16.206072
val phase, Epoch 9/20, Loss: 16.702824
Val Best Loss: 16.136656
Epoch loss: 16.702824
train phase, Epoch 10/20, Loss: 15.931107
val phase, Epoch 10/20, Loss: 16.781866
Val Best Loss: 16.136656
Epoch loss: 16.781866
train phase, Epoch 11/20, Loss: 15.866229
val phase, Epoch 11/20, Loss: 15.704924
Val Best Loss: 15.704924
Epoch loss: 15.704924
train phase, Epoch 12/20, Loss: 15.750976
val phase, Epoch 12/20, Loss: 15.798356
Val Best Loss: 15.704924
Epoch loss: 15.798356
train phase, Epoch 13/20, Loss: 15.397466
val phase, Epoch 13/20, Loss: 16.141408
Val Best Loss: 15.704924
Epoch loss: 16.141408
train phase, Epoch 14/20, Loss: 15.349793
val phase, Epoch 14/20, Loss: 16.134364
Val Best Loss: 15.704924
Epoch loss: 16.134364
train phase, Epoch 15/20, Loss: 15.278332
val phase, Epoch 15/20, Loss: 18.361801
Val Best Loss: 15.704924
Epoch loss: 18.361801
train phase, Epoch 16/20, Loss: 15.114680
val phase, Epoch 16/20, Loss: 15.967982
Val Best Loss: 15.704924
Epoch loss: 15.967982
train phase, Epoch 17/20, Loss: 14.783311
val phase, Epoch 17/20, Loss: 18.095097
Val Best Loss: 15.704924
Epoch loss: 18.095097
train phase, Epoch 18/20, Loss: 14.590423
val phase, Epoch 18/20, Loss: 16.474311
Val Best Loss: 15.704924
Epoch loss: 16.474311
train phase, Epoch 19/20, Loss: 14.354104
val phase, Epoch 19/20, Loss: 15.914993
Val Best Loss: 15.704924
Epoch loss: 15.914993
train phase, Epoch 20/20, Loss: 14.029921
val phase, Epoch 20/20, Loss: 16.623050
Val Best Loss: 15.704924
Epoch loss: 16.623050
[Trial 357] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/30, Loss: 20.516196
val phase, Epoch 1/30, Loss: 18.049933
Val Best Loss: 18.049933
Epoch loss: 18.049933
train phase, Epoch 2/30, Loss: 18.261224
val phase, Epoch 2/30, Loss: 17.725934
Val Best Loss: 17.725934
Epoch loss: 17.725934
train phase, Epoch 3/30, Loss: 18.116604
val phase, Epoch 3/30, Loss: 16.830229
Val Best Loss: 16.830229
Epoch loss: 16.830229
train phase, Epoch 4/30, Loss: 17.458976
val phase, Epoch 4/30, Loss: 16.775028
Val Best Loss: 16.775028
Epoch loss: 16.775028
train phase, Epoch 5/30, Loss: 17.278407
val phase, Epoch 5/30, Loss: 17.101768
Val Best Loss: 16.775028
Epoch loss: 17.101768
train phase, Epoch 6/30, Loss: 17.029831
val phase, Epoch 6/30, Loss: 16.474267
Val Best Loss: 16.474267
Epoch loss: 16.474267
train phase, Epoch 7/30, Loss: 17.035484
val phase, Epoch 7/30, Loss: 17.022679
Val Best Loss: 16.474267
Epoch loss: 17.022679
train phase, Epoch 8/30, Loss: 16.849164
val phase, Epoch 8/30, Loss: 17.032867
Val Best Loss: 16.474267
Epoch loss: 17.032867
train phase, Epoch 9/30, Loss: 16.485922
val phase, Epoch 9/30, Loss: 16.897787
Val Best Loss: 16.474267
Epoch loss: 16.897787
train phase, Epoch 10/30, Loss: 16.586462
val phase, Epoch 10/30, Loss: 16.623066
Val Best Loss: 16.474267
Epoch loss: 16.623066
train phase, Epoch 11/30, Loss: 16.405346
val phase, Epoch 11/30, Loss: 16.526394
Val Best Loss: 16.474267
Epoch loss: 16.526394
train phase, Epoch 12/30, Loss: 16.335775
val phase, Epoch 12/30, Loss: 16.838820
Val Best Loss: 16.474267
Epoch loss: 16.838820
train phase, Epoch 13/30, Loss: 16.133679
val phase, Epoch 13/30, Loss: 16.714847
Val Best Loss: 16.474267
Epoch loss: 16.714847
train phase, Epoch 14/30, Loss: 15.899602
val phase, Epoch 14/30, Loss: 16.052934
Val Best Loss: 16.052934
Epoch loss: 16.052934
train phase, Epoch 15/30, Loss: 15.643178
val phase, Epoch 15/30, Loss: 17.638314
Val Best Loss: 16.052934
Epoch loss: 17.638314
train phase, Epoch 16/30, Loss: 15.606865
val phase, Epoch 16/30, Loss: 16.174673
Val Best Loss: 16.052934
Epoch loss: 16.174673
train phase, Epoch 17/30, Loss: 15.572862
val phase, Epoch 17/30, Loss: 16.172491
Val Best Loss: 16.052934
Epoch loss: 16.172491
train phase, Epoch 18/30, Loss: 15.379184
val phase, Epoch 18/30, Loss: 16.225521
Val Best Loss: 16.052934
Epoch loss: 16.225521
train phase, Epoch 19/30, Loss: 15.325336
val phase, Epoch 19/30, Loss: 16.431768
Val Best Loss: 16.052934
Epoch loss: 16.431768
train phase, Epoch 20/30, Loss: 15.129307
val phase, Epoch 20/30, Loss: 16.289928
Val Best Loss: 16.052934
Epoch loss: 16.289928
train phase, Epoch 21/30, Loss: 14.831650
val phase, Epoch 21/30, Loss: 16.480743
Val Best Loss: 16.052934
Epoch loss: 16.480743
train phase, Epoch 22/30, Loss: 14.859651
val phase, Epoch 22/30, Loss: 17.596382
Val Best Loss: 16.052934
Epoch loss: 17.596382
train phase, Epoch 23/30, Loss: 14.549806
val phase, Epoch 23/30, Loss: 16.613160
Val Best Loss: 16.052934
Epoch loss: 16.613160
train phase, Epoch 24/30, Loss: 14.330978
val phase, Epoch 24/30, Loss: 19.831145
Val Best Loss: 16.052934
Epoch loss: 19.831145
train phase, Epoch 25/30, Loss: 14.224896
val phase, Epoch 25/30, Loss: 16.827149
Val Best Loss: 16.052934
Epoch loss: 16.827149
train phase, Epoch 26/30, Loss: 13.865798
val phase, Epoch 26/30, Loss: 17.533949
Val Best Loss: 16.052934
Epoch loss: 17.533949
train phase, Epoch 27/30, Loss: 13.752753
val phase, Epoch 27/30, Loss: 16.975685
Val Best Loss: 16.052934
Epoch loss: 16.975685
train phase, Epoch 28/30, Loss: 13.624012
val phase, Epoch 28/30, Loss: 17.309111
Val Best Loss: 16.052934
Epoch loss: 17.309111
train phase, Epoch 29/30, Loss: 13.407199
val phase, Epoch 29/30, Loss: 18.307019
Val Best Loss: 16.052934
Epoch loss: 18.307019
train phase, Epoch 30/30, Loss: 13.726870
val phase, Epoch 30/30, Loss: 17.717756
Val Best Loss: 16.052934
Epoch loss: 17.717756
train phase, Epoch 1/20, Loss: 21.561469
val phase, Epoch 1/20, Loss: 20.608702
Val Best Loss: 20.608702
Epoch loss: 20.608702
train phase, Epoch 2/20, Loss: 17.731972
val phase, Epoch 2/20, Loss: 17.674347
Val Best Loss: 17.674347
Epoch loss: 17.674347
train phase, Epoch 3/20, Loss: 17.110532
val phase, Epoch 3/20, Loss: 17.700088
Val Best Loss: 17.674347
Epoch loss: 17.700088
train phase, Epoch 4/20, Loss: 16.863389
val phase, Epoch 4/20, Loss: 16.996880
Val Best Loss: 16.996880
Epoch loss: 16.996880
train phase, Epoch 5/20, Loss: 16.871513
val phase, Epoch 5/20, Loss: 16.651117
Val Best Loss: 16.651117
Epoch loss: 16.651117
train phase, Epoch 6/20, Loss: 16.386284
val phase, Epoch 6/20, Loss: 18.136722
Val Best Loss: 16.651117
Epoch loss: 18.136722
train phase, Epoch 7/20, Loss: 16.264077
val phase, Epoch 7/20, Loss: 17.292600
Val Best Loss: 16.651117
Epoch loss: 17.292600
train phase, Epoch 8/20, Loss: 16.113219
val phase, Epoch 8/20, Loss: 16.579657
Val Best Loss: 16.579657
Epoch loss: 16.579657
train phase, Epoch 9/20, Loss: 15.968241
val phase, Epoch 9/20, Loss: 16.735454
Val Best Loss: 16.579657
Epoch loss: 16.735454
train phase, Epoch 10/20, Loss: 15.773550
val phase, Epoch 10/20, Loss: 17.399640
Val Best Loss: 16.579657
Epoch loss: 17.399640
train phase, Epoch 11/20, Loss: 15.718917
val phase, Epoch 11/20, Loss: 16.582545
Val Best Loss: 16.579657
Epoch loss: 16.582545
train phase, Epoch 12/20, Loss: 15.368101
val phase, Epoch 12/20, Loss: 16.908162
Val Best Loss: 16.579657
Epoch loss: 16.908162
train phase, Epoch 13/20, Loss: 15.481664
val phase, Epoch 13/20, Loss: 16.794337
Val Best Loss: 16.579657
Epoch loss: 16.794337
train phase, Epoch 14/20, Loss: 15.185429
val phase, Epoch 14/20, Loss: 16.417375
Val Best Loss: 16.417375
Epoch loss: 16.417375
train phase, Epoch 15/20, Loss: 15.039502
val phase, Epoch 15/20, Loss: 16.239988
Val Best Loss: 16.239988
Epoch loss: 16.239988
train phase, Epoch 16/20, Loss: 14.702134
val phase, Epoch 16/20, Loss: 17.291163
Val Best Loss: 16.239988
Epoch loss: 17.291163
train phase, Epoch 17/20, Loss: 14.385041
val phase, Epoch 17/20, Loss: 16.902212
Val Best Loss: 16.239988
Epoch loss: 16.902212
train phase, Epoch 18/20, Loss: 14.261368
val phase, Epoch 18/20, Loss: 16.337036
Val Best Loss: 16.239988
Epoch loss: 16.337036
train phase, Epoch 19/20, Loss: 13.971552
val phase, Epoch 19/20, Loss: 18.712789
Val Best Loss: 16.239988
Epoch loss: 18.712789
train phase, Epoch 20/20, Loss: 13.674878
val phase, Epoch 20/20, Loss: 17.321856
Val Best Loss: 16.239988
Epoch loss: 17.321856
[Trial 360] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/15, Loss: 20.203260
val phase, Epoch 1/15, Loss: 18.589387
Val Best Loss: 18.589387
Epoch loss: 18.589387
train phase, Epoch 2/15, Loss: 17.671321
val phase, Epoch 2/15, Loss: 18.223694
Val Best Loss: 18.223694
Epoch loss: 18.223694
train phase, Epoch 3/15, Loss: 17.379094
val phase, Epoch 3/15, Loss: 16.782356
Val Best Loss: 16.782356
Epoch loss: 16.782356
train phase, Epoch 4/15, Loss: 17.339840
val phase, Epoch 4/15, Loss: 19.253244
Val Best Loss: 16.782356
Epoch loss: 19.253244
train phase, Epoch 5/15, Loss: 16.718838
val phase, Epoch 5/15, Loss: 17.210676
Val Best Loss: 16.782356
Epoch loss: 17.210676
train phase, Epoch 6/15, Loss: 16.569562
val phase, Epoch 6/15, Loss: 16.433242
Val Best Loss: 16.433242
Epoch loss: 16.433242
train phase, Epoch 7/15, Loss: 16.689551
val phase, Epoch 7/15, Loss: 17.471784
Val Best Loss: 16.433242
Epoch loss: 17.471784
train phase, Epoch 8/15, Loss: 16.432980
val phase, Epoch 8/15, Loss: 17.703515
Val Best Loss: 16.433242
Epoch loss: 17.703515
train phase, Epoch 9/15, Loss: 16.207852
val phase, Epoch 9/15, Loss: 15.993563
Val Best Loss: 15.993563
Epoch loss: 15.993563
train phase, Epoch 10/15, Loss: 15.957630
val phase, Epoch 10/15, Loss: 15.942693
Val Best Loss: 15.942693
Epoch loss: 15.942693
train phase, Epoch 11/15, Loss: 15.895866
val phase, Epoch 11/15, Loss: 16.671811
Val Best Loss: 15.942693
Epoch loss: 16.671811
train phase, Epoch 12/15, Loss: 15.833731
val phase, Epoch 12/15, Loss: 16.374535
Val Best Loss: 15.942693
Epoch loss: 16.374535
train phase, Epoch 13/15, Loss: 15.543219
val phase, Epoch 13/15, Loss: 15.672288
Val Best Loss: 15.672288
Epoch loss: 15.672288
train phase, Epoch 14/15, Loss: 15.273636
val phase, Epoch 14/15, Loss: 16.298711
Val Best Loss: 15.672288
Epoch loss: 16.298711
train phase, Epoch 15/15, Loss: 15.235976
val phase, Epoch 15/15, Loss: 16.184366
Val Best Loss: 15.672288
Epoch loss: 16.184366
train phase, Epoch 1/20, Loss: 20.715980
val phase, Epoch 1/20, Loss: 20.000175
Val Best Loss: 20.000175
Epoch loss: 20.000175
train phase, Epoch 2/20, Loss: 18.875175
val phase, Epoch 2/20, Loss: 23.779601
Val Best Loss: 20.000175
Epoch loss: 23.779601
train phase, Epoch 3/20, Loss: 18.529543
val phase, Epoch 3/20, Loss: 18.574053
Val Best Loss: 18.574053
Epoch loss: 18.574053
train phase, Epoch 4/20, Loss: 18.098674
val phase, Epoch 4/20, Loss: 16.758524
Val Best Loss: 16.758524
Epoch loss: 16.758524
train phase, Epoch 5/20, Loss: 17.825451
val phase, Epoch 5/20, Loss: 17.014596
Val Best Loss: 16.758524
Epoch loss: 17.014596
train phase, Epoch 6/20, Loss: 17.731210
val phase, Epoch 6/20, Loss: 16.986869
Val Best Loss: 16.758524
Epoch loss: 16.986869
train phase, Epoch 7/20, Loss: 17.696130
val phase, Epoch 7/20, Loss: 17.274736
Val Best Loss: 16.758524
Epoch loss: 17.274736
train phase, Epoch 8/20, Loss: 17.351774
val phase, Epoch 8/20, Loss: 17.321394
Val Best Loss: 16.758524
Epoch loss: 17.321394
train phase, Epoch 9/20, Loss: 17.131770
val phase, Epoch 9/20, Loss: 17.099808
Val Best Loss: 16.758524
Epoch loss: 17.099808
train phase, Epoch 10/20, Loss: 17.182196
val phase, Epoch 10/20, Loss: 18.472755
Val Best Loss: 16.758524
Epoch loss: 18.472755
train phase, Epoch 11/20, Loss: 16.840768
val phase, Epoch 11/20, Loss: 16.492517
Val Best Loss: 16.492517
Epoch loss: 16.492517
train phase, Epoch 12/20, Loss: 16.680417
val phase, Epoch 12/20, Loss: 16.616087
Val Best Loss: 16.492517
Epoch loss: 16.616087
train phase, Epoch 13/20, Loss: 16.583177
val phase, Epoch 13/20, Loss: 17.799596
Val Best Loss: 16.492517
Epoch loss: 17.799596
train phase, Epoch 14/20, Loss: 16.790727
val phase, Epoch 14/20, Loss: 17.333791
Val Best Loss: 16.492517
Epoch loss: 17.333791
train phase, Epoch 15/20, Loss: 16.184476
val phase, Epoch 15/20, Loss: 16.499122
Val Best Loss: 16.492517
Epoch loss: 16.499122
train phase, Epoch 16/20, Loss: 16.305369
val phase, Epoch 16/20, Loss: 15.952318
Val Best Loss: 15.952318
Epoch loss: 15.952318
train phase, Epoch 17/20, Loss: 16.234274
val phase, Epoch 17/20, Loss: 15.973731
Val Best Loss: 15.952318
Epoch loss: 15.973731
train phase, Epoch 18/20, Loss: 16.053334
val phase, Epoch 18/20, Loss: 15.925146
Val Best Loss: 15.925146
Epoch loss: 15.925146
train phase, Epoch 19/20, Loss: 16.089714
val phase, Epoch 19/20, Loss: 16.188810
Val Best Loss: 15.925146
Epoch loss: 16.188810
train phase, Epoch 20/20, Loss: 16.055113
val phase, Epoch 20/20, Loss: 16.125343
Val Best Loss: 15.925146
Epoch loss: 16.125343
train phase, Epoch 1/30, Loss: 20.325718
val phase, Epoch 1/30, Loss: 16.947901
Val Best Loss: 16.947901
Epoch loss: 16.947901
train phase, Epoch 2/30, Loss: 17.814365
val phase, Epoch 2/30, Loss: 17.489745
Val Best Loss: 16.947901
Epoch loss: 17.489745
train phase, Epoch 3/30, Loss: 17.164733
val phase, Epoch 3/30, Loss: 16.840801
Val Best Loss: 16.840801
Epoch loss: 16.840801
train phase, Epoch 4/30, Loss: 17.059058
val phase, Epoch 4/30, Loss: 18.300571
Val Best Loss: 16.840801
Epoch loss: 18.300571
train phase, Epoch 5/30, Loss: 16.744313
val phase, Epoch 5/30, Loss: 16.966575
Val Best Loss: 16.840801
Epoch loss: 16.966575
train phase, Epoch 6/30, Loss: 16.421451
val phase, Epoch 6/30, Loss: 16.507375
Val Best Loss: 16.507375
Epoch loss: 16.507375
train phase, Epoch 7/30, Loss: 16.354508
val phase, Epoch 7/30, Loss: 15.971428
Val Best Loss: 15.971428
Epoch loss: 15.971428
train phase, Epoch 8/30, Loss: 15.993771
val phase, Epoch 8/30, Loss: 16.196817
Val Best Loss: 15.971428
Epoch loss: 16.196817
train phase, Epoch 9/30, Loss: 16.490242
val phase, Epoch 9/30, Loss: 16.273911
Val Best Loss: 15.971428
Epoch loss: 16.273911
train phase, Epoch 10/30, Loss: 15.962897
val phase, Epoch 10/30, Loss: 16.171462
Val Best Loss: 15.971428
Epoch loss: 16.171462
train phase, Epoch 11/30, Loss: 15.695662
val phase, Epoch 11/30, Loss: 16.334682
Val Best Loss: 15.971428
Epoch loss: 16.334682
train phase, Epoch 12/30, Loss: 15.268079
val phase, Epoch 12/30, Loss: 15.887998
Val Best Loss: 15.887998
Epoch loss: 15.887998
train phase, Epoch 13/30, Loss: 15.332570
val phase, Epoch 13/30, Loss: 16.324008
Val Best Loss: 15.887998
Epoch loss: 16.324008
train phase, Epoch 14/30, Loss: 15.241492
val phase, Epoch 14/30, Loss: 16.440858
Val Best Loss: 15.887998
Epoch loss: 16.440858
train phase, Epoch 15/30, Loss: 14.988168
val phase, Epoch 15/30, Loss: 16.016450
Val Best Loss: 15.887998
Epoch loss: 16.016450
train phase, Epoch 16/30, Loss: 14.739995
val phase, Epoch 16/30, Loss: 16.502279
Val Best Loss: 15.887998
Epoch loss: 16.502279
train phase, Epoch 17/30, Loss: 14.657554
val phase, Epoch 17/30, Loss: 16.502654
Val Best Loss: 15.887998
Epoch loss: 16.502654
train phase, Epoch 18/30, Loss: 14.545437
val phase, Epoch 18/30, Loss: 16.834080
Val Best Loss: 15.887998
Epoch loss: 16.834080
train phase, Epoch 19/30, Loss: 14.644225
val phase, Epoch 19/30, Loss: 16.149192
Val Best Loss: 15.887998
Epoch loss: 16.149192
train phase, Epoch 20/30, Loss: 14.140549
val phase, Epoch 20/30, Loss: 17.456912
Val Best Loss: 15.887998
Epoch loss: 17.456912
train phase, Epoch 21/30, Loss: 13.686658
val phase, Epoch 21/30, Loss: 16.740473
Val Best Loss: 15.887998
Epoch loss: 16.740473
train phase, Epoch 22/30, Loss: 13.513816
val phase, Epoch 22/30, Loss: 16.045724
Val Best Loss: 15.887998
Epoch loss: 16.045724
train phase, Epoch 23/30, Loss: 13.055699
val phase, Epoch 23/30, Loss: 18.582766
Val Best Loss: 15.887998
Epoch loss: 18.582766
train phase, Epoch 24/30, Loss: 12.805839
val phase, Epoch 24/30, Loss: 18.425845
Val Best Loss: 15.887998
Epoch loss: 18.425845
train phase, Epoch 25/30, Loss: 12.169592
val phase, Epoch 25/30, Loss: 17.147648
Val Best Loss: 15.887998
Epoch loss: 17.147648
train phase, Epoch 26/30, Loss: 11.904597
val phase, Epoch 26/30, Loss: 17.105623
Val Best Loss: 15.887998
Epoch loss: 17.105623
train phase, Epoch 27/30, Loss: 11.548104
val phase, Epoch 27/30, Loss: 19.092385
Val Best Loss: 15.887998
Epoch loss: 19.092385
train phase, Epoch 28/30, Loss: 11.224664
val phase, Epoch 28/30, Loss: 18.362140
Val Best Loss: 15.887998
Epoch loss: 18.362140
train phase, Epoch 29/30, Loss: 10.562801
val phase, Epoch 29/30, Loss: 18.210396
Val Best Loss: 15.887998
Epoch loss: 18.210396
train phase, Epoch 30/30, Loss: 10.369775
val phase, Epoch 30/30, Loss: 18.436086
Val Best Loss: 15.887998
Epoch loss: 18.436086
[Trial 364] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.843141
val phase, Epoch 1/20, Loss: 17.488050
Val Best Loss: 17.488050
Epoch loss: 17.488050
train phase, Epoch 2/20, Loss: 18.126267
val phase, Epoch 2/20, Loss: 17.202536
Val Best Loss: 17.202536
Epoch loss: 17.202536
train phase, Epoch 3/20, Loss: 17.581127
val phase, Epoch 3/20, Loss: 17.778863
Val Best Loss: 17.202536
Epoch loss: 17.778863
train phase, Epoch 4/20, Loss: 17.305398
val phase, Epoch 4/20, Loss: 17.699075
Val Best Loss: 17.202536
Epoch loss: 17.699075
train phase, Epoch 5/20, Loss: 17.311707
val phase, Epoch 5/20, Loss: 17.031285
Val Best Loss: 17.031285
Epoch loss: 17.031285
train phase, Epoch 6/20, Loss: 17.180935
val phase, Epoch 6/20, Loss: 18.346986
Val Best Loss: 17.031285
Epoch loss: 18.346986
train phase, Epoch 7/20, Loss: 16.746820
val phase, Epoch 7/20, Loss: 18.714889
Val Best Loss: 17.031285
Epoch loss: 18.714889
train phase, Epoch 8/20, Loss: 16.613174
val phase, Epoch 8/20, Loss: 16.197089
Val Best Loss: 16.197089
Epoch loss: 16.197089
train phase, Epoch 9/20, Loss: 16.282600
val phase, Epoch 9/20, Loss: 15.869287
Val Best Loss: 15.869287
Epoch loss: 15.869287
train phase, Epoch 10/20, Loss: 16.288708
val phase, Epoch 10/20, Loss: 16.130310
Val Best Loss: 15.869287
Epoch loss: 16.130310
train phase, Epoch 11/20, Loss: 16.054964
val phase, Epoch 11/20, Loss: 15.918508
Val Best Loss: 15.869287
Epoch loss: 15.918508
train phase, Epoch 12/20, Loss: 16.115021
val phase, Epoch 12/20, Loss: 15.840701
Val Best Loss: 15.840701
Epoch loss: 15.840701
train phase, Epoch 13/20, Loss: 15.708768
val phase, Epoch 13/20, Loss: 16.340787
Val Best Loss: 15.840701
Epoch loss: 16.340787
train phase, Epoch 14/20, Loss: 15.602855
val phase, Epoch 14/20, Loss: 17.766261
Val Best Loss: 15.840701
Epoch loss: 17.766261
train phase, Epoch 15/20, Loss: 15.629203
val phase, Epoch 15/20, Loss: 15.891836
Val Best Loss: 15.840701
Epoch loss: 15.891836
train phase, Epoch 16/20, Loss: 15.176628
val phase, Epoch 16/20, Loss: 16.215100
Val Best Loss: 15.840701
Epoch loss: 16.215100
train phase, Epoch 17/20, Loss: 14.984841
val phase, Epoch 17/20, Loss: 16.171142
Val Best Loss: 15.840701
Epoch loss: 16.171142
train phase, Epoch 18/20, Loss: 14.768914
val phase, Epoch 18/20, Loss: 16.274463
Val Best Loss: 15.840701
Epoch loss: 16.274463
train phase, Epoch 19/20, Loss: 14.703288
val phase, Epoch 19/20, Loss: 16.702599
Val Best Loss: 15.840701
Epoch loss: 16.702599
train phase, Epoch 20/20, Loss: 14.632918
val phase, Epoch 20/20, Loss: 16.316310
Val Best Loss: 15.840701
Epoch loss: 16.316310
train phase, Epoch 1/30, Loss: 19.535889
val phase, Epoch 1/30, Loss: 17.116693
Val Best Loss: 17.116693
Epoch loss: 17.116693
train phase, Epoch 2/30, Loss: 17.924623
val phase, Epoch 2/30, Loss: 17.858614
Val Best Loss: 17.116693
Epoch loss: 17.858614
train phase, Epoch 3/30, Loss: 17.457767
val phase, Epoch 3/30, Loss: 16.956688
Val Best Loss: 16.956688
Epoch loss: 16.956688
train phase, Epoch 4/30, Loss: 16.940763
val phase, Epoch 4/30, Loss: 16.110336
Val Best Loss: 16.110336
Epoch loss: 16.110336
train phase, Epoch 5/30, Loss: 17.002322
val phase, Epoch 5/30, Loss: 18.601616
Val Best Loss: 16.110336
Epoch loss: 18.601616
train phase, Epoch 6/30, Loss: 16.612462
val phase, Epoch 6/30, Loss: 16.513661
Val Best Loss: 16.110336
Epoch loss: 16.513661
train phase, Epoch 7/30, Loss: 16.565299
val phase, Epoch 7/30, Loss: 16.470061
Val Best Loss: 16.110336
Epoch loss: 16.470061
train phase, Epoch 8/30, Loss: 16.313874
val phase, Epoch 8/30, Loss: 16.737681
Val Best Loss: 16.110336
Epoch loss: 16.737681
train phase, Epoch 9/30, Loss: 16.514578
val phase, Epoch 9/30, Loss: 17.403783
Val Best Loss: 16.110336
Epoch loss: 17.403783
train phase, Epoch 10/30, Loss: 15.911489
val phase, Epoch 10/30, Loss: 16.821929
Val Best Loss: 16.110336
Epoch loss: 16.821929
train phase, Epoch 11/30, Loss: 15.882561
val phase, Epoch 11/30, Loss: 16.063665
Val Best Loss: 16.063665
Epoch loss: 16.063665
train phase, Epoch 12/30, Loss: 15.666930
val phase, Epoch 12/30, Loss: 16.268016
Val Best Loss: 16.063665
Epoch loss: 16.268016
train phase, Epoch 13/30, Loss: 15.539499
val phase, Epoch 13/30, Loss: 18.195076
Val Best Loss: 16.063665
Epoch loss: 18.195076
train phase, Epoch 14/30, Loss: 15.665773
val phase, Epoch 14/30, Loss: 15.963918
Val Best Loss: 15.963918
Epoch loss: 15.963918
train phase, Epoch 15/30, Loss: 15.379079
val phase, Epoch 15/30, Loss: 15.915554
Val Best Loss: 15.915554
Epoch loss: 15.915554
train phase, Epoch 16/30, Loss: 14.973825
val phase, Epoch 16/30, Loss: 15.967073
Val Best Loss: 15.915554
Epoch loss: 15.967073
train phase, Epoch 17/30, Loss: 14.593712
val phase, Epoch 17/30, Loss: 16.498698
Val Best Loss: 15.915554
Epoch loss: 16.498698
train phase, Epoch 18/30, Loss: 14.565366
val phase, Epoch 18/30, Loss: 16.052128
Val Best Loss: 15.915554
Epoch loss: 16.052128
train phase, Epoch 19/30, Loss: 14.291827
val phase, Epoch 19/30, Loss: 17.253225
Val Best Loss: 15.915554
Epoch loss: 17.253225
train phase, Epoch 20/30, Loss: 14.002658
val phase, Epoch 20/30, Loss: 15.947468
Val Best Loss: 15.915554
Epoch loss: 15.947468
train phase, Epoch 21/30, Loss: 13.539108
val phase, Epoch 21/30, Loss: 16.692176
Val Best Loss: 15.915554
Epoch loss: 16.692176
train phase, Epoch 22/30, Loss: 13.212389
val phase, Epoch 22/30, Loss: 16.487475
Val Best Loss: 15.915554
Epoch loss: 16.487475
train phase, Epoch 23/30, Loss: 12.887834
val phase, Epoch 23/30, Loss: 17.395713
Val Best Loss: 15.915554
Epoch loss: 17.395713
train phase, Epoch 24/30, Loss: 12.535918
val phase, Epoch 24/30, Loss: 17.290863
Val Best Loss: 15.915554
Epoch loss: 17.290863
train phase, Epoch 25/30, Loss: 12.269314
val phase, Epoch 25/30, Loss: 17.537182
Val Best Loss: 15.915554
Epoch loss: 17.537182
train phase, Epoch 26/30, Loss: 11.378261
val phase, Epoch 26/30, Loss: 18.402940
Val Best Loss: 15.915554
Epoch loss: 18.402940
train phase, Epoch 27/30, Loss: 11.032997
val phase, Epoch 27/30, Loss: 18.473272
Val Best Loss: 15.915554
Epoch loss: 18.473272
train phase, Epoch 28/30, Loss: 10.580362
val phase, Epoch 28/30, Loss: 18.245197
Val Best Loss: 15.915554
Epoch loss: 18.245197
train phase, Epoch 29/30, Loss: 9.872866
val phase, Epoch 29/30, Loss: 18.408168
Val Best Loss: 15.915554
Epoch loss: 18.408168
train phase, Epoch 30/30, Loss: 9.625393
val phase, Epoch 30/30, Loss: 20.440582
Val Best Loss: 15.915554
Epoch loss: 20.440582
train phase, Epoch 1/20, Loss: 20.198623
val phase, Epoch 1/20, Loss: 16.907574
Val Best Loss: 16.907574
Epoch loss: 16.907574
train phase, Epoch 2/20, Loss: 18.110512
val phase, Epoch 2/20, Loss: 16.655543
Val Best Loss: 16.655543
Epoch loss: 16.655543
train phase, Epoch 3/20, Loss: 17.609514
val phase, Epoch 3/20, Loss: 16.818809
Val Best Loss: 16.655543
Epoch loss: 16.818809
train phase, Epoch 4/20, Loss: 17.449142
val phase, Epoch 4/20, Loss: 16.532375
Val Best Loss: 16.532375
Epoch loss: 16.532375
train phase, Epoch 5/20, Loss: 17.225091
val phase, Epoch 5/20, Loss: 16.568826
Val Best Loss: 16.532375
Epoch loss: 16.568826
train phase, Epoch 6/20, Loss: 17.031936
val phase, Epoch 6/20, Loss: 16.631024
Val Best Loss: 16.532375
Epoch loss: 16.631024
train phase, Epoch 7/20, Loss: 16.849541
val phase, Epoch 7/20, Loss: 16.447106
Val Best Loss: 16.447106
Epoch loss: 16.447106
train phase, Epoch 8/20, Loss: 16.812040
val phase, Epoch 8/20, Loss: 16.005266
Val Best Loss: 16.005266
Epoch loss: 16.005266
train phase, Epoch 9/20, Loss: 16.565162
val phase, Epoch 9/20, Loss: 15.965729
Val Best Loss: 15.965729
Epoch loss: 15.965729
train phase, Epoch 10/20, Loss: 16.416693
val phase, Epoch 10/20, Loss: 16.151774
Val Best Loss: 15.965729
Epoch loss: 16.151774
train phase, Epoch 11/20, Loss: 16.188980
val phase, Epoch 11/20, Loss: 16.256649
Val Best Loss: 15.965729
Epoch loss: 16.256649
train phase, Epoch 12/20, Loss: 16.368559
val phase, Epoch 12/20, Loss: 16.429466
Val Best Loss: 15.965729
Epoch loss: 16.429466
train phase, Epoch 13/20, Loss: 15.993835
val phase, Epoch 13/20, Loss: 17.183204
Val Best Loss: 15.965729
Epoch loss: 17.183204
train phase, Epoch 14/20, Loss: 15.920672
val phase, Epoch 14/20, Loss: 15.939947
Val Best Loss: 15.939947
Epoch loss: 15.939947
train phase, Epoch 15/20, Loss: 15.766842
val phase, Epoch 15/20, Loss: 16.692014
Val Best Loss: 15.939947
Epoch loss: 16.692014
train phase, Epoch 16/20, Loss: 15.513230
val phase, Epoch 16/20, Loss: 16.003009
Val Best Loss: 15.939947
Epoch loss: 16.003009
train phase, Epoch 17/20, Loss: 15.280721
val phase, Epoch 17/20, Loss: 16.722174
Val Best Loss: 15.939947
Epoch loss: 16.722174
train phase, Epoch 18/20, Loss: 14.934971
val phase, Epoch 18/20, Loss: 16.647299
Val Best Loss: 15.939947
Epoch loss: 16.647299
train phase, Epoch 19/20, Loss: 14.864924
val phase, Epoch 19/20, Loss: 16.898421
Val Best Loss: 15.939947
Epoch loss: 16.898421
train phase, Epoch 20/20, Loss: 14.523549
val phase, Epoch 20/20, Loss: 16.039384
Val Best Loss: 15.939947
Epoch loss: 16.039384
train phase, Epoch 1/12, Loss: 20.638086
val phase, Epoch 1/12, Loss: 19.864036
Val Best Loss: 19.864036
Epoch loss: 19.864036
train phase, Epoch 2/12, Loss: 18.567734
val phase, Epoch 2/12, Loss: 18.388055
Val Best Loss: 18.388055
Epoch loss: 18.388055
train phase, Epoch 3/12, Loss: 17.561147
val phase, Epoch 3/12, Loss: 20.764733
Val Best Loss: 18.388055
Epoch loss: 20.764733
train phase, Epoch 4/12, Loss: 17.409602
val phase, Epoch 4/12, Loss: 17.145469
Val Best Loss: 17.145469
Epoch loss: 17.145469
train phase, Epoch 5/12, Loss: 17.176580
val phase, Epoch 5/12, Loss: 19.143280
Val Best Loss: 17.145469
Epoch loss: 19.143280
train phase, Epoch 6/12, Loss: 16.632755
val phase, Epoch 6/12, Loss: 16.157389
Val Best Loss: 16.157389
Epoch loss: 16.157389
train phase, Epoch 7/12, Loss: 16.500135
val phase, Epoch 7/12, Loss: 18.650505
Val Best Loss: 16.157389
Epoch loss: 18.650505
train phase, Epoch 8/12, Loss: 16.540744
val phase, Epoch 8/12, Loss: 16.439199
Val Best Loss: 16.157389
Epoch loss: 16.439199
train phase, Epoch 9/12, Loss: 16.393003
val phase, Epoch 9/12, Loss: 15.879124
Val Best Loss: 15.879124
Epoch loss: 15.879124
train phase, Epoch 10/12, Loss: 16.132915
val phase, Epoch 10/12, Loss: 18.382872
Val Best Loss: 15.879124
Epoch loss: 18.382872
train phase, Epoch 11/12, Loss: 16.218244
val phase, Epoch 11/12, Loss: 16.375653
Val Best Loss: 15.879124
Epoch loss: 16.375653
train phase, Epoch 12/12, Loss: 15.596568
val phase, Epoch 12/12, Loss: 16.381496
Val Best Loss: 15.879124
Epoch loss: 16.381496
train phase, Epoch 1/20, Loss: 19.578226
val phase, Epoch 1/20, Loss: 18.974336
Val Best Loss: 18.974336
Epoch loss: 18.974336
train phase, Epoch 2/20, Loss: 18.013590
val phase, Epoch 2/20, Loss: 19.034613
Val Best Loss: 18.974336
Epoch loss: 19.034613
train phase, Epoch 3/20, Loss: 17.446243
val phase, Epoch 3/20, Loss: 16.474757
Val Best Loss: 16.474757
Epoch loss: 16.474757
train phase, Epoch 4/20, Loss: 17.010243
val phase, Epoch 4/20, Loss: 16.566369
Val Best Loss: 16.474757
Epoch loss: 16.566369
train phase, Epoch 5/20, Loss: 16.704725
val phase, Epoch 5/20, Loss: 16.303510
Val Best Loss: 16.303510
Epoch loss: 16.303510
train phase, Epoch 6/20, Loss: 16.536837
val phase, Epoch 6/20, Loss: 16.757901
Val Best Loss: 16.303510
Epoch loss: 16.757901
train phase, Epoch 7/20, Loss: 16.374757
val phase, Epoch 7/20, Loss: 16.597891
Val Best Loss: 16.303510
Epoch loss: 16.597891
train phase, Epoch 8/20, Loss: 16.449282
val phase, Epoch 8/20, Loss: 15.893555
Val Best Loss: 15.893555
Epoch loss: 15.893555
train phase, Epoch 9/20, Loss: 16.082954
val phase, Epoch 9/20, Loss: 16.178132
Val Best Loss: 15.893555
Epoch loss: 16.178132
train phase, Epoch 10/20, Loss: 15.861510
val phase, Epoch 10/20, Loss: 15.697644
Val Best Loss: 15.697644
Epoch loss: 15.697644
train phase, Epoch 11/20, Loss: 15.635795
val phase, Epoch 11/20, Loss: 15.698445
Val Best Loss: 15.697644
Epoch loss: 15.698445
train phase, Epoch 12/20, Loss: 15.543538
val phase, Epoch 12/20, Loss: 16.298587
Val Best Loss: 15.697644
Epoch loss: 16.298587
train phase, Epoch 13/20, Loss: 15.581953
val phase, Epoch 13/20, Loss: 16.026642
Val Best Loss: 15.697644
Epoch loss: 16.026642
train phase, Epoch 14/20, Loss: 15.335722
val phase, Epoch 14/20, Loss: 17.427597
Val Best Loss: 15.697644
Epoch loss: 17.427597
train phase, Epoch 15/20, Loss: 15.387710
val phase, Epoch 15/20, Loss: 16.285915
Val Best Loss: 15.697644
Epoch loss: 16.285915
train phase, Epoch 16/20, Loss: 14.990380
val phase, Epoch 16/20, Loss: 15.791419
Val Best Loss: 15.697644
Epoch loss: 15.791419
train phase, Epoch 17/20, Loss: 14.697456
val phase, Epoch 17/20, Loss: 16.008811
Val Best Loss: 15.697644
Epoch loss: 16.008811
train phase, Epoch 18/20, Loss: 14.559027
val phase, Epoch 18/20, Loss: 17.591840
Val Best Loss: 15.697644
Epoch loss: 17.591840
train phase, Epoch 19/20, Loss: 14.655430
val phase, Epoch 19/20, Loss: 16.443842
Val Best Loss: 15.697644
Epoch loss: 16.443842
train phase, Epoch 20/20, Loss: 14.219174
val phase, Epoch 20/20, Loss: 16.596974
Val Best Loss: 15.697644
Epoch loss: 16.596974
train phase, Epoch 1/30, Loss: 25.501932
val phase, Epoch 1/30, Loss: 18.105488
Val Best Loss: 18.105488
Epoch loss: 18.105488
train phase, Epoch 2/30, Loss: 18.089464
val phase, Epoch 2/30, Loss: 17.567999
Val Best Loss: 17.567999
Epoch loss: 17.567999
train phase, Epoch 3/30, Loss: 17.641990
val phase, Epoch 3/30, Loss: 16.617174
Val Best Loss: 16.617174
Epoch loss: 16.617174
train phase, Epoch 4/30, Loss: 17.259182
val phase, Epoch 4/30, Loss: 17.722721
Val Best Loss: 16.617174
Epoch loss: 17.722721
train phase, Epoch 5/30, Loss: 16.877582
val phase, Epoch 5/30, Loss: 16.399311
Val Best Loss: 16.399311
Epoch loss: 16.399311
train phase, Epoch 6/30, Loss: 16.849963
val phase, Epoch 6/30, Loss: 16.968035
Val Best Loss: 16.399311
Epoch loss: 16.968035
train phase, Epoch 7/30, Loss: 16.681618
val phase, Epoch 7/30, Loss: 16.171496
Val Best Loss: 16.171496
Epoch loss: 16.171496
train phase, Epoch 8/30, Loss: 16.469971
val phase, Epoch 8/30, Loss: 18.797338
Val Best Loss: 16.171496
Epoch loss: 18.797338
train phase, Epoch 9/30, Loss: 16.356478
val phase, Epoch 9/30, Loss: 15.901912
Val Best Loss: 15.901912
Epoch loss: 15.901912
train phase, Epoch 10/30, Loss: 16.097041
val phase, Epoch 10/30, Loss: 15.950182
Val Best Loss: 15.901912
Epoch loss: 15.950182
train phase, Epoch 11/30, Loss: 16.114877
val phase, Epoch 11/30, Loss: 16.411083
Val Best Loss: 15.901912
Epoch loss: 16.411083
train phase, Epoch 12/30, Loss: 16.039617
val phase, Epoch 12/30, Loss: 16.021848
Val Best Loss: 15.901912
Epoch loss: 16.021848
train phase, Epoch 13/30, Loss: 15.839424
val phase, Epoch 13/30, Loss: 15.942789
Val Best Loss: 15.901912
Epoch loss: 15.942789
train phase, Epoch 14/30, Loss: 15.738950
val phase, Epoch 14/30, Loss: 16.084502
Val Best Loss: 15.901912
Epoch loss: 16.084502
train phase, Epoch 15/30, Loss: 15.520415
val phase, Epoch 15/30, Loss: 15.926470
Val Best Loss: 15.901912
Epoch loss: 15.926470
train phase, Epoch 16/30, Loss: 15.526300
val phase, Epoch 16/30, Loss: 15.967276
Val Best Loss: 15.901912
Epoch loss: 15.967276
train phase, Epoch 17/30, Loss: 15.286107
val phase, Epoch 17/30, Loss: 16.128908
Val Best Loss: 15.901912
Epoch loss: 16.128908
train phase, Epoch 18/30, Loss: 15.551229
val phase, Epoch 18/30, Loss: 16.343366
Val Best Loss: 15.901912
Epoch loss: 16.343366
train phase, Epoch 19/30, Loss: 15.477666
val phase, Epoch 19/30, Loss: 15.934376
Val Best Loss: 15.901912
Epoch loss: 15.934376
train phase, Epoch 20/30, Loss: 15.287109
val phase, Epoch 20/30, Loss: 15.890758
Val Best Loss: 15.890758
Epoch loss: 15.890758
train phase, Epoch 21/30, Loss: 15.015855
val phase, Epoch 21/30, Loss: 16.670092
Val Best Loss: 15.890758
Epoch loss: 16.670092
train phase, Epoch 22/30, Loss: 14.936339
val phase, Epoch 22/30, Loss: 16.552730
Val Best Loss: 15.890758
Epoch loss: 16.552730
train phase, Epoch 23/30, Loss: 14.999349
val phase, Epoch 23/30, Loss: 15.892660
Val Best Loss: 15.890758
Epoch loss: 15.892660
train phase, Epoch 24/30, Loss: 14.856695
val phase, Epoch 24/30, Loss: 16.865736
Val Best Loss: 15.890758
Epoch loss: 16.865736
train phase, Epoch 25/30, Loss: 14.714722
val phase, Epoch 25/30, Loss: 16.641310
Val Best Loss: 15.890758
Epoch loss: 16.641310
train phase, Epoch 26/30, Loss: 14.785730
val phase, Epoch 26/30, Loss: 16.087383
Val Best Loss: 15.890758
Epoch loss: 16.087383
train phase, Epoch 27/30, Loss: 14.539770
val phase, Epoch 27/30, Loss: 16.759560
Val Best Loss: 15.890758
Epoch loss: 16.759560
train phase, Epoch 28/30, Loss: 14.168175
val phase, Epoch 28/30, Loss: 16.865896
Val Best Loss: 15.890758
Epoch loss: 16.865896
train phase, Epoch 29/30, Loss: 14.275939
val phase, Epoch 29/30, Loss: 17.444547
Val Best Loss: 15.890758
Epoch loss: 17.444547
train phase, Epoch 30/30, Loss: 14.128728
val phase, Epoch 30/30, Loss: 17.035378
Val Best Loss: 15.890758
Epoch loss: 17.035378
train phase, Epoch 1/20, Loss: 21.185738
val phase, Epoch 1/20, Loss: 19.630470
Val Best Loss: 19.630470
Epoch loss: 19.630470
train phase, Epoch 2/20, Loss: 18.414437
val phase, Epoch 2/20, Loss: 17.812878
Val Best Loss: 17.812878
Epoch loss: 17.812878
train phase, Epoch 3/20, Loss: 18.200167
val phase, Epoch 3/20, Loss: 18.775677
Val Best Loss: 17.812878
Epoch loss: 18.775677
train phase, Epoch 4/20, Loss: 17.752269
val phase, Epoch 4/20, Loss: 17.553037
Val Best Loss: 17.553037
Epoch loss: 17.553037
train phase, Epoch 5/20, Loss: 17.259927
val phase, Epoch 5/20, Loss: 18.223611
Val Best Loss: 17.553037
Epoch loss: 18.223611
train phase, Epoch 6/20, Loss: 17.341183
val phase, Epoch 6/20, Loss: 19.868346
Val Best Loss: 17.553037
Epoch loss: 19.868346
train phase, Epoch 7/20, Loss: 16.992026
val phase, Epoch 7/20, Loss: 18.717505
Val Best Loss: 17.553037
Epoch loss: 18.717505
train phase, Epoch 8/20, Loss: 17.170414
val phase, Epoch 8/20, Loss: 17.664049
Val Best Loss: 17.553037
Epoch loss: 17.664049
train phase, Epoch 9/20, Loss: 16.554471
val phase, Epoch 9/20, Loss: 18.014690
Val Best Loss: 17.553037
Epoch loss: 18.014690
train phase, Epoch 10/20, Loss: 16.477506
val phase, Epoch 10/20, Loss: 17.369497
Val Best Loss: 17.369497
Epoch loss: 17.369497
train phase, Epoch 11/20, Loss: 16.612595
val phase, Epoch 11/20, Loss: 17.288987
Val Best Loss: 17.288987
Epoch loss: 17.288987
train phase, Epoch 12/20, Loss: 16.247364
val phase, Epoch 12/20, Loss: 16.806545
Val Best Loss: 16.806545
Epoch loss: 16.806545
train phase, Epoch 13/20, Loss: 16.001738
val phase, Epoch 13/20, Loss: 17.077719
Val Best Loss: 16.806545
Epoch loss: 17.077719
train phase, Epoch 14/20, Loss: 15.911222
val phase, Epoch 14/20, Loss: 19.076956
Val Best Loss: 16.806545
Epoch loss: 19.076956
train phase, Epoch 15/20, Loss: 15.740489
val phase, Epoch 15/20, Loss: 17.651419
Val Best Loss: 16.806545
Epoch loss: 17.651419
train phase, Epoch 16/20, Loss: 15.503043
val phase, Epoch 16/20, Loss: 17.423120
Val Best Loss: 16.806545
Epoch loss: 17.423120
train phase, Epoch 17/20, Loss: 15.279657
val phase, Epoch 17/20, Loss: 17.428245
Val Best Loss: 16.806545
Epoch loss: 17.428245
train phase, Epoch 18/20, Loss: 15.048875
val phase, Epoch 18/20, Loss: 17.335302
Val Best Loss: 16.806545
Epoch loss: 17.335302
train phase, Epoch 19/20, Loss: 14.968120
val phase, Epoch 19/20, Loss: 17.181150
Val Best Loss: 16.806545
Epoch loss: 17.181150
train phase, Epoch 20/20, Loss: 14.658900
val phase, Epoch 20/20, Loss: 17.501714
Val Best Loss: 16.806545
Epoch loss: 17.501714
train phase, Epoch 1/25, Loss: 19.753704
val phase, Epoch 1/25, Loss: 33.595748
Val Best Loss: 33.595748
Epoch loss: 33.595748
train phase, Epoch 2/25, Loss: 18.142798
val phase, Epoch 2/25, Loss: 32.430944
Val Best Loss: 32.430944
Epoch loss: 32.430944
train phase, Epoch 3/25, Loss: 17.626379
val phase, Epoch 3/25, Loss: 34.005144
Val Best Loss: 32.430944
Epoch loss: 34.005144
train phase, Epoch 4/25, Loss: 16.803444
val phase, Epoch 4/25, Loss: 30.070355
Val Best Loss: 30.070355
Epoch loss: 30.070355
train phase, Epoch 5/25, Loss: 16.848329
val phase, Epoch 5/25, Loss: 40.357023
Val Best Loss: 30.070355
Epoch loss: 40.357023
train phase, Epoch 6/25, Loss: 16.822891
val phase, Epoch 6/25, Loss: 48.341809
Val Best Loss: 30.070355
Epoch loss: 48.341809
train phase, Epoch 7/25, Loss: 16.421194
val phase, Epoch 7/25, Loss: 42.896343
Val Best Loss: 30.070355
Epoch loss: 42.896343
train phase, Epoch 8/25, Loss: 16.684550
val phase, Epoch 8/25, Loss: 36.914112
Val Best Loss: 30.070355
Epoch loss: 36.914112
train phase, Epoch 9/25, Loss: 16.055462
val phase, Epoch 9/25, Loss: 36.510957
Val Best Loss: 30.070355
Epoch loss: 36.510957
train phase, Epoch 10/25, Loss: 15.957366
val phase, Epoch 10/25, Loss: 36.461003
Val Best Loss: 30.070355
Epoch loss: 36.461003
train phase, Epoch 11/25, Loss: 15.853529
val phase, Epoch 11/25, Loss: 40.716109
Val Best Loss: 30.070355
Epoch loss: 40.716109
train phase, Epoch 12/25, Loss: 15.540961
val phase, Epoch 12/25, Loss: 41.710315
Val Best Loss: 30.070355
Epoch loss: 41.710315
train phase, Epoch 13/25, Loss: 15.417695
val phase, Epoch 13/25, Loss: 44.634625
Val Best Loss: 30.070355
Epoch loss: 44.634625
train phase, Epoch 14/25, Loss: 15.315506
val phase, Epoch 14/25, Loss: 39.654545
Val Best Loss: 30.070355
Epoch loss: 39.654545
train phase, Epoch 15/25, Loss: 15.191770
val phase, Epoch 15/25, Loss: 43.382341
Val Best Loss: 30.070355
Epoch loss: 43.382341
train phase, Epoch 16/25, Loss: 14.958984
val phase, Epoch 16/25, Loss: 39.888704
Val Best Loss: 30.070355
Epoch loss: 39.888704
train phase, Epoch 17/25, Loss: 14.876570
val phase, Epoch 17/25, Loss: 35.508254
Val Best Loss: 30.070355
Epoch loss: 35.508254
train phase, Epoch 18/25, Loss: 14.577116
val phase, Epoch 18/25, Loss: 44.253748
Val Best Loss: 30.070355
Epoch loss: 44.253748
train phase, Epoch 19/25, Loss: 14.219124
val phase, Epoch 19/25, Loss: 39.805315
Val Best Loss: 30.070355
Epoch loss: 39.805315
train phase, Epoch 20/25, Loss: 13.991876
val phase, Epoch 20/25, Loss: 42.920435
Val Best Loss: 30.070355
Epoch loss: 42.920435
train phase, Epoch 21/25, Loss: 13.787864
val phase, Epoch 21/25, Loss: 62.991386
Val Best Loss: 30.070355
Epoch loss: 62.991386
train phase, Epoch 22/25, Loss: 13.458992
val phase, Epoch 22/25, Loss: 33.854008
Val Best Loss: 30.070355
Epoch loss: 33.854008
train phase, Epoch 23/25, Loss: 12.945288
val phase, Epoch 23/25, Loss: 47.500395
Val Best Loss: 30.070355
Epoch loss: 47.500395
train phase, Epoch 24/25, Loss: 12.692297
val phase, Epoch 24/25, Loss: 38.963873
Val Best Loss: 30.070355
Epoch loss: 38.963873
train phase, Epoch 25/25, Loss: 12.281474
val phase, Epoch 25/25, Loss: 35.277852
Val Best Loss: 30.070355
Epoch loss: 35.277852
train phase, Epoch 1/20, Loss: 19.781668
val phase, Epoch 1/20, Loss: 17.685758
Val Best Loss: 17.685758
Epoch loss: 17.685758
train phase, Epoch 2/20, Loss: 18.730588
val phase, Epoch 2/20, Loss: 18.408415
Val Best Loss: 17.685758
Epoch loss: 18.408415
train phase, Epoch 3/20, Loss: 17.652859
val phase, Epoch 3/20, Loss: 17.537420
Val Best Loss: 17.537420
Epoch loss: 17.537420
train phase, Epoch 4/20, Loss: 17.106305
val phase, Epoch 4/20, Loss: 16.649417
Val Best Loss: 16.649417
Epoch loss: 16.649417
train phase, Epoch 5/20, Loss: 17.115339
val phase, Epoch 5/20, Loss: 17.099580
Val Best Loss: 16.649417
Epoch loss: 17.099580
train phase, Epoch 6/20, Loss: 17.281955
val phase, Epoch 6/20, Loss: 16.521753
Val Best Loss: 16.521753
Epoch loss: 16.521753
train phase, Epoch 7/20, Loss: 16.552423
val phase, Epoch 7/20, Loss: 16.192958
Val Best Loss: 16.192958
Epoch loss: 16.192958
train phase, Epoch 8/20, Loss: 16.377099
val phase, Epoch 8/20, Loss: 16.283747
Val Best Loss: 16.192958
Epoch loss: 16.283747
train phase, Epoch 9/20, Loss: 16.285678
val phase, Epoch 9/20, Loss: 16.034478
Val Best Loss: 16.034478
Epoch loss: 16.034478
train phase, Epoch 10/20, Loss: 15.982730
val phase, Epoch 10/20, Loss: 16.338953
Val Best Loss: 16.034478
Epoch loss: 16.338953
train phase, Epoch 11/20, Loss: 16.035539
val phase, Epoch 11/20, Loss: 17.287171
Val Best Loss: 16.034478
Epoch loss: 17.287171
train phase, Epoch 12/20, Loss: 15.980229
val phase, Epoch 12/20, Loss: 17.469344
Val Best Loss: 16.034478
Epoch loss: 17.469344
train phase, Epoch 13/20, Loss: 15.687285
val phase, Epoch 13/20, Loss: 16.124253
Val Best Loss: 16.034478
Epoch loss: 16.124253
train phase, Epoch 14/20, Loss: 15.473202
val phase, Epoch 14/20, Loss: 16.055588
Val Best Loss: 16.034478
Epoch loss: 16.055588
train phase, Epoch 15/20, Loss: 15.485447
val phase, Epoch 15/20, Loss: 16.521220
Val Best Loss: 16.034478
Epoch loss: 16.521220
train phase, Epoch 16/20, Loss: 15.395587
val phase, Epoch 16/20, Loss: 17.122019
Val Best Loss: 16.034478
Epoch loss: 17.122019
train phase, Epoch 17/20, Loss: 14.945812
val phase, Epoch 17/20, Loss: 16.122475
Val Best Loss: 16.034478
Epoch loss: 16.122475
train phase, Epoch 18/20, Loss: 14.719528
val phase, Epoch 18/20, Loss: 16.669474
Val Best Loss: 16.034478
Epoch loss: 16.669474
train phase, Epoch 19/20, Loss: 14.534786
val phase, Epoch 19/20, Loss: 18.313377
Val Best Loss: 16.034478
Epoch loss: 18.313377
train phase, Epoch 20/20, Loss: 14.455371
val phase, Epoch 20/20, Loss: 16.346835
Val Best Loss: 16.034478
Epoch loss: 16.346835
train phase, Epoch 1/5, Loss: 20.232519
val phase, Epoch 1/5, Loss: 20.160270
Val Best Loss: 20.160270
Epoch loss: 20.160270
train phase, Epoch 2/5, Loss: 18.481793
val phase, Epoch 2/5, Loss: 17.198173
Val Best Loss: 17.198173
Epoch loss: 17.198173
train phase, Epoch 3/5, Loss: 17.843004
val phase, Epoch 3/5, Loss: 16.413809
Val Best Loss: 16.413809
Epoch loss: 16.413809
train phase, Epoch 4/5, Loss: 17.567794
val phase, Epoch 4/5, Loss: 17.712800
Val Best Loss: 16.413809
Epoch loss: 17.712800
train phase, Epoch 5/5, Loss: 17.004381
val phase, Epoch 5/5, Loss: 16.940041
Val Best Loss: 16.413809
Epoch loss: 16.940041
train phase, Epoch 1/20, Loss: 25.049983
val phase, Epoch 1/20, Loss: 22.634265
Val Best Loss: 22.634265
Epoch loss: 22.634265
train phase, Epoch 2/20, Loss: 19.382121
val phase, Epoch 2/20, Loss: 22.158762
Val Best Loss: 22.158762
Epoch loss: 22.158762
train phase, Epoch 3/20, Loss: 17.985478
val phase, Epoch 3/20, Loss: 17.365556
Val Best Loss: 17.365556
Epoch loss: 17.365556
train phase, Epoch 4/20, Loss: 17.538779
val phase, Epoch 4/20, Loss: 17.343313
Val Best Loss: 17.343313
Epoch loss: 17.343313
train phase, Epoch 5/20, Loss: 17.525229
val phase, Epoch 5/20, Loss: 19.715265
Val Best Loss: 17.343313
Epoch loss: 19.715265
train phase, Epoch 6/20, Loss: 17.253601
val phase, Epoch 6/20, Loss: 17.342060
Val Best Loss: 17.342060
Epoch loss: 17.342060
train phase, Epoch 7/20, Loss: 16.875005
val phase, Epoch 7/20, Loss: 17.168772
Val Best Loss: 17.168772
Epoch loss: 17.168772
train phase, Epoch 8/20, Loss: 16.730281
val phase, Epoch 8/20, Loss: 24.539440
Val Best Loss: 17.168772
Epoch loss: 24.539440
train phase, Epoch 9/20, Loss: 16.386756
val phase, Epoch 9/20, Loss: 16.783625
Val Best Loss: 16.783625
Epoch loss: 16.783625
train phase, Epoch 10/20, Loss: 16.291996
val phase, Epoch 10/20, Loss: 16.983877
Val Best Loss: 16.783625
Epoch loss: 16.983877
train phase, Epoch 11/20, Loss: 16.433379
val phase, Epoch 11/20, Loss: 18.258620
Val Best Loss: 16.783625
Epoch loss: 18.258620
train phase, Epoch 12/20, Loss: 16.200194
val phase, Epoch 12/20, Loss: 17.992232
Val Best Loss: 16.783625
Epoch loss: 17.992232
train phase, Epoch 13/20, Loss: 15.814105
val phase, Epoch 13/20, Loss: 17.154948
Val Best Loss: 16.783625
Epoch loss: 17.154948
train phase, Epoch 14/20, Loss: 15.531810
val phase, Epoch 14/20, Loss: 18.067329
Val Best Loss: 16.783625
Epoch loss: 18.067329
train phase, Epoch 15/20, Loss: 15.457096
val phase, Epoch 15/20, Loss: 18.564884
Val Best Loss: 16.783625
Epoch loss: 18.564884
train phase, Epoch 16/20, Loss: 15.189673
val phase, Epoch 16/20, Loss: 18.830119
Val Best Loss: 16.783625
Epoch loss: 18.830119
train phase, Epoch 17/20, Loss: 15.040401
val phase, Epoch 17/20, Loss: 18.284744
Val Best Loss: 16.783625
Epoch loss: 18.284744
train phase, Epoch 18/20, Loss: 14.949722
val phase, Epoch 18/20, Loss: 17.395142
Val Best Loss: 16.783625
Epoch loss: 17.395142
train phase, Epoch 19/20, Loss: 14.215319
val phase, Epoch 19/20, Loss: 17.581903
Val Best Loss: 16.783625
Epoch loss: 17.581903
train phase, Epoch 20/20, Loss: 14.500116
val phase, Epoch 20/20, Loss: 18.097897
Val Best Loss: 16.783625
Epoch loss: 18.097897
[Trial 376] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.607581
val phase, Epoch 1/20, Loss: 21.140692
Val Best Loss: 21.140692
Epoch loss: 21.140692
train phase, Epoch 2/20, Loss: 17.480777
val phase, Epoch 2/20, Loss: 16.912752
Val Best Loss: 16.912752
Epoch loss: 16.912752
train phase, Epoch 3/20, Loss: 17.446298
val phase, Epoch 3/20, Loss: 16.367763
Val Best Loss: 16.367763
Epoch loss: 16.367763
train phase, Epoch 4/20, Loss: 17.118933
val phase, Epoch 4/20, Loss: 16.694851
Val Best Loss: 16.367763
Epoch loss: 16.694851
train phase, Epoch 5/20, Loss: 16.759885
val phase, Epoch 5/20, Loss: 16.982486
Val Best Loss: 16.367763
Epoch loss: 16.982486
train phase, Epoch 6/20, Loss: 16.849133
val phase, Epoch 6/20, Loss: 16.121273
Val Best Loss: 16.121273
Epoch loss: 16.121273
train phase, Epoch 7/20, Loss: 16.382847
val phase, Epoch 7/20, Loss: 15.897220
Val Best Loss: 15.897220
Epoch loss: 15.897220
train phase, Epoch 8/20, Loss: 16.082915
val phase, Epoch 8/20, Loss: 17.935335
Val Best Loss: 15.897220
Epoch loss: 17.935335
train phase, Epoch 9/20, Loss: 16.111270
val phase, Epoch 9/20, Loss: 16.069847
Val Best Loss: 15.897220
Epoch loss: 16.069847
train phase, Epoch 10/20, Loss: 15.690013
val phase, Epoch 10/20, Loss: 16.067205
Val Best Loss: 15.897220
Epoch loss: 16.067205
train phase, Epoch 11/20, Loss: 15.770126
val phase, Epoch 11/20, Loss: 16.555506
Val Best Loss: 15.897220
Epoch loss: 16.555506
train phase, Epoch 12/20, Loss: 15.586979
val phase, Epoch 12/20, Loss: 15.925376
Val Best Loss: 15.897220
Epoch loss: 15.925376
train phase, Epoch 13/20, Loss: 15.454687
val phase, Epoch 13/20, Loss: 16.105611
Val Best Loss: 15.897220
Epoch loss: 16.105611
train phase, Epoch 14/20, Loss: 15.122224
val phase, Epoch 14/20, Loss: 16.629433
Val Best Loss: 15.897220
Epoch loss: 16.629433
train phase, Epoch 15/20, Loss: 14.886235
val phase, Epoch 15/20, Loss: 16.699502
Val Best Loss: 15.897220
Epoch loss: 16.699502
train phase, Epoch 16/20, Loss: 14.978407
val phase, Epoch 16/20, Loss: 15.973174
Val Best Loss: 15.897220
Epoch loss: 15.973174
train phase, Epoch 17/20, Loss: 14.474051
val phase, Epoch 17/20, Loss: 16.837712
Val Best Loss: 15.897220
Epoch loss: 16.837712
train phase, Epoch 18/20, Loss: 14.369871
val phase, Epoch 18/20, Loss: 16.503096
Val Best Loss: 15.897220
Epoch loss: 16.503096
train phase, Epoch 19/20, Loss: 14.046929
val phase, Epoch 19/20, Loss: 17.049377
Val Best Loss: 15.897220
Epoch loss: 17.049377
train phase, Epoch 20/20, Loss: 13.885152
val phase, Epoch 20/20, Loss: 16.415095
Val Best Loss: 15.897220
Epoch loss: 16.415095
[Trial 378] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.210334
val phase, Epoch 1/20, Loss: 18.337076
Val Best Loss: 18.337076
Epoch loss: 18.337076
train phase, Epoch 2/20, Loss: 18.023922
val phase, Epoch 2/20, Loss: 18.242434
Val Best Loss: 18.242434
Epoch loss: 18.242434
train phase, Epoch 3/20, Loss: 17.419145
val phase, Epoch 3/20, Loss: 16.546311
Val Best Loss: 16.546311
Epoch loss: 16.546311
train phase, Epoch 4/20, Loss: 17.023356
val phase, Epoch 4/20, Loss: 16.653540
Val Best Loss: 16.546311
Epoch loss: 16.653540
train phase, Epoch 5/20, Loss: 17.165962
val phase, Epoch 5/20, Loss: 16.310794
Val Best Loss: 16.310794
Epoch loss: 16.310794
train phase, Epoch 6/20, Loss: 16.777423
val phase, Epoch 6/20, Loss: 17.588424
Val Best Loss: 16.310794
Epoch loss: 17.588424
train phase, Epoch 7/20, Loss: 16.372763
val phase, Epoch 7/20, Loss: 16.584826
Val Best Loss: 16.310794
Epoch loss: 16.584826
train phase, Epoch 8/20, Loss: 16.207018
val phase, Epoch 8/20, Loss: 16.344662
Val Best Loss: 16.310794
Epoch loss: 16.344662
train phase, Epoch 9/20, Loss: 15.862468
val phase, Epoch 9/20, Loss: 16.687628
Val Best Loss: 16.310794
Epoch loss: 16.687628
train phase, Epoch 10/20, Loss: 16.029432
val phase, Epoch 10/20, Loss: 16.034078
Val Best Loss: 16.034078
Epoch loss: 16.034078
train phase, Epoch 11/20, Loss: 15.773944
val phase, Epoch 11/20, Loss: 16.576891
Val Best Loss: 16.034078
Epoch loss: 16.576891
train phase, Epoch 12/20, Loss: 15.561734
val phase, Epoch 12/20, Loss: 15.762849
Val Best Loss: 15.762849
Epoch loss: 15.762849
train phase, Epoch 13/20, Loss: 15.589682
val phase, Epoch 13/20, Loss: 16.851213
Val Best Loss: 15.762849
Epoch loss: 16.851213
train phase, Epoch 14/20, Loss: 15.249522
val phase, Epoch 14/20, Loss: 16.131249
Val Best Loss: 15.762849
Epoch loss: 16.131249
train phase, Epoch 15/20, Loss: 15.029365
val phase, Epoch 15/20, Loss: 16.431327
Val Best Loss: 15.762849
Epoch loss: 16.431327
train phase, Epoch 16/20, Loss: 14.858867
val phase, Epoch 16/20, Loss: 17.193728
Val Best Loss: 15.762849
Epoch loss: 17.193728
train phase, Epoch 17/20, Loss: 14.883450
val phase, Epoch 17/20, Loss: 17.199811
Val Best Loss: 15.762849
Epoch loss: 17.199811
train phase, Epoch 18/20, Loss: 14.310625
val phase, Epoch 18/20, Loss: 16.085337
Val Best Loss: 15.762849
Epoch loss: 16.085337
train phase, Epoch 19/20, Loss: 14.212376
val phase, Epoch 19/20, Loss: 18.660881
Val Best Loss: 15.762849
Epoch loss: 18.660881
train phase, Epoch 20/20, Loss: 13.993843
val phase, Epoch 20/20, Loss: 16.716311
Val Best Loss: 15.762849
Epoch loss: 16.716311
[Trial 380] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/20, Loss: 21.109055
val phase, Epoch 1/20, Loss: 17.827819
Val Best Loss: 17.827819
Epoch loss: 17.827819
train phase, Epoch 2/20, Loss: 18.439664
val phase, Epoch 2/20, Loss: 16.773789
Val Best Loss: 16.773789
Epoch loss: 16.773789
train phase, Epoch 3/20, Loss: 18.083909
val phase, Epoch 3/20, Loss: 16.604669
Val Best Loss: 16.604669
Epoch loss: 16.604669
train phase, Epoch 4/20, Loss: 17.416040
val phase, Epoch 4/20, Loss: 19.385980
Val Best Loss: 16.604669
Epoch loss: 19.385980
train phase, Epoch 5/20, Loss: 17.248239
val phase, Epoch 5/20, Loss: 17.099006
Val Best Loss: 16.604669
Epoch loss: 17.099006
train phase, Epoch 6/20, Loss: 16.981393
val phase, Epoch 6/20, Loss: 25.714959
Val Best Loss: 16.604669
Epoch loss: 25.714959
train phase, Epoch 7/20, Loss: 17.041652
val phase, Epoch 7/20, Loss: 16.472487
Val Best Loss: 16.472487
Epoch loss: 16.472487
train phase, Epoch 8/20, Loss: 16.900138
val phase, Epoch 8/20, Loss: 16.332382
Val Best Loss: 16.332382
Epoch loss: 16.332382
train phase, Epoch 9/20, Loss: 16.164286
val phase, Epoch 9/20, Loss: 16.397271
Val Best Loss: 16.332382
Epoch loss: 16.397271
train phase, Epoch 10/20, Loss: 16.235460
val phase, Epoch 10/20, Loss: 16.722314
Val Best Loss: 16.332382
Epoch loss: 16.722314
train phase, Epoch 11/20, Loss: 16.300449
val phase, Epoch 11/20, Loss: 16.172132
Val Best Loss: 16.172132
Epoch loss: 16.172132
train phase, Epoch 12/20, Loss: 16.121093
val phase, Epoch 12/20, Loss: 16.799909
Val Best Loss: 16.172132
Epoch loss: 16.799909
train phase, Epoch 13/20, Loss: 15.966923
val phase, Epoch 13/20, Loss: 16.379104
Val Best Loss: 16.172132
Epoch loss: 16.379104
train phase, Epoch 14/20, Loss: 15.603089
val phase, Epoch 14/20, Loss: 16.528128
Val Best Loss: 16.172132
Epoch loss: 16.528128
train phase, Epoch 15/20, Loss: 15.537021
val phase, Epoch 15/20, Loss: 16.952846
Val Best Loss: 16.172132
Epoch loss: 16.952846
train phase, Epoch 16/20, Loss: 15.675874
val phase, Epoch 16/20, Loss: 16.433227
Val Best Loss: 16.172132
Epoch loss: 16.433227
train phase, Epoch 17/20, Loss: 15.401759
val phase, Epoch 17/20, Loss: 18.300332
Val Best Loss: 16.172132
Epoch loss: 18.300332
train phase, Epoch 18/20, Loss: 14.929174
val phase, Epoch 18/20, Loss: 16.753435
Val Best Loss: 16.172132
Epoch loss: 16.753435
train phase, Epoch 19/20, Loss: 14.994351
val phase, Epoch 19/20, Loss: 16.313943
Val Best Loss: 16.172132
Epoch loss: 16.313943
train phase, Epoch 20/20, Loss: 14.708049
val phase, Epoch 20/20, Loss: 16.599790
Val Best Loss: 16.172132
Epoch loss: 16.599790
train phase, Epoch 1/20, Loss: 20.096102
val phase, Epoch 1/20, Loss: 18.249445
Val Best Loss: 18.249445
Epoch loss: 18.249445
train phase, Epoch 2/20, Loss: 17.810783
val phase, Epoch 2/20, Loss: 19.920201
Val Best Loss: 18.249445
Epoch loss: 19.920201
train phase, Epoch 3/20, Loss: 17.382560
val phase, Epoch 3/20, Loss: 18.856672
Val Best Loss: 18.249445
Epoch loss: 18.856672
train phase, Epoch 4/20, Loss: 17.180142
val phase, Epoch 4/20, Loss: 16.587447
Val Best Loss: 16.587447
Epoch loss: 16.587447
train phase, Epoch 5/20, Loss: 16.678829
val phase, Epoch 5/20, Loss: 18.604793
Val Best Loss: 16.587447
Epoch loss: 18.604793
train phase, Epoch 6/20, Loss: 16.598709
val phase, Epoch 6/20, Loss: 18.207396
Val Best Loss: 16.587447
Epoch loss: 18.207396
train phase, Epoch 7/20, Loss: 16.513064
val phase, Epoch 7/20, Loss: 16.561819
Val Best Loss: 16.561819
Epoch loss: 16.561819
train phase, Epoch 8/20, Loss: 16.389794
val phase, Epoch 8/20, Loss: 16.200006
Val Best Loss: 16.200006
Epoch loss: 16.200006
train phase, Epoch 9/20, Loss: 16.112125
val phase, Epoch 9/20, Loss: 17.468086
Val Best Loss: 16.200006
Epoch loss: 17.468086
train phase, Epoch 10/20, Loss: 15.901507
val phase, Epoch 10/20, Loss: 16.017822
Val Best Loss: 16.017822
Epoch loss: 16.017822
train phase, Epoch 11/20, Loss: 16.014477
val phase, Epoch 11/20, Loss: 16.795393
Val Best Loss: 16.017822
Epoch loss: 16.795393
train phase, Epoch 12/20, Loss: 15.634367
val phase, Epoch 12/20, Loss: 16.165642
Val Best Loss: 16.017822
Epoch loss: 16.165642
train phase, Epoch 13/20, Loss: 15.698657
val phase, Epoch 13/20, Loss: 16.924767
Val Best Loss: 16.017822
Epoch loss: 16.924767
train phase, Epoch 14/20, Loss: 15.406769
val phase, Epoch 14/20, Loss: 15.649251
Val Best Loss: 15.649251
Epoch loss: 15.649251
train phase, Epoch 15/20, Loss: 15.184863
val phase, Epoch 15/20, Loss: 16.830733
Val Best Loss: 15.649251
Epoch loss: 16.830733
train phase, Epoch 16/20, Loss: 15.142028
val phase, Epoch 16/20, Loss: 15.991565
Val Best Loss: 15.649251
Epoch loss: 15.991565
train phase, Epoch 17/20, Loss: 14.735486
val phase, Epoch 17/20, Loss: 16.426086
Val Best Loss: 15.649251
Epoch loss: 16.426086
train phase, Epoch 18/20, Loss: 14.453399
val phase, Epoch 18/20, Loss: 17.095689
Val Best Loss: 15.649251
Epoch loss: 17.095689
train phase, Epoch 19/20, Loss: 14.416137
val phase, Epoch 19/20, Loss: 16.574243
Val Best Loss: 15.649251
Epoch loss: 16.574243
train phase, Epoch 20/20, Loss: 13.771537
val phase, Epoch 20/20, Loss: 17.053054
Val Best Loss: 15.649251
Epoch loss: 17.053054
train phase, Epoch 1/20, Loss: 19.654312
val phase, Epoch 1/20, Loss: 17.088767
Val Best Loss: 17.088767
Epoch loss: 17.088767
train phase, Epoch 2/20, Loss: 17.854503
val phase, Epoch 2/20, Loss: 17.294073
Val Best Loss: 17.088767
Epoch loss: 17.294073
train phase, Epoch 3/20, Loss: 17.099175
val phase, Epoch 3/20, Loss: 17.936136
Val Best Loss: 17.088767
Epoch loss: 17.936136
train phase, Epoch 4/20, Loss: 17.104650
val phase, Epoch 4/20, Loss: 17.000877
Val Best Loss: 17.000877
Epoch loss: 17.000877
train phase, Epoch 5/20, Loss: 16.717455
val phase, Epoch 5/20, Loss: 16.423576
Val Best Loss: 16.423576
Epoch loss: 16.423576
train phase, Epoch 6/20, Loss: 16.731664
val phase, Epoch 6/20, Loss: 16.432235
Val Best Loss: 16.423576
Epoch loss: 16.432235
train phase, Epoch 7/20, Loss: 16.386233
val phase, Epoch 7/20, Loss: 16.123293
Val Best Loss: 16.123293
Epoch loss: 16.123293
train phase, Epoch 8/20, Loss: 16.254613
val phase, Epoch 8/20, Loss: 16.426912
Val Best Loss: 16.123293
Epoch loss: 16.426912
train phase, Epoch 9/20, Loss: 16.173869
val phase, Epoch 9/20, Loss: 16.387161
Val Best Loss: 16.123293
Epoch loss: 16.387161
train phase, Epoch 10/20, Loss: 15.919398
val phase, Epoch 10/20, Loss: 16.120955
Val Best Loss: 16.120955
Epoch loss: 16.120955
train phase, Epoch 11/20, Loss: 15.881932
val phase, Epoch 11/20, Loss: 16.066744
Val Best Loss: 16.066744
Epoch loss: 16.066744
train phase, Epoch 12/20, Loss: 15.630154
val phase, Epoch 12/20, Loss: 16.300460
Val Best Loss: 16.066744
Epoch loss: 16.300460
train phase, Epoch 13/20, Loss: 15.211319
val phase, Epoch 13/20, Loss: 17.289493
Val Best Loss: 16.066744
Epoch loss: 17.289493
train phase, Epoch 14/20, Loss: 15.271875
val phase, Epoch 14/20, Loss: 16.873455
Val Best Loss: 16.066744
Epoch loss: 16.873455
train phase, Epoch 15/20, Loss: 15.265532
val phase, Epoch 15/20, Loss: 17.628408
Val Best Loss: 16.066744
Epoch loss: 17.628408
train phase, Epoch 16/20, Loss: 14.753445
val phase, Epoch 16/20, Loss: 16.204183
Val Best Loss: 16.066744
Epoch loss: 16.204183
train phase, Epoch 17/20, Loss: 14.427011
val phase, Epoch 17/20, Loss: 15.877463
Val Best Loss: 15.877463
Epoch loss: 15.877463
train phase, Epoch 18/20, Loss: 14.242435
val phase, Epoch 18/20, Loss: 16.090151
Val Best Loss: 15.877463
Epoch loss: 16.090151
train phase, Epoch 19/20, Loss: 13.928205
val phase, Epoch 19/20, Loss: 17.557605
Val Best Loss: 15.877463
Epoch loss: 17.557605
train phase, Epoch 20/20, Loss: 13.859777
val phase, Epoch 20/20, Loss: 18.754843
Val Best Loss: 15.877463
Epoch loss: 18.754843
train phase, Epoch 1/30, Loss: 21.029826
val phase, Epoch 1/30, Loss: 19.274846
Val Best Loss: 19.274846
Epoch loss: 19.274846
train phase, Epoch 2/30, Loss: 18.163994
val phase, Epoch 2/30, Loss: 17.328631
Val Best Loss: 17.328631
Epoch loss: 17.328631
train phase, Epoch 3/30, Loss: 17.910186
val phase, Epoch 3/30, Loss: 16.544182
Val Best Loss: 16.544182
Epoch loss: 16.544182
train phase, Epoch 4/30, Loss: 17.424226
val phase, Epoch 4/30, Loss: 17.008597
Val Best Loss: 16.544182
Epoch loss: 17.008597
train phase, Epoch 5/30, Loss: 17.122518
val phase, Epoch 5/30, Loss: 17.019427
Val Best Loss: 16.544182
Epoch loss: 17.019427
train phase, Epoch 6/30, Loss: 16.777542
val phase, Epoch 6/30, Loss: 16.125365
Val Best Loss: 16.125365
Epoch loss: 16.125365
train phase, Epoch 7/30, Loss: 16.483605
val phase, Epoch 7/30, Loss: 16.274360
Val Best Loss: 16.125365
Epoch loss: 16.274360
train phase, Epoch 8/30, Loss: 16.494229
val phase, Epoch 8/30, Loss: 16.398122
Val Best Loss: 16.125365
Epoch loss: 16.398122
train phase, Epoch 9/30, Loss: 16.505005
val phase, Epoch 9/30, Loss: 18.990822
Val Best Loss: 16.125365
Epoch loss: 18.990822
train phase, Epoch 10/30, Loss: 16.201632
val phase, Epoch 10/30, Loss: 15.914740
Val Best Loss: 15.914740
Epoch loss: 15.914740
train phase, Epoch 11/30, Loss: 16.299042
val phase, Epoch 11/30, Loss: 15.986871
Val Best Loss: 15.914740
Epoch loss: 15.986871
train phase, Epoch 12/30, Loss: 15.992501
val phase, Epoch 12/30, Loss: 15.915984
Val Best Loss: 15.914740
Epoch loss: 15.915984
train phase, Epoch 13/30, Loss: 15.818524
val phase, Epoch 13/30, Loss: 16.189216
Val Best Loss: 15.914740
Epoch loss: 16.189216
train phase, Epoch 14/30, Loss: 15.668603
val phase, Epoch 14/30, Loss: 18.964126
Val Best Loss: 15.914740
Epoch loss: 18.964126
train phase, Epoch 15/30, Loss: 15.557643
val phase, Epoch 15/30, Loss: 16.414752
Val Best Loss: 15.914740
Epoch loss: 16.414752
train phase, Epoch 16/30, Loss: 15.265954
val phase, Epoch 16/30, Loss: 15.981152
Val Best Loss: 15.914740
Epoch loss: 15.981152
train phase, Epoch 17/30, Loss: 14.919001
val phase, Epoch 17/30, Loss: 16.178918
Val Best Loss: 15.914740
Epoch loss: 16.178918
train phase, Epoch 18/30, Loss: 14.918626
val phase, Epoch 18/30, Loss: 16.839208
Val Best Loss: 15.914740
Epoch loss: 16.839208
train phase, Epoch 19/30, Loss: 14.925695
val phase, Epoch 19/30, Loss: 16.524749
Val Best Loss: 15.914740
Epoch loss: 16.524749
train phase, Epoch 20/30, Loss: 14.545751
val phase, Epoch 20/30, Loss: 16.329837
Val Best Loss: 15.914740
Epoch loss: 16.329837
train phase, Epoch 21/30, Loss: 14.261054
val phase, Epoch 21/30, Loss: 16.398134
Val Best Loss: 15.914740
Epoch loss: 16.398134
train phase, Epoch 22/30, Loss: 13.993015
val phase, Epoch 22/30, Loss: 17.034407
Val Best Loss: 15.914740
Epoch loss: 17.034407
train phase, Epoch 23/30, Loss: 13.774678
val phase, Epoch 23/30, Loss: 17.434752
Val Best Loss: 15.914740
Epoch loss: 17.434752
train phase, Epoch 24/30, Loss: 13.569881
val phase, Epoch 24/30, Loss: 18.118399
Val Best Loss: 15.914740
Epoch loss: 18.118399
train phase, Epoch 25/30, Loss: 13.142633
val phase, Epoch 25/30, Loss: 17.953193
Val Best Loss: 15.914740
Epoch loss: 17.953193
train phase, Epoch 26/30, Loss: 12.936344
val phase, Epoch 26/30, Loss: 17.997555
Val Best Loss: 15.914740
Epoch loss: 17.997555
train phase, Epoch 27/30, Loss: 13.080930
val phase, Epoch 27/30, Loss: 18.470789
Val Best Loss: 15.914740
Epoch loss: 18.470789
train phase, Epoch 28/30, Loss: 12.264644
val phase, Epoch 28/30, Loss: 17.561222
Val Best Loss: 15.914740
Epoch loss: 17.561222
train phase, Epoch 29/30, Loss: 11.926397
val phase, Epoch 29/30, Loss: 18.081939
Val Best Loss: 15.914740
Epoch loss: 18.081939
train phase, Epoch 30/30, Loss: 11.646387
val phase, Epoch 30/30, Loss: 17.494709
Val Best Loss: 15.914740
Epoch loss: 17.494709
train phase, Epoch 1/20, Loss: 23.700000
val phase, Epoch 1/20, Loss: 19.425762
Val Best Loss: 19.425762
Epoch loss: 19.425762
train phase, Epoch 2/20, Loss: 18.917706
val phase, Epoch 2/20, Loss: 22.551720
Val Best Loss: 19.425762
Epoch loss: 22.551720
train phase, Epoch 3/20, Loss: 18.859633
val phase, Epoch 3/20, Loss: 18.384482
Val Best Loss: 18.384482
Epoch loss: 18.384482
train phase, Epoch 4/20, Loss: 18.580348
val phase, Epoch 4/20, Loss: 17.113619
Val Best Loss: 17.113619
Epoch loss: 17.113619
train phase, Epoch 5/20, Loss: 18.266614
val phase, Epoch 5/20, Loss: 17.315839
Val Best Loss: 17.113619
Epoch loss: 17.315839
train phase, Epoch 6/20, Loss: 17.758267
val phase, Epoch 6/20, Loss: 16.883644
Val Best Loss: 16.883644
Epoch loss: 16.883644
train phase, Epoch 7/20, Loss: 17.730174
val phase, Epoch 7/20, Loss: 19.893468
Val Best Loss: 16.883644
Epoch loss: 19.893468
train phase, Epoch 8/20, Loss: 17.525034
val phase, Epoch 8/20, Loss: 16.816352
Val Best Loss: 16.816352
Epoch loss: 16.816352
train phase, Epoch 9/20, Loss: 17.298070
val phase, Epoch 9/20, Loss: 17.046161
Val Best Loss: 16.816352
Epoch loss: 17.046161
train phase, Epoch 10/20, Loss: 17.101120
val phase, Epoch 10/20, Loss: 16.607214
Val Best Loss: 16.607214
Epoch loss: 16.607214
train phase, Epoch 11/20, Loss: 16.936062
val phase, Epoch 11/20, Loss: 16.635124
Val Best Loss: 16.607214
Epoch loss: 16.635124
train phase, Epoch 12/20, Loss: 16.793364
val phase, Epoch 12/20, Loss: 17.426891
Val Best Loss: 16.607214
Epoch loss: 17.426891
train phase, Epoch 13/20, Loss: 16.734539
val phase, Epoch 13/20, Loss: 16.170918
Val Best Loss: 16.170918
Epoch loss: 16.170918
train phase, Epoch 14/20, Loss: 16.618357
val phase, Epoch 14/20, Loss: 17.233284
Val Best Loss: 16.170918
Epoch loss: 17.233284
train phase, Epoch 15/20, Loss: 16.555956
val phase, Epoch 15/20, Loss: 16.765113
Val Best Loss: 16.170918
Epoch loss: 16.765113
train phase, Epoch 16/20, Loss: 16.444952
val phase, Epoch 16/20, Loss: 17.295903
Val Best Loss: 16.170918
Epoch loss: 17.295903
train phase, Epoch 17/20, Loss: 16.360649
val phase, Epoch 17/20, Loss: 16.451644
Val Best Loss: 16.170918
Epoch loss: 16.451644
train phase, Epoch 18/20, Loss: 16.372172
val phase, Epoch 18/20, Loss: 16.893390
Val Best Loss: 16.170918
Epoch loss: 16.893390
train phase, Epoch 19/20, Loss: 16.380143
val phase, Epoch 19/20, Loss: 17.061763
Val Best Loss: 16.170918
Epoch loss: 17.061763
train phase, Epoch 20/20, Loss: 16.014524
val phase, Epoch 20/20, Loss: 17.199740
Val Best Loss: 16.170918
Epoch loss: 17.199740
train phase, Epoch 1/20, Loss: 19.844672
val phase, Epoch 1/20, Loss: 17.500456
Val Best Loss: 17.500456
Epoch loss: 17.500456
train phase, Epoch 2/20, Loss: 17.589704
val phase, Epoch 2/20, Loss: 16.767459
Val Best Loss: 16.767459
Epoch loss: 16.767459
train phase, Epoch 3/20, Loss: 17.114464
val phase, Epoch 3/20, Loss: 17.081542
Val Best Loss: 16.767459
Epoch loss: 17.081542
train phase, Epoch 4/20, Loss: 16.834206
val phase, Epoch 4/20, Loss: 16.550906
Val Best Loss: 16.550906
Epoch loss: 16.550906
train phase, Epoch 5/20, Loss: 16.445258
val phase, Epoch 5/20, Loss: 16.891212
Val Best Loss: 16.550906
Epoch loss: 16.891212
train phase, Epoch 6/20, Loss: 16.430901
val phase, Epoch 6/20, Loss: 16.639368
Val Best Loss: 16.550906
Epoch loss: 16.639368
train phase, Epoch 7/20, Loss: 16.405889
val phase, Epoch 7/20, Loss: 16.175252
Val Best Loss: 16.175252
Epoch loss: 16.175252
train phase, Epoch 8/20, Loss: 16.153770
val phase, Epoch 8/20, Loss: 16.570769
Val Best Loss: 16.175252
Epoch loss: 16.570769
train phase, Epoch 9/20, Loss: 15.788076
val phase, Epoch 9/20, Loss: 16.297904
Val Best Loss: 16.175252
Epoch loss: 16.297904
train phase, Epoch 10/20, Loss: 15.896054
val phase, Epoch 10/20, Loss: 16.158457
Val Best Loss: 16.158457
Epoch loss: 16.158457
train phase, Epoch 11/20, Loss: 15.459606
val phase, Epoch 11/20, Loss: 16.015687
Val Best Loss: 16.015687
Epoch loss: 16.015687
train phase, Epoch 12/20, Loss: 15.305752
val phase, Epoch 12/20, Loss: 16.120671
Val Best Loss: 16.015687
Epoch loss: 16.120671
train phase, Epoch 13/20, Loss: 15.167377
val phase, Epoch 13/20, Loss: 16.043321
Val Best Loss: 16.015687
Epoch loss: 16.043321
train phase, Epoch 14/20, Loss: 14.963513
val phase, Epoch 14/20, Loss: 16.219219
Val Best Loss: 16.015687
Epoch loss: 16.219219
train phase, Epoch 15/20, Loss: 14.747108
val phase, Epoch 15/20, Loss: 16.537774
Val Best Loss: 16.015687
Epoch loss: 16.537774
train phase, Epoch 16/20, Loss: 14.450908
val phase, Epoch 16/20, Loss: 16.392909
Val Best Loss: 16.015687
Epoch loss: 16.392909
train phase, Epoch 17/20, Loss: 14.112738
val phase, Epoch 17/20, Loss: 18.906504
Val Best Loss: 16.015687
Epoch loss: 18.906504
train phase, Epoch 18/20, Loss: 13.782860
val phase, Epoch 18/20, Loss: 17.159345
Val Best Loss: 16.015687
Epoch loss: 17.159345
train phase, Epoch 19/20, Loss: 13.473022
val phase, Epoch 19/20, Loss: 16.799172
Val Best Loss: 16.015687
Epoch loss: 16.799172
train phase, Epoch 20/20, Loss: 13.169384
val phase, Epoch 20/20, Loss: 17.592398
Val Best Loss: 16.015687
Epoch loss: 17.592398
train phase, Epoch 1/20, Loss: 20.753543
val phase, Epoch 1/20, Loss: 17.280209
Val Best Loss: 17.280209
Epoch loss: 17.280209
train phase, Epoch 2/20, Loss: 17.554637
val phase, Epoch 2/20, Loss: 17.466427
Val Best Loss: 17.280209
Epoch loss: 17.466427
train phase, Epoch 3/20, Loss: 17.043251
val phase, Epoch 3/20, Loss: 16.462511
Val Best Loss: 16.462511
Epoch loss: 16.462511
train phase, Epoch 4/20, Loss: 16.960902
val phase, Epoch 4/20, Loss: 18.710761
Val Best Loss: 16.462511
Epoch loss: 18.710761
train phase, Epoch 5/20, Loss: 16.902817
val phase, Epoch 5/20, Loss: 18.148705
Val Best Loss: 16.462511
Epoch loss: 18.148705
train phase, Epoch 6/20, Loss: 16.333110
val phase, Epoch 6/20, Loss: 16.951513
Val Best Loss: 16.462511
Epoch loss: 16.951513
train phase, Epoch 7/20, Loss: 16.084827
val phase, Epoch 7/20, Loss: 16.320610
Val Best Loss: 16.320610
Epoch loss: 16.320610
train phase, Epoch 8/20, Loss: 16.046424
val phase, Epoch 8/20, Loss: 16.615268
Val Best Loss: 16.320610
Epoch loss: 16.615268
train phase, Epoch 9/20, Loss: 15.898471
val phase, Epoch 9/20, Loss: 15.783071
Val Best Loss: 15.783071
Epoch loss: 15.783071
train phase, Epoch 10/20, Loss: 15.832516
val phase, Epoch 10/20, Loss: 16.946769
Val Best Loss: 15.783071
Epoch loss: 16.946769
train phase, Epoch 11/20, Loss: 15.554718
val phase, Epoch 11/20, Loss: 16.002628
Val Best Loss: 15.783071
Epoch loss: 16.002628
train phase, Epoch 12/20, Loss: 15.364190
val phase, Epoch 12/20, Loss: 16.123356
Val Best Loss: 15.783071
Epoch loss: 16.123356
train phase, Epoch 13/20, Loss: 15.347314
val phase, Epoch 13/20, Loss: 15.582724
Val Best Loss: 15.582724
Epoch loss: 15.582724
train phase, Epoch 14/20, Loss: 15.178030
val phase, Epoch 14/20, Loss: 15.810082
Val Best Loss: 15.582724
Epoch loss: 15.810082
train phase, Epoch 15/20, Loss: 14.982660
val phase, Epoch 15/20, Loss: 16.174788
Val Best Loss: 15.582724
Epoch loss: 16.174788
train phase, Epoch 16/20, Loss: 14.462755
val phase, Epoch 16/20, Loss: 15.772926
Val Best Loss: 15.582724
Epoch loss: 15.772926
train phase, Epoch 17/20, Loss: 14.407512
val phase, Epoch 17/20, Loss: 15.837539
Val Best Loss: 15.582724
Epoch loss: 15.837539
train phase, Epoch 18/20, Loss: 14.123593
val phase, Epoch 18/20, Loss: 16.556329
Val Best Loss: 15.582724
Epoch loss: 16.556329
train phase, Epoch 19/20, Loss: 13.935018
val phase, Epoch 19/20, Loss: 16.383779
Val Best Loss: 15.582724
Epoch loss: 16.383779
train phase, Epoch 20/20, Loss: 13.617533
val phase, Epoch 20/20, Loss: 16.299393
Val Best Loss: 15.582724
Epoch loss: 16.299393
[Trial 388] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 21.795915
val phase, Epoch 1/20, Loss: 17.153835
Val Best Loss: 17.153835
Epoch loss: 17.153835
train phase, Epoch 2/20, Loss: 17.792719
val phase, Epoch 2/20, Loss: 16.609452
Val Best Loss: 16.609452
Epoch loss: 16.609452
train phase, Epoch 3/20, Loss: 17.744338
val phase, Epoch 3/20, Loss: 16.771178
Val Best Loss: 16.609452
Epoch loss: 16.771178
train phase, Epoch 4/20, Loss: 17.520634
val phase, Epoch 4/20, Loss: 16.410851
Val Best Loss: 16.410851
Epoch loss: 16.410851
train phase, Epoch 5/20, Loss: 17.391585
val phase, Epoch 5/20, Loss: 16.570336
Val Best Loss: 16.410851
Epoch loss: 16.570336
train phase, Epoch 6/20, Loss: 16.946185
val phase, Epoch 6/20, Loss: 16.482312
Val Best Loss: 16.410851
Epoch loss: 16.482312
train phase, Epoch 7/20, Loss: 16.727269
val phase, Epoch 7/20, Loss: 16.032582
Val Best Loss: 16.032582
Epoch loss: 16.032582
train phase, Epoch 8/20, Loss: 16.605330
val phase, Epoch 8/20, Loss: 15.861311
Val Best Loss: 15.861311
Epoch loss: 15.861311
train phase, Epoch 9/20, Loss: 16.383803
val phase, Epoch 9/20, Loss: 17.564175
Val Best Loss: 15.861311
Epoch loss: 17.564175
train phase, Epoch 10/20, Loss: 16.516993
val phase, Epoch 10/20, Loss: 18.203475
Val Best Loss: 15.861311
Epoch loss: 18.203475
train phase, Epoch 11/20, Loss: 16.254718
val phase, Epoch 11/20, Loss: 17.621606
Val Best Loss: 15.861311
Epoch loss: 17.621606
train phase, Epoch 12/20, Loss: 16.091487
val phase, Epoch 12/20, Loss: 16.319317
Val Best Loss: 15.861311
Epoch loss: 16.319317
train phase, Epoch 13/20, Loss: 16.491932
val phase, Epoch 13/20, Loss: 17.278240
Val Best Loss: 15.861311
Epoch loss: 17.278240
train phase, Epoch 14/20, Loss: 15.869181
val phase, Epoch 14/20, Loss: 17.096423
Val Best Loss: 15.861311
Epoch loss: 17.096423
train phase, Epoch 15/20, Loss: 15.926233
val phase, Epoch 15/20, Loss: 15.934653
Val Best Loss: 15.861311
Epoch loss: 15.934653
train phase, Epoch 16/20, Loss: 15.661158
val phase, Epoch 16/20, Loss: 15.915581
Val Best Loss: 15.861311
Epoch loss: 15.915581
train phase, Epoch 17/20, Loss: 15.604388
val phase, Epoch 17/20, Loss: 16.291168
Val Best Loss: 15.861311
Epoch loss: 16.291168
train phase, Epoch 18/20, Loss: 15.656063
val phase, Epoch 18/20, Loss: 17.049960
Val Best Loss: 15.861311
Epoch loss: 17.049960
train phase, Epoch 19/20, Loss: 15.264971
val phase, Epoch 19/20, Loss: 16.380244
Val Best Loss: 15.861311
Epoch loss: 16.380244
train phase, Epoch 20/20, Loss: 15.021836
val phase, Epoch 20/20, Loss: 16.089797
Val Best Loss: 15.861311
Epoch loss: 16.089797
train phase, Epoch 1/20, Loss: 20.228708
val phase, Epoch 1/20, Loss: 17.592120
Val Best Loss: 17.592120
Epoch loss: 17.592120
train phase, Epoch 2/20, Loss: 17.525061
val phase, Epoch 2/20, Loss: 17.834674
Val Best Loss: 17.592120
Epoch loss: 17.834674
train phase, Epoch 3/20, Loss: 17.045038
val phase, Epoch 3/20, Loss: 17.130467
Val Best Loss: 17.130467
Epoch loss: 17.130467
train phase, Epoch 4/20, Loss: 16.856480
val phase, Epoch 4/20, Loss: 16.815747
Val Best Loss: 16.815747
Epoch loss: 16.815747
train phase, Epoch 5/20, Loss: 16.536845
val phase, Epoch 5/20, Loss: 17.755666
Val Best Loss: 16.815747
Epoch loss: 17.755666
train phase, Epoch 6/20, Loss: 16.677580
val phase, Epoch 6/20, Loss: 17.462415
Val Best Loss: 16.815747
Epoch loss: 17.462415
train phase, Epoch 7/20, Loss: 16.479242
val phase, Epoch 7/20, Loss: 18.059370
Val Best Loss: 16.815747
Epoch loss: 18.059370
train phase, Epoch 8/20, Loss: 16.271648
val phase, Epoch 8/20, Loss: 16.810638
Val Best Loss: 16.810638
Epoch loss: 16.810638
train phase, Epoch 9/20, Loss: 16.169953
val phase, Epoch 9/20, Loss: 16.177263
Val Best Loss: 16.177263
Epoch loss: 16.177263
train phase, Epoch 10/20, Loss: 15.580161
val phase, Epoch 10/20, Loss: 16.557311
Val Best Loss: 16.177263
Epoch loss: 16.557311
train phase, Epoch 11/20, Loss: 15.914416
val phase, Epoch 11/20, Loss: 18.398453
Val Best Loss: 16.177263
Epoch loss: 18.398453
train phase, Epoch 12/20, Loss: 15.673567
val phase, Epoch 12/20, Loss: 16.273150
Val Best Loss: 16.177263
Epoch loss: 16.273150
train phase, Epoch 13/20, Loss: 15.737226
val phase, Epoch 13/20, Loss: 17.467732
Val Best Loss: 16.177263
Epoch loss: 17.467732
train phase, Epoch 14/20, Loss: 15.269580
val phase, Epoch 14/20, Loss: 16.424923
Val Best Loss: 16.177263
Epoch loss: 16.424923
train phase, Epoch 15/20, Loss: 15.012483
val phase, Epoch 15/20, Loss: 16.477617
Val Best Loss: 16.177263
Epoch loss: 16.477617
train phase, Epoch 16/20, Loss: 14.879570
val phase, Epoch 16/20, Loss: 16.831651
Val Best Loss: 16.177263
Epoch loss: 16.831651
train phase, Epoch 17/20, Loss: 14.667843
val phase, Epoch 17/20, Loss: 15.842171
Val Best Loss: 15.842171
Epoch loss: 15.842171
train phase, Epoch 18/20, Loss: 14.483082
val phase, Epoch 18/20, Loss: 16.920656
Val Best Loss: 15.842171
Epoch loss: 16.920656
train phase, Epoch 19/20, Loss: 14.278473
val phase, Epoch 19/20, Loss: 16.811686
Val Best Loss: 15.842171
Epoch loss: 16.811686
train phase, Epoch 20/20, Loss: 13.727542
val phase, Epoch 20/20, Loss: 16.090893
Val Best Loss: 15.842171
Epoch loss: 16.090893
train phase, Epoch 1/15, Loss: 22.863509
val phase, Epoch 1/15, Loss: 18.858078
Val Best Loss: 18.858078
Epoch loss: 18.858078
train phase, Epoch 2/15, Loss: 18.985104
val phase, Epoch 2/15, Loss: 18.272575
Val Best Loss: 18.272575
Epoch loss: 18.272575
train phase, Epoch 3/15, Loss: 18.626076
val phase, Epoch 3/15, Loss: 17.231145
Val Best Loss: 17.231145
Epoch loss: 17.231145
train phase, Epoch 4/15, Loss: 18.567544
val phase, Epoch 4/15, Loss: 17.930661
Val Best Loss: 17.231145
Epoch loss: 17.930661
train phase, Epoch 5/15, Loss: 18.389731
val phase, Epoch 5/15, Loss: 17.652234
Val Best Loss: 17.231145
Epoch loss: 17.652234
train phase, Epoch 6/15, Loss: 18.247594
val phase, Epoch 6/15, Loss: 17.177731
Val Best Loss: 17.177731
Epoch loss: 17.177731
train phase, Epoch 7/15, Loss: 17.977693
val phase, Epoch 7/15, Loss: 20.638927
Val Best Loss: 17.177731
Epoch loss: 20.638927
train phase, Epoch 8/15, Loss: 18.181037
val phase, Epoch 8/15, Loss: 18.281820
Val Best Loss: 17.177731
Epoch loss: 18.281820
train phase, Epoch 9/15, Loss: 17.833514
val phase, Epoch 9/15, Loss: 19.243237
Val Best Loss: 17.177731
Epoch loss: 19.243237
train phase, Epoch 10/15, Loss: 17.964633
val phase, Epoch 10/15, Loss: 17.994556
Val Best Loss: 17.177731
Epoch loss: 17.994556
train phase, Epoch 11/15, Loss: 17.457001
val phase, Epoch 11/15, Loss: 17.559593
Val Best Loss: 17.177731
Epoch loss: 17.559593
train phase, Epoch 12/15, Loss: 17.360245
val phase, Epoch 12/15, Loss: 18.697123
Val Best Loss: 17.177731
Epoch loss: 18.697123
train phase, Epoch 13/15, Loss: 17.603231
val phase, Epoch 13/15, Loss: 18.889086
Val Best Loss: 17.177731
Epoch loss: 18.889086
train phase, Epoch 14/15, Loss: 17.540090
val phase, Epoch 14/15, Loss: 17.441992
Val Best Loss: 17.177731
Epoch loss: 17.441992
train phase, Epoch 15/15, Loss: 17.140705
val phase, Epoch 15/15, Loss: 16.999163
Val Best Loss: 16.999163
Epoch loss: 16.999163
train phase, Epoch 1/20, Loss: 21.746553
val phase, Epoch 1/20, Loss: 23.710978
Val Best Loss: 23.710978
Epoch loss: 23.710978
train phase, Epoch 2/20, Loss: 18.172898
val phase, Epoch 2/20, Loss: 22.121889
Val Best Loss: 22.121889
Epoch loss: 22.121889
train phase, Epoch 3/20, Loss: 17.456113
val phase, Epoch 3/20, Loss: 16.472167
Val Best Loss: 16.472167
Epoch loss: 16.472167
train phase, Epoch 4/20, Loss: 17.132841
val phase, Epoch 4/20, Loss: 20.598210
Val Best Loss: 16.472167
Epoch loss: 20.598210
train phase, Epoch 5/20, Loss: 16.960078
val phase, Epoch 5/20, Loss: 16.792185
Val Best Loss: 16.472167
Epoch loss: 16.792185
train phase, Epoch 6/20, Loss: 16.705739
val phase, Epoch 6/20, Loss: 17.203334
Val Best Loss: 16.472167
Epoch loss: 17.203334
train phase, Epoch 7/20, Loss: 16.627483
val phase, Epoch 7/20, Loss: 16.430085
Val Best Loss: 16.430085
Epoch loss: 16.430085
train phase, Epoch 8/20, Loss: 16.544660
val phase, Epoch 8/20, Loss: 16.153783
Val Best Loss: 16.153783
Epoch loss: 16.153783
train phase, Epoch 9/20, Loss: 16.230920
val phase, Epoch 9/20, Loss: 16.205284
Val Best Loss: 16.153783
Epoch loss: 16.205284
train phase, Epoch 10/20, Loss: 15.928395
val phase, Epoch 10/20, Loss: 16.234631
Val Best Loss: 16.153783
Epoch loss: 16.234631
train phase, Epoch 11/20, Loss: 15.827528
val phase, Epoch 11/20, Loss: 16.495092
Val Best Loss: 16.153783
Epoch loss: 16.495092
train phase, Epoch 12/20, Loss: 15.789644
val phase, Epoch 12/20, Loss: 17.050193
Val Best Loss: 16.153783
Epoch loss: 17.050193
train phase, Epoch 13/20, Loss: 15.622831
val phase, Epoch 13/20, Loss: 16.601985
Val Best Loss: 16.153783
Epoch loss: 16.601985
train phase, Epoch 14/20, Loss: 15.576407
val phase, Epoch 14/20, Loss: 15.898599
Val Best Loss: 15.898599
Epoch loss: 15.898599
train phase, Epoch 15/20, Loss: 15.259551
val phase, Epoch 15/20, Loss: 16.184197
Val Best Loss: 15.898599
Epoch loss: 16.184197
train phase, Epoch 16/20, Loss: 15.310975
val phase, Epoch 16/20, Loss: 16.159786
Val Best Loss: 15.898599
Epoch loss: 16.159786
train phase, Epoch 17/20, Loss: 14.827973
val phase, Epoch 17/20, Loss: 16.420695
Val Best Loss: 15.898599
Epoch loss: 16.420695
train phase, Epoch 18/20, Loss: 14.846200
val phase, Epoch 18/20, Loss: 16.958425
Val Best Loss: 15.898599
Epoch loss: 16.958425
train phase, Epoch 19/20, Loss: 14.316617
val phase, Epoch 19/20, Loss: 16.424797
Val Best Loss: 15.898599
Epoch loss: 16.424797
train phase, Epoch 20/20, Loss: 14.026089
val phase, Epoch 20/20, Loss: 16.539385
Val Best Loss: 15.898599
Epoch loss: 16.539385
train phase, Epoch 1/30, Loss: 21.092234
val phase, Epoch 1/30, Loss: 18.627123
Val Best Loss: 18.627123
Epoch loss: 18.627123
train phase, Epoch 2/30, Loss: 17.773436
val phase, Epoch 2/30, Loss: 19.461756
Val Best Loss: 18.627123
Epoch loss: 19.461756
train phase, Epoch 3/30, Loss: 17.730796
val phase, Epoch 3/30, Loss: 16.824510
Val Best Loss: 16.824510
Epoch loss: 16.824510
train phase, Epoch 4/30, Loss: 16.941756
val phase, Epoch 4/30, Loss: 16.344740
Val Best Loss: 16.344740
Epoch loss: 16.344740
train phase, Epoch 5/30, Loss: 16.936138
val phase, Epoch 5/30, Loss: 18.423912
Val Best Loss: 16.344740
Epoch loss: 18.423912
train phase, Epoch 6/30, Loss: 16.803343
val phase, Epoch 6/30, Loss: 16.697637
Val Best Loss: 16.344740
Epoch loss: 16.697637
train phase, Epoch 7/30, Loss: 16.641591
val phase, Epoch 7/30, Loss: 16.669325
Val Best Loss: 16.344740
Epoch loss: 16.669325
train phase, Epoch 8/30, Loss: 16.421962
val phase, Epoch 8/30, Loss: 16.162604
Val Best Loss: 16.162604
Epoch loss: 16.162604
train phase, Epoch 9/30, Loss: 16.548196
val phase, Epoch 9/30, Loss: 16.407954
Val Best Loss: 16.162604
Epoch loss: 16.407954
train phase, Epoch 10/30, Loss: 16.034121
val phase, Epoch 10/30, Loss: 16.987566
Val Best Loss: 16.162604
Epoch loss: 16.987566
train phase, Epoch 11/30, Loss: 15.725896
val phase, Epoch 11/30, Loss: 20.688718
Val Best Loss: 16.162604
Epoch loss: 20.688718
train phase, Epoch 12/30, Loss: 15.856519
val phase, Epoch 12/30, Loss: 15.967796
Val Best Loss: 15.967796
Epoch loss: 15.967796
train phase, Epoch 13/30, Loss: 15.474401
val phase, Epoch 13/30, Loss: 16.131328
Val Best Loss: 15.967796
Epoch loss: 16.131328
train phase, Epoch 14/30, Loss: 15.269882
val phase, Epoch 14/30, Loss: 17.700860
Val Best Loss: 15.967796
Epoch loss: 17.700860
train phase, Epoch 15/30, Loss: 15.033475
val phase, Epoch 15/30, Loss: 16.334058
Val Best Loss: 15.967796
Epoch loss: 16.334058
train phase, Epoch 16/30, Loss: 15.165478
val phase, Epoch 16/30, Loss: 16.665847
Val Best Loss: 15.967796
Epoch loss: 16.665847
train phase, Epoch 17/30, Loss: 14.664514
val phase, Epoch 17/30, Loss: 16.005035
Val Best Loss: 15.967796
Epoch loss: 16.005035
train phase, Epoch 18/30, Loss: 14.584467
val phase, Epoch 18/30, Loss: 18.913490
Val Best Loss: 15.967796
Epoch loss: 18.913490
train phase, Epoch 19/30, Loss: 14.391455
val phase, Epoch 19/30, Loss: 16.908584
Val Best Loss: 15.967796
Epoch loss: 16.908584
train phase, Epoch 20/30, Loss: 14.264995
val phase, Epoch 20/30, Loss: 16.443352
Val Best Loss: 15.967796
Epoch loss: 16.443352
train phase, Epoch 21/30, Loss: 13.896045
val phase, Epoch 21/30, Loss: 16.531865
Val Best Loss: 15.967796
Epoch loss: 16.531865
train phase, Epoch 22/30, Loss: 13.589851
val phase, Epoch 22/30, Loss: 17.031939
Val Best Loss: 15.967796
Epoch loss: 17.031939
train phase, Epoch 23/30, Loss: 13.112285
val phase, Epoch 23/30, Loss: 17.756843
Val Best Loss: 15.967796
Epoch loss: 17.756843
train phase, Epoch 24/30, Loss: 12.772022
val phase, Epoch 24/30, Loss: 16.850395
Val Best Loss: 15.967796
Epoch loss: 16.850395
train phase, Epoch 25/30, Loss: 12.368996
val phase, Epoch 25/30, Loss: 16.698812
Val Best Loss: 15.967796
Epoch loss: 16.698812
train phase, Epoch 26/30, Loss: 12.110818
val phase, Epoch 26/30, Loss: 17.279937
Val Best Loss: 15.967796
Epoch loss: 17.279937
train phase, Epoch 27/30, Loss: 11.403051
val phase, Epoch 27/30, Loss: 17.672829
Val Best Loss: 15.967796
Epoch loss: 17.672829
train phase, Epoch 28/30, Loss: 11.566486
val phase, Epoch 28/30, Loss: 17.950753
Val Best Loss: 15.967796
Epoch loss: 17.950753
train phase, Epoch 29/30, Loss: 10.875657
val phase, Epoch 29/30, Loss: 17.459642
Val Best Loss: 15.967796
Epoch loss: 17.459642
train phase, Epoch 30/30, Loss: 10.316066
val phase, Epoch 30/30, Loss: 17.816904
Val Best Loss: 15.967796
Epoch loss: 17.816904
train phase, Epoch 1/20, Loss: 21.057210
val phase, Epoch 1/20, Loss: 18.076536
Val Best Loss: 18.076536
Epoch loss: 18.076536
train phase, Epoch 2/20, Loss: 17.241957
val phase, Epoch 2/20, Loss: 16.938989
Val Best Loss: 16.938989
Epoch loss: 16.938989
train phase, Epoch 3/20, Loss: 17.102555
val phase, Epoch 3/20, Loss: 16.672583
Val Best Loss: 16.672583
Epoch loss: 16.672583
train phase, Epoch 4/20, Loss: 16.604692
val phase, Epoch 4/20, Loss: 18.981742
Val Best Loss: 16.672583
Epoch loss: 18.981742
train phase, Epoch 5/20, Loss: 16.887959
val phase, Epoch 5/20, Loss: 16.692717
Val Best Loss: 16.672583
Epoch loss: 16.692717
train phase, Epoch 6/20, Loss: 16.623939
val phase, Epoch 6/20, Loss: 17.104173
Val Best Loss: 16.672583
Epoch loss: 17.104173
train phase, Epoch 7/20, Loss: 16.224225
val phase, Epoch 7/20, Loss: 17.264398
Val Best Loss: 16.672583
Epoch loss: 17.264398
train phase, Epoch 8/20, Loss: 15.887352
val phase, Epoch 8/20, Loss: 16.099491
Val Best Loss: 16.099491
Epoch loss: 16.099491
train phase, Epoch 9/20, Loss: 15.845293
val phase, Epoch 9/20, Loss: 16.197275
Val Best Loss: 16.099491
Epoch loss: 16.197275
train phase, Epoch 10/20, Loss: 15.637592
val phase, Epoch 10/20, Loss: 16.814208
Val Best Loss: 16.099491
Epoch loss: 16.814208
train phase, Epoch 11/20, Loss: 15.472846
val phase, Epoch 11/20, Loss: 16.810374
Val Best Loss: 16.099491
Epoch loss: 16.810374
train phase, Epoch 12/20, Loss: 15.250531
val phase, Epoch 12/20, Loss: 16.384539
Val Best Loss: 16.099491
Epoch loss: 16.384539
train phase, Epoch 13/20, Loss: 14.986538
val phase, Epoch 13/20, Loss: 18.948345
Val Best Loss: 16.099491
Epoch loss: 18.948345
train phase, Epoch 14/20, Loss: 15.035424
val phase, Epoch 14/20, Loss: 16.476086
Val Best Loss: 16.099491
Epoch loss: 16.476086
train phase, Epoch 15/20, Loss: 14.831948
val phase, Epoch 15/20, Loss: 17.920982
Val Best Loss: 16.099491
Epoch loss: 17.920982
train phase, Epoch 16/20, Loss: 14.605352
val phase, Epoch 16/20, Loss: 16.590718
Val Best Loss: 16.099491
Epoch loss: 16.590718
train phase, Epoch 17/20, Loss: 14.107048
val phase, Epoch 17/20, Loss: 17.224831
Val Best Loss: 16.099491
Epoch loss: 17.224831
train phase, Epoch 18/20, Loss: 14.010832
val phase, Epoch 18/20, Loss: 16.819634
Val Best Loss: 16.099491
Epoch loss: 16.819634
train phase, Epoch 19/20, Loss: 13.632479
val phase, Epoch 19/20, Loss: 17.741721
Val Best Loss: 16.099491
Epoch loss: 17.741721
train phase, Epoch 20/20, Loss: 13.446305
val phase, Epoch 20/20, Loss: 17.061633
Val Best Loss: 16.099491
Epoch loss: 17.061633
train phase, Epoch 1/20, Loss: 37.144998
val phase, Epoch 1/20, Loss: 20.857659
Val Best Loss: 20.857659
Epoch loss: 20.857659
train phase, Epoch 2/20, Loss: 19.584506
val phase, Epoch 2/20, Loss: 23.180636
Val Best Loss: 20.857659
Epoch loss: 23.180636
train phase, Epoch 3/20, Loss: 19.431273
val phase, Epoch 3/20, Loss: 21.263718
Val Best Loss: 20.857659
Epoch loss: 21.263718
train phase, Epoch 4/20, Loss: 18.994230
val phase, Epoch 4/20, Loss: 18.050529
Val Best Loss: 18.050529
Epoch loss: 18.050529
train phase, Epoch 5/20, Loss: 18.195772
val phase, Epoch 5/20, Loss: 19.091646
Val Best Loss: 18.050529
Epoch loss: 19.091646
train phase, Epoch 6/20, Loss: 18.270938
val phase, Epoch 6/20, Loss: 18.043812
Val Best Loss: 18.043812
Epoch loss: 18.043812
train phase, Epoch 7/20, Loss: 18.202491
val phase, Epoch 7/20, Loss: 18.466838
Val Best Loss: 18.043812
Epoch loss: 18.466838
train phase, Epoch 8/20, Loss: 17.924561
val phase, Epoch 8/20, Loss: 21.270331
Val Best Loss: 18.043812
Epoch loss: 21.270331
train phase, Epoch 9/20, Loss: 17.710112
val phase, Epoch 9/20, Loss: 17.095959
Val Best Loss: 17.095959
Epoch loss: 17.095959
train phase, Epoch 10/20, Loss: 17.994865
val phase, Epoch 10/20, Loss: 17.196350
Val Best Loss: 17.095959
Epoch loss: 17.196350
train phase, Epoch 11/20, Loss: 17.467945
val phase, Epoch 11/20, Loss: 17.510750
Val Best Loss: 17.095959
Epoch loss: 17.510750
train phase, Epoch 12/20, Loss: 17.445616
val phase, Epoch 12/20, Loss: 17.774248
Val Best Loss: 17.095959
Epoch loss: 17.774248
train phase, Epoch 13/20, Loss: 17.230720
val phase, Epoch 13/20, Loss: 16.779285
Val Best Loss: 16.779285
Epoch loss: 16.779285
train phase, Epoch 14/20, Loss: 17.307107
val phase, Epoch 14/20, Loss: 17.569725
Val Best Loss: 16.779285
Epoch loss: 17.569725
train phase, Epoch 15/20, Loss: 17.219118
val phase, Epoch 15/20, Loss: 17.053473
Val Best Loss: 16.779285
Epoch loss: 17.053473
train phase, Epoch 16/20, Loss: 17.696998
val phase, Epoch 16/20, Loss: 17.241811
Val Best Loss: 16.779285
Epoch loss: 17.241811
train phase, Epoch 17/20, Loss: 16.779995
val phase, Epoch 17/20, Loss: 20.482591
Val Best Loss: 16.779285
Epoch loss: 20.482591
train phase, Epoch 18/20, Loss: 16.933047
val phase, Epoch 18/20, Loss: 17.655093
Val Best Loss: 16.779285
Epoch loss: 17.655093
train phase, Epoch 19/20, Loss: 16.437429
val phase, Epoch 19/20, Loss: 17.015873
Val Best Loss: 16.779285
Epoch loss: 17.015873
train phase, Epoch 20/20, Loss: 16.363855
val phase, Epoch 20/20, Loss: 16.862967
Val Best Loss: 16.779285
Epoch loss: 16.862967
train phase, Epoch 1/30, Loss: 21.813798
val phase, Epoch 1/30, Loss: 20.359513
Val Best Loss: 20.359513
Epoch loss: 20.359513
train phase, Epoch 2/30, Loss: 17.536458
val phase, Epoch 2/30, Loss: 16.873255
Val Best Loss: 16.873255
Epoch loss: 16.873255
train phase, Epoch 3/30, Loss: 17.348018
val phase, Epoch 3/30, Loss: 20.584375
Val Best Loss: 16.873255
Epoch loss: 20.584375
train phase, Epoch 4/30, Loss: 17.824849
val phase, Epoch 4/30, Loss: 16.966170
Val Best Loss: 16.873255
Epoch loss: 16.966170
train phase, Epoch 5/30, Loss: 17.247379
val phase, Epoch 5/30, Loss: 16.968143
Val Best Loss: 16.873255
Epoch loss: 16.968143
train phase, Epoch 6/30, Loss: 16.606698
val phase, Epoch 6/30, Loss: 16.373423
Val Best Loss: 16.373423
Epoch loss: 16.373423
train phase, Epoch 7/30, Loss: 16.518803
val phase, Epoch 7/30, Loss: 17.766015
Val Best Loss: 16.373423
Epoch loss: 17.766015
train phase, Epoch 8/30, Loss: 16.464138
val phase, Epoch 8/30, Loss: 17.565478
Val Best Loss: 16.373423
Epoch loss: 17.565478
train phase, Epoch 9/30, Loss: 16.277610
val phase, Epoch 9/30, Loss: 16.382953
Val Best Loss: 16.373423
Epoch loss: 16.382953
train phase, Epoch 10/30, Loss: 15.707863
val phase, Epoch 10/30, Loss: 16.148086
Val Best Loss: 16.148086
Epoch loss: 16.148086
train phase, Epoch 11/30, Loss: 15.776741
val phase, Epoch 11/30, Loss: 16.838061
Val Best Loss: 16.148086
Epoch loss: 16.838061
train phase, Epoch 12/30, Loss: 15.588824
val phase, Epoch 12/30, Loss: 16.612381
Val Best Loss: 16.148086
Epoch loss: 16.612381
train phase, Epoch 13/30, Loss: 15.519573
val phase, Epoch 13/30, Loss: 16.091224
Val Best Loss: 16.091224
Epoch loss: 16.091224
train phase, Epoch 14/30, Loss: 15.051375
val phase, Epoch 14/30, Loss: 16.217170
Val Best Loss: 16.091224
Epoch loss: 16.217170
train phase, Epoch 15/30, Loss: 15.141338
val phase, Epoch 15/30, Loss: 16.400918
Val Best Loss: 16.091224
Epoch loss: 16.400918
train phase, Epoch 16/30, Loss: 14.992041
val phase, Epoch 16/30, Loss: 15.959496
Val Best Loss: 15.959496
Epoch loss: 15.959496
train phase, Epoch 17/30, Loss: 14.664045
val phase, Epoch 17/30, Loss: 16.249283
Val Best Loss: 15.959496
Epoch loss: 16.249283
train phase, Epoch 18/30, Loss: 14.507925
val phase, Epoch 18/30, Loss: 16.259183
Val Best Loss: 15.959496
Epoch loss: 16.259183
train phase, Epoch 19/30, Loss: 14.134061
val phase, Epoch 19/30, Loss: 16.034663
Val Best Loss: 15.959496
Epoch loss: 16.034663
train phase, Epoch 20/30, Loss: 13.771254
val phase, Epoch 20/30, Loss: 16.704420
Val Best Loss: 15.959496
Epoch loss: 16.704420
train phase, Epoch 21/30, Loss: 13.721224
val phase, Epoch 21/30, Loss: 16.195663
Val Best Loss: 15.959496
Epoch loss: 16.195663
train phase, Epoch 22/30, Loss: 13.247129
val phase, Epoch 22/30, Loss: 17.131206
Val Best Loss: 15.959496
Epoch loss: 17.131206
train phase, Epoch 23/30, Loss: 13.076841
val phase, Epoch 23/30, Loss: 16.836927
Val Best Loss: 15.959496
Epoch loss: 16.836927
train phase, Epoch 24/30, Loss: 12.892658
val phase, Epoch 24/30, Loss: 17.669936
Val Best Loss: 15.959496
Epoch loss: 17.669936
train phase, Epoch 25/30, Loss: 12.364160
val phase, Epoch 25/30, Loss: 17.371970
Val Best Loss: 15.959496
Epoch loss: 17.371970
train phase, Epoch 26/30, Loss: 11.883790
val phase, Epoch 26/30, Loss: 18.183050
Val Best Loss: 15.959496
Epoch loss: 18.183050
train phase, Epoch 27/30, Loss: 11.226393
val phase, Epoch 27/30, Loss: 17.704162
Val Best Loss: 15.959496
Epoch loss: 17.704162
train phase, Epoch 28/30, Loss: 11.040916
val phase, Epoch 28/30, Loss: 18.545513
Val Best Loss: 15.959496
Epoch loss: 18.545513
train phase, Epoch 29/30, Loss: 10.706729
val phase, Epoch 29/30, Loss: 18.294111
Val Best Loss: 15.959496
Epoch loss: 18.294111
train phase, Epoch 30/30, Loss: 10.202995
val phase, Epoch 30/30, Loss: 17.586844
Val Best Loss: 15.959496
Epoch loss: 17.586844
[Trial 397] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.971232
val phase, Epoch 1/20, Loss: 17.517019
Val Best Loss: 17.517019
Epoch loss: 17.517019
train phase, Epoch 2/20, Loss: 18.162610
val phase, Epoch 2/20, Loss: 17.455960
Val Best Loss: 17.455960
Epoch loss: 17.455960
train phase, Epoch 3/20, Loss: 17.365774
val phase, Epoch 3/20, Loss: 16.331870
Val Best Loss: 16.331870
Epoch loss: 16.331870
train phase, Epoch 4/20, Loss: 17.246653
val phase, Epoch 4/20, Loss: 18.129840
Val Best Loss: 16.331870
Epoch loss: 18.129840
train phase, Epoch 5/20, Loss: 17.108456
val phase, Epoch 5/20, Loss: 17.257927
Val Best Loss: 16.331870
Epoch loss: 17.257927
train phase, Epoch 6/20, Loss: 16.700640
val phase, Epoch 6/20, Loss: 16.251240
Val Best Loss: 16.251240
Epoch loss: 16.251240
train phase, Epoch 7/20, Loss: 16.649468
val phase, Epoch 7/20, Loss: 16.264531
Val Best Loss: 16.251240
Epoch loss: 16.264531
train phase, Epoch 8/20, Loss: 16.554290
val phase, Epoch 8/20, Loss: 16.787546
Val Best Loss: 16.251240
Epoch loss: 16.787546
train phase, Epoch 9/20, Loss: 15.986521
val phase, Epoch 9/20, Loss: 16.610754
Val Best Loss: 16.251240
Epoch loss: 16.610754
train phase, Epoch 10/20, Loss: 16.202590
val phase, Epoch 10/20, Loss: 16.125607
Val Best Loss: 16.125607
Epoch loss: 16.125607
train phase, Epoch 11/20, Loss: 16.047337
val phase, Epoch 11/20, Loss: 17.415282
Val Best Loss: 16.125607
Epoch loss: 17.415282
train phase, Epoch 12/20, Loss: 15.784509
val phase, Epoch 12/20, Loss: 15.917270
Val Best Loss: 15.917270
Epoch loss: 15.917270
train phase, Epoch 13/20, Loss: 15.560115
val phase, Epoch 13/20, Loss: 16.327076
Val Best Loss: 15.917270
Epoch loss: 16.327076
train phase, Epoch 14/20, Loss: 15.353911
val phase, Epoch 14/20, Loss: 15.686611
Val Best Loss: 15.686611
Epoch loss: 15.686611
train phase, Epoch 15/20, Loss: 15.285390
val phase, Epoch 15/20, Loss: 17.066325
Val Best Loss: 15.686611
Epoch loss: 17.066325
train phase, Epoch 16/20, Loss: 15.037540
val phase, Epoch 16/20, Loss: 16.113422
Val Best Loss: 15.686611
Epoch loss: 16.113422
train phase, Epoch 17/20, Loss: 14.741836
val phase, Epoch 17/20, Loss: 16.338911
Val Best Loss: 15.686611
Epoch loss: 16.338911
train phase, Epoch 18/20, Loss: 14.443593
val phase, Epoch 18/20, Loss: 16.495909
Val Best Loss: 15.686611
Epoch loss: 16.495909
train phase, Epoch 19/20, Loss: 14.369809
val phase, Epoch 19/20, Loss: 15.854035
Val Best Loss: 15.686611
Epoch loss: 15.854035
train phase, Epoch 20/20, Loss: 14.041613
val phase, Epoch 20/20, Loss: 15.933508
Val Best Loss: 15.686611
Epoch loss: 15.933508
train phase, Epoch 1/30, Loss: 22.499429
val phase, Epoch 1/30, Loss: 17.214910
Val Best Loss: 17.214910
Epoch loss: 17.214910
train phase, Epoch 2/30, Loss: 17.312737
val phase, Epoch 2/30, Loss: 17.173873
Val Best Loss: 17.173873
Epoch loss: 17.173873
train phase, Epoch 3/30, Loss: 16.724865
val phase, Epoch 3/30, Loss: 17.951378
Val Best Loss: 17.173873
Epoch loss: 17.951378
train phase, Epoch 4/30, Loss: 16.320733
val phase, Epoch 4/30, Loss: 17.669791
Val Best Loss: 17.173873
Epoch loss: 17.669791
train phase, Epoch 5/30, Loss: 16.063713
val phase, Epoch 5/30, Loss: 16.767088
Val Best Loss: 16.767088
Epoch loss: 16.767088
train phase, Epoch 6/30, Loss: 15.593459
val phase, Epoch 6/30, Loss: 18.628490
Val Best Loss: 16.767088
Epoch loss: 18.628490
train phase, Epoch 7/30, Loss: 15.388628
val phase, Epoch 7/30, Loss: 16.597384
Val Best Loss: 16.597384
Epoch loss: 16.597384
train phase, Epoch 8/30, Loss: 14.861238
val phase, Epoch 8/30, Loss: 16.942786
Val Best Loss: 16.597384
Epoch loss: 16.942786
train phase, Epoch 9/30, Loss: 14.665828
val phase, Epoch 9/30, Loss: 17.399611
Val Best Loss: 16.597384
Epoch loss: 17.399611
train phase, Epoch 10/30, Loss: 14.194688
val phase, Epoch 10/30, Loss: 17.464090
Val Best Loss: 16.597384
Epoch loss: 17.464090
train phase, Epoch 11/30, Loss: 13.651802
val phase, Epoch 11/30, Loss: 16.775763
Val Best Loss: 16.597384
Epoch loss: 16.775763
train phase, Epoch 12/30, Loss: 13.248029
val phase, Epoch 12/30, Loss: 18.604055
Val Best Loss: 16.597384
Epoch loss: 18.604055
train phase, Epoch 13/30, Loss: 12.679725
val phase, Epoch 13/30, Loss: 17.066678
Val Best Loss: 16.597384
Epoch loss: 17.066678
train phase, Epoch 14/30, Loss: 11.949004
val phase, Epoch 14/30, Loss: 17.622939
Val Best Loss: 16.597384
Epoch loss: 17.622939
train phase, Epoch 15/30, Loss: 11.649200
val phase, Epoch 15/30, Loss: 18.086137
Val Best Loss: 16.597384
Epoch loss: 18.086137
train phase, Epoch 16/30, Loss: 10.628348
val phase, Epoch 16/30, Loss: 18.031399
Val Best Loss: 16.597384
Epoch loss: 18.031399
train phase, Epoch 17/30, Loss: 10.330388
val phase, Epoch 17/30, Loss: 18.993986
Val Best Loss: 16.597384
Epoch loss: 18.993986
train phase, Epoch 18/30, Loss: 9.574427
val phase, Epoch 18/30, Loss: 19.033625
Val Best Loss: 16.597384
Epoch loss: 19.033625
train phase, Epoch 19/30, Loss: 8.824910
val phase, Epoch 19/30, Loss: 20.467232
Val Best Loss: 16.597384
Epoch loss: 20.467232
train phase, Epoch 20/30, Loss: 8.578276
val phase, Epoch 20/30, Loss: 19.081274
Val Best Loss: 16.597384
Epoch loss: 19.081274
train phase, Epoch 21/30, Loss: 7.909483
val phase, Epoch 21/30, Loss: 20.034303
Val Best Loss: 16.597384
Epoch loss: 20.034303
train phase, Epoch 22/30, Loss: 7.586913
val phase, Epoch 22/30, Loss: 20.158706
Val Best Loss: 16.597384
Epoch loss: 20.158706
train phase, Epoch 23/30, Loss: 6.832612
val phase, Epoch 23/30, Loss: 20.841213
Val Best Loss: 16.597384
Epoch loss: 20.841213
train phase, Epoch 24/30, Loss: 6.365220
val phase, Epoch 24/30, Loss: 19.782122
Val Best Loss: 16.597384
Epoch loss: 19.782122
train phase, Epoch 25/30, Loss: 6.139135
val phase, Epoch 25/30, Loss: 20.424464
Val Best Loss: 16.597384
Epoch loss: 20.424464
train phase, Epoch 26/30, Loss: 5.841912
val phase, Epoch 26/30, Loss: 19.675329
Val Best Loss: 16.597384
Epoch loss: 19.675329
train phase, Epoch 27/30, Loss: 5.509049
val phase, Epoch 27/30, Loss: 19.911712
Val Best Loss: 16.597384
Epoch loss: 19.911712
train phase, Epoch 28/30, Loss: 5.292635
val phase, Epoch 28/30, Loss: 20.649359
Val Best Loss: 16.597384
Epoch loss: 20.649359
train phase, Epoch 29/30, Loss: 5.087034
val phase, Epoch 29/30, Loss: 22.179054
Val Best Loss: 16.597384
Epoch loss: 22.179054
train phase, Epoch 30/30, Loss: 4.901027
val phase, Epoch 30/30, Loss: 20.973832
Val Best Loss: 16.597384
Epoch loss: 20.973832
[Trial 400] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/20, Loss: 19.822160
val phase, Epoch 1/20, Loss: 20.008811
Val Best Loss: 20.008811
Epoch loss: 20.008811
train phase, Epoch 2/20, Loss: 18.113181
val phase, Epoch 2/20, Loss: 16.506672
Val Best Loss: 16.506672
Epoch loss: 16.506672
train phase, Epoch 3/20, Loss: 17.270993
val phase, Epoch 3/20, Loss: 16.463811
Val Best Loss: 16.463811
Epoch loss: 16.463811
train phase, Epoch 4/20, Loss: 17.383831
val phase, Epoch 4/20, Loss: 17.559368
Val Best Loss: 16.463811
Epoch loss: 17.559368
train phase, Epoch 5/20, Loss: 16.879160
val phase, Epoch 5/20, Loss: 16.508295
Val Best Loss: 16.463811
Epoch loss: 16.508295
train phase, Epoch 6/20, Loss: 16.692456
val phase, Epoch 6/20, Loss: 16.591623
Val Best Loss: 16.463811
Epoch loss: 16.591623
train phase, Epoch 7/20, Loss: 16.720608
val phase, Epoch 7/20, Loss: 16.419140
Val Best Loss: 16.419140
Epoch loss: 16.419140
train phase, Epoch 8/20, Loss: 16.338354
val phase, Epoch 8/20, Loss: 16.166781
Val Best Loss: 16.166781
Epoch loss: 16.166781
train phase, Epoch 9/20, Loss: 16.141945
val phase, Epoch 9/20, Loss: 17.116474
Val Best Loss: 16.166781
Epoch loss: 17.116474
train phase, Epoch 10/20, Loss: 16.504629
val phase, Epoch 10/20, Loss: 17.140361
Val Best Loss: 16.166781
Epoch loss: 17.140361
train phase, Epoch 11/20, Loss: 16.091708
val phase, Epoch 11/20, Loss: 16.177540
Val Best Loss: 16.166781
Epoch loss: 16.177540
train phase, Epoch 12/20, Loss: 15.745402
val phase, Epoch 12/20, Loss: 16.049790
Val Best Loss: 16.049790
Epoch loss: 16.049790
train phase, Epoch 13/20, Loss: 15.482534
val phase, Epoch 13/20, Loss: 18.773643
Val Best Loss: 16.049790
Epoch loss: 18.773643
train phase, Epoch 14/20, Loss: 15.504850
val phase, Epoch 14/20, Loss: 15.791075
Val Best Loss: 15.791075
Epoch loss: 15.791075
train phase, Epoch 15/20, Loss: 15.215418
val phase, Epoch 15/20, Loss: 16.446933
Val Best Loss: 15.791075
Epoch loss: 16.446933
train phase, Epoch 16/20, Loss: 15.183225
val phase, Epoch 16/20, Loss: 16.363028
Val Best Loss: 15.791075
Epoch loss: 16.363028
train phase, Epoch 17/20, Loss: 14.787773
val phase, Epoch 17/20, Loss: 16.572400
Val Best Loss: 15.791075
Epoch loss: 16.572400
train phase, Epoch 18/20, Loss: 14.872728
val phase, Epoch 18/20, Loss: 16.396515
Val Best Loss: 15.791075
Epoch loss: 16.396515
train phase, Epoch 19/20, Loss: 14.516003
val phase, Epoch 19/20, Loss: 16.321654
Val Best Loss: 15.791075
Epoch loss: 16.321654
train phase, Epoch 20/20, Loss: 14.293399
val phase, Epoch 20/20, Loss: 15.980271
Val Best Loss: 15.791075
Epoch loss: 15.980271
[Trial 402] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/25, Loss: 19.780341
val phase, Epoch 1/25, Loss: 21.323035
Val Best Loss: 21.323035
Epoch loss: 21.323035
train phase, Epoch 2/25, Loss: 17.576103
val phase, Epoch 2/25, Loss: 19.757733
Val Best Loss: 19.757733
Epoch loss: 19.757733
train phase, Epoch 3/25, Loss: 17.217689
val phase, Epoch 3/25, Loss: 17.207692
Val Best Loss: 17.207692
Epoch loss: 17.207692
train phase, Epoch 4/25, Loss: 17.184754
val phase, Epoch 4/25, Loss: 17.690322
Val Best Loss: 17.207692
Epoch loss: 17.690322
train phase, Epoch 5/25, Loss: 16.876473
val phase, Epoch 5/25, Loss: 18.426933
Val Best Loss: 17.207692
Epoch loss: 18.426933
train phase, Epoch 6/25, Loss: 16.499889
val phase, Epoch 6/25, Loss: 17.817121
Val Best Loss: 17.207692
Epoch loss: 17.817121
train phase, Epoch 7/25, Loss: 16.308184
val phase, Epoch 7/25, Loss: 16.271339
Val Best Loss: 16.271339
Epoch loss: 16.271339
train phase, Epoch 8/25, Loss: 16.167652
val phase, Epoch 8/25, Loss: 16.385286
Val Best Loss: 16.271339
Epoch loss: 16.385286
train phase, Epoch 9/25, Loss: 15.968873
val phase, Epoch 9/25, Loss: 18.048395
Val Best Loss: 16.271339
Epoch loss: 18.048395
train phase, Epoch 10/25, Loss: 15.775094
val phase, Epoch 10/25, Loss: 17.134311
Val Best Loss: 16.271339
Epoch loss: 17.134311
train phase, Epoch 11/25, Loss: 15.746875
val phase, Epoch 11/25, Loss: 17.116026
Val Best Loss: 16.271339
Epoch loss: 17.116026
train phase, Epoch 12/25, Loss: 15.489730
val phase, Epoch 12/25, Loss: 17.422125
Val Best Loss: 16.271339
Epoch loss: 17.422125
train phase, Epoch 13/25, Loss: 15.679352
val phase, Epoch 13/25, Loss: 16.203562
Val Best Loss: 16.203562
Epoch loss: 16.203562
train phase, Epoch 14/25, Loss: 15.223162
val phase, Epoch 14/25, Loss: 16.032414
Val Best Loss: 16.032414
Epoch loss: 16.032414
train phase, Epoch 15/25, Loss: 15.040076
val phase, Epoch 15/25, Loss: 15.847580
Val Best Loss: 15.847580
Epoch loss: 15.847580
train phase, Epoch 16/25, Loss: 14.759568
val phase, Epoch 16/25, Loss: 16.010244
Val Best Loss: 15.847580
Epoch loss: 16.010244
train phase, Epoch 17/25, Loss: 14.703877
val phase, Epoch 17/25, Loss: 16.315854
Val Best Loss: 15.847580
Epoch loss: 16.315854
train phase, Epoch 18/25, Loss: 14.260056
val phase, Epoch 18/25, Loss: 15.864331
Val Best Loss: 15.847580
Epoch loss: 15.864331
train phase, Epoch 19/25, Loss: 13.977747
val phase, Epoch 19/25, Loss: 16.153801
Val Best Loss: 15.847580
Epoch loss: 16.153801
train phase, Epoch 20/25, Loss: 13.609634
val phase, Epoch 20/25, Loss: 19.773246
Val Best Loss: 15.847580
Epoch loss: 19.773246
train phase, Epoch 21/25, Loss: 13.322028
val phase, Epoch 21/25, Loss: 16.540775
Val Best Loss: 15.847580
Epoch loss: 16.540775
train phase, Epoch 22/25, Loss: 13.074541
val phase, Epoch 22/25, Loss: 16.608732
Val Best Loss: 15.847580
Epoch loss: 16.608732
train phase, Epoch 23/25, Loss: 12.685046
val phase, Epoch 23/25, Loss: 17.295656
Val Best Loss: 15.847580
Epoch loss: 17.295656
train phase, Epoch 24/25, Loss: 12.140516
val phase, Epoch 24/25, Loss: 16.469161
Val Best Loss: 15.847580
Epoch loss: 16.469161
train phase, Epoch 25/25, Loss: 11.653375
val phase, Epoch 25/25, Loss: 20.373151
Val Best Loss: 15.847580
Epoch loss: 20.373151
train phase, Epoch 1/5, Loss: 21.113099
val phase, Epoch 1/5, Loss: 19.167730
Val Best Loss: 19.167730
Epoch loss: 19.167730
train phase, Epoch 2/5, Loss: 18.355820
val phase, Epoch 2/5, Loss: 21.906355
Val Best Loss: 19.167730
Epoch loss: 21.906355
train phase, Epoch 3/5, Loss: 17.807348
val phase, Epoch 3/5, Loss: 16.560988
Val Best Loss: 16.560988
Epoch loss: 16.560988
train phase, Epoch 4/5, Loss: 17.731475
val phase, Epoch 4/5, Loss: 19.148551
Val Best Loss: 16.560988
Epoch loss: 19.148551
train phase, Epoch 5/5, Loss: 17.542199
val phase, Epoch 5/5, Loss: 16.652494
Val Best Loss: 16.560988
Epoch loss: 16.652494
train phase, Epoch 1/20, Loss: 20.120959
val phase, Epoch 1/20, Loss: 17.809104
Val Best Loss: 17.809104
Epoch loss: 17.809104
train phase, Epoch 2/20, Loss: 18.224930
val phase, Epoch 2/20, Loss: 17.211172
Val Best Loss: 17.211172
Epoch loss: 17.211172
train phase, Epoch 3/20, Loss: 17.595455
val phase, Epoch 3/20, Loss: 17.245361
Val Best Loss: 17.211172
Epoch loss: 17.245361
train phase, Epoch 4/20, Loss: 17.470447
val phase, Epoch 4/20, Loss: 16.556587
Val Best Loss: 16.556587
Epoch loss: 16.556587
train phase, Epoch 5/20, Loss: 16.965863
val phase, Epoch 5/20, Loss: 16.198486
Val Best Loss: 16.198486
Epoch loss: 16.198486
train phase, Epoch 6/20, Loss: 16.826657
val phase, Epoch 6/20, Loss: 16.748598
Val Best Loss: 16.198486
Epoch loss: 16.748598
train phase, Epoch 7/20, Loss: 16.813052
val phase, Epoch 7/20, Loss: 16.162082
Val Best Loss: 16.162082
Epoch loss: 16.162082
train phase, Epoch 8/20, Loss: 16.293302
val phase, Epoch 8/20, Loss: 16.370610
Val Best Loss: 16.162082
Epoch loss: 16.370610
train phase, Epoch 9/20, Loss: 16.310959
val phase, Epoch 9/20, Loss: 17.674255
Val Best Loss: 16.162082
Epoch loss: 17.674255
train phase, Epoch 10/20, Loss: 16.235631
val phase, Epoch 10/20, Loss: 16.055788
Val Best Loss: 16.055788
Epoch loss: 16.055788
train phase, Epoch 11/20, Loss: 15.918736
val phase, Epoch 11/20, Loss: 15.884679
Val Best Loss: 15.884679
Epoch loss: 15.884679
train phase, Epoch 12/20, Loss: 15.850744
val phase, Epoch 12/20, Loss: 16.316508
Val Best Loss: 15.884679
Epoch loss: 16.316508
train phase, Epoch 13/20, Loss: 15.456634
val phase, Epoch 13/20, Loss: 17.070080
Val Best Loss: 15.884679
Epoch loss: 17.070080
train phase, Epoch 14/20, Loss: 15.528854
val phase, Epoch 14/20, Loss: 16.582773
Val Best Loss: 15.884679
Epoch loss: 16.582773
train phase, Epoch 15/20, Loss: 15.047557
val phase, Epoch 15/20, Loss: 15.787930
Val Best Loss: 15.787930
Epoch loss: 15.787930
train phase, Epoch 16/20, Loss: 15.040966
val phase, Epoch 16/20, Loss: 15.876811
Val Best Loss: 15.787930
Epoch loss: 15.876811
train phase, Epoch 17/20, Loss: 15.039412
val phase, Epoch 17/20, Loss: 16.352117
Val Best Loss: 15.787930
Epoch loss: 16.352117
train phase, Epoch 18/20, Loss: 14.812598
val phase, Epoch 18/20, Loss: 16.074477
Val Best Loss: 15.787930
Epoch loss: 16.074477
train phase, Epoch 19/20, Loss: 14.399924
val phase, Epoch 19/20, Loss: 16.616660
Val Best Loss: 15.787930
Epoch loss: 16.616660
train phase, Epoch 20/20, Loss: 14.198708
val phase, Epoch 20/20, Loss: 16.351036
Val Best Loss: 15.787930
Epoch loss: 16.351036
train phase, Epoch 1/30, Loss: 20.681708
val phase, Epoch 1/30, Loss: 20.870124
Val Best Loss: 20.870124
Epoch loss: 20.870124
train phase, Epoch 2/30, Loss: 18.163844
val phase, Epoch 2/30, Loss: 18.866609
Val Best Loss: 18.866609
Epoch loss: 18.866609
train phase, Epoch 3/30, Loss: 17.690802
val phase, Epoch 3/30, Loss: 18.615803
Val Best Loss: 18.615803
Epoch loss: 18.615803
train phase, Epoch 4/30, Loss: 17.793001
val phase, Epoch 4/30, Loss: 16.481800
Val Best Loss: 16.481800
Epoch loss: 16.481800
train phase, Epoch 5/30, Loss: 17.293360
val phase, Epoch 5/30, Loss: 16.898873
Val Best Loss: 16.481800
Epoch loss: 16.898873
train phase, Epoch 6/30, Loss: 17.051075
val phase, Epoch 6/30, Loss: 16.621793
Val Best Loss: 16.481800
Epoch loss: 16.621793
train phase, Epoch 7/30, Loss: 16.640364
val phase, Epoch 7/30, Loss: 16.321874
Val Best Loss: 16.321874
Epoch loss: 16.321874
train phase, Epoch 8/30, Loss: 16.607992
val phase, Epoch 8/30, Loss: 16.794511
Val Best Loss: 16.321874
Epoch loss: 16.794511
train phase, Epoch 9/30, Loss: 16.637414
val phase, Epoch 9/30, Loss: 15.936798
Val Best Loss: 15.936798
Epoch loss: 15.936798
train phase, Epoch 10/30, Loss: 16.325695
val phase, Epoch 10/30, Loss: 16.828562
Val Best Loss: 15.936798
Epoch loss: 16.828562
train phase, Epoch 11/30, Loss: 16.151594
val phase, Epoch 11/30, Loss: 16.356646
Val Best Loss: 15.936798
Epoch loss: 16.356646
train phase, Epoch 12/30, Loss: 16.137489
val phase, Epoch 12/30, Loss: 16.674272
Val Best Loss: 15.936798
Epoch loss: 16.674272
train phase, Epoch 13/30, Loss: 15.831800
val phase, Epoch 13/30, Loss: 16.317553
Val Best Loss: 15.936798
Epoch loss: 16.317553
train phase, Epoch 14/30, Loss: 15.842754
val phase, Epoch 14/30, Loss: 15.760668
Val Best Loss: 15.760668
Epoch loss: 15.760668
train phase, Epoch 15/30, Loss: 15.727414
val phase, Epoch 15/30, Loss: 16.069974
Val Best Loss: 15.760668
Epoch loss: 16.069974
train phase, Epoch 16/30, Loss: 15.507357
val phase, Epoch 16/30, Loss: 16.856167
Val Best Loss: 15.760668
Epoch loss: 16.856167
train phase, Epoch 17/30, Loss: 15.465317
val phase, Epoch 17/30, Loss: 15.967972
Val Best Loss: 15.760668
Epoch loss: 15.967972
train phase, Epoch 18/30, Loss: 14.963231
val phase, Epoch 18/30, Loss: 16.283543
Val Best Loss: 15.760668
Epoch loss: 16.283543
train phase, Epoch 19/30, Loss: 14.935635
val phase, Epoch 19/30, Loss: 16.892248
Val Best Loss: 15.760668
Epoch loss: 16.892248
train phase, Epoch 20/30, Loss: 14.572752
val phase, Epoch 20/30, Loss: 20.016610
Val Best Loss: 15.760668
Epoch loss: 20.016610
train phase, Epoch 21/30, Loss: 14.820942
val phase, Epoch 21/30, Loss: 15.846513
Val Best Loss: 15.760668
Epoch loss: 15.846513
train phase, Epoch 22/30, Loss: 14.425972
val phase, Epoch 22/30, Loss: 16.018604
Val Best Loss: 15.760668
Epoch loss: 16.018604
train phase, Epoch 23/30, Loss: 14.254533
val phase, Epoch 23/30, Loss: 16.837251
Val Best Loss: 15.760668
Epoch loss: 16.837251
train phase, Epoch 24/30, Loss: 13.965738
val phase, Epoch 24/30, Loss: 16.204488
Val Best Loss: 15.760668
Epoch loss: 16.204488
train phase, Epoch 25/30, Loss: 13.690039
val phase, Epoch 25/30, Loss: 16.886341
Val Best Loss: 15.760668
Epoch loss: 16.886341
train phase, Epoch 26/30, Loss: 13.719516
val phase, Epoch 26/30, Loss: 17.016090
Val Best Loss: 15.760668
Epoch loss: 17.016090
train phase, Epoch 27/30, Loss: 13.131176
val phase, Epoch 27/30, Loss: 17.930218
Val Best Loss: 15.760668
Epoch loss: 17.930218
train phase, Epoch 28/30, Loss: 13.036419
val phase, Epoch 28/30, Loss: 18.464533
Val Best Loss: 15.760668
Epoch loss: 18.464533
train phase, Epoch 29/30, Loss: 12.461443
val phase, Epoch 29/30, Loss: 17.295981
Val Best Loss: 15.760668
Epoch loss: 17.295981
train phase, Epoch 30/30, Loss: 12.482607
val phase, Epoch 30/30, Loss: 17.106534
Val Best Loss: 15.760668
Epoch loss: 17.106534
train phase, Epoch 1/20, Loss: 20.272419
val phase, Epoch 1/20, Loss: 17.123605
Val Best Loss: 17.123605
Epoch loss: 17.123605
train phase, Epoch 2/20, Loss: 17.697249
val phase, Epoch 2/20, Loss: 19.529199
Val Best Loss: 17.123605
Epoch loss: 19.529199
train phase, Epoch 3/20, Loss: 17.426413
val phase, Epoch 3/20, Loss: 16.753190
Val Best Loss: 16.753190
Epoch loss: 16.753190
train phase, Epoch 4/20, Loss: 17.381540
val phase, Epoch 4/20, Loss: 17.135663
Val Best Loss: 16.753190
Epoch loss: 17.135663
train phase, Epoch 5/20, Loss: 16.950257
val phase, Epoch 5/20, Loss: 16.269073
Val Best Loss: 16.269073
Epoch loss: 16.269073
train phase, Epoch 6/20, Loss: 16.542326
val phase, Epoch 6/20, Loss: 16.992629
Val Best Loss: 16.269073
Epoch loss: 16.992629
train phase, Epoch 7/20, Loss: 16.290074
val phase, Epoch 7/20, Loss: 16.373066
Val Best Loss: 16.269073
Epoch loss: 16.373066
train phase, Epoch 8/20, Loss: 16.163394
val phase, Epoch 8/20, Loss: 16.031531
Val Best Loss: 16.031531
Epoch loss: 16.031531
train phase, Epoch 9/20, Loss: 16.008255
val phase, Epoch 9/20, Loss: 16.680280
Val Best Loss: 16.031531
Epoch loss: 16.680280
train phase, Epoch 10/20, Loss: 16.000259
val phase, Epoch 10/20, Loss: 16.007859
Val Best Loss: 16.007859
Epoch loss: 16.007859
train phase, Epoch 11/20, Loss: 15.671228
val phase, Epoch 11/20, Loss: 15.901629
Val Best Loss: 15.901629
Epoch loss: 15.901629
train phase, Epoch 12/20, Loss: 15.755643
val phase, Epoch 12/20, Loss: 16.106945
Val Best Loss: 15.901629
Epoch loss: 16.106945
train phase, Epoch 13/20, Loss: 15.665095
val phase, Epoch 13/20, Loss: 16.312825
Val Best Loss: 15.901629
Epoch loss: 16.312825
train phase, Epoch 14/20, Loss: 15.713150
val phase, Epoch 14/20, Loss: 15.554111
Val Best Loss: 15.554111
Epoch loss: 15.554111
train phase, Epoch 15/20, Loss: 15.266242
val phase, Epoch 15/20, Loss: 17.048826
Val Best Loss: 15.554111
Epoch loss: 17.048826
train phase, Epoch 16/20, Loss: 15.225082
val phase, Epoch 16/20, Loss: 16.242375
Val Best Loss: 15.554111
Epoch loss: 16.242375
train phase, Epoch 17/20, Loss: 14.933141
val phase, Epoch 17/20, Loss: 15.983226
Val Best Loss: 15.554111
Epoch loss: 15.983226
train phase, Epoch 18/20, Loss: 14.861925
val phase, Epoch 18/20, Loss: 16.013236
Val Best Loss: 15.554111
Epoch loss: 16.013236
train phase, Epoch 19/20, Loss: 14.733673
val phase, Epoch 19/20, Loss: 16.820605
Val Best Loss: 15.554111
Epoch loss: 16.820605
train phase, Epoch 20/20, Loss: 14.652987
val phase, Epoch 20/20, Loss: 16.055811
Val Best Loss: 15.554111
Epoch loss: 16.055811
train phase, Epoch 1/20, Loss: 20.709905
val phase, Epoch 1/20, Loss: 17.449745
Val Best Loss: 17.449745
Epoch loss: 17.449745
train phase, Epoch 2/20, Loss: 18.072658
val phase, Epoch 2/20, Loss: 17.336734
Val Best Loss: 17.336734
Epoch loss: 17.336734
train phase, Epoch 3/20, Loss: 17.072071
val phase, Epoch 3/20, Loss: 16.985912
Val Best Loss: 16.985912
Epoch loss: 16.985912
train phase, Epoch 4/20, Loss: 16.824886
val phase, Epoch 4/20, Loss: 17.531837
Val Best Loss: 16.985912
Epoch loss: 17.531837
train phase, Epoch 5/20, Loss: 16.913316
val phase, Epoch 5/20, Loss: 16.442062
Val Best Loss: 16.442062
Epoch loss: 16.442062
train phase, Epoch 6/20, Loss: 16.436670
val phase, Epoch 6/20, Loss: 16.191382
Val Best Loss: 16.191382
Epoch loss: 16.191382
train phase, Epoch 7/20, Loss: 16.480390
val phase, Epoch 7/20, Loss: 19.593783
Val Best Loss: 16.191382
Epoch loss: 19.593783
train phase, Epoch 8/20, Loss: 16.251507
val phase, Epoch 8/20, Loss: 18.003605
Val Best Loss: 16.191382
Epoch loss: 18.003605
train phase, Epoch 9/20, Loss: 16.205657
val phase, Epoch 9/20, Loss: 16.464891
Val Best Loss: 16.191382
Epoch loss: 16.464891
train phase, Epoch 10/20, Loss: 15.689944
val phase, Epoch 10/20, Loss: 17.345223
Val Best Loss: 16.191382
Epoch loss: 17.345223
train phase, Epoch 11/20, Loss: 15.552492
val phase, Epoch 11/20, Loss: 16.662081
Val Best Loss: 16.191382
Epoch loss: 16.662081
train phase, Epoch 12/20, Loss: 15.437921
val phase, Epoch 12/20, Loss: 16.916890
Val Best Loss: 16.191382
Epoch loss: 16.916890
train phase, Epoch 13/20, Loss: 15.477254
val phase, Epoch 13/20, Loss: 16.066420
Val Best Loss: 16.066420
Epoch loss: 16.066420
train phase, Epoch 14/20, Loss: 15.236601
val phase, Epoch 14/20, Loss: 15.739780
Val Best Loss: 15.739780
Epoch loss: 15.739780
train phase, Epoch 15/20, Loss: 15.104515
val phase, Epoch 15/20, Loss: 16.142559
Val Best Loss: 15.739780
Epoch loss: 16.142559
train phase, Epoch 16/20, Loss: 14.638922
val phase, Epoch 16/20, Loss: 16.714969
Val Best Loss: 15.739780
Epoch loss: 16.714969
train phase, Epoch 17/20, Loss: 14.696550
val phase, Epoch 17/20, Loss: 16.391272
Val Best Loss: 15.739780
Epoch loss: 16.391272
train phase, Epoch 18/20, Loss: 14.451146
val phase, Epoch 18/20, Loss: 16.282845
Val Best Loss: 15.739780
Epoch loss: 16.282845
train phase, Epoch 19/20, Loss: 14.321010
val phase, Epoch 19/20, Loss: 16.770291
Val Best Loss: 15.739780
Epoch loss: 16.770291
train phase, Epoch 20/20, Loss: 14.041102
val phase, Epoch 20/20, Loss: 16.547943
Val Best Loss: 15.739780
Epoch loss: 16.547943
train phase, Epoch 1/20, Loss: 20.431503
val phase, Epoch 1/20, Loss: 18.766323
Val Best Loss: 18.766323
Epoch loss: 18.766323
train phase, Epoch 2/20, Loss: 17.665914
val phase, Epoch 2/20, Loss: 18.008963
Val Best Loss: 18.008963
Epoch loss: 18.008963
train phase, Epoch 3/20, Loss: 17.531003
val phase, Epoch 3/20, Loss: 17.120378
Val Best Loss: 17.120378
Epoch loss: 17.120378
train phase, Epoch 4/20, Loss: 17.093587
val phase, Epoch 4/20, Loss: 17.582705
Val Best Loss: 17.120378
Epoch loss: 17.582705
train phase, Epoch 5/20, Loss: 16.953312
val phase, Epoch 5/20, Loss: 17.527606
Val Best Loss: 17.120378
Epoch loss: 17.527606
train phase, Epoch 6/20, Loss: 16.528484
val phase, Epoch 6/20, Loss: 16.804174
Val Best Loss: 16.804174
Epoch loss: 16.804174
train phase, Epoch 7/20, Loss: 16.486481
val phase, Epoch 7/20, Loss: 16.624707
Val Best Loss: 16.624707
Epoch loss: 16.624707
train phase, Epoch 8/20, Loss: 16.176313
val phase, Epoch 8/20, Loss: 16.716262
Val Best Loss: 16.624707
Epoch loss: 16.716262
train phase, Epoch 9/20, Loss: 16.053265
val phase, Epoch 9/20, Loss: 16.583305
Val Best Loss: 16.583305
Epoch loss: 16.583305
train phase, Epoch 10/20, Loss: 16.175241
val phase, Epoch 10/20, Loss: 16.421877
Val Best Loss: 16.421877
Epoch loss: 16.421877
train phase, Epoch 11/20, Loss: 15.703657
val phase, Epoch 11/20, Loss: 16.633151
Val Best Loss: 16.421877
Epoch loss: 16.633151
train phase, Epoch 12/20, Loss: 15.570604
val phase, Epoch 12/20, Loss: 18.980463
Val Best Loss: 16.421877
Epoch loss: 18.980463
train phase, Epoch 13/20, Loss: 15.416570
val phase, Epoch 13/20, Loss: 16.257863
Val Best Loss: 16.257863
Epoch loss: 16.257863
train phase, Epoch 14/20, Loss: 15.169637
val phase, Epoch 14/20, Loss: 16.352649
Val Best Loss: 16.257863
Epoch loss: 16.352649
train phase, Epoch 15/20, Loss: 15.140014
val phase, Epoch 15/20, Loss: 18.084397
Val Best Loss: 16.257863
Epoch loss: 18.084397
train phase, Epoch 16/20, Loss: 14.865944
val phase, Epoch 16/20, Loss: 16.399879
Val Best Loss: 16.257863
Epoch loss: 16.399879
train phase, Epoch 17/20, Loss: 15.102547
val phase, Epoch 17/20, Loss: 16.207697
Val Best Loss: 16.207697
Epoch loss: 16.207697
train phase, Epoch 18/20, Loss: 14.675034
val phase, Epoch 18/20, Loss: 15.960547
Val Best Loss: 15.960547
Epoch loss: 15.960547
train phase, Epoch 19/20, Loss: 14.282156
val phase, Epoch 19/20, Loss: 16.831048
Val Best Loss: 15.960547
Epoch loss: 16.831048
train phase, Epoch 20/20, Loss: 14.599986
val phase, Epoch 20/20, Loss: 16.472189
Val Best Loss: 15.960547
Epoch loss: 16.472189
train phase, Epoch 1/20, Loss: nan
val phase, Epoch 1/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/20, Loss: nan
val phase, Epoch 2/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/20, Loss: nan
val phase, Epoch 3/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/20, Loss: nan
val phase, Epoch 4/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/20, Loss: nan
val phase, Epoch 5/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/20, Loss: nan
val phase, Epoch 6/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/20, Loss: nan
val phase, Epoch 7/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/20, Loss: nan
val phase, Epoch 8/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/20, Loss: nan
val phase, Epoch 9/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/20, Loss: nan
val phase, Epoch 10/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 11/20, Loss: nan
val phase, Epoch 11/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 12/20, Loss: nan
val phase, Epoch 12/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 13/20, Loss: nan
val phase, Epoch 13/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 14/20, Loss: nan
val phase, Epoch 14/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 15/20, Loss: nan
val phase, Epoch 15/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 16/20, Loss: nan
val phase, Epoch 16/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 17/20, Loss: nan
val phase, Epoch 17/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 18/20, Loss: nan
val phase, Epoch 18/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 19/20, Loss: nan
val phase, Epoch 19/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 20/20, Loss: nan
val phase, Epoch 20/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 1/20, Loss: 19.990967
val phase, Epoch 1/20, Loss: 19.076972
Val Best Loss: 19.076972
Epoch loss: 19.076972
train phase, Epoch 2/20, Loss: 17.585880
val phase, Epoch 2/20, Loss: 18.027925
Val Best Loss: 18.027925
Epoch loss: 18.027925
train phase, Epoch 3/20, Loss: 17.305609
val phase, Epoch 3/20, Loss: 17.439834
Val Best Loss: 17.439834
Epoch loss: 17.439834
train phase, Epoch 4/20, Loss: 17.174952
val phase, Epoch 4/20, Loss: 18.214959
Val Best Loss: 17.439834
Epoch loss: 18.214959
train phase, Epoch 5/20, Loss: 16.824181
val phase, Epoch 5/20, Loss: 16.767505
Val Best Loss: 16.767505
Epoch loss: 16.767505
train phase, Epoch 6/20, Loss: 16.523067
val phase, Epoch 6/20, Loss: 18.254418
Val Best Loss: 16.767505
Epoch loss: 18.254418
train phase, Epoch 7/20, Loss: 16.832806
val phase, Epoch 7/20, Loss: 17.287177
Val Best Loss: 16.767505
Epoch loss: 17.287177
train phase, Epoch 8/20, Loss: 16.158142
val phase, Epoch 8/20, Loss: 18.106191
Val Best Loss: 16.767505
Epoch loss: 18.106191
train phase, Epoch 9/20, Loss: 16.139261
val phase, Epoch 9/20, Loss: 16.611616
Val Best Loss: 16.611616
Epoch loss: 16.611616
train phase, Epoch 10/20, Loss: 15.798638
val phase, Epoch 10/20, Loss: 17.013997
Val Best Loss: 16.611616
Epoch loss: 17.013997
train phase, Epoch 11/20, Loss: 15.634030
val phase, Epoch 11/20, Loss: 16.797444
Val Best Loss: 16.611616
Epoch loss: 16.797444
train phase, Epoch 12/20, Loss: 15.629194
val phase, Epoch 12/20, Loss: 16.486231
Val Best Loss: 16.486231
Epoch loss: 16.486231
train phase, Epoch 13/20, Loss: 15.354078
val phase, Epoch 13/20, Loss: 16.186422
Val Best Loss: 16.186422
Epoch loss: 16.186422
train phase, Epoch 14/20, Loss: 15.455571
val phase, Epoch 14/20, Loss: 16.309613
Val Best Loss: 16.186422
Epoch loss: 16.309613
train phase, Epoch 15/20, Loss: 14.953718
val phase, Epoch 15/20, Loss: 16.529667
Val Best Loss: 16.186422
Epoch loss: 16.529667
train phase, Epoch 16/20, Loss: 15.232690
val phase, Epoch 16/20, Loss: 18.140649
Val Best Loss: 16.186422
Epoch loss: 18.140649
train phase, Epoch 17/20, Loss: 14.793905
val phase, Epoch 17/20, Loss: 16.372274
Val Best Loss: 16.186422
Epoch loss: 16.372274
train phase, Epoch 18/20, Loss: 14.681358
val phase, Epoch 18/20, Loss: 16.033991
Val Best Loss: 16.033991
Epoch loss: 16.033991
train phase, Epoch 19/20, Loss: 14.445673
val phase, Epoch 19/20, Loss: 16.528350
Val Best Loss: 16.033991
Epoch loss: 16.528350
train phase, Epoch 20/20, Loss: 14.292320
val phase, Epoch 20/20, Loss: 17.122083
Val Best Loss: 16.033991
Epoch loss: 17.122083
[Trial 412] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.248132
val phase, Epoch 1/20, Loss: 17.252783
Val Best Loss: 17.252783
Epoch loss: 17.252783
train phase, Epoch 2/20, Loss: 17.904031
val phase, Epoch 2/20, Loss: 18.520831
Val Best Loss: 17.252783
Epoch loss: 18.520831
train phase, Epoch 3/20, Loss: 17.318222
val phase, Epoch 3/20, Loss: 18.753082
Val Best Loss: 17.252783
Epoch loss: 18.753082
train phase, Epoch 4/20, Loss: 17.373130
val phase, Epoch 4/20, Loss: 17.394839
Val Best Loss: 17.252783
Epoch loss: 17.394839
train phase, Epoch 5/20, Loss: 16.884910
val phase, Epoch 5/20, Loss: 16.728043
Val Best Loss: 16.728043
Epoch loss: 16.728043
train phase, Epoch 6/20, Loss: 17.176836
val phase, Epoch 6/20, Loss: 17.297726
Val Best Loss: 16.728043
Epoch loss: 17.297726
train phase, Epoch 7/20, Loss: 16.636282
val phase, Epoch 7/20, Loss: 17.102441
Val Best Loss: 16.728043
Epoch loss: 17.102441
train phase, Epoch 8/20, Loss: 16.573007
val phase, Epoch 8/20, Loss: 16.361121
Val Best Loss: 16.361121
Epoch loss: 16.361121
train phase, Epoch 9/20, Loss: 16.322097
val phase, Epoch 9/20, Loss: 16.284936
Val Best Loss: 16.284936
Epoch loss: 16.284936
train phase, Epoch 10/20, Loss: 16.153548
val phase, Epoch 10/20, Loss: 19.097151
Val Best Loss: 16.284936
Epoch loss: 19.097151
train phase, Epoch 11/20, Loss: 15.942282
val phase, Epoch 11/20, Loss: 17.706765
Val Best Loss: 16.284936
Epoch loss: 17.706765
train phase, Epoch 12/20, Loss: 15.819678
val phase, Epoch 12/20, Loss: 16.924111
Val Best Loss: 16.284936
Epoch loss: 16.924111
train phase, Epoch 13/20, Loss: 15.982077
val phase, Epoch 13/20, Loss: 17.161176
Val Best Loss: 16.284936
Epoch loss: 17.161176
train phase, Epoch 14/20, Loss: 15.392335
val phase, Epoch 14/20, Loss: 15.842591
Val Best Loss: 15.842591
Epoch loss: 15.842591
train phase, Epoch 15/20, Loss: 15.336767
val phase, Epoch 15/20, Loss: 18.152052
Val Best Loss: 15.842591
Epoch loss: 18.152052
train phase, Epoch 16/20, Loss: 15.529797
val phase, Epoch 16/20, Loss: 16.993437
Val Best Loss: 15.842591
Epoch loss: 16.993437
train phase, Epoch 17/20, Loss: 15.185595
val phase, Epoch 17/20, Loss: 16.058424
Val Best Loss: 15.842591
Epoch loss: 16.058424
train phase, Epoch 18/20, Loss: 14.972157
val phase, Epoch 18/20, Loss: 16.884058
Val Best Loss: 15.842591
Epoch loss: 16.884058
train phase, Epoch 19/20, Loss: 14.651591
val phase, Epoch 19/20, Loss: 18.135787
Val Best Loss: 15.842591
Epoch loss: 18.135787
train phase, Epoch 20/20, Loss: 14.672074
val phase, Epoch 20/20, Loss: 16.194091
Val Best Loss: 15.842591
Epoch loss: 16.194091
train phase, Epoch 1/20, Loss: 21.707138
val phase, Epoch 1/20, Loss: 17.010731
Val Best Loss: 17.010731
Epoch loss: 17.010731
train phase, Epoch 2/20, Loss: 17.427925
val phase, Epoch 2/20, Loss: 18.075501
Val Best Loss: 17.010731
Epoch loss: 18.075501
train phase, Epoch 3/20, Loss: 16.825725
val phase, Epoch 3/20, Loss: 16.609601
Val Best Loss: 16.609601
Epoch loss: 16.609601
train phase, Epoch 4/20, Loss: 16.707151
val phase, Epoch 4/20, Loss: 16.085272
Val Best Loss: 16.085272
Epoch loss: 16.085272
train phase, Epoch 5/20, Loss: 16.262405
val phase, Epoch 5/20, Loss: 16.600863
Val Best Loss: 16.085272
Epoch loss: 16.600863
train phase, Epoch 6/20, Loss: 16.443260
val phase, Epoch 6/20, Loss: 16.790034
Val Best Loss: 16.085272
Epoch loss: 16.790034
train phase, Epoch 7/20, Loss: 15.783436
val phase, Epoch 7/20, Loss: 16.024014
Val Best Loss: 16.024014
Epoch loss: 16.024014
train phase, Epoch 8/20, Loss: 15.813654
val phase, Epoch 8/20, Loss: 16.895444
Val Best Loss: 16.024014
Epoch loss: 16.895444
train phase, Epoch 9/20, Loss: 16.026061
val phase, Epoch 9/20, Loss: 15.770771
Val Best Loss: 15.770771
Epoch loss: 15.770771
train phase, Epoch 10/20, Loss: 15.737924
val phase, Epoch 10/20, Loss: 15.958111
Val Best Loss: 15.770771
Epoch loss: 15.958111
train phase, Epoch 11/20, Loss: 15.379649
val phase, Epoch 11/20, Loss: 17.750154
Val Best Loss: 15.770771
Epoch loss: 17.750154
train phase, Epoch 12/20, Loss: 15.904714
val phase, Epoch 12/20, Loss: 16.649924
Val Best Loss: 15.770771
Epoch loss: 16.649924
train phase, Epoch 13/20, Loss: 15.112896
val phase, Epoch 13/20, Loss: 17.626495
Val Best Loss: 15.770771
Epoch loss: 17.626495
train phase, Epoch 14/20, Loss: 14.777572
val phase, Epoch 14/20, Loss: 15.852984
Val Best Loss: 15.770771
Epoch loss: 15.852984
train phase, Epoch 15/20, Loss: 14.751999
val phase, Epoch 15/20, Loss: 17.006725
Val Best Loss: 15.770771
Epoch loss: 17.006725
train phase, Epoch 16/20, Loss: 14.307717
val phase, Epoch 16/20, Loss: 17.571291
Val Best Loss: 15.770771
Epoch loss: 17.571291
train phase, Epoch 17/20, Loss: 14.172502
val phase, Epoch 17/20, Loss: 18.579701
Val Best Loss: 15.770771
Epoch loss: 18.579701
train phase, Epoch 18/20, Loss: 14.089300
val phase, Epoch 18/20, Loss: 19.642115
Val Best Loss: 15.770771
Epoch loss: 19.642115
train phase, Epoch 19/20, Loss: 14.040046
val phase, Epoch 19/20, Loss: 16.864119
Val Best Loss: 15.770771
Epoch loss: 16.864119
train phase, Epoch 20/20, Loss: 13.355029
val phase, Epoch 20/20, Loss: 16.619178
Val Best Loss: 15.770771
Epoch loss: 16.619178
train phase, Epoch 1/20, Loss: 34.570529
val phase, Epoch 1/20, Loss: 23.578543
Val Best Loss: 23.578543
Epoch loss: 23.578543
train phase, Epoch 2/20, Loss: 18.879834
val phase, Epoch 2/20, Loss: 20.521921
Val Best Loss: 20.521921
Epoch loss: 20.521921
train phase, Epoch 3/20, Loss: 18.460822
val phase, Epoch 3/20, Loss: 21.175022
Val Best Loss: 20.521921
Epoch loss: 21.175022
train phase, Epoch 4/20, Loss: 17.954111
val phase, Epoch 4/20, Loss: 17.367504
Val Best Loss: 17.367504
Epoch loss: 17.367504
train phase, Epoch 5/20, Loss: 17.700204
val phase, Epoch 5/20, Loss: 17.132886
Val Best Loss: 17.132886
Epoch loss: 17.132886
train phase, Epoch 6/20, Loss: 17.305401
val phase, Epoch 6/20, Loss: 19.714297
Val Best Loss: 17.132886
Epoch loss: 19.714297
train phase, Epoch 7/20, Loss: 17.340880
val phase, Epoch 7/20, Loss: 18.250653
Val Best Loss: 17.132886
Epoch loss: 18.250653
train phase, Epoch 8/20, Loss: 16.942344
val phase, Epoch 8/20, Loss: 17.556585
Val Best Loss: 17.132886
Epoch loss: 17.556585
train phase, Epoch 9/20, Loss: 16.837280
val phase, Epoch 9/20, Loss: 18.121087
Val Best Loss: 17.132886
Epoch loss: 18.121087
train phase, Epoch 10/20, Loss: 16.419217
val phase, Epoch 10/20, Loss: 16.597615
Val Best Loss: 16.597615
Epoch loss: 16.597615
train phase, Epoch 11/20, Loss: 16.357641
val phase, Epoch 11/20, Loss: 17.780404
Val Best Loss: 16.597615
Epoch loss: 17.780404
train phase, Epoch 12/20, Loss: 15.997184
val phase, Epoch 12/20, Loss: 16.705830
Val Best Loss: 16.597615
Epoch loss: 16.705830
train phase, Epoch 13/20, Loss: 15.870480
val phase, Epoch 13/20, Loss: 16.411693
Val Best Loss: 16.411693
Epoch loss: 16.411693
train phase, Epoch 14/20, Loss: 15.654351
val phase, Epoch 14/20, Loss: 16.882643
Val Best Loss: 16.411693
Epoch loss: 16.882643
train phase, Epoch 15/20, Loss: 15.775402
val phase, Epoch 15/20, Loss: 16.654037
Val Best Loss: 16.411693
Epoch loss: 16.654037
train phase, Epoch 16/20, Loss: 15.164549
val phase, Epoch 16/20, Loss: 16.649163
Val Best Loss: 16.411693
Epoch loss: 16.649163
train phase, Epoch 17/20, Loss: 15.384441
val phase, Epoch 17/20, Loss: 17.143673
Val Best Loss: 16.411693
Epoch loss: 17.143673
train phase, Epoch 18/20, Loss: 14.919367
val phase, Epoch 18/20, Loss: 16.215588
Val Best Loss: 16.215588
Epoch loss: 16.215588
train phase, Epoch 19/20, Loss: 14.735486
val phase, Epoch 19/20, Loss: 16.698769
Val Best Loss: 16.215588
Epoch loss: 16.698769
train phase, Epoch 20/20, Loss: 14.489335
val phase, Epoch 20/20, Loss: 16.681318
Val Best Loss: 16.215588
Epoch loss: 16.681318
train phase, Epoch 1/20, Loss: 20.010227
val phase, Epoch 1/20, Loss: 17.381056
Val Best Loss: 17.381056
Epoch loss: 17.381056
train phase, Epoch 2/20, Loss: 18.228863
val phase, Epoch 2/20, Loss: 17.838698
Val Best Loss: 17.381056
Epoch loss: 17.838698
train phase, Epoch 3/20, Loss: 17.761987
val phase, Epoch 3/20, Loss: 17.663599
Val Best Loss: 17.381056
Epoch loss: 17.663599
train phase, Epoch 4/20, Loss: 17.757385
val phase, Epoch 4/20, Loss: 17.632707
Val Best Loss: 17.381056
Epoch loss: 17.632707
train phase, Epoch 5/20, Loss: 17.473785
val phase, Epoch 5/20, Loss: 16.328346
Val Best Loss: 16.328346
Epoch loss: 16.328346
train phase, Epoch 6/20, Loss: 17.356893
val phase, Epoch 6/20, Loss: 18.817946
Val Best Loss: 16.328346
Epoch loss: 18.817946
train phase, Epoch 7/20, Loss: 17.067022
val phase, Epoch 7/20, Loss: 16.325227
Val Best Loss: 16.325227
Epoch loss: 16.325227
train phase, Epoch 8/20, Loss: 17.005729
val phase, Epoch 8/20, Loss: 16.114924
Val Best Loss: 16.114924
Epoch loss: 16.114924
train phase, Epoch 9/20, Loss: 16.766536
val phase, Epoch 9/20, Loss: 16.103413
Val Best Loss: 16.103413
Epoch loss: 16.103413
train phase, Epoch 10/20, Loss: 16.837057
val phase, Epoch 10/20, Loss: 16.640312
Val Best Loss: 16.103413
Epoch loss: 16.640312
train phase, Epoch 11/20, Loss: 16.324699
val phase, Epoch 11/20, Loss: 18.156464
Val Best Loss: 16.103413
Epoch loss: 18.156464
train phase, Epoch 12/20, Loss: 16.305483
val phase, Epoch 12/20, Loss: 16.048829
Val Best Loss: 16.048829
Epoch loss: 16.048829
train phase, Epoch 13/20, Loss: 16.301846
val phase, Epoch 13/20, Loss: 16.167057
Val Best Loss: 16.048829
Epoch loss: 16.167057
train phase, Epoch 14/20, Loss: 16.021100
val phase, Epoch 14/20, Loss: 15.871788
Val Best Loss: 15.871788
Epoch loss: 15.871788
train phase, Epoch 15/20, Loss: 15.932539
val phase, Epoch 15/20, Loss: 16.042677
Val Best Loss: 15.871788
Epoch loss: 16.042677
train phase, Epoch 16/20, Loss: 15.724563
val phase, Epoch 16/20, Loss: 16.170332
Val Best Loss: 15.871788
Epoch loss: 16.170332
train phase, Epoch 17/20, Loss: 15.868972
val phase, Epoch 17/20, Loss: 17.197393
Val Best Loss: 15.871788
Epoch loss: 17.197393
train phase, Epoch 18/20, Loss: 15.618725
val phase, Epoch 18/20, Loss: 16.147132
Val Best Loss: 15.871788
Epoch loss: 16.147132
train phase, Epoch 19/20, Loss: 15.301055
val phase, Epoch 19/20, Loss: 16.673097
Val Best Loss: 15.871788
Epoch loss: 16.673097
train phase, Epoch 20/20, Loss: 15.244408
val phase, Epoch 20/20, Loss: 16.063172
Val Best Loss: 15.871788
Epoch loss: 16.063172
[Trial 417] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.868780
val phase, Epoch 1/20, Loss: 22.323269
Val Best Loss: 22.323269
Epoch loss: 22.323269
train phase, Epoch 2/20, Loss: 17.366698
val phase, Epoch 2/20, Loss: 17.391875
Val Best Loss: 17.391875
Epoch loss: 17.391875
train phase, Epoch 3/20, Loss: 17.241387
val phase, Epoch 3/20, Loss: 18.247571
Val Best Loss: 17.391875
Epoch loss: 18.247571
train phase, Epoch 4/20, Loss: 17.011127
val phase, Epoch 4/20, Loss: 16.843487
Val Best Loss: 16.843487
Epoch loss: 16.843487
train phase, Epoch 5/20, Loss: 16.770923
val phase, Epoch 5/20, Loss: 16.126989
Val Best Loss: 16.126989
Epoch loss: 16.126989
train phase, Epoch 6/20, Loss: 16.293851
val phase, Epoch 6/20, Loss: 17.038764
Val Best Loss: 16.126989
Epoch loss: 17.038764
train phase, Epoch 7/20, Loss: 16.202469
val phase, Epoch 7/20, Loss: 16.637697
Val Best Loss: 16.126989
Epoch loss: 16.637697
train phase, Epoch 8/20, Loss: 16.288738
val phase, Epoch 8/20, Loss: 16.162272
Val Best Loss: 16.126989
Epoch loss: 16.162272
train phase, Epoch 9/20, Loss: 15.964310
val phase, Epoch 9/20, Loss: 17.953138
Val Best Loss: 16.126989
Epoch loss: 17.953138
train phase, Epoch 10/20, Loss: 15.914536
val phase, Epoch 10/20, Loss: 16.481775
Val Best Loss: 16.126989
Epoch loss: 16.481775
train phase, Epoch 11/20, Loss: 15.624005
val phase, Epoch 11/20, Loss: 16.842778
Val Best Loss: 16.126989
Epoch loss: 16.842778
train phase, Epoch 12/20, Loss: 15.388560
val phase, Epoch 12/20, Loss: 16.085714
Val Best Loss: 16.085714
Epoch loss: 16.085714
train phase, Epoch 13/20, Loss: 15.082578
val phase, Epoch 13/20, Loss: 16.413010
Val Best Loss: 16.085714
Epoch loss: 16.413010
train phase, Epoch 14/20, Loss: 14.992685
val phase, Epoch 14/20, Loss: 18.565825
Val Best Loss: 16.085714
Epoch loss: 18.565825
train phase, Epoch 15/20, Loss: 14.782929
val phase, Epoch 15/20, Loss: 16.642261
Val Best Loss: 16.085714
Epoch loss: 16.642261
train phase, Epoch 16/20, Loss: 14.235691
val phase, Epoch 16/20, Loss: 18.423639
Val Best Loss: 16.085714
Epoch loss: 18.423639
train phase, Epoch 17/20, Loss: 14.302347
val phase, Epoch 17/20, Loss: 17.275018
Val Best Loss: 16.085714
Epoch loss: 17.275018
train phase, Epoch 18/20, Loss: 13.795419
val phase, Epoch 18/20, Loss: 16.378045
Val Best Loss: 16.085714
Epoch loss: 16.378045
train phase, Epoch 19/20, Loss: 13.522244
val phase, Epoch 19/20, Loss: 17.706288
Val Best Loss: 16.085714
Epoch loss: 17.706288
train phase, Epoch 20/20, Loss: 13.132355
val phase, Epoch 20/20, Loss: 17.353052
Val Best Loss: 16.085714
Epoch loss: 17.353052
train phase, Epoch 1/20, Loss: 20.312846
val phase, Epoch 1/20, Loss: 17.309185
Val Best Loss: 17.309185
Epoch loss: 17.309185
train phase, Epoch 2/20, Loss: 17.624869
val phase, Epoch 2/20, Loss: 17.072186
Val Best Loss: 17.072186
Epoch loss: 17.072186
train phase, Epoch 3/20, Loss: 17.442431
val phase, Epoch 3/20, Loss: 17.043516
Val Best Loss: 17.043516
Epoch loss: 17.043516
train phase, Epoch 4/20, Loss: 16.744713
val phase, Epoch 4/20, Loss: 16.271004
Val Best Loss: 16.271004
Epoch loss: 16.271004
train phase, Epoch 5/20, Loss: 16.942789
val phase, Epoch 5/20, Loss: 17.432331
Val Best Loss: 16.271004
Epoch loss: 17.432331
train phase, Epoch 6/20, Loss: 16.485859
val phase, Epoch 6/20, Loss: 17.095479
Val Best Loss: 16.271004
Epoch loss: 17.095479
train phase, Epoch 7/20, Loss: 16.612882
val phase, Epoch 7/20, Loss: 16.262508
Val Best Loss: 16.262508
Epoch loss: 16.262508
train phase, Epoch 8/20, Loss: 15.954125
val phase, Epoch 8/20, Loss: 17.365790
Val Best Loss: 16.262508
Epoch loss: 17.365790
train phase, Epoch 9/20, Loss: 15.879304
val phase, Epoch 9/20, Loss: 16.449123
Val Best Loss: 16.262508
Epoch loss: 16.449123
train phase, Epoch 10/20, Loss: 15.777084
val phase, Epoch 10/20, Loss: 16.195581
Val Best Loss: 16.195581
Epoch loss: 16.195581
train phase, Epoch 11/20, Loss: 15.822835
val phase, Epoch 11/20, Loss: 15.849373
Val Best Loss: 15.849373
Epoch loss: 15.849373
train phase, Epoch 12/20, Loss: 15.464029
val phase, Epoch 12/20, Loss: 15.595107
Val Best Loss: 15.595107
Epoch loss: 15.595107
train phase, Epoch 13/20, Loss: 15.359625
val phase, Epoch 13/20, Loss: 16.411181
Val Best Loss: 15.595107
Epoch loss: 16.411181
train phase, Epoch 14/20, Loss: 15.193781
val phase, Epoch 14/20, Loss: 17.536968
Val Best Loss: 15.595107
Epoch loss: 17.536968
train phase, Epoch 15/20, Loss: 15.018533
val phase, Epoch 15/20, Loss: 16.904366
Val Best Loss: 15.595107
Epoch loss: 16.904366
train phase, Epoch 16/20, Loss: 14.955137
val phase, Epoch 16/20, Loss: 17.039771
Val Best Loss: 15.595107
Epoch loss: 17.039771
train phase, Epoch 17/20, Loss: 14.514490
val phase, Epoch 17/20, Loss: 16.344211
Val Best Loss: 15.595107
Epoch loss: 16.344211
train phase, Epoch 18/20, Loss: 14.401197
val phase, Epoch 18/20, Loss: 16.206741
Val Best Loss: 15.595107
Epoch loss: 16.206741
train phase, Epoch 19/20, Loss: 13.978439
val phase, Epoch 19/20, Loss: 17.956244
Val Best Loss: 15.595107
Epoch loss: 17.956244
train phase, Epoch 20/20, Loss: 13.973688
val phase, Epoch 20/20, Loss: 16.469795
Val Best Loss: 15.595107
Epoch loss: 16.469795
train phase, Epoch 1/20, Loss: 20.551928
val phase, Epoch 1/20, Loss: 18.845026
Val Best Loss: 18.845026
Epoch loss: 18.845026
train phase, Epoch 2/20, Loss: 17.711918
val phase, Epoch 2/20, Loss: 16.620803
Val Best Loss: 16.620803
Epoch loss: 16.620803
train phase, Epoch 3/20, Loss: 16.918008
val phase, Epoch 3/20, Loss: 17.257350
Val Best Loss: 16.620803
Epoch loss: 17.257350
train phase, Epoch 4/20, Loss: 16.708295
val phase, Epoch 4/20, Loss: 18.078415
Val Best Loss: 16.620803
Epoch loss: 18.078415
train phase, Epoch 5/20, Loss: 16.619530
val phase, Epoch 5/20, Loss: 17.048026
Val Best Loss: 16.620803
Epoch loss: 17.048026
train phase, Epoch 6/20, Loss: 16.403650
val phase, Epoch 6/20, Loss: 16.162892
Val Best Loss: 16.162892
Epoch loss: 16.162892
train phase, Epoch 7/20, Loss: 16.164316
val phase, Epoch 7/20, Loss: 16.227229
Val Best Loss: 16.162892
Epoch loss: 16.227229
train phase, Epoch 8/20, Loss: 16.121314
val phase, Epoch 8/20, Loss: 16.017868
Val Best Loss: 16.017868
Epoch loss: 16.017868
train phase, Epoch 9/20, Loss: 15.840615
val phase, Epoch 9/20, Loss: 16.527697
Val Best Loss: 16.017868
Epoch loss: 16.527697
train phase, Epoch 10/20, Loss: 16.035743
val phase, Epoch 10/20, Loss: 15.736724
Val Best Loss: 15.736724
Epoch loss: 15.736724
train phase, Epoch 11/20, Loss: 15.441728
val phase, Epoch 11/20, Loss: 15.759250
Val Best Loss: 15.736724
Epoch loss: 15.759250
train phase, Epoch 12/20, Loss: 15.591085
val phase, Epoch 12/20, Loss: 16.748474
Val Best Loss: 15.736724
Epoch loss: 16.748474
train phase, Epoch 13/20, Loss: 15.249503
val phase, Epoch 13/20, Loss: 16.805299
Val Best Loss: 15.736724
Epoch loss: 16.805299
train phase, Epoch 14/20, Loss: 14.966938
val phase, Epoch 14/20, Loss: 16.971659
Val Best Loss: 15.736724
Epoch loss: 16.971659
train phase, Epoch 15/20, Loss: 14.920156
val phase, Epoch 15/20, Loss: 16.190426
Val Best Loss: 15.736724
Epoch loss: 16.190426
train phase, Epoch 16/20, Loss: 14.604799
val phase, Epoch 16/20, Loss: 17.033822
Val Best Loss: 15.736724
Epoch loss: 17.033822
train phase, Epoch 17/20, Loss: 14.529400
val phase, Epoch 17/20, Loss: 16.309746
Val Best Loss: 15.736724
Epoch loss: 16.309746
train phase, Epoch 18/20, Loss: 14.055011
val phase, Epoch 18/20, Loss: 16.105625
Val Best Loss: 15.736724
Epoch loss: 16.105625
train phase, Epoch 19/20, Loss: 13.806808
val phase, Epoch 19/20, Loss: 16.395221
Val Best Loss: 15.736724
Epoch loss: 16.395221
train phase, Epoch 20/20, Loss: 13.831851
val phase, Epoch 20/20, Loss: 18.626055
Val Best Loss: 15.736724
Epoch loss: 18.626055
[Trial 421] Skipped due to model construction error: Given input size: (128x5x2). Calculated output size: (128x1x0). Output size is too small
train phase, Epoch 1/20, Loss: 20.714829
val phase, Epoch 1/20, Loss: 18.197915
Val Best Loss: 18.197915
Epoch loss: 18.197915
train phase, Epoch 2/20, Loss: 17.363801
val phase, Epoch 2/20, Loss: 16.926723
Val Best Loss: 16.926723
Epoch loss: 16.926723
train phase, Epoch 3/20, Loss: 17.075895
val phase, Epoch 3/20, Loss: 17.369156
Val Best Loss: 16.926723
Epoch loss: 17.369156
train phase, Epoch 4/20, Loss: 16.900820
val phase, Epoch 4/20, Loss: 19.039052
Val Best Loss: 16.926723
Epoch loss: 19.039052
train phase, Epoch 5/20, Loss: 16.430999
val phase, Epoch 5/20, Loss: 18.087672
Val Best Loss: 16.926723
Epoch loss: 18.087672
train phase, Epoch 6/20, Loss: 16.466504
val phase, Epoch 6/20, Loss: 16.764632
Val Best Loss: 16.764632
Epoch loss: 16.764632
train phase, Epoch 7/20, Loss: 16.326436
val phase, Epoch 7/20, Loss: 16.256915
Val Best Loss: 16.256915
Epoch loss: 16.256915
train phase, Epoch 8/20, Loss: 15.776268
val phase, Epoch 8/20, Loss: 16.272063
Val Best Loss: 16.256915
Epoch loss: 16.272063
train phase, Epoch 9/20, Loss: 15.669082
val phase, Epoch 9/20, Loss: 16.322599
Val Best Loss: 16.256915
Epoch loss: 16.322599
train phase, Epoch 10/20, Loss: 15.477592
val phase, Epoch 10/20, Loss: 18.088679
Val Best Loss: 16.256915
Epoch loss: 18.088679
train phase, Epoch 11/20, Loss: 15.174765
val phase, Epoch 11/20, Loss: 16.662321
Val Best Loss: 16.256915
Epoch loss: 16.662321
train phase, Epoch 12/20, Loss: 15.758967
val phase, Epoch 12/20, Loss: 16.020092
Val Best Loss: 16.020092
Epoch loss: 16.020092
train phase, Epoch 13/20, Loss: 14.847362
val phase, Epoch 13/20, Loss: 16.171195
Val Best Loss: 16.020092
Epoch loss: 16.171195
train phase, Epoch 14/20, Loss: 14.656421
val phase, Epoch 14/20, Loss: 16.950238
Val Best Loss: 16.020092
Epoch loss: 16.950238
train phase, Epoch 15/20, Loss: 14.472911
val phase, Epoch 15/20, Loss: 16.424865
Val Best Loss: 16.020092
Epoch loss: 16.424865
train phase, Epoch 16/20, Loss: 14.238283
val phase, Epoch 16/20, Loss: 16.335718
Val Best Loss: 16.020092
Epoch loss: 16.335718
train phase, Epoch 17/20, Loss: 14.093956
val phase, Epoch 17/20, Loss: 17.744266
Val Best Loss: 16.020092
Epoch loss: 17.744266
train phase, Epoch 18/20, Loss: 13.554500
val phase, Epoch 18/20, Loss: 16.859620
Val Best Loss: 16.020092
Epoch loss: 16.859620
train phase, Epoch 19/20, Loss: 13.416743
val phase, Epoch 19/20, Loss: 19.251345
Val Best Loss: 16.020092
Epoch loss: 19.251345
train phase, Epoch 20/20, Loss: 12.942071
val phase, Epoch 20/20, Loss: 16.919135
Val Best Loss: 16.020092
Epoch loss: 16.919135
train phase, Epoch 1/20, Loss: 21.268144
val phase, Epoch 1/20, Loss: 17.967446
Val Best Loss: 17.967446
Epoch loss: 17.967446
train phase, Epoch 2/20, Loss: 17.571751
val phase, Epoch 2/20, Loss: 19.233409
Val Best Loss: 17.967446
Epoch loss: 19.233409
train phase, Epoch 3/20, Loss: 17.021220
val phase, Epoch 3/20, Loss: 17.875394
Val Best Loss: 17.875394
Epoch loss: 17.875394
train phase, Epoch 4/20, Loss: 16.969181
val phase, Epoch 4/20, Loss: 16.888336
Val Best Loss: 16.888336
Epoch loss: 16.888336
train phase, Epoch 5/20, Loss: 16.591476
val phase, Epoch 5/20, Loss: 16.400137
Val Best Loss: 16.400137
Epoch loss: 16.400137
train phase, Epoch 6/20, Loss: 16.668076
val phase, Epoch 6/20, Loss: 16.129721
Val Best Loss: 16.129721
Epoch loss: 16.129721
train phase, Epoch 7/20, Loss: 16.048627
val phase, Epoch 7/20, Loss: 16.453710
Val Best Loss: 16.129721
Epoch loss: 16.453710
train phase, Epoch 8/20, Loss: 16.049496
val phase, Epoch 8/20, Loss: 16.806505
Val Best Loss: 16.129721
Epoch loss: 16.806505
train phase, Epoch 9/20, Loss: 15.973627
val phase, Epoch 9/20, Loss: 15.973135
Val Best Loss: 15.973135
Epoch loss: 15.973135
train phase, Epoch 10/20, Loss: 15.616360
val phase, Epoch 10/20, Loss: 16.360619
Val Best Loss: 15.973135
Epoch loss: 16.360619
train phase, Epoch 11/20, Loss: 15.690400
val phase, Epoch 11/20, Loss: 17.667259
Val Best Loss: 15.973135
Epoch loss: 17.667259
train phase, Epoch 12/20, Loss: 15.692046
val phase, Epoch 12/20, Loss: 16.077360
Val Best Loss: 15.973135
Epoch loss: 16.077360
train phase, Epoch 13/20, Loss: 15.539631
val phase, Epoch 13/20, Loss: 16.373969
Val Best Loss: 15.973135
Epoch loss: 16.373969
train phase, Epoch 14/20, Loss: 15.138891
val phase, Epoch 14/20, Loss: 16.638901
Val Best Loss: 15.973135
Epoch loss: 16.638901
train phase, Epoch 15/20, Loss: 15.041040
val phase, Epoch 15/20, Loss: 15.756426
Val Best Loss: 15.756426
Epoch loss: 15.756426
train phase, Epoch 16/20, Loss: 14.689701
val phase, Epoch 16/20, Loss: 16.247684
Val Best Loss: 15.756426
Epoch loss: 16.247684
train phase, Epoch 17/20, Loss: 14.440509
val phase, Epoch 17/20, Loss: 16.202982
Val Best Loss: 15.756426
Epoch loss: 16.202982
train phase, Epoch 18/20, Loss: 14.261252
val phase, Epoch 18/20, Loss: 16.101875
Val Best Loss: 15.756426
Epoch loss: 16.101875
train phase, Epoch 19/20, Loss: 14.231578
val phase, Epoch 19/20, Loss: 16.552336
Val Best Loss: 15.756426
Epoch loss: 16.552336
train phase, Epoch 20/20, Loss: 13.940848
val phase, Epoch 20/20, Loss: 16.193130
Val Best Loss: 15.756426
Epoch loss: 16.193130
train phase, Epoch 1/20, Loss: 20.737530
val phase, Epoch 1/20, Loss: 17.212907
Val Best Loss: 17.212907
Epoch loss: 17.212907
train phase, Epoch 2/20, Loss: 17.585323
val phase, Epoch 2/20, Loss: 18.286859
Val Best Loss: 17.212907
Epoch loss: 18.286859
train phase, Epoch 3/20, Loss: 17.260433
val phase, Epoch 3/20, Loss: 16.388338
Val Best Loss: 16.388338
Epoch loss: 16.388338
train phase, Epoch 4/20, Loss: 16.977740
val phase, Epoch 4/20, Loss: 16.308899
Val Best Loss: 16.308899
Epoch loss: 16.308899
train phase, Epoch 5/20, Loss: 16.715744
val phase, Epoch 5/20, Loss: 16.290442
Val Best Loss: 16.290442
Epoch loss: 16.290442
train phase, Epoch 6/20, Loss: 16.215857
val phase, Epoch 6/20, Loss: 16.397769
Val Best Loss: 16.290442
Epoch loss: 16.397769
train phase, Epoch 7/20, Loss: 16.165600
val phase, Epoch 7/20, Loss: 16.105839
Val Best Loss: 16.105839
Epoch loss: 16.105839
train phase, Epoch 8/20, Loss: 16.207422
val phase, Epoch 8/20, Loss: 17.509276
Val Best Loss: 16.105839
Epoch loss: 17.509276
train phase, Epoch 9/20, Loss: 15.981944
val phase, Epoch 9/20, Loss: 16.254366
Val Best Loss: 16.105839
Epoch loss: 16.254366
train phase, Epoch 10/20, Loss: 16.254906
val phase, Epoch 10/20, Loss: 16.447499
Val Best Loss: 16.105839
Epoch loss: 16.447499
train phase, Epoch 11/20, Loss: 15.590618
val phase, Epoch 11/20, Loss: 15.747658
Val Best Loss: 15.747658
Epoch loss: 15.747658
train phase, Epoch 12/20, Loss: 15.628312
val phase, Epoch 12/20, Loss: 16.310868
Val Best Loss: 15.747658
Epoch loss: 16.310868
train phase, Epoch 13/20, Loss: 15.472526
val phase, Epoch 13/20, Loss: 15.980677
Val Best Loss: 15.747658
Epoch loss: 15.980677
train phase, Epoch 14/20, Loss: 15.222272
val phase, Epoch 14/20, Loss: 18.783410
Val Best Loss: 15.747658
Epoch loss: 18.783410
train phase, Epoch 15/20, Loss: 15.296765
val phase, Epoch 15/20, Loss: 15.828001
Val Best Loss: 15.747658
Epoch loss: 15.828001
train phase, Epoch 16/20, Loss: 14.855042
val phase, Epoch 16/20, Loss: 16.192501
Val Best Loss: 15.747658
Epoch loss: 16.192501
train phase, Epoch 17/20, Loss: 14.867180
val phase, Epoch 17/20, Loss: 15.847216
Val Best Loss: 15.747658
Epoch loss: 15.847216
train phase, Epoch 18/20, Loss: 14.728782
val phase, Epoch 18/20, Loss: 18.154046
Val Best Loss: 15.747658
Epoch loss: 18.154046
train phase, Epoch 19/20, Loss: 14.286984
val phase, Epoch 19/20, Loss: 16.744722
Val Best Loss: 15.747658
Epoch loss: 16.744722
train phase, Epoch 20/20, Loss: 14.030783
val phase, Epoch 20/20, Loss: 16.279210
Val Best Loss: 15.747658
Epoch loss: 16.279210
train phase, Epoch 1/20, Loss: 22.447899
val phase, Epoch 1/20, Loss: 17.969118
Val Best Loss: 17.969118
Epoch loss: 17.969118
train phase, Epoch 2/20, Loss: 18.015686
val phase, Epoch 2/20, Loss: 18.858008
Val Best Loss: 17.969118
Epoch loss: 18.858008
train phase, Epoch 3/20, Loss: 17.917404
val phase, Epoch 3/20, Loss: 17.825333
Val Best Loss: 17.825333
Epoch loss: 17.825333
train phase, Epoch 4/20, Loss: 17.414386
val phase, Epoch 4/20, Loss: 18.641167
Val Best Loss: 17.825333
Epoch loss: 18.641167
train phase, Epoch 5/20, Loss: 17.319762
val phase, Epoch 5/20, Loss: 18.243223
Val Best Loss: 17.825333
Epoch loss: 18.243223
train phase, Epoch 6/20, Loss: 17.279563
val phase, Epoch 6/20, Loss: 17.415509
Val Best Loss: 17.415509
Epoch loss: 17.415509
train phase, Epoch 7/20, Loss: 16.742869
val phase, Epoch 7/20, Loss: 18.549343
Val Best Loss: 17.415509
Epoch loss: 18.549343
train phase, Epoch 8/20, Loss: 16.819893
val phase, Epoch 8/20, Loss: 17.187668
Val Best Loss: 17.187668
Epoch loss: 17.187668
train phase, Epoch 9/20, Loss: 16.440427
val phase, Epoch 9/20, Loss: 17.255399
Val Best Loss: 17.187668
Epoch loss: 17.255399
train phase, Epoch 10/20, Loss: 16.623235
val phase, Epoch 10/20, Loss: 18.629421
Val Best Loss: 17.187668
Epoch loss: 18.629421
train phase, Epoch 11/20, Loss: 16.380013
val phase, Epoch 11/20, Loss: 19.210633
Val Best Loss: 17.187668
Epoch loss: 19.210633
train phase, Epoch 12/20, Loss: 16.135180
val phase, Epoch 12/20, Loss: 17.032900
Val Best Loss: 17.032900
Epoch loss: 17.032900
train phase, Epoch 13/20, Loss: 15.879258
val phase, Epoch 13/20, Loss: 18.713845
Val Best Loss: 17.032900
Epoch loss: 18.713845
train phase, Epoch 14/20, Loss: 15.892557
val phase, Epoch 14/20, Loss: 17.331918
Val Best Loss: 17.032900
Epoch loss: 17.331918
train phase, Epoch 15/20, Loss: 15.612724
val phase, Epoch 15/20, Loss: 17.126316
Val Best Loss: 17.032900
Epoch loss: 17.126316
train phase, Epoch 16/20, Loss: 15.635147
val phase, Epoch 16/20, Loss: 16.569596
Val Best Loss: 16.569596
Epoch loss: 16.569596
train phase, Epoch 17/20, Loss: 15.424339
val phase, Epoch 17/20, Loss: 17.334514
Val Best Loss: 16.569596
Epoch loss: 17.334514
train phase, Epoch 18/20, Loss: 15.348384
val phase, Epoch 18/20, Loss: 18.325092
Val Best Loss: 16.569596
Epoch loss: 18.325092
train phase, Epoch 19/20, Loss: 15.085042
val phase, Epoch 19/20, Loss: 16.847794
Val Best Loss: 16.569596
Epoch loss: 16.847794
train phase, Epoch 20/20, Loss: 15.008406
val phase, Epoch 20/20, Loss: 16.939261
Val Best Loss: 16.569596
Epoch loss: 16.939261
train phase, Epoch 1/20, Loss: 20.984296
val phase, Epoch 1/20, Loss: 19.828239
Val Best Loss: 19.828239
Epoch loss: 19.828239
train phase, Epoch 2/20, Loss: 17.544813
val phase, Epoch 2/20, Loss: 16.858622
Val Best Loss: 16.858622
Epoch loss: 16.858622
train phase, Epoch 3/20, Loss: 16.927413
val phase, Epoch 3/20, Loss: 16.912603
Val Best Loss: 16.858622
Epoch loss: 16.912603
train phase, Epoch 4/20, Loss: 16.646450
val phase, Epoch 4/20, Loss: 18.418109
Val Best Loss: 16.858622
Epoch loss: 18.418109
train phase, Epoch 5/20, Loss: 16.229730
val phase, Epoch 5/20, Loss: 16.931086
Val Best Loss: 16.858622
Epoch loss: 16.931086
train phase, Epoch 6/20, Loss: 16.234387
val phase, Epoch 6/20, Loss: 16.246696
Val Best Loss: 16.246696
Epoch loss: 16.246696
train phase, Epoch 7/20, Loss: 16.195250
val phase, Epoch 7/20, Loss: 17.028230
Val Best Loss: 16.246696
Epoch loss: 17.028230
train phase, Epoch 8/20, Loss: 15.849750
val phase, Epoch 8/20, Loss: 18.145164
Val Best Loss: 16.246696
Epoch loss: 18.145164
train phase, Epoch 9/20, Loss: 15.742810
val phase, Epoch 9/20, Loss: 16.139921
Val Best Loss: 16.139921
Epoch loss: 16.139921
train phase, Epoch 10/20, Loss: 15.711145
val phase, Epoch 10/20, Loss: 17.526947
Val Best Loss: 16.139921
Epoch loss: 17.526947
train phase, Epoch 11/20, Loss: 15.372646
val phase, Epoch 11/20, Loss: 16.198264
Val Best Loss: 16.139921
Epoch loss: 16.198264
train phase, Epoch 12/20, Loss: 15.383295
val phase, Epoch 12/20, Loss: 16.078135
Val Best Loss: 16.078135
Epoch loss: 16.078135
train phase, Epoch 13/20, Loss: 14.857401
val phase, Epoch 13/20, Loss: 18.119394
Val Best Loss: 16.078135
Epoch loss: 18.119394
train phase, Epoch 14/20, Loss: 14.867186
val phase, Epoch 14/20, Loss: 16.618858
Val Best Loss: 16.078135
Epoch loss: 16.618858
train phase, Epoch 15/20, Loss: 14.703584
val phase, Epoch 15/20, Loss: 16.684041
Val Best Loss: 16.078135
Epoch loss: 16.684041
train phase, Epoch 16/20, Loss: 14.349859
val phase, Epoch 16/20, Loss: 16.571766
Val Best Loss: 16.078135
Epoch loss: 16.571766
train phase, Epoch 17/20, Loss: 14.401179
val phase, Epoch 17/20, Loss: 16.211997
Val Best Loss: 16.078135
Epoch loss: 16.211997
train phase, Epoch 18/20, Loss: 13.719232
val phase, Epoch 18/20, Loss: 16.383629
Val Best Loss: 16.078135
Epoch loss: 16.383629
train phase, Epoch 19/20, Loss: 13.322483
val phase, Epoch 19/20, Loss: 16.543140
Val Best Loss: 16.078135
Epoch loss: 16.543140
train phase, Epoch 20/20, Loss: 13.241428
val phase, Epoch 20/20, Loss: 17.198105
Val Best Loss: 16.078135
Epoch loss: 17.198105
[Trial 427] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 22.395849
val phase, Epoch 1/20, Loss: 33.101582
Val Best Loss: 33.101582
Epoch loss: 33.101582
train phase, Epoch 2/20, Loss: 17.588836
val phase, Epoch 2/20, Loss: 30.879641
Val Best Loss: 30.879641
Epoch loss: 30.879641
train phase, Epoch 3/20, Loss: 17.150010
val phase, Epoch 3/20, Loss: 32.133520
Val Best Loss: 30.879641
Epoch loss: 32.133520
train phase, Epoch 4/20, Loss: 16.868455
val phase, Epoch 4/20, Loss: 28.601697
Val Best Loss: 28.601697
Epoch loss: 28.601697
train phase, Epoch 5/20, Loss: 16.681560
val phase, Epoch 5/20, Loss: 29.787108
Val Best Loss: 28.601697
Epoch loss: 29.787108
train phase, Epoch 6/20, Loss: 16.702075
val phase, Epoch 6/20, Loss: 30.076731
Val Best Loss: 28.601697
Epoch loss: 30.076731
train phase, Epoch 7/20, Loss: 16.438000
val phase, Epoch 7/20, Loss: 27.923635
Val Best Loss: 27.923635
Epoch loss: 27.923635
train phase, Epoch 8/20, Loss: 16.277395
val phase, Epoch 8/20, Loss: 30.736193
Val Best Loss: 27.923635
Epoch loss: 30.736193
train phase, Epoch 9/20, Loss: 16.055825
val phase, Epoch 9/20, Loss: 29.967760
Val Best Loss: 27.923635
Epoch loss: 29.967760
train phase, Epoch 10/20, Loss: 15.970203
val phase, Epoch 10/20, Loss: 31.500634
Val Best Loss: 27.923635
Epoch loss: 31.500634
train phase, Epoch 11/20, Loss: 15.653505
val phase, Epoch 11/20, Loss: 29.431901
Val Best Loss: 27.923635
Epoch loss: 29.431901
train phase, Epoch 12/20, Loss: 15.635141
val phase, Epoch 12/20, Loss: 29.908877
Val Best Loss: 27.923635
Epoch loss: 29.908877
train phase, Epoch 13/20, Loss: 15.520525
val phase, Epoch 13/20, Loss: 32.949659
Val Best Loss: 27.923635
Epoch loss: 32.949659
train phase, Epoch 14/20, Loss: 15.376286
val phase, Epoch 14/20, Loss: 32.303221
Val Best Loss: 27.923635
Epoch loss: 32.303221
train phase, Epoch 15/20, Loss: 15.101621
val phase, Epoch 15/20, Loss: 32.318454
Val Best Loss: 27.923635
Epoch loss: 32.318454
train phase, Epoch 16/20, Loss: 14.935781
val phase, Epoch 16/20, Loss: 35.770179
Val Best Loss: 27.923635
Epoch loss: 35.770179
train phase, Epoch 17/20, Loss: 14.779852
val phase, Epoch 17/20, Loss: 40.699591
Val Best Loss: 27.923635
Epoch loss: 40.699591
train phase, Epoch 18/20, Loss: 14.568635
val phase, Epoch 18/20, Loss: 39.143391
Val Best Loss: 27.923635
Epoch loss: 39.143391
train phase, Epoch 19/20, Loss: 14.788092
val phase, Epoch 19/20, Loss: 39.177018
Val Best Loss: 27.923635
Epoch loss: 39.177018
train phase, Epoch 20/20, Loss: 14.150591
val phase, Epoch 20/20, Loss: 42.956192
Val Best Loss: 27.923635
Epoch loss: 42.956192
train phase, Epoch 1/20, Loss: nan
val phase, Epoch 1/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 2/20, Loss: nan
val phase, Epoch 2/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 3/20, Loss: nan
val phase, Epoch 3/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 4/20, Loss: nan
val phase, Epoch 4/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 5/20, Loss: nan
val phase, Epoch 5/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 6/20, Loss: nan
val phase, Epoch 6/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 7/20, Loss: nan
val phase, Epoch 7/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 8/20, Loss: nan
val phase, Epoch 8/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 9/20, Loss: nan
val phase, Epoch 9/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 10/20, Loss: nan
val phase, Epoch 10/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 11/20, Loss: nan
val phase, Epoch 11/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 12/20, Loss: nan
val phase, Epoch 12/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 13/20, Loss: nan
val phase, Epoch 13/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 14/20, Loss: nan
val phase, Epoch 14/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 15/20, Loss: nan
val phase, Epoch 15/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 16/20, Loss: nan
val phase, Epoch 16/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 17/20, Loss: nan
val phase, Epoch 17/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 18/20, Loss: nan
val phase, Epoch 18/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 19/20, Loss: nan
val phase, Epoch 19/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 20/20, Loss: nan
val phase, Epoch 20/20, Loss: nan
Val Best Loss: inf
Epoch loss: nan
train phase, Epoch 1/20, Loss: 20.179318
val phase, Epoch 1/20, Loss: 17.569519
Val Best Loss: 17.569519
Epoch loss: 17.569519
train phase, Epoch 2/20, Loss: 17.864427
val phase, Epoch 2/20, Loss: 16.491317
Val Best Loss: 16.491317
Epoch loss: 16.491317
train phase, Epoch 3/20, Loss: 17.378111
val phase, Epoch 3/20, Loss: 16.979800
Val Best Loss: 16.491317
Epoch loss: 16.979800
train phase, Epoch 4/20, Loss: 17.317304
val phase, Epoch 4/20, Loss: 16.358090
Val Best Loss: 16.358090
Epoch loss: 16.358090
train phase, Epoch 5/20, Loss: 17.134304
val phase, Epoch 5/20, Loss: 18.617007
Val Best Loss: 16.358090
Epoch loss: 18.617007
train phase, Epoch 6/20, Loss: 16.835505
val phase, Epoch 6/20, Loss: 16.533856
Val Best Loss: 16.358090
Epoch loss: 16.533856
train phase, Epoch 7/20, Loss: 16.474195
val phase, Epoch 7/20, Loss: 16.304680
Val Best Loss: 16.304680
Epoch loss: 16.304680
train phase, Epoch 8/20, Loss: 16.296034
val phase, Epoch 8/20, Loss: 16.089478
Val Best Loss: 16.089478
Epoch loss: 16.089478
train phase, Epoch 9/20, Loss: 16.080936
val phase, Epoch 9/20, Loss: 16.235410
Val Best Loss: 16.089478
Epoch loss: 16.235410
train phase, Epoch 10/20, Loss: 15.981137
val phase, Epoch 10/20, Loss: 17.627186
Val Best Loss: 16.089478
Epoch loss: 17.627186
train phase, Epoch 11/20, Loss: 15.774767
val phase, Epoch 11/20, Loss: 17.244101
Val Best Loss: 16.089478
Epoch loss: 17.244101
train phase, Epoch 12/20, Loss: 15.873273
val phase, Epoch 12/20, Loss: 16.954761
Val Best Loss: 16.089478
Epoch loss: 16.954761
train phase, Epoch 13/20, Loss: 15.363329
val phase, Epoch 13/20, Loss: 16.666175
Val Best Loss: 16.089478
Epoch loss: 16.666175
train phase, Epoch 14/20, Loss: 15.449620
val phase, Epoch 14/20, Loss: 16.356363
Val Best Loss: 16.089478
Epoch loss: 16.356363
train phase, Epoch 15/20, Loss: 15.039555
val phase, Epoch 15/20, Loss: 16.836781
Val Best Loss: 16.089478
Epoch loss: 16.836781
train phase, Epoch 16/20, Loss: 14.869352
val phase, Epoch 16/20, Loss: 16.320533
Val Best Loss: 16.089478
Epoch loss: 16.320533
train phase, Epoch 17/20, Loss: 14.769598
val phase, Epoch 17/20, Loss: 16.456351
Val Best Loss: 16.089478
Epoch loss: 16.456351
train phase, Epoch 18/20, Loss: 14.448179
val phase, Epoch 18/20, Loss: 15.849912
Val Best Loss: 15.849912
Epoch loss: 15.849912
train phase, Epoch 19/20, Loss: 14.118893
val phase, Epoch 19/20, Loss: 16.324099
Val Best Loss: 15.849912
Epoch loss: 16.324099
train phase, Epoch 20/20, Loss: 13.956498
val phase, Epoch 20/20, Loss: 16.653985
Val Best Loss: 15.849912
Epoch loss: 16.653985
train phase, Epoch 1/20, Loss: 20.271974
val phase, Epoch 1/20, Loss: 16.870861
Val Best Loss: 16.870861
Epoch loss: 16.870861
train phase, Epoch 2/20, Loss: 17.344068
val phase, Epoch 2/20, Loss: 17.330427
Val Best Loss: 16.870861
Epoch loss: 17.330427
train phase, Epoch 3/20, Loss: 16.963063
val phase, Epoch 3/20, Loss: 16.534853
Val Best Loss: 16.534853
Epoch loss: 16.534853
train phase, Epoch 4/20, Loss: 17.153767
val phase, Epoch 4/20, Loss: 16.683492
Val Best Loss: 16.534853
Epoch loss: 16.683492
train phase, Epoch 5/20, Loss: 16.399248
val phase, Epoch 5/20, Loss: 16.683478
Val Best Loss: 16.534853
Epoch loss: 16.683478
train phase, Epoch 6/20, Loss: 16.426485
val phase, Epoch 6/20, Loss: 15.979071
Val Best Loss: 15.979071
Epoch loss: 15.979071
train phase, Epoch 7/20, Loss: 16.191070
val phase, Epoch 7/20, Loss: 16.081969
Val Best Loss: 15.979071
Epoch loss: 16.081969
train phase, Epoch 8/20, Loss: 15.940632
val phase, Epoch 8/20, Loss: 17.939672
Val Best Loss: 15.979071
Epoch loss: 17.939672
train phase, Epoch 9/20, Loss: 16.163004
val phase, Epoch 9/20, Loss: 17.972485
Val Best Loss: 15.979071
Epoch loss: 17.972485
train phase, Epoch 10/20, Loss: 15.832164
val phase, Epoch 10/20, Loss: 16.415855
Val Best Loss: 15.979071
Epoch loss: 16.415855
train phase, Epoch 11/20, Loss: 15.492404
val phase, Epoch 11/20, Loss: 18.173506
Val Best Loss: 15.979071
Epoch loss: 18.173506
train phase, Epoch 12/20, Loss: 15.550865
val phase, Epoch 12/20, Loss: 17.015943
Val Best Loss: 15.979071
Epoch loss: 17.015943
train phase, Epoch 13/20, Loss: 15.226105
val phase, Epoch 13/20, Loss: 15.936391
Val Best Loss: 15.936391
Epoch loss: 15.936391
train phase, Epoch 14/20, Loss: 14.903182
val phase, Epoch 14/20, Loss: 15.897325
Val Best Loss: 15.897325
Epoch loss: 15.897325
train phase, Epoch 15/20, Loss: 14.752322
val phase, Epoch 15/20, Loss: 15.826846
Val Best Loss: 15.826846
Epoch loss: 15.826846
train phase, Epoch 16/20, Loss: 14.447298
val phase, Epoch 16/20, Loss: 16.143341
Val Best Loss: 15.826846
Epoch loss: 16.143341
train phase, Epoch 17/20, Loss: 14.182135
val phase, Epoch 17/20, Loss: 16.176002
Val Best Loss: 15.826846
Epoch loss: 16.176002
train phase, Epoch 18/20, Loss: 13.810152
val phase, Epoch 18/20, Loss: 17.477615
Val Best Loss: 15.826846
Epoch loss: 17.477615
train phase, Epoch 19/20, Loss: 13.706468
val phase, Epoch 19/20, Loss: 16.791804
Val Best Loss: 15.826846
Epoch loss: 16.791804
train phase, Epoch 20/20, Loss: 13.392017
val phase, Epoch 20/20, Loss: 17.463608
Val Best Loss: 15.826846
Epoch loss: 17.463608
train phase, Epoch 1/15, Loss: 19.689629
val phase, Epoch 1/15, Loss: 17.403207
Val Best Loss: 17.403207
Epoch loss: 17.403207
train phase, Epoch 2/15, Loss: 17.890225
val phase, Epoch 2/15, Loss: 17.119846
Val Best Loss: 17.119846
Epoch loss: 17.119846
train phase, Epoch 3/15, Loss: 17.579629
val phase, Epoch 3/15, Loss: 18.183358
Val Best Loss: 17.119846
Epoch loss: 18.183358
train phase, Epoch 4/15, Loss: 17.063959
val phase, Epoch 4/15, Loss: 17.043746
Val Best Loss: 17.043746
Epoch loss: 17.043746
train phase, Epoch 5/15, Loss: 17.041667
val phase, Epoch 5/15, Loss: 16.832933
Val Best Loss: 16.832933
Epoch loss: 16.832933
train phase, Epoch 6/15, Loss: 16.548441
val phase, Epoch 6/15, Loss: 16.028915
Val Best Loss: 16.028915
Epoch loss: 16.028915
train phase, Epoch 7/15, Loss: 16.605833
val phase, Epoch 7/15, Loss: 17.143809
Val Best Loss: 16.028915
Epoch loss: 17.143809
train phase, Epoch 8/15, Loss: 16.550778
val phase, Epoch 8/15, Loss: 16.377599
Val Best Loss: 16.028915
Epoch loss: 16.377599
train phase, Epoch 9/15, Loss: 16.242999
val phase, Epoch 9/15, Loss: 16.045105
Val Best Loss: 16.028915
Epoch loss: 16.045105
train phase, Epoch 10/15, Loss: 15.917433
val phase, Epoch 10/15, Loss: 16.001268
Val Best Loss: 16.001268
Epoch loss: 16.001268
train phase, Epoch 11/15, Loss: 15.864324
val phase, Epoch 11/15, Loss: 15.779726
Val Best Loss: 15.779726
Epoch loss: 15.779726
train phase, Epoch 12/15, Loss: 15.881156
val phase, Epoch 12/15, Loss: 16.022292
Val Best Loss: 15.779726
Epoch loss: 16.022292
train phase, Epoch 13/15, Loss: 15.650257
val phase, Epoch 13/15, Loss: 16.089567
Val Best Loss: 15.779726
Epoch loss: 16.089567
train phase, Epoch 14/15, Loss: 15.518343
val phase, Epoch 14/15, Loss: 16.111838
Val Best Loss: 15.779726
Epoch loss: 16.111838
train phase, Epoch 15/15, Loss: 15.374544
val phase, Epoch 15/15, Loss: 16.311026
Val Best Loss: 15.779726
Epoch loss: 16.311026
train phase, Epoch 1/20, Loss: 19.946298
val phase, Epoch 1/20, Loss: 20.286621
Val Best Loss: 20.286621
Epoch loss: 20.286621
train phase, Epoch 2/20, Loss: 18.111914
val phase, Epoch 2/20, Loss: 20.113899
Val Best Loss: 20.113899
Epoch loss: 20.113899
train phase, Epoch 3/20, Loss: 17.416233
val phase, Epoch 3/20, Loss: 16.912336
Val Best Loss: 16.912336
Epoch loss: 16.912336
train phase, Epoch 4/20, Loss: 16.947865
val phase, Epoch 4/20, Loss: 17.896744
Val Best Loss: 16.912336
Epoch loss: 17.896744
train phase, Epoch 5/20, Loss: 16.906779
val phase, Epoch 5/20, Loss: 16.219879
Val Best Loss: 16.219879
Epoch loss: 16.219879
train phase, Epoch 6/20, Loss: 16.501732
val phase, Epoch 6/20, Loss: 16.719582
Val Best Loss: 16.219879
Epoch loss: 16.719582
train phase, Epoch 7/20, Loss: 16.330969
val phase, Epoch 7/20, Loss: 16.534244
Val Best Loss: 16.219879
Epoch loss: 16.534244
train phase, Epoch 8/20, Loss: 16.240482
val phase, Epoch 8/20, Loss: 16.204981
Val Best Loss: 16.204981
Epoch loss: 16.204981
train phase, Epoch 9/20, Loss: 15.992347
val phase, Epoch 9/20, Loss: 16.603761
Val Best Loss: 16.204981
Epoch loss: 16.603761
train phase, Epoch 10/20, Loss: 15.954907
val phase, Epoch 10/20, Loss: 16.328843
Val Best Loss: 16.204981
Epoch loss: 16.328843
train phase, Epoch 11/20, Loss: 15.559484
val phase, Epoch 11/20, Loss: 16.384604
Val Best Loss: 16.204981
Epoch loss: 16.384604
train phase, Epoch 12/20, Loss: 15.547050
val phase, Epoch 12/20, Loss: 15.789504
Val Best Loss: 15.789504
Epoch loss: 15.789504
train phase, Epoch 13/20, Loss: 15.087471
val phase, Epoch 13/20, Loss: 15.518504
Val Best Loss: 15.518504
Epoch loss: 15.518504
train phase, Epoch 14/20, Loss: 14.943739
val phase, Epoch 14/20, Loss: 20.274467
Val Best Loss: 15.518504
Epoch loss: 20.274467
train phase, Epoch 15/20, Loss: 14.874107
val phase, Epoch 15/20, Loss: 19.731116
Val Best Loss: 15.518504
Epoch loss: 19.731116
train phase, Epoch 16/20, Loss: 14.516365
val phase, Epoch 16/20, Loss: 16.850940
Val Best Loss: 15.518504
Epoch loss: 16.850940
train phase, Epoch 17/20, Loss: 14.137125
val phase, Epoch 17/20, Loss: 15.813675
Val Best Loss: 15.518504
Epoch loss: 15.813675
train phase, Epoch 18/20, Loss: 13.759774
val phase, Epoch 18/20, Loss: 16.737061
Val Best Loss: 15.518504
Epoch loss: 16.737061
train phase, Epoch 19/20, Loss: 13.448505
val phase, Epoch 19/20, Loss: 16.819086
Val Best Loss: 15.518504
Epoch loss: 16.819086
train phase, Epoch 20/20, Loss: 13.151212
val phase, Epoch 20/20, Loss: 16.947045
Val Best Loss: 15.518504
Epoch loss: 16.947045
[Trial 434] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 32.073086
val phase, Epoch 1/20, Loss: 18.371760
Val Best Loss: 18.371760
Epoch loss: 18.371760
train phase, Epoch 2/20, Loss: 18.632634
val phase, Epoch 2/20, Loss: 17.769313
Val Best Loss: 17.769313
Epoch loss: 17.769313
train phase, Epoch 3/20, Loss: 18.712675
val phase, Epoch 3/20, Loss: 17.979456
Val Best Loss: 17.769313
Epoch loss: 17.979456
train phase, Epoch 4/20, Loss: 17.655437
val phase, Epoch 4/20, Loss: 19.564943
Val Best Loss: 17.769313
Epoch loss: 19.564943
train phase, Epoch 5/20, Loss: 17.338996
val phase, Epoch 5/20, Loss: 16.742719
Val Best Loss: 16.742719
Epoch loss: 16.742719
train phase, Epoch 6/20, Loss: 17.461789
val phase, Epoch 6/20, Loss: 19.053663
Val Best Loss: 16.742719
Epoch loss: 19.053663
train phase, Epoch 7/20, Loss: 16.987488
val phase, Epoch 7/20, Loss: 16.827707
Val Best Loss: 16.742719
Epoch loss: 16.827707
train phase, Epoch 8/20, Loss: 16.649224
val phase, Epoch 8/20, Loss: 19.608785
Val Best Loss: 16.742719
Epoch loss: 19.608785
train phase, Epoch 9/20, Loss: 17.095075
val phase, Epoch 9/20, Loss: 17.876963
Val Best Loss: 16.742719
Epoch loss: 17.876963
train phase, Epoch 10/20, Loss: 16.576520
val phase, Epoch 10/20, Loss: 18.609586
Val Best Loss: 16.742719
Epoch loss: 18.609586
train phase, Epoch 11/20, Loss: 16.560558
val phase, Epoch 11/20, Loss: 17.633617
Val Best Loss: 16.742719
Epoch loss: 17.633617
train phase, Epoch 12/20, Loss: 16.322335
val phase, Epoch 12/20, Loss: 17.638158
Val Best Loss: 16.742719
Epoch loss: 17.638158
train phase, Epoch 13/20, Loss: 15.863495
val phase, Epoch 13/20, Loss: 20.933967
Val Best Loss: 16.742719
Epoch loss: 20.933967
train phase, Epoch 14/20, Loss: 15.918371
val phase, Epoch 14/20, Loss: 18.058617
Val Best Loss: 16.742719
Epoch loss: 18.058617
train phase, Epoch 15/20, Loss: 15.974708
val phase, Epoch 15/20, Loss: 20.816009
Val Best Loss: 16.742719
Epoch loss: 20.816009
train phase, Epoch 16/20, Loss: 15.804295
val phase, Epoch 16/20, Loss: 17.859576
Val Best Loss: 16.742719
Epoch loss: 17.859576
train phase, Epoch 17/20, Loss: 15.791029
val phase, Epoch 17/20, Loss: 17.599720
Val Best Loss: 16.742719
Epoch loss: 17.599720
train phase, Epoch 18/20, Loss: 15.417628
val phase, Epoch 18/20, Loss: 17.833047
Val Best Loss: 16.742719
Epoch loss: 17.833047
train phase, Epoch 19/20, Loss: 15.098193
val phase, Epoch 19/20, Loss: 20.047910
Val Best Loss: 16.742719
Epoch loss: 20.047910
train phase, Epoch 20/20, Loss: 14.993129
val phase, Epoch 20/20, Loss: 18.089747
Val Best Loss: 16.742719
Epoch loss: 18.089747
[Trial 436] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 19.647927
val phase, Epoch 1/20, Loss: 17.427500
Val Best Loss: 17.427500
Epoch loss: 17.427500
train phase, Epoch 2/20, Loss: 18.049396
val phase, Epoch 2/20, Loss: 17.032941
Val Best Loss: 17.032941
Epoch loss: 17.032941
train phase, Epoch 3/20, Loss: 17.723115
val phase, Epoch 3/20, Loss: 16.517701
Val Best Loss: 16.517701
Epoch loss: 16.517701
train phase, Epoch 4/20, Loss: 17.186782
val phase, Epoch 4/20, Loss: 16.759019
Val Best Loss: 16.517701
Epoch loss: 16.759019
train phase, Epoch 5/20, Loss: 17.121304
val phase, Epoch 5/20, Loss: 16.158346
Val Best Loss: 16.158346
Epoch loss: 16.158346
train phase, Epoch 6/20, Loss: 16.767971
val phase, Epoch 6/20, Loss: 16.456243
Val Best Loss: 16.158346
Epoch loss: 16.456243
train phase, Epoch 7/20, Loss: 16.495088
val phase, Epoch 7/20, Loss: 20.408836
Val Best Loss: 16.158346
Epoch loss: 20.408836
train phase, Epoch 8/20, Loss: 16.476396
val phase, Epoch 8/20, Loss: 16.229746
Val Best Loss: 16.158346
Epoch loss: 16.229746
train phase, Epoch 9/20, Loss: 16.060214
val phase, Epoch 9/20, Loss: 15.900260
Val Best Loss: 15.900260
Epoch loss: 15.900260
train phase, Epoch 10/20, Loss: 16.126089
val phase, Epoch 10/20, Loss: 15.995649
Val Best Loss: 15.900260
Epoch loss: 15.995649
train phase, Epoch 11/20, Loss: 15.757641
val phase, Epoch 11/20, Loss: 19.826237
Val Best Loss: 15.900260
Epoch loss: 19.826237
train phase, Epoch 12/20, Loss: 15.702414
val phase, Epoch 12/20, Loss: 15.873311
Val Best Loss: 15.873311
Epoch loss: 15.873311
train phase, Epoch 13/20, Loss: 15.285855
val phase, Epoch 13/20, Loss: 16.219034
Val Best Loss: 15.873311
Epoch loss: 16.219034
train phase, Epoch 14/20, Loss: 15.113909
val phase, Epoch 14/20, Loss: 15.777424
Val Best Loss: 15.777424
Epoch loss: 15.777424
train phase, Epoch 15/20, Loss: 14.807084
val phase, Epoch 15/20, Loss: 16.612336
Val Best Loss: 15.777424
Epoch loss: 16.612336
train phase, Epoch 16/20, Loss: 14.653403
val phase, Epoch 16/20, Loss: 16.212959
Val Best Loss: 15.777424
Epoch loss: 16.212959
train phase, Epoch 17/20, Loss: 14.493075
val phase, Epoch 17/20, Loss: 16.687742
Val Best Loss: 15.777424
Epoch loss: 16.687742
train phase, Epoch 18/20, Loss: 14.221183
val phase, Epoch 18/20, Loss: 16.385325
Val Best Loss: 15.777424
Epoch loss: 16.385325
train phase, Epoch 19/20, Loss: 13.769262
val phase, Epoch 19/20, Loss: 16.815157
Val Best Loss: 15.777424
Epoch loss: 16.815157
train phase, Epoch 20/20, Loss: 13.472259
val phase, Epoch 20/20, Loss: 16.667133
Val Best Loss: 15.777424
Epoch loss: 16.667133
train phase, Epoch 1/12, Loss: 21.214725
val phase, Epoch 1/12, Loss: 18.640734
Val Best Loss: 18.640734
Epoch loss: 18.640734
train phase, Epoch 2/12, Loss: 19.039776
val phase, Epoch 2/12, Loss: 18.407406
Val Best Loss: 18.407406
Epoch loss: 18.407406
train phase, Epoch 3/12, Loss: 18.345638
val phase, Epoch 3/12, Loss: 17.096919
Val Best Loss: 17.096919
Epoch loss: 17.096919
train phase, Epoch 4/12, Loss: 17.906052
val phase, Epoch 4/12, Loss: 17.526570
Val Best Loss: 17.096919
Epoch loss: 17.526570
train phase, Epoch 5/12, Loss: 17.959480
val phase, Epoch 5/12, Loss: 17.572056
Val Best Loss: 17.096919
Epoch loss: 17.572056
train phase, Epoch 6/12, Loss: 17.563167
val phase, Epoch 6/12, Loss: 17.572048
Val Best Loss: 17.096919
Epoch loss: 17.572048
train phase, Epoch 7/12, Loss: 17.241709
val phase, Epoch 7/12, Loss: 18.728688
Val Best Loss: 17.096919
Epoch loss: 18.728688
train phase, Epoch 8/12, Loss: 17.535611
val phase, Epoch 8/12, Loss: 16.940599
Val Best Loss: 16.940599
Epoch loss: 16.940599
train phase, Epoch 9/12, Loss: 16.901219
val phase, Epoch 9/12, Loss: 16.463220
Val Best Loss: 16.463220
Epoch loss: 16.463220
train phase, Epoch 10/12, Loss: 16.954047
val phase, Epoch 10/12, Loss: 17.534985
Val Best Loss: 16.463220
Epoch loss: 17.534985
train phase, Epoch 11/12, Loss: 17.186763
val phase, Epoch 11/12, Loss: 17.220964
Val Best Loss: 16.463220
Epoch loss: 17.220964
train phase, Epoch 12/12, Loss: 16.589603
val phase, Epoch 12/12, Loss: 16.431344
Val Best Loss: 16.431344
Epoch loss: 16.431344
train phase, Epoch 1/20, Loss: 20.756681
val phase, Epoch 1/20, Loss: 17.983375
Val Best Loss: 17.983375
Epoch loss: 17.983375
train phase, Epoch 2/20, Loss: 17.338576
val phase, Epoch 2/20, Loss: 17.758494
Val Best Loss: 17.758494
Epoch loss: 17.758494
train phase, Epoch 3/20, Loss: 16.986778
val phase, Epoch 3/20, Loss: 16.563922
Val Best Loss: 16.563922
Epoch loss: 16.563922
train phase, Epoch 4/20, Loss: 16.526347
val phase, Epoch 4/20, Loss: 17.935123
Val Best Loss: 16.563922
Epoch loss: 17.935123
train phase, Epoch 5/20, Loss: 16.407009
val phase, Epoch 5/20, Loss: 16.337838
Val Best Loss: 16.337838
Epoch loss: 16.337838
train phase, Epoch 6/20, Loss: 15.970980
val phase, Epoch 6/20, Loss: 16.481384
Val Best Loss: 16.337838
Epoch loss: 16.481384
train phase, Epoch 7/20, Loss: 15.983384
val phase, Epoch 7/20, Loss: 15.826792
Val Best Loss: 15.826792
Epoch loss: 15.826792
train phase, Epoch 8/20, Loss: 15.507954
val phase, Epoch 8/20, Loss: 16.798397
Val Best Loss: 15.826792
Epoch loss: 16.798397
train phase, Epoch 9/20, Loss: 15.409655
val phase, Epoch 9/20, Loss: 16.120276
Val Best Loss: 15.826792
Epoch loss: 16.120276
train phase, Epoch 10/20, Loss: 15.254793
val phase, Epoch 10/20, Loss: 17.164410
Val Best Loss: 15.826792
Epoch loss: 17.164410
train phase, Epoch 11/20, Loss: 14.891072
val phase, Epoch 11/20, Loss: 19.954696
Val Best Loss: 15.826792
Epoch loss: 19.954696
train phase, Epoch 12/20, Loss: 14.691057
val phase, Epoch 12/20, Loss: 17.178911
Val Best Loss: 15.826792
Epoch loss: 17.178911
train phase, Epoch 13/20, Loss: 14.435262
val phase, Epoch 13/20, Loss: 17.155840
Val Best Loss: 15.826792
Epoch loss: 17.155840
train phase, Epoch 14/20, Loss: 14.131045
val phase, Epoch 14/20, Loss: 16.467636
Val Best Loss: 15.826792
Epoch loss: 16.467636
train phase, Epoch 15/20, Loss: 13.866819
val phase, Epoch 15/20, Loss: 17.293598
Val Best Loss: 15.826792
Epoch loss: 17.293598
train phase, Epoch 16/20, Loss: 13.295804
val phase, Epoch 16/20, Loss: 16.510182
Val Best Loss: 15.826792
Epoch loss: 16.510182
train phase, Epoch 17/20, Loss: 13.037329
val phase, Epoch 17/20, Loss: 17.728466
Val Best Loss: 15.826792
Epoch loss: 17.728466
train phase, Epoch 18/20, Loss: 12.855971
val phase, Epoch 18/20, Loss: 17.233513
Val Best Loss: 15.826792
Epoch loss: 17.233513
train phase, Epoch 19/20, Loss: 12.256289
val phase, Epoch 19/20, Loss: 17.190638
Val Best Loss: 15.826792
Epoch loss: 17.190638
train phase, Epoch 20/20, Loss: 11.917050
val phase, Epoch 20/20, Loss: 18.421421
Val Best Loss: 15.826792
Epoch loss: 18.421421
[Trial 440] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/20, Loss: 20.143764
val phase, Epoch 1/20, Loss: 17.039481
Val Best Loss: 17.039481
Epoch loss: 17.039481
train phase, Epoch 2/20, Loss: 17.492279
val phase, Epoch 2/20, Loss: 16.617142
Val Best Loss: 16.617142
Epoch loss: 16.617142
train phase, Epoch 3/20, Loss: 16.993516
val phase, Epoch 3/20, Loss: 17.776625
Val Best Loss: 16.617142
Epoch loss: 17.776625
train phase, Epoch 4/20, Loss: 17.169697
val phase, Epoch 4/20, Loss: 16.647390
Val Best Loss: 16.617142
Epoch loss: 16.647390
train phase, Epoch 5/20, Loss: 16.851721
val phase, Epoch 5/20, Loss: 17.301045
Val Best Loss: 16.617142
Epoch loss: 17.301045
train phase, Epoch 6/20, Loss: 16.480585
val phase, Epoch 6/20, Loss: 16.404597
Val Best Loss: 16.404597
Epoch loss: 16.404597
train phase, Epoch 7/20, Loss: 16.451204
val phase, Epoch 7/20, Loss: 18.546438
Val Best Loss: 16.404597
Epoch loss: 18.546438
train phase, Epoch 8/20, Loss: 16.012309
val phase, Epoch 8/20, Loss: 16.489099
Val Best Loss: 16.404597
Epoch loss: 16.489099
train phase, Epoch 9/20, Loss: 16.017447
val phase, Epoch 9/20, Loss: 15.972984
Val Best Loss: 15.972984
Epoch loss: 15.972984
train phase, Epoch 10/20, Loss: 15.793973
val phase, Epoch 10/20, Loss: 17.545043
Val Best Loss: 15.972984
Epoch loss: 17.545043
train phase, Epoch 11/20, Loss: 15.823120
val phase, Epoch 11/20, Loss: 16.394255
Val Best Loss: 15.972984
Epoch loss: 16.394255
train phase, Epoch 12/20, Loss: 15.317274
val phase, Epoch 12/20, Loss: 16.323694
Val Best Loss: 15.972984
Epoch loss: 16.323694
train phase, Epoch 13/20, Loss: 15.054591
val phase, Epoch 13/20, Loss: 16.151563
Val Best Loss: 15.972984
Epoch loss: 16.151563
train phase, Epoch 14/20, Loss: 14.998508
val phase, Epoch 14/20, Loss: 16.517907
Val Best Loss: 15.972984
Epoch loss: 16.517907
train phase, Epoch 15/20, Loss: 14.780545
val phase, Epoch 15/20, Loss: 17.435631
Val Best Loss: 15.972984
Epoch loss: 17.435631
train phase, Epoch 16/20, Loss: 14.476940
val phase, Epoch 16/20, Loss: 17.030012
Val Best Loss: 15.972984
Epoch loss: 17.030012
train phase, Epoch 17/20, Loss: 14.233004
val phase, Epoch 17/20, Loss: 15.844445
Val Best Loss: 15.844445
Epoch loss: 15.844445
train phase, Epoch 18/20, Loss: 13.700395
val phase, Epoch 18/20, Loss: 17.772425
Val Best Loss: 15.844445
Epoch loss: 17.772425
train phase, Epoch 19/20, Loss: 13.520843
val phase, Epoch 19/20, Loss: 18.490763
Val Best Loss: 15.844445
Epoch loss: 18.490763
train phase, Epoch 20/20, Loss: 13.194818
val phase, Epoch 20/20, Loss: 16.242326
Val Best Loss: 15.844445
Epoch loss: 16.242326
train phase, Epoch 1/5, Loss: 19.644765
val phase, Epoch 1/5, Loss: 18.242490
Val Best Loss: 18.242490
Epoch loss: 18.242490
train phase, Epoch 2/5, Loss: 17.751499
val phase, Epoch 2/5, Loss: 17.600577
Val Best Loss: 17.600577
Epoch loss: 17.600577
train phase, Epoch 3/5, Loss: 17.311401
val phase, Epoch 3/5, Loss: 17.400147
Val Best Loss: 17.400147
Epoch loss: 17.400147
train phase, Epoch 4/5, Loss: 16.882674
val phase, Epoch 4/5, Loss: 18.826670
Val Best Loss: 17.400147
Epoch loss: 18.826670
train phase, Epoch 5/5, Loss: 16.869671
val phase, Epoch 5/5, Loss: 16.788654
Val Best Loss: 16.788654
Epoch loss: 16.788654
train phase, Epoch 1/20, Loss: 21.610910
val phase, Epoch 1/20, Loss: 17.877259
Val Best Loss: 17.877259
Epoch loss: 17.877259
train phase, Epoch 2/20, Loss: 18.311331
val phase, Epoch 2/20, Loss: 17.346584
Val Best Loss: 17.346584
Epoch loss: 17.346584
train phase, Epoch 3/20, Loss: 17.726541
val phase, Epoch 3/20, Loss: 17.136455
Val Best Loss: 17.136455
Epoch loss: 17.136455
train phase, Epoch 4/20, Loss: 17.637451
val phase, Epoch 4/20, Loss: 16.523942
Val Best Loss: 16.523942
Epoch loss: 16.523942
train phase, Epoch 5/20, Loss: 17.278950
val phase, Epoch 5/20, Loss: 17.591112
Val Best Loss: 16.523942
Epoch loss: 17.591112
train phase, Epoch 6/20, Loss: 17.150715
val phase, Epoch 6/20, Loss: 20.390664
Val Best Loss: 16.523942
Epoch loss: 20.390664
train phase, Epoch 7/20, Loss: 17.201461
val phase, Epoch 7/20, Loss: 16.304506
Val Best Loss: 16.304506
Epoch loss: 16.304506
train phase, Epoch 8/20, Loss: 16.682930
val phase, Epoch 8/20, Loss: 16.821561
Val Best Loss: 16.304506
Epoch loss: 16.821561
train phase, Epoch 9/20, Loss: 16.403918
val phase, Epoch 9/20, Loss: 16.719371
Val Best Loss: 16.304506
Epoch loss: 16.719371
train phase, Epoch 10/20, Loss: 16.327689
val phase, Epoch 10/20, Loss: 16.575483
Val Best Loss: 16.304506
Epoch loss: 16.575483
train phase, Epoch 11/20, Loss: 16.176427
val phase, Epoch 11/20, Loss: 15.931745
Val Best Loss: 15.931745
Epoch loss: 15.931745
train phase, Epoch 12/20, Loss: 15.886531
val phase, Epoch 12/20, Loss: 16.433414
Val Best Loss: 15.931745
Epoch loss: 16.433414
train phase, Epoch 13/20, Loss: 16.026971
val phase, Epoch 13/20, Loss: 16.224586
Val Best Loss: 15.931745
Epoch loss: 16.224586
train phase, Epoch 14/20, Loss: 15.639691
val phase, Epoch 14/20, Loss: 17.136716
Val Best Loss: 15.931745
Epoch loss: 17.136716
train phase, Epoch 15/20, Loss: 15.736915
val phase, Epoch 15/20, Loss: 17.452206
Val Best Loss: 15.931745
Epoch loss: 17.452206
train phase, Epoch 16/20, Loss: 15.840888
val phase, Epoch 16/20, Loss: 16.128698
Val Best Loss: 15.931745
Epoch loss: 16.128698
train phase, Epoch 17/20, Loss: 15.437553
val phase, Epoch 17/20, Loss: 17.312086
Val Best Loss: 15.931745
Epoch loss: 17.312086
train phase, Epoch 18/20, Loss: 15.091358
val phase, Epoch 18/20, Loss: 16.286032
Val Best Loss: 15.931745
Epoch loss: 16.286032
train phase, Epoch 19/20, Loss: 15.180549
val phase, Epoch 19/20, Loss: 15.882026
Val Best Loss: 15.882026
Epoch loss: 15.882026
train phase, Epoch 20/20, Loss: 14.873755
val phase, Epoch 20/20, Loss: 16.158732
Val Best Loss: 15.882026
Epoch loss: 16.158732
train phase, Epoch 1/25, Loss: 19.742719
val phase, Epoch 1/25, Loss: 17.548025
Val Best Loss: 17.548025
Epoch loss: 17.548025
train phase, Epoch 2/25, Loss: 17.589065
val phase, Epoch 2/25, Loss: 16.872308
Val Best Loss: 16.872308
Epoch loss: 16.872308
train phase, Epoch 3/25, Loss: 17.342124
val phase, Epoch 3/25, Loss: 16.698187
Val Best Loss: 16.698187
Epoch loss: 16.698187
train phase, Epoch 4/25, Loss: 17.146122
val phase, Epoch 4/25, Loss: 16.929139
Val Best Loss: 16.698187
Epoch loss: 16.929139
train phase, Epoch 5/25, Loss: 16.657234
val phase, Epoch 5/25, Loss: 23.021904
Val Best Loss: 16.698187
Epoch loss: 23.021904
train phase, Epoch 6/25, Loss: 16.841715
val phase, Epoch 6/25, Loss: 16.577810
Val Best Loss: 16.577810
Epoch loss: 16.577810
train phase, Epoch 7/25, Loss: 16.366381
val phase, Epoch 7/25, Loss: 16.174502
Val Best Loss: 16.174502
Epoch loss: 16.174502
train phase, Epoch 8/25, Loss: 16.297849
val phase, Epoch 8/25, Loss: 16.568975
Val Best Loss: 16.174502
Epoch loss: 16.568975
train phase, Epoch 9/25, Loss: 16.147048
val phase, Epoch 9/25, Loss: 16.263689
Val Best Loss: 16.174502
Epoch loss: 16.263689
train phase, Epoch 10/25, Loss: 15.782800
val phase, Epoch 10/25, Loss: 17.889525
Val Best Loss: 16.174502
Epoch loss: 17.889525
train phase, Epoch 11/25, Loss: 15.607695
val phase, Epoch 11/25, Loss: 15.851598
Val Best Loss: 15.851598
Epoch loss: 15.851598
train phase, Epoch 12/25, Loss: 15.518620
val phase, Epoch 12/25, Loss: 15.650893
Val Best Loss: 15.650893
Epoch loss: 15.650893
train phase, Epoch 13/25, Loss: 15.387990
val phase, Epoch 13/25, Loss: 16.520063
Val Best Loss: 15.650893
Epoch loss: 16.520063
train phase, Epoch 14/25, Loss: 15.152085
val phase, Epoch 14/25, Loss: 15.909217
Val Best Loss: 15.650893
Epoch loss: 15.909217
train phase, Epoch 15/25, Loss: 14.819703
val phase, Epoch 15/25, Loss: 16.104323
Val Best Loss: 15.650893
Epoch loss: 16.104323
train phase, Epoch 16/25, Loss: 14.612994
val phase, Epoch 16/25, Loss: 15.732919
Val Best Loss: 15.650893
Epoch loss: 15.732919
train phase, Epoch 17/25, Loss: 14.760760
val phase, Epoch 17/25, Loss: 17.045072
Val Best Loss: 15.650893
Epoch loss: 17.045072
train phase, Epoch 18/25, Loss: 14.689984
val phase, Epoch 18/25, Loss: 16.356532
Val Best Loss: 15.650893
Epoch loss: 16.356532
train phase, Epoch 19/25, Loss: 14.042539
val phase, Epoch 19/25, Loss: 17.828134
Val Best Loss: 15.650893
Epoch loss: 17.828134
train phase, Epoch 20/25, Loss: 13.692166
val phase, Epoch 20/25, Loss: 16.400086
Val Best Loss: 15.650893
Epoch loss: 16.400086
train phase, Epoch 21/25, Loss: 13.373293
val phase, Epoch 21/25, Loss: 16.918750
Val Best Loss: 15.650893
Epoch loss: 16.918750
train phase, Epoch 22/25, Loss: 13.240641
val phase, Epoch 22/25, Loss: 17.580540
Val Best Loss: 15.650893
Epoch loss: 17.580540
train phase, Epoch 23/25, Loss: 12.969818
val phase, Epoch 23/25, Loss: 16.683261
Val Best Loss: 15.650893
Epoch loss: 16.683261
train phase, Epoch 24/25, Loss: 12.187241
val phase, Epoch 24/25, Loss: 17.084886
Val Best Loss: 15.650893
Epoch loss: 17.084886
train phase, Epoch 25/25, Loss: 11.908225
val phase, Epoch 25/25, Loss: 17.692098
Val Best Loss: 15.650893
Epoch loss: 17.692098
train phase, Epoch 1/25, Loss: 20.422921
val phase, Epoch 1/25, Loss: 17.162748
Val Best Loss: 17.162748
Epoch loss: 17.162748
train phase, Epoch 2/25, Loss: 17.645010
val phase, Epoch 2/25, Loss: 17.017422
Val Best Loss: 17.017422
Epoch loss: 17.017422
train phase, Epoch 3/25, Loss: 17.169341
val phase, Epoch 3/25, Loss: 18.743942
Val Best Loss: 17.017422
Epoch loss: 18.743942
train phase, Epoch 4/25, Loss: 17.077723
val phase, Epoch 4/25, Loss: 17.475984
Val Best Loss: 17.017422
Epoch loss: 17.475984
train phase, Epoch 5/25, Loss: 16.883345
val phase, Epoch 5/25, Loss: 16.363088
Val Best Loss: 16.363088
Epoch loss: 16.363088
train phase, Epoch 6/25, Loss: 16.418262
val phase, Epoch 6/25, Loss: 16.622010
Val Best Loss: 16.363088
Epoch loss: 16.622010
train phase, Epoch 7/25, Loss: 16.307329
val phase, Epoch 7/25, Loss: 16.461183
Val Best Loss: 16.363088
Epoch loss: 16.461183
train phase, Epoch 8/25, Loss: 16.186476
val phase, Epoch 8/25, Loss: 15.956783
Val Best Loss: 15.956783
Epoch loss: 15.956783
train phase, Epoch 9/25, Loss: 16.136097
val phase, Epoch 9/25, Loss: 16.201896
Val Best Loss: 15.956783
Epoch loss: 16.201896
train phase, Epoch 10/25, Loss: 16.032088
val phase, Epoch 10/25, Loss: 16.425170
Val Best Loss: 15.956783
Epoch loss: 16.425170
train phase, Epoch 11/25, Loss: 15.636201
val phase, Epoch 11/25, Loss: 16.377975
Val Best Loss: 15.956783
Epoch loss: 16.377975
train phase, Epoch 12/25, Loss: 15.443373
val phase, Epoch 12/25, Loss: 17.392694
Val Best Loss: 15.956783
Epoch loss: 17.392694
train phase, Epoch 13/25, Loss: 15.339143
val phase, Epoch 13/25, Loss: 16.096991
Val Best Loss: 15.956783
Epoch loss: 16.096991
train phase, Epoch 14/25, Loss: 15.191267
val phase, Epoch 14/25, Loss: 16.216348
Val Best Loss: 15.956783
Epoch loss: 16.216348
train phase, Epoch 15/25, Loss: 15.309535
val phase, Epoch 15/25, Loss: 16.680463
Val Best Loss: 15.956783
Epoch loss: 16.680463
train phase, Epoch 16/25, Loss: 14.755482
val phase, Epoch 16/25, Loss: 16.422704
Val Best Loss: 15.956783
Epoch loss: 16.422704
train phase, Epoch 17/25, Loss: 14.592770
val phase, Epoch 17/25, Loss: 16.525737
Val Best Loss: 15.956783
Epoch loss: 16.525737
train phase, Epoch 18/25, Loss: 14.297422
val phase, Epoch 18/25, Loss: 16.570940
Val Best Loss: 15.956783
Epoch loss: 16.570940
train phase, Epoch 19/25, Loss: 14.161570
val phase, Epoch 19/25, Loss: 16.425398
Val Best Loss: 15.956783
Epoch loss: 16.425398
train phase, Epoch 20/25, Loss: 13.732754
val phase, Epoch 20/25, Loss: 18.603454
Val Best Loss: 15.956783
Epoch loss: 18.603454
train phase, Epoch 21/25, Loss: 13.682311
val phase, Epoch 21/25, Loss: 16.644407
Val Best Loss: 15.956783
Epoch loss: 16.644407
train phase, Epoch 22/25, Loss: 12.960446
val phase, Epoch 22/25, Loss: 17.339896
Val Best Loss: 15.956783
Epoch loss: 17.339896
train phase, Epoch 23/25, Loss: 12.940960
val phase, Epoch 23/25, Loss: 17.082559
Val Best Loss: 15.956783
Epoch loss: 17.082559
train phase, Epoch 24/25, Loss: 12.654071
val phase, Epoch 24/25, Loss: 18.277710
Val Best Loss: 15.956783
Epoch loss: 18.277710
train phase, Epoch 25/25, Loss: 12.103181
val phase, Epoch 25/25, Loss: 17.650083
Val Best Loss: 15.956783
Epoch loss: 17.650083
train phase, Epoch 1/25, Loss: 20.363302
val phase, Epoch 1/25, Loss: 17.876162
Val Best Loss: 17.876162
Epoch loss: 17.876162
train phase, Epoch 2/25, Loss: 17.679287
val phase, Epoch 2/25, Loss: 17.216046
Val Best Loss: 17.216046
Epoch loss: 17.216046
train phase, Epoch 3/25, Loss: 17.687678
val phase, Epoch 3/25, Loss: 24.390756
Val Best Loss: 17.216046
Epoch loss: 24.390756
train phase, Epoch 4/25, Loss: 17.207843
val phase, Epoch 4/25, Loss: 16.421252
Val Best Loss: 16.421252
Epoch loss: 16.421252
train phase, Epoch 5/25, Loss: 16.685390
val phase, Epoch 5/25, Loss: 17.026080
Val Best Loss: 16.421252
Epoch loss: 17.026080
train phase, Epoch 6/25, Loss: 16.668125
val phase, Epoch 6/25, Loss: 16.479022
Val Best Loss: 16.421252
Epoch loss: 16.479022
train phase, Epoch 7/25, Loss: 16.557094
val phase, Epoch 7/25, Loss: 16.661710
Val Best Loss: 16.421252
Epoch loss: 16.661710
train phase, Epoch 8/25, Loss: 16.520043
val phase, Epoch 8/25, Loss: 15.875699
Val Best Loss: 15.875699
Epoch loss: 15.875699
train phase, Epoch 9/25, Loss: 15.961376
val phase, Epoch 9/25, Loss: 16.462062
Val Best Loss: 15.875699
Epoch loss: 16.462062
train phase, Epoch 10/25, Loss: 16.126998
val phase, Epoch 10/25, Loss: 16.117569
Val Best Loss: 15.875699
Epoch loss: 16.117569
train phase, Epoch 11/25, Loss: 15.907271
val phase, Epoch 11/25, Loss: 16.101994
Val Best Loss: 15.875699
Epoch loss: 16.101994
train phase, Epoch 12/25, Loss: 15.456242
val phase, Epoch 12/25, Loss: 15.840152
Val Best Loss: 15.840152
Epoch loss: 15.840152
train phase, Epoch 13/25, Loss: 15.683271
val phase, Epoch 13/25, Loss: 16.491579
Val Best Loss: 15.840152
Epoch loss: 16.491579
train phase, Epoch 14/25, Loss: 15.404633
val phase, Epoch 14/25, Loss: 19.775707
Val Best Loss: 15.840152
Epoch loss: 19.775707
train phase, Epoch 15/25, Loss: 15.074630
val phase, Epoch 15/25, Loss: 16.409941
Val Best Loss: 15.840152
Epoch loss: 16.409941
train phase, Epoch 16/25, Loss: 15.004701
val phase, Epoch 16/25, Loss: 16.985636
Val Best Loss: 15.840152
Epoch loss: 16.985636
train phase, Epoch 17/25, Loss: 14.685151
val phase, Epoch 17/25, Loss: 16.058274
Val Best Loss: 15.840152
Epoch loss: 16.058274
train phase, Epoch 18/25, Loss: 14.560995
val phase, Epoch 18/25, Loss: 17.577125
Val Best Loss: 15.840152
Epoch loss: 17.577125
train phase, Epoch 19/25, Loss: 14.206235
val phase, Epoch 19/25, Loss: 16.341424
Val Best Loss: 15.840152
Epoch loss: 16.341424
train phase, Epoch 20/25, Loss: 13.814018
val phase, Epoch 20/25, Loss: 16.562038
Val Best Loss: 15.840152
Epoch loss: 16.562038
train phase, Epoch 21/25, Loss: 13.623519
val phase, Epoch 21/25, Loss: 17.005590
Val Best Loss: 15.840152
Epoch loss: 17.005590
train phase, Epoch 22/25, Loss: 13.387308
val phase, Epoch 22/25, Loss: 18.030023
Val Best Loss: 15.840152
Epoch loss: 18.030023
train phase, Epoch 23/25, Loss: 12.942763
val phase, Epoch 23/25, Loss: 18.039896
Val Best Loss: 15.840152
Epoch loss: 18.039896
train phase, Epoch 24/25, Loss: 12.610042
val phase, Epoch 24/25, Loss: 18.316171
Val Best Loss: 15.840152
Epoch loss: 18.316171
train phase, Epoch 25/25, Loss: 12.250759
val phase, Epoch 25/25, Loss: 18.955709
Val Best Loss: 15.840152
Epoch loss: 18.955709
train phase, Epoch 1/25, Loss: 19.821375
val phase, Epoch 1/25, Loss: 17.771142
Val Best Loss: 17.771142
Epoch loss: 17.771142
train phase, Epoch 2/25, Loss: 18.386809
val phase, Epoch 2/25, Loss: 20.415834
Val Best Loss: 17.771142
Epoch loss: 20.415834
train phase, Epoch 3/25, Loss: 17.572914
val phase, Epoch 3/25, Loss: 17.958488
Val Best Loss: 17.771142
Epoch loss: 17.958488
train phase, Epoch 4/25, Loss: 17.309205
val phase, Epoch 4/25, Loss: 17.018802
Val Best Loss: 17.018802
Epoch loss: 17.018802
train phase, Epoch 5/25, Loss: 16.727686
val phase, Epoch 5/25, Loss: 17.567919
Val Best Loss: 17.018802
Epoch loss: 17.567919
train phase, Epoch 6/25, Loss: 16.823420
val phase, Epoch 6/25, Loss: 16.508804
Val Best Loss: 16.508804
Epoch loss: 16.508804
train phase, Epoch 7/25, Loss: 16.491796
val phase, Epoch 7/25, Loss: 16.859848
Val Best Loss: 16.508804
Epoch loss: 16.859848
train phase, Epoch 8/25, Loss: 16.223032
val phase, Epoch 8/25, Loss: 15.977882
Val Best Loss: 15.977882
Epoch loss: 15.977882
train phase, Epoch 9/25, Loss: 16.105520
val phase, Epoch 9/25, Loss: 16.295381
Val Best Loss: 15.977882
Epoch loss: 16.295381
train phase, Epoch 10/25, Loss: 15.934446
val phase, Epoch 10/25, Loss: 16.128047
Val Best Loss: 15.977882
Epoch loss: 16.128047
train phase, Epoch 11/25, Loss: 15.939266
val phase, Epoch 11/25, Loss: 16.148793
Val Best Loss: 15.977882
Epoch loss: 16.148793
train phase, Epoch 12/25, Loss: 15.678708
val phase, Epoch 12/25, Loss: 15.961320
Val Best Loss: 15.961320
Epoch loss: 15.961320
train phase, Epoch 13/25, Loss: 15.585171
val phase, Epoch 13/25, Loss: 15.989674
Val Best Loss: 15.961320
Epoch loss: 15.989674
train phase, Epoch 14/25, Loss: 15.362164
val phase, Epoch 14/25, Loss: 15.715153
Val Best Loss: 15.715153
Epoch loss: 15.715153
train phase, Epoch 15/25, Loss: 15.138364
val phase, Epoch 15/25, Loss: 16.808832
Val Best Loss: 15.715153
Epoch loss: 16.808832
train phase, Epoch 16/25, Loss: 15.043717
val phase, Epoch 16/25, Loss: 15.839624
Val Best Loss: 15.715153
Epoch loss: 15.839624
train phase, Epoch 17/25, Loss: 14.886170
val phase, Epoch 17/25, Loss: 20.015133
Val Best Loss: 15.715153
Epoch loss: 20.015133
train phase, Epoch 18/25, Loss: 14.727568
val phase, Epoch 18/25, Loss: 16.177712
Val Best Loss: 15.715153
Epoch loss: 16.177712
train phase, Epoch 19/25, Loss: 14.260698
val phase, Epoch 19/25, Loss: 16.361613
Val Best Loss: 15.715153
Epoch loss: 16.361613
train phase, Epoch 20/25, Loss: 14.128838
val phase, Epoch 20/25, Loss: 16.536364
Val Best Loss: 15.715153
Epoch loss: 16.536364
train phase, Epoch 21/25, Loss: 13.995092
val phase, Epoch 21/25, Loss: 16.169448
Val Best Loss: 15.715153
Epoch loss: 16.169448
train phase, Epoch 22/25, Loss: 13.565253
val phase, Epoch 22/25, Loss: 16.367754
Val Best Loss: 15.715153
Epoch loss: 16.367754
train phase, Epoch 23/25, Loss: 13.206690
val phase, Epoch 23/25, Loss: 18.632331
Val Best Loss: 15.715153
Epoch loss: 18.632331
train phase, Epoch 24/25, Loss: 13.002920
val phase, Epoch 24/25, Loss: 17.802284
Val Best Loss: 15.715153
Epoch loss: 17.802284
train phase, Epoch 25/25, Loss: 12.606580
val phase, Epoch 25/25, Loss: 17.137339
Val Best Loss: 15.715153
Epoch loss: 17.137339
[Trial 448] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/25, Loss: 33.230525
val phase, Epoch 1/25, Loss: 17.869852
Val Best Loss: 17.869852
Epoch loss: 17.869852
train phase, Epoch 2/25, Loss: 17.600636
val phase, Epoch 2/25, Loss: 17.702861
Val Best Loss: 17.702861
Epoch loss: 17.702861
train phase, Epoch 3/25, Loss: 17.179786
val phase, Epoch 3/25, Loss: 17.335691
Val Best Loss: 17.335691
Epoch loss: 17.335691
train phase, Epoch 4/25, Loss: 16.733538
val phase, Epoch 4/25, Loss: 16.890310
Val Best Loss: 16.890310
Epoch loss: 16.890310
train phase, Epoch 5/25, Loss: 16.437584
val phase, Epoch 5/25, Loss: 17.510704
Val Best Loss: 16.890310
Epoch loss: 17.510704
train phase, Epoch 6/25, Loss: 16.082353
val phase, Epoch 6/25, Loss: 17.567263
Val Best Loss: 16.890310
Epoch loss: 17.567263
train phase, Epoch 7/25, Loss: 15.784030
val phase, Epoch 7/25, Loss: 17.898423
Val Best Loss: 16.890310
Epoch loss: 17.898423
train phase, Epoch 8/25, Loss: 15.420922
val phase, Epoch 8/25, Loss: 17.112059
Val Best Loss: 16.890310
Epoch loss: 17.112059
train phase, Epoch 9/25, Loss: 15.171113
val phase, Epoch 9/25, Loss: 17.653626
Val Best Loss: 16.890310
Epoch loss: 17.653626
train phase, Epoch 10/25, Loss: 14.784445
val phase, Epoch 10/25, Loss: 16.904463
Val Best Loss: 16.890310
Epoch loss: 16.904463
train phase, Epoch 11/25, Loss: 14.483295
val phase, Epoch 11/25, Loss: 17.084762
Val Best Loss: 16.890310
Epoch loss: 17.084762
train phase, Epoch 12/25, Loss: 14.127960
val phase, Epoch 12/25, Loss: 17.268281
Val Best Loss: 16.890310
Epoch loss: 17.268281
train phase, Epoch 13/25, Loss: 13.844778
val phase, Epoch 13/25, Loss: 17.729662
Val Best Loss: 16.890310
Epoch loss: 17.729662
train phase, Epoch 14/25, Loss: 13.517684
val phase, Epoch 14/25, Loss: 18.975157
Val Best Loss: 16.890310
Epoch loss: 18.975157
train phase, Epoch 15/25, Loss: 12.945967
val phase, Epoch 15/25, Loss: 17.579945
Val Best Loss: 16.890310
Epoch loss: 17.579945
train phase, Epoch 16/25, Loss: 12.380827
val phase, Epoch 16/25, Loss: 17.790447
Val Best Loss: 16.890310
Epoch loss: 17.790447
train phase, Epoch 17/25, Loss: 12.090053
val phase, Epoch 17/25, Loss: 17.783868
Val Best Loss: 16.890310
Epoch loss: 17.783868
train phase, Epoch 18/25, Loss: 11.660231
val phase, Epoch 18/25, Loss: 17.990483
Val Best Loss: 16.890310
Epoch loss: 17.990483
train phase, Epoch 19/25, Loss: 11.232239
val phase, Epoch 19/25, Loss: 18.302649
Val Best Loss: 16.890310
Epoch loss: 18.302649
train phase, Epoch 20/25, Loss: 10.692552
val phase, Epoch 20/25, Loss: 18.745264
Val Best Loss: 16.890310
Epoch loss: 18.745264
train phase, Epoch 21/25, Loss: 10.213187
val phase, Epoch 21/25, Loss: 18.689888
Val Best Loss: 16.890310
Epoch loss: 18.689888
train phase, Epoch 22/25, Loss: 9.805783
val phase, Epoch 22/25, Loss: 19.156603
Val Best Loss: 16.890310
Epoch loss: 19.156603
train phase, Epoch 23/25, Loss: 9.389949
val phase, Epoch 23/25, Loss: 18.576572
Val Best Loss: 16.890310
Epoch loss: 18.576572
train phase, Epoch 24/25, Loss: 8.997486
val phase, Epoch 24/25, Loss: 19.472230
Val Best Loss: 16.890310
Epoch loss: 19.472230
train phase, Epoch 25/25, Loss: 8.747180
val phase, Epoch 25/25, Loss: 19.957873
Val Best Loss: 16.890310
Epoch loss: 19.957873
train phase, Epoch 1/25, Loss: 25.434004
val phase, Epoch 1/25, Loss: 18.793844
Val Best Loss: 18.793844
Epoch loss: 18.793844
train phase, Epoch 2/25, Loss: 17.846390
val phase, Epoch 2/25, Loss: 17.766410
Val Best Loss: 17.766410
Epoch loss: 17.766410
train phase, Epoch 3/25, Loss: 17.486800
val phase, Epoch 3/25, Loss: 17.014715
Val Best Loss: 17.014715
Epoch loss: 17.014715
train phase, Epoch 4/25, Loss: 17.155934
val phase, Epoch 4/25, Loss: 17.196219
Val Best Loss: 17.014715
Epoch loss: 17.196219
train phase, Epoch 5/25, Loss: 16.918719
val phase, Epoch 5/25, Loss: 17.040140
Val Best Loss: 17.014715
Epoch loss: 17.040140
train phase, Epoch 6/25, Loss: 16.881792
val phase, Epoch 6/25, Loss: 16.960841
Val Best Loss: 16.960841
Epoch loss: 16.960841
train phase, Epoch 7/25, Loss: 16.750065
val phase, Epoch 7/25, Loss: 16.484429
Val Best Loss: 16.484429
Epoch loss: 16.484429
train phase, Epoch 8/25, Loss: 16.518861
val phase, Epoch 8/25, Loss: 16.439867
Val Best Loss: 16.439867
Epoch loss: 16.439867
train phase, Epoch 9/25, Loss: 16.367170
val phase, Epoch 9/25, Loss: 15.965646
Val Best Loss: 15.965646
Epoch loss: 15.965646
train phase, Epoch 10/25, Loss: 16.094028
val phase, Epoch 10/25, Loss: 17.477539
Val Best Loss: 15.965646
Epoch loss: 17.477539
train phase, Epoch 11/25, Loss: 15.969149
val phase, Epoch 11/25, Loss: 16.002518
Val Best Loss: 15.965646
Epoch loss: 16.002518
train phase, Epoch 12/25, Loss: 16.045333
val phase, Epoch 12/25, Loss: 16.360868
Val Best Loss: 15.965646
Epoch loss: 16.360868
train phase, Epoch 13/25, Loss: 15.910375
val phase, Epoch 13/25, Loss: 16.749519
Val Best Loss: 15.965646
Epoch loss: 16.749519
train phase, Epoch 14/25, Loss: 15.832521
val phase, Epoch 14/25, Loss: 16.132503
Val Best Loss: 15.965646
Epoch loss: 16.132503
train phase, Epoch 15/25, Loss: 15.557494
val phase, Epoch 15/25, Loss: 15.859612
Val Best Loss: 15.859612
Epoch loss: 15.859612
train phase, Epoch 16/25, Loss: 15.609664
val phase, Epoch 16/25, Loss: 16.511755
Val Best Loss: 15.859612
Epoch loss: 16.511755
train phase, Epoch 17/25, Loss: 15.472920
val phase, Epoch 17/25, Loss: 15.834455
Val Best Loss: 15.834455
Epoch loss: 15.834455
train phase, Epoch 18/25, Loss: 15.209533
val phase, Epoch 18/25, Loss: 15.879076
Val Best Loss: 15.834455
Epoch loss: 15.879076
train phase, Epoch 19/25, Loss: 15.186142
val phase, Epoch 19/25, Loss: 16.352846
Val Best Loss: 15.834455
Epoch loss: 16.352846
train phase, Epoch 20/25, Loss: 15.181072
val phase, Epoch 20/25, Loss: 16.596654
Val Best Loss: 15.834455
Epoch loss: 16.596654
train phase, Epoch 21/25, Loss: 14.986999
val phase, Epoch 21/25, Loss: 15.938177
Val Best Loss: 15.834455
Epoch loss: 15.938177
train phase, Epoch 22/25, Loss: 14.975818
val phase, Epoch 22/25, Loss: 16.171630
Val Best Loss: 15.834455
Epoch loss: 16.171630
train phase, Epoch 23/25, Loss: 14.705751
val phase, Epoch 23/25, Loss: 15.704195
Val Best Loss: 15.704195
Epoch loss: 15.704195
train phase, Epoch 24/25, Loss: 14.665964
val phase, Epoch 24/25, Loss: 16.194984
Val Best Loss: 15.704195
Epoch loss: 16.194984
train phase, Epoch 25/25, Loss: 14.599603
val phase, Epoch 25/25, Loss: 16.248152
Val Best Loss: 15.704195
Epoch loss: 16.248152
train phase, Epoch 1/25, Loss: 20.457346
val phase, Epoch 1/25, Loss: 17.753941
Val Best Loss: 17.753941
Epoch loss: 17.753941
train phase, Epoch 2/25, Loss: 17.584100
val phase, Epoch 2/25, Loss: 17.280828
Val Best Loss: 17.280828
Epoch loss: 17.280828
train phase, Epoch 3/25, Loss: 17.336300
val phase, Epoch 3/25, Loss: 17.781841
Val Best Loss: 17.280828
Epoch loss: 17.781841
train phase, Epoch 4/25, Loss: 17.595584
val phase, Epoch 4/25, Loss: 17.083194
Val Best Loss: 17.083194
Epoch loss: 17.083194
train phase, Epoch 5/25, Loss: 16.924277
val phase, Epoch 5/25, Loss: 17.651151
Val Best Loss: 17.083194
Epoch loss: 17.651151
train phase, Epoch 6/25, Loss: 16.696745
val phase, Epoch 6/25, Loss: 16.982240
Val Best Loss: 16.982240
Epoch loss: 16.982240
train phase, Epoch 7/25, Loss: 16.505012
val phase, Epoch 7/25, Loss: 16.277450
Val Best Loss: 16.277450
Epoch loss: 16.277450
train phase, Epoch 8/25, Loss: 16.625773
val phase, Epoch 8/25, Loss: 16.044304
Val Best Loss: 16.044304
Epoch loss: 16.044304
train phase, Epoch 9/25, Loss: 16.061307
val phase, Epoch 9/25, Loss: 17.708386
Val Best Loss: 16.044304
Epoch loss: 17.708386
train phase, Epoch 10/25, Loss: 15.951899
val phase, Epoch 10/25, Loss: 16.942026
Val Best Loss: 16.044304
Epoch loss: 16.942026
train phase, Epoch 11/25, Loss: 15.973208
val phase, Epoch 11/25, Loss: 16.498461
Val Best Loss: 16.044304
Epoch loss: 16.498461
train phase, Epoch 12/25, Loss: 15.468965
val phase, Epoch 12/25, Loss: 15.614882
Val Best Loss: 15.614882
Epoch loss: 15.614882
train phase, Epoch 13/25, Loss: 15.542069
val phase, Epoch 13/25, Loss: 16.677885
Val Best Loss: 15.614882
Epoch loss: 16.677885
train phase, Epoch 14/25, Loss: 15.331073
val phase, Epoch 14/25, Loss: 16.001429
Val Best Loss: 15.614882
Epoch loss: 16.001429
train phase, Epoch 15/25, Loss: 15.171961
val phase, Epoch 15/25, Loss: 16.029959
Val Best Loss: 15.614882
Epoch loss: 16.029959
train phase, Epoch 16/25, Loss: 15.076740
val phase, Epoch 16/25, Loss: 16.870694
Val Best Loss: 15.614882
Epoch loss: 16.870694
train phase, Epoch 17/25, Loss: 15.090903
val phase, Epoch 17/25, Loss: 16.837662
Val Best Loss: 15.614882
Epoch loss: 16.837662
train phase, Epoch 18/25, Loss: 14.840724
val phase, Epoch 18/25, Loss: 16.199581
Val Best Loss: 15.614882
Epoch loss: 16.199581
train phase, Epoch 19/25, Loss: 14.445845
val phase, Epoch 19/25, Loss: 16.094035
Val Best Loss: 15.614882
Epoch loss: 16.094035
train phase, Epoch 20/25, Loss: 14.319189
val phase, Epoch 20/25, Loss: 16.407863
Val Best Loss: 15.614882
Epoch loss: 16.407863
train phase, Epoch 21/25, Loss: 14.041721
val phase, Epoch 21/25, Loss: 16.785994
Val Best Loss: 15.614882
Epoch loss: 16.785994
train phase, Epoch 22/25, Loss: 13.919893
val phase, Epoch 22/25, Loss: 16.042340
Val Best Loss: 15.614882
Epoch loss: 16.042340
train phase, Epoch 23/25, Loss: 14.001585
val phase, Epoch 23/25, Loss: 16.870240
Val Best Loss: 15.614882
Epoch loss: 16.870240
train phase, Epoch 24/25, Loss: 13.351105
val phase, Epoch 24/25, Loss: 17.725493
Val Best Loss: 15.614882
Epoch loss: 17.725493
train phase, Epoch 25/25, Loss: 13.188942
val phase, Epoch 25/25, Loss: 16.192722
Val Best Loss: 15.614882
Epoch loss: 16.192722
train phase, Epoch 1/25, Loss: 20.977081
val phase, Epoch 1/25, Loss: 19.243814
Val Best Loss: 19.243814
Epoch loss: 19.243814
train phase, Epoch 2/25, Loss: 18.538994
val phase, Epoch 2/25, Loss: 18.682869
Val Best Loss: 18.682869
Epoch loss: 18.682869
train phase, Epoch 3/25, Loss: 18.005295
val phase, Epoch 3/25, Loss: 18.644445
Val Best Loss: 18.644445
Epoch loss: 18.644445
train phase, Epoch 4/25, Loss: 17.723166
val phase, Epoch 4/25, Loss: 18.397822
Val Best Loss: 18.397822
Epoch loss: 18.397822
train phase, Epoch 5/25, Loss: 18.203918
val phase, Epoch 5/25, Loss: 20.052785
Val Best Loss: 18.397822
Epoch loss: 20.052785
train phase, Epoch 6/25, Loss: 17.539263
val phase, Epoch 6/25, Loss: 18.796826
Val Best Loss: 18.397822
Epoch loss: 18.796826
train phase, Epoch 7/25, Loss: 17.340713
val phase, Epoch 7/25, Loss: 19.311334
Val Best Loss: 18.397822
Epoch loss: 19.311334
train phase, Epoch 8/25, Loss: 16.985648
val phase, Epoch 8/25, Loss: 17.764361
Val Best Loss: 17.764361
Epoch loss: 17.764361
train phase, Epoch 9/25, Loss: 16.968302
val phase, Epoch 9/25, Loss: 17.256593
Val Best Loss: 17.256593
Epoch loss: 17.256593
train phase, Epoch 10/25, Loss: 16.772476
val phase, Epoch 10/25, Loss: 17.316906
Val Best Loss: 17.256593
Epoch loss: 17.316906
train phase, Epoch 11/25, Loss: 16.847388
val phase, Epoch 11/25, Loss: 17.148993
Val Best Loss: 17.148993
Epoch loss: 17.148993
train phase, Epoch 12/25, Loss: 16.463288
val phase, Epoch 12/25, Loss: 17.220260
Val Best Loss: 17.148993
Epoch loss: 17.220260
train phase, Epoch 13/25, Loss: 16.156286
val phase, Epoch 13/25, Loss: 17.331199
Val Best Loss: 17.148993
Epoch loss: 17.331199
train phase, Epoch 14/25, Loss: 16.198502
val phase, Epoch 14/25, Loss: 17.309465
Val Best Loss: 17.148993
Epoch loss: 17.309465
train phase, Epoch 15/25, Loss: 16.188231
val phase, Epoch 15/25, Loss: 18.890644
Val Best Loss: 17.148993
Epoch loss: 18.890644
train phase, Epoch 16/25, Loss: 16.107709
val phase, Epoch 16/25, Loss: 16.777290
Val Best Loss: 16.777290
Epoch loss: 16.777290
train phase, Epoch 17/25, Loss: 15.780664
val phase, Epoch 17/25, Loss: 18.278293
Val Best Loss: 16.777290
Epoch loss: 18.278293
train phase, Epoch 18/25, Loss: 15.756077
val phase, Epoch 18/25, Loss: 17.715443
Val Best Loss: 16.777290
Epoch loss: 17.715443
train phase, Epoch 19/25, Loss: 15.768761
val phase, Epoch 19/25, Loss: 16.807982
Val Best Loss: 16.777290
Epoch loss: 16.807982
train phase, Epoch 20/25, Loss: 15.693625
val phase, Epoch 20/25, Loss: 19.462527
Val Best Loss: 16.777290
Epoch loss: 19.462527
train phase, Epoch 21/25, Loss: 15.559229
val phase, Epoch 21/25, Loss: 16.866043
Val Best Loss: 16.777290
Epoch loss: 16.866043
train phase, Epoch 22/25, Loss: 15.516523
val phase, Epoch 22/25, Loss: 17.093577
Val Best Loss: 16.777290
Epoch loss: 17.093577
train phase, Epoch 23/25, Loss: 15.362636
val phase, Epoch 23/25, Loss: 17.349753
Val Best Loss: 16.777290
Epoch loss: 17.349753
train phase, Epoch 24/25, Loss: 15.129284
val phase, Epoch 24/25, Loss: 16.827219
Val Best Loss: 16.777290
Epoch loss: 16.827219
train phase, Epoch 25/25, Loss: 15.112619
val phase, Epoch 25/25, Loss: 16.431893
Val Best Loss: 16.431893
Epoch loss: 16.431893
train phase, Epoch 1/25, Loss: 21.103224
val phase, Epoch 1/25, Loss: 17.982280
Val Best Loss: 17.982280
Epoch loss: 17.982280
train phase, Epoch 2/25, Loss: 17.346524
val phase, Epoch 2/25, Loss: 16.920414
Val Best Loss: 16.920414
Epoch loss: 16.920414
train phase, Epoch 3/25, Loss: 17.146983
val phase, Epoch 3/25, Loss: 16.248949
Val Best Loss: 16.248949
Epoch loss: 16.248949
train phase, Epoch 4/25, Loss: 16.792477
val phase, Epoch 4/25, Loss: 16.864939
Val Best Loss: 16.248949
Epoch loss: 16.864939
train phase, Epoch 5/25, Loss: 16.923819
val phase, Epoch 5/25, Loss: 16.181947
Val Best Loss: 16.181947
Epoch loss: 16.181947
train phase, Epoch 6/25, Loss: 16.391852
val phase, Epoch 6/25, Loss: 15.973177
Val Best Loss: 15.973177
Epoch loss: 15.973177
train phase, Epoch 7/25, Loss: 16.217386
val phase, Epoch 7/25, Loss: 17.943588
Val Best Loss: 15.973177
Epoch loss: 17.943588
train phase, Epoch 8/25, Loss: 16.018163
val phase, Epoch 8/25, Loss: 16.137123
Val Best Loss: 15.973177
Epoch loss: 16.137123
train phase, Epoch 9/25, Loss: 15.876037
val phase, Epoch 9/25, Loss: 16.185489
Val Best Loss: 15.973177
Epoch loss: 16.185489
train phase, Epoch 10/25, Loss: 15.944834
val phase, Epoch 10/25, Loss: 16.931359
Val Best Loss: 15.973177
Epoch loss: 16.931359
train phase, Epoch 11/25, Loss: 15.686233
val phase, Epoch 11/25, Loss: 16.849811
Val Best Loss: 15.973177
Epoch loss: 16.849811
train phase, Epoch 12/25, Loss: 15.257525
val phase, Epoch 12/25, Loss: 16.844267
Val Best Loss: 15.973177
Epoch loss: 16.844267
train phase, Epoch 13/25, Loss: 15.151934
val phase, Epoch 13/25, Loss: 16.244272
Val Best Loss: 15.973177
Epoch loss: 16.244272
train phase, Epoch 14/25, Loss: 14.913556
val phase, Epoch 14/25, Loss: 16.717297
Val Best Loss: 15.973177
Epoch loss: 16.717297
train phase, Epoch 15/25, Loss: 14.643452
val phase, Epoch 15/25, Loss: 15.920845
Val Best Loss: 15.920845
Epoch loss: 15.920845
train phase, Epoch 16/25, Loss: 14.339686
val phase, Epoch 16/25, Loss: 15.997808
Val Best Loss: 15.920845
Epoch loss: 15.997808
train phase, Epoch 17/25, Loss: 14.169402
val phase, Epoch 17/25, Loss: 16.242991
Val Best Loss: 15.920845
Epoch loss: 16.242991
train phase, Epoch 18/25, Loss: 14.058604
val phase, Epoch 18/25, Loss: 18.160618
Val Best Loss: 15.920845
Epoch loss: 18.160618
train phase, Epoch 19/25, Loss: 13.713925
val phase, Epoch 19/25, Loss: 18.578396
Val Best Loss: 15.920845
Epoch loss: 18.578396
train phase, Epoch 20/25, Loss: 13.562176
val phase, Epoch 20/25, Loss: 16.718923
Val Best Loss: 15.920845
Epoch loss: 16.718923
train phase, Epoch 21/25, Loss: 13.072915
val phase, Epoch 21/25, Loss: 18.243509
Val Best Loss: 15.920845
Epoch loss: 18.243509
train phase, Epoch 22/25, Loss: 12.670415
val phase, Epoch 22/25, Loss: 17.468722
Val Best Loss: 15.920845
Epoch loss: 17.468722
train phase, Epoch 23/25, Loss: 12.304051
val phase, Epoch 23/25, Loss: 17.522463
Val Best Loss: 15.920845
Epoch loss: 17.522463
train phase, Epoch 24/25, Loss: 12.056972
val phase, Epoch 24/25, Loss: 17.057754
Val Best Loss: 15.920845
Epoch loss: 17.057754
train phase, Epoch 25/25, Loss: 11.687974
val phase, Epoch 25/25, Loss: 16.812316
Val Best Loss: 15.920845
Epoch loss: 16.812316
train phase, Epoch 1/25, Loss: 20.601806
val phase, Epoch 1/25, Loss: 17.677003
Val Best Loss: 17.677003
Epoch loss: 17.677003
train phase, Epoch 2/25, Loss: 17.829682
val phase, Epoch 2/25, Loss: 18.017174
Val Best Loss: 17.677003
Epoch loss: 18.017174
train phase, Epoch 3/25, Loss: 17.353963
val phase, Epoch 3/25, Loss: 19.976362
Val Best Loss: 17.677003
Epoch loss: 19.976362
train phase, Epoch 4/25, Loss: 17.771540
val phase, Epoch 4/25, Loss: 16.913236
Val Best Loss: 16.913236
Epoch loss: 16.913236
train phase, Epoch 5/25, Loss: 16.853375
val phase, Epoch 5/25, Loss: 17.067827
Val Best Loss: 16.913236
Epoch loss: 17.067827
train phase, Epoch 6/25, Loss: 16.639684
val phase, Epoch 6/25, Loss: 16.641147
Val Best Loss: 16.641147
Epoch loss: 16.641147
train phase, Epoch 7/25, Loss: 16.609629
val phase, Epoch 7/25, Loss: 16.496361
Val Best Loss: 16.496361
Epoch loss: 16.496361
train phase, Epoch 8/25, Loss: 16.645620
val phase, Epoch 8/25, Loss: 16.148339
Val Best Loss: 16.148339
Epoch loss: 16.148339
train phase, Epoch 9/25, Loss: 16.241538
val phase, Epoch 9/25, Loss: 16.265399
Val Best Loss: 16.148339
Epoch loss: 16.265399
train phase, Epoch 10/25, Loss: 16.201947
val phase, Epoch 10/25, Loss: 16.435527
Val Best Loss: 16.148339
Epoch loss: 16.435527
train phase, Epoch 11/25, Loss: 15.870913
val phase, Epoch 11/25, Loss: 16.343000
Val Best Loss: 16.148339
Epoch loss: 16.343000
train phase, Epoch 12/25, Loss: 15.829989
val phase, Epoch 12/25, Loss: 17.276014
Val Best Loss: 16.148339
Epoch loss: 17.276014
train phase, Epoch 13/25, Loss: 15.874328
val phase, Epoch 13/25, Loss: 15.841349
Val Best Loss: 15.841349
Epoch loss: 15.841349
train phase, Epoch 14/25, Loss: 15.690188
val phase, Epoch 14/25, Loss: 16.185546
Val Best Loss: 15.841349
Epoch loss: 16.185546
train phase, Epoch 15/25, Loss: 15.219236
val phase, Epoch 15/25, Loss: 16.671152
Val Best Loss: 15.841349
Epoch loss: 16.671152
train phase, Epoch 16/25, Loss: 15.247068
val phase, Epoch 16/25, Loss: 16.404819
Val Best Loss: 15.841349
Epoch loss: 16.404819
train phase, Epoch 17/25, Loss: 15.116944
val phase, Epoch 17/25, Loss: 16.253420
Val Best Loss: 15.841349
Epoch loss: 16.253420
train phase, Epoch 18/25, Loss: 14.801230
val phase, Epoch 18/25, Loss: 15.767182
Val Best Loss: 15.767182
Epoch loss: 15.767182
train phase, Epoch 19/25, Loss: 14.567604
val phase, Epoch 19/25, Loss: 17.040734
Val Best Loss: 15.767182
Epoch loss: 17.040734
train phase, Epoch 20/25, Loss: 14.756768
val phase, Epoch 20/25, Loss: 16.011266
Val Best Loss: 15.767182
Epoch loss: 16.011266
train phase, Epoch 21/25, Loss: 14.494994
val phase, Epoch 21/25, Loss: 16.447688
Val Best Loss: 15.767182
Epoch loss: 16.447688
train phase, Epoch 22/25, Loss: 14.086197
val phase, Epoch 22/25, Loss: 16.224205
Val Best Loss: 15.767182
Epoch loss: 16.224205
train phase, Epoch 23/25, Loss: 14.008096
val phase, Epoch 23/25, Loss: 17.038575
Val Best Loss: 15.767182
Epoch loss: 17.038575
train phase, Epoch 24/25, Loss: 13.818942
val phase, Epoch 24/25, Loss: 16.820673
Val Best Loss: 15.767182
Epoch loss: 16.820673
train phase, Epoch 25/25, Loss: 13.783421
val phase, Epoch 25/25, Loss: 16.455276
Val Best Loss: 15.767182
Epoch loss: 16.455276
train phase, Epoch 1/25, Loss: 23.688147
val phase, Epoch 1/25, Loss: 18.660427
Val Best Loss: 18.660427
Epoch loss: 18.660427
train phase, Epoch 2/25, Loss: 19.534165
val phase, Epoch 2/25, Loss: 17.768616
Val Best Loss: 17.768616
Epoch loss: 17.768616
train phase, Epoch 3/25, Loss: 18.581536
val phase, Epoch 3/25, Loss: 18.516415
Val Best Loss: 17.768616
Epoch loss: 18.516415
train phase, Epoch 4/25, Loss: 17.803812
val phase, Epoch 4/25, Loss: 17.788338
Val Best Loss: 17.768616
Epoch loss: 17.788338
train phase, Epoch 5/25, Loss: 17.374555
val phase, Epoch 5/25, Loss: 17.167566
Val Best Loss: 17.167566
Epoch loss: 17.167566
train phase, Epoch 6/25, Loss: 17.347956
val phase, Epoch 6/25, Loss: 18.451515
Val Best Loss: 17.167566
Epoch loss: 18.451515
train phase, Epoch 7/25, Loss: 17.163406
val phase, Epoch 7/25, Loss: 16.812272
Val Best Loss: 16.812272
Epoch loss: 16.812272
train phase, Epoch 8/25, Loss: 16.732217
val phase, Epoch 8/25, Loss: 17.601939
Val Best Loss: 16.812272
Epoch loss: 17.601939
train phase, Epoch 9/25, Loss: 16.857482
val phase, Epoch 9/25, Loss: 20.519539
Val Best Loss: 16.812272
Epoch loss: 20.519539
train phase, Epoch 10/25, Loss: 16.467486
val phase, Epoch 10/25, Loss: 18.442115
Val Best Loss: 16.812272
Epoch loss: 18.442115
train phase, Epoch 11/25, Loss: 17.218676
val phase, Epoch 11/25, Loss: 19.555169
Val Best Loss: 16.812272
Epoch loss: 19.555169
train phase, Epoch 12/25, Loss: 15.984415
val phase, Epoch 12/25, Loss: 16.934640
Val Best Loss: 16.812272
Epoch loss: 16.934640
train phase, Epoch 13/25, Loss: 15.894307
val phase, Epoch 13/25, Loss: 16.488852
Val Best Loss: 16.488852
Epoch loss: 16.488852
train phase, Epoch 14/25, Loss: 15.678171
val phase, Epoch 14/25, Loss: 18.257504
Val Best Loss: 16.488852
Epoch loss: 18.257504
train phase, Epoch 15/25, Loss: 15.561443
val phase, Epoch 15/25, Loss: 19.310140
Val Best Loss: 16.488852
Epoch loss: 19.310140
train phase, Epoch 16/25, Loss: 15.306974
val phase, Epoch 16/25, Loss: 17.222780
Val Best Loss: 16.488852
Epoch loss: 17.222780
train phase, Epoch 17/25, Loss: 14.732025
val phase, Epoch 17/25, Loss: 17.899198
Val Best Loss: 16.488852
Epoch loss: 17.899198
train phase, Epoch 18/25, Loss: 14.802522
val phase, Epoch 18/25, Loss: 17.128710
Val Best Loss: 16.488852
Epoch loss: 17.128710
train phase, Epoch 19/25, Loss: 14.592417
val phase, Epoch 19/25, Loss: 17.793155
Val Best Loss: 16.488852
Epoch loss: 17.793155
train phase, Epoch 20/25, Loss: 13.930013
val phase, Epoch 20/25, Loss: 17.161339
Val Best Loss: 16.488852
Epoch loss: 17.161339
train phase, Epoch 21/25, Loss: 13.666167
val phase, Epoch 21/25, Loss: 17.460944
Val Best Loss: 16.488852
Epoch loss: 17.460944
train phase, Epoch 22/25, Loss: 13.293003
val phase, Epoch 22/25, Loss: 17.880879
Val Best Loss: 16.488852
Epoch loss: 17.880879
train phase, Epoch 23/25, Loss: 12.633831
val phase, Epoch 23/25, Loss: 18.126289
Val Best Loss: 16.488852
Epoch loss: 18.126289
train phase, Epoch 24/25, Loss: 12.320173
val phase, Epoch 24/25, Loss: 19.060216
Val Best Loss: 16.488852
Epoch loss: 19.060216
train phase, Epoch 25/25, Loss: 11.722398
val phase, Epoch 25/25, Loss: 18.588304
Val Best Loss: 16.488852
Epoch loss: 18.588304
train phase, Epoch 1/25, Loss: 23.114229
val phase, Epoch 1/25, Loss: 18.639051
Val Best Loss: 18.639051
Epoch loss: 18.639051
train phase, Epoch 2/25, Loss: 18.507982
val phase, Epoch 2/25, Loss: 18.270594
Val Best Loss: 18.270594
Epoch loss: 18.270594
train phase, Epoch 3/25, Loss: 18.207065
val phase, Epoch 3/25, Loss: 17.766647
Val Best Loss: 17.766647
Epoch loss: 17.766647
train phase, Epoch 4/25, Loss: 17.432535
val phase, Epoch 4/25, Loss: 19.154736
Val Best Loss: 17.766647
Epoch loss: 19.154736
train phase, Epoch 5/25, Loss: 17.393819
val phase, Epoch 5/25, Loss: 17.907019
Val Best Loss: 17.766647
Epoch loss: 17.907019
train phase, Epoch 6/25, Loss: 17.471079
val phase, Epoch 6/25, Loss: 22.943371
Val Best Loss: 17.766647
Epoch loss: 22.943371
train phase, Epoch 7/25, Loss: 17.006156
val phase, Epoch 7/25, Loss: 18.661298
Val Best Loss: 17.766647
Epoch loss: 18.661298
train phase, Epoch 8/25, Loss: 17.101839
val phase, Epoch 8/25, Loss: 17.357942
Val Best Loss: 17.357942
Epoch loss: 17.357942
train phase, Epoch 9/25, Loss: 17.008251
val phase, Epoch 9/25, Loss: 16.869077
Val Best Loss: 16.869077
Epoch loss: 16.869077
train phase, Epoch 10/25, Loss: 16.852113
val phase, Epoch 10/25, Loss: 17.182442
Val Best Loss: 16.869077
Epoch loss: 17.182442
train phase, Epoch 11/25, Loss: 16.393942
val phase, Epoch 11/25, Loss: 17.114993
Val Best Loss: 16.869077
Epoch loss: 17.114993
train phase, Epoch 12/25, Loss: 16.504738
val phase, Epoch 12/25, Loss: 16.940650
Val Best Loss: 16.869077
Epoch loss: 16.940650
train phase, Epoch 13/25, Loss: 16.735313
val phase, Epoch 13/25, Loss: 16.805990
Val Best Loss: 16.805990
Epoch loss: 16.805990
train phase, Epoch 14/25, Loss: 16.237933
val phase, Epoch 14/25, Loss: 17.930890
Val Best Loss: 16.805990
Epoch loss: 17.930890
train phase, Epoch 15/25, Loss: 16.227488
val phase, Epoch 15/25, Loss: 17.715990
Val Best Loss: 16.805990
Epoch loss: 17.715990
train phase, Epoch 16/25, Loss: 16.291028
val phase, Epoch 16/25, Loss: 17.189072
Val Best Loss: 16.805990
Epoch loss: 17.189072
train phase, Epoch 17/25, Loss: 15.998921
val phase, Epoch 17/25, Loss: 17.724062
Val Best Loss: 16.805990
Epoch loss: 17.724062
train phase, Epoch 18/25, Loss: 15.559635
val phase, Epoch 18/25, Loss: 17.097778
Val Best Loss: 16.805990
Epoch loss: 17.097778
train phase, Epoch 19/25, Loss: 15.570531
val phase, Epoch 19/25, Loss: 17.062997
Val Best Loss: 16.805990
Epoch loss: 17.062997
train phase, Epoch 20/25, Loss: 15.228808
val phase, Epoch 20/25, Loss: 17.051045
Val Best Loss: 16.805990
Epoch loss: 17.051045
train phase, Epoch 21/25, Loss: 15.272102
val phase, Epoch 21/25, Loss: 16.423341
Val Best Loss: 16.423341
Epoch loss: 16.423341
train phase, Epoch 22/25, Loss: 14.939696
val phase, Epoch 22/25, Loss: 17.171672
Val Best Loss: 16.423341
Epoch loss: 17.171672
train phase, Epoch 23/25, Loss: 14.923257
val phase, Epoch 23/25, Loss: 16.839589
Val Best Loss: 16.423341
Epoch loss: 16.839589
train phase, Epoch 24/25, Loss: 14.796095
val phase, Epoch 24/25, Loss: 16.735487
Val Best Loss: 16.423341
Epoch loss: 16.735487
train phase, Epoch 25/25, Loss: 14.745044
val phase, Epoch 25/25, Loss: 16.650511
Val Best Loss: 16.423341
Epoch loss: 16.650511
[Trial 457] Skipped due to model construction error: Calculated padded input size per channel: (11 x 5). Kernel size: (7 x 7). Kernel size can't be greater than actual input size
train phase, Epoch 1/25, Loss: 20.790412
val phase, Epoch 1/25, Loss: 29.281604
Val Best Loss: 29.281604
Epoch loss: 29.281604
train phase, Epoch 2/25, Loss: 17.896349
val phase, Epoch 2/25, Loss: 30.344721
Val Best Loss: 29.281604
Epoch loss: 30.344721
train phase, Epoch 3/25, Loss: 17.071522
val phase, Epoch 3/25, Loss: 32.456188
Val Best Loss: 29.281604
Epoch loss: 32.456188
train phase, Epoch 4/25, Loss: 16.953335
val phase, Epoch 4/25, Loss: 34.148832
Val Best Loss: 29.281604
Epoch loss: 34.148832
train phase, Epoch 5/25, Loss: 16.666227
val phase, Epoch 5/25, Loss: 29.865048
Val Best Loss: 29.281604
Epoch loss: 29.865048
train phase, Epoch 6/25, Loss: 16.510012
val phase, Epoch 6/25, Loss: 31.349470
Val Best Loss: 29.281604
Epoch loss: 31.349470
train phase, Epoch 7/25, Loss: 16.052364
val phase, Epoch 7/25, Loss: 29.639750
Val Best Loss: 29.281604
Epoch loss: 29.639750
train phase, Epoch 8/25, Loss: 16.008276
val phase, Epoch 8/25, Loss: 28.492240
Val Best Loss: 28.492240
Epoch loss: 28.492240
train phase, Epoch 9/25, Loss: 16.042694
val phase, Epoch 9/25, Loss: 28.348504
Val Best Loss: 28.348504
Epoch loss: 28.348504
train phase, Epoch 10/25, Loss: 15.841718
val phase, Epoch 10/25, Loss: 33.040065
Val Best Loss: 28.348504
Epoch loss: 33.040065
train phase, Epoch 11/25, Loss: 15.842620
val phase, Epoch 11/25, Loss: 33.916128
Val Best Loss: 28.348504
Epoch loss: 33.916128
train phase, Epoch 12/25, Loss: 15.546478
val phase, Epoch 12/25, Loss: 39.914422
Val Best Loss: 28.348504
Epoch loss: 39.914422
train phase, Epoch 13/25, Loss: 15.308320
val phase, Epoch 13/25, Loss: 26.777110
Val Best Loss: 26.777110
Epoch loss: 26.777110
train phase, Epoch 14/25, Loss: 15.172373
val phase, Epoch 14/25, Loss: 28.635315
Val Best Loss: 26.777110
Epoch loss: 28.635315
train phase, Epoch 15/25, Loss: 15.175948
val phase, Epoch 15/25, Loss: 42.356067
Val Best Loss: 26.777110
Epoch loss: 42.356067
train phase, Epoch 16/25, Loss: 14.944908
val phase, Epoch 16/25, Loss: 30.873126
Val Best Loss: 26.777110
Epoch loss: 30.873126
train phase, Epoch 17/25, Loss: 14.683113
val phase, Epoch 17/25, Loss: 27.722462
Val Best Loss: 26.777110
Epoch loss: 27.722462
train phase, Epoch 18/25, Loss: 14.570402
val phase, Epoch 18/25, Loss: 32.573181
Val Best Loss: 26.777110
Epoch loss: 32.573181
train phase, Epoch 19/25, Loss: 14.486107
val phase, Epoch 19/25, Loss: 33.027211
Val Best Loss: 26.777110
Epoch loss: 33.027211
train phase, Epoch 20/25, Loss: 14.185632
val phase, Epoch 20/25, Loss: 36.208448
Val Best Loss: 26.777110
Epoch loss: 36.208448
train phase, Epoch 21/25, Loss: 14.218368
val phase, Epoch 21/25, Loss: 38.181297
Val Best Loss: 26.777110
Epoch loss: 38.181297
train phase, Epoch 22/25, Loss: 13.682162
val phase, Epoch 22/25, Loss: 32.299612
Val Best Loss: 26.777110
Epoch loss: 32.299612
train phase, Epoch 23/25, Loss: 13.690970
val phase, Epoch 23/25, Loss: 39.544893
Val Best Loss: 26.777110
Epoch loss: 39.544893
train phase, Epoch 24/25, Loss: 13.149475
val phase, Epoch 24/25, Loss: 34.661046
Val Best Loss: 26.777110
Epoch loss: 34.661046
train phase, Epoch 25/25, Loss: 12.995856
val phase, Epoch 25/25, Loss: 38.901989
Val Best Loss: 26.777110
Epoch loss: 38.901989
train phase, Epoch 1/15, Loss: 20.651153
val phase, Epoch 1/15, Loss: 17.879346
Val Best Loss: 17.879346
Epoch loss: 17.879346
train phase, Epoch 2/15, Loss: 17.764653
val phase, Epoch 2/15, Loss: 16.731609
Val Best Loss: 16.731609
Epoch loss: 16.731609
train phase, Epoch 3/15, Loss: 17.177983
val phase, Epoch 3/15, Loss: 17.452729
Val Best Loss: 16.731609
Epoch loss: 17.452729
train phase, Epoch 4/15, Loss: 17.338941
val phase, Epoch 4/15, Loss: 17.960556
Val Best Loss: 16.731609
Epoch loss: 17.960556
train phase, Epoch 5/15, Loss: 16.748369
val phase, Epoch 5/15, Loss: 16.260307
Val Best Loss: 16.260307
Epoch loss: 16.260307
train phase, Epoch 6/15, Loss: 16.538749
val phase, Epoch 6/15, Loss: 16.559372
Val Best Loss: 16.260307
Epoch loss: 16.559372
train phase, Epoch 7/15, Loss: 16.345091
val phase, Epoch 7/15, Loss: 17.917436
Val Best Loss: 16.260307
Epoch loss: 17.917436
train phase, Epoch 8/15, Loss: 16.326683
val phase, Epoch 8/15, Loss: 16.312539
Val Best Loss: 16.260307
Epoch loss: 16.312539
train phase, Epoch 9/15, Loss: 16.519570
val phase, Epoch 9/15, Loss: 15.962223
Val Best Loss: 15.962223
Epoch loss: 15.962223
train phase, Epoch 10/15, Loss: 15.869411
val phase, Epoch 10/15, Loss: 16.206412
Val Best Loss: 15.962223
Epoch loss: 16.206412
train phase, Epoch 11/15, Loss: 15.961546
val phase, Epoch 11/15, Loss: 15.966162
Val Best Loss: 15.962223
Epoch loss: 15.966162
train phase, Epoch 12/15, Loss: 15.754367
val phase, Epoch 12/15, Loss: 16.545831
Val Best Loss: 15.962223
Epoch loss: 16.545831
train phase, Epoch 13/15, Loss: 15.620657
val phase, Epoch 13/15, Loss: 16.082473
Val Best Loss: 15.962223
Epoch loss: 16.082473
train phase, Epoch 14/15, Loss: 15.510902
val phase, Epoch 14/15, Loss: 16.321359
Val Best Loss: 15.962223
Epoch loss: 16.321359
train phase, Epoch 15/15, Loss: 15.230748
val phase, Epoch 15/15, Loss: 16.619327
Val Best Loss: 15.962223
Epoch loss: 16.619327
[Trial 460] Skipped due to model construction error: Given input size: (128x5x2). Calculated output size: (128x1x0). Output size is too small
train phase, Epoch 1/25, Loss: 20.947748
val phase, Epoch 1/25, Loss: 18.559538
Val Best Loss: 18.559538
Epoch loss: 18.559538
train phase, Epoch 2/25, Loss: 17.486244
val phase, Epoch 2/25, Loss: 17.367832
Val Best Loss: 17.367832
Epoch loss: 17.367832
train phase, Epoch 3/25, Loss: 17.343514
val phase, Epoch 3/25, Loss: 16.694138
Val Best Loss: 16.694138
Epoch loss: 16.694138
train phase, Epoch 4/25, Loss: 17.121876
val phase, Epoch 4/25, Loss: 16.573919
Val Best Loss: 16.573919
Epoch loss: 16.573919
train phase, Epoch 5/25, Loss: 17.102958
val phase, Epoch 5/25, Loss: 17.208316
Val Best Loss: 16.573919
Epoch loss: 17.208316
train phase, Epoch 6/25, Loss: 16.432872
val phase, Epoch 6/25, Loss: 16.968274
Val Best Loss: 16.573919
Epoch loss: 16.968274
train phase, Epoch 7/25, Loss: 16.446126
val phase, Epoch 7/25, Loss: 18.184739
Val Best Loss: 16.573919
Epoch loss: 18.184739
train phase, Epoch 8/25, Loss: 16.191528
val phase, Epoch 8/25, Loss: 16.368106
Val Best Loss: 16.368106
Epoch loss: 16.368106
train phase, Epoch 9/25, Loss: 16.092218
val phase, Epoch 9/25, Loss: 15.977412
Val Best Loss: 15.977412
Epoch loss: 15.977412
train phase, Epoch 10/25, Loss: 15.775186
val phase, Epoch 10/25, Loss: 16.755083
Val Best Loss: 15.977412
Epoch loss: 16.755083
train phase, Epoch 11/25, Loss: 15.670886
val phase, Epoch 11/25, Loss: 16.377222
Val Best Loss: 15.977412
Epoch loss: 16.377222
train phase, Epoch 12/25, Loss: 15.634982
val phase, Epoch 12/25, Loss: 17.521974
Val Best Loss: 15.977412
Epoch loss: 17.521974
train phase, Epoch 13/25, Loss: 15.540222
val phase, Epoch 13/25, Loss: 16.491312
Val Best Loss: 15.977412
Epoch loss: 16.491312
train phase, Epoch 14/25, Loss: 15.178632
val phase, Epoch 14/25, Loss: 16.292078
Val Best Loss: 15.977412
Epoch loss: 16.292078
train phase, Epoch 15/25, Loss: 15.259577
val phase, Epoch 15/25, Loss: 16.172722
Val Best Loss: 15.977412
Epoch loss: 16.172722
train phase, Epoch 16/25, Loss: 14.934662
val phase, Epoch 16/25, Loss: 15.689433
Val Best Loss: 15.689433
Epoch loss: 15.689433
train phase, Epoch 17/25, Loss: 14.754745
val phase, Epoch 17/25, Loss: 16.116285
Val Best Loss: 15.689433
Epoch loss: 16.116285
train phase, Epoch 18/25, Loss: 14.677686
val phase, Epoch 18/25, Loss: 15.751719
Val Best Loss: 15.689433
Epoch loss: 15.751719
train phase, Epoch 19/25, Loss: 14.322831
val phase, Epoch 19/25, Loss: 16.045791
Val Best Loss: 15.689433
Epoch loss: 16.045791
train phase, Epoch 20/25, Loss: 14.179568
val phase, Epoch 20/25, Loss: 15.835112
Val Best Loss: 15.689433
Epoch loss: 15.835112
train phase, Epoch 21/25, Loss: 14.061013
val phase, Epoch 21/25, Loss: 16.315971
Val Best Loss: 15.689433
Epoch loss: 16.315971
train phase, Epoch 22/25, Loss: 13.864049
val phase, Epoch 22/25, Loss: 15.903551
Val Best Loss: 15.689433
Epoch loss: 15.903551
train phase, Epoch 23/25, Loss: 13.333527
val phase, Epoch 23/25, Loss: 16.302449
Val Best Loss: 15.689433
Epoch loss: 16.302449
train phase, Epoch 24/25, Loss: 13.129395
val phase, Epoch 24/25, Loss: 16.839253
Val Best Loss: 15.689433
Epoch loss: 16.839253
train phase, Epoch 25/25, Loss: 12.933260
val phase, Epoch 25/25, Loss: 16.116991
Val Best Loss: 15.689433
Epoch loss: 16.116991
train phase, Epoch 1/25, Loss: 20.128901
val phase, Epoch 1/25, Loss: 19.684321
Val Best Loss: 19.684321
Epoch loss: 19.684321
train phase, Epoch 2/25, Loss: 18.138712
val phase, Epoch 2/25, Loss: 17.340463
Val Best Loss: 17.340463
Epoch loss: 17.340463
train phase, Epoch 3/25, Loss: 17.673318
val phase, Epoch 3/25, Loss: 17.344748
Val Best Loss: 17.340463
Epoch loss: 17.344748
train phase, Epoch 4/25, Loss: 17.680816
val phase, Epoch 4/25, Loss: 16.611591
Val Best Loss: 16.611591
Epoch loss: 16.611591
train phase, Epoch 5/25, Loss: 17.374337
val phase, Epoch 5/25, Loss: 20.220002
Val Best Loss: 16.611591
Epoch loss: 20.220002
train phase, Epoch 6/25, Loss: 17.104877
val phase, Epoch 6/25, Loss: 17.072876
Val Best Loss: 16.611591
Epoch loss: 17.072876
train phase, Epoch 7/25, Loss: 16.675726
val phase, Epoch 7/25, Loss: 16.521640
Val Best Loss: 16.521640
Epoch loss: 16.521640
train phase, Epoch 8/25, Loss: 16.720981
val phase, Epoch 8/25, Loss: 16.761901
Val Best Loss: 16.521640
Epoch loss: 16.761901
train phase, Epoch 9/25, Loss: 16.609273
val phase, Epoch 9/25, Loss: 16.086855
Val Best Loss: 16.086855
Epoch loss: 16.086855
train phase, Epoch 10/25, Loss: 16.360992
val phase, Epoch 10/25, Loss: 16.825070
Val Best Loss: 16.086855
Epoch loss: 16.825070
train phase, Epoch 11/25, Loss: 16.329220
val phase, Epoch 11/25, Loss: 17.157675
Val Best Loss: 16.086855
Epoch loss: 17.157675
train phase, Epoch 12/25, Loss: 15.955247
val phase, Epoch 12/25, Loss: 19.266225
Val Best Loss: 16.086855
Epoch loss: 19.266225
train phase, Epoch 13/25, Loss: 16.088574
val phase, Epoch 13/25, Loss: 16.868527
Val Best Loss: 16.086855
Epoch loss: 16.868527
train phase, Epoch 14/25, Loss: 15.827368
val phase, Epoch 14/25, Loss: 16.563510
Val Best Loss: 16.086855
Epoch loss: 16.563510
train phase, Epoch 15/25, Loss: 15.486042
val phase, Epoch 15/25, Loss: 18.599847
Val Best Loss: 16.086855
Epoch loss: 18.599847
train phase, Epoch 16/25, Loss: 15.924413
val phase, Epoch 16/25, Loss: 15.913448
Val Best Loss: 15.913448
Epoch loss: 15.913448
train phase, Epoch 17/25, Loss: 15.330673
val phase, Epoch 17/25, Loss: 16.997063
Val Best Loss: 15.913448
Epoch loss: 16.997063
train phase, Epoch 18/25, Loss: 15.197068
val phase, Epoch 18/25, Loss: 16.166860
Val Best Loss: 15.913448
Epoch loss: 16.166860
train phase, Epoch 19/25, Loss: 15.215343
val phase, Epoch 19/25, Loss: 16.833641
Val Best Loss: 15.913448
Epoch loss: 16.833641
train phase, Epoch 20/25, Loss: 14.804210
val phase, Epoch 20/25, Loss: 17.732220
Val Best Loss: 15.913448
Epoch loss: 17.732220
train phase, Epoch 21/25, Loss: 14.533033
val phase, Epoch 21/25, Loss: 16.452109
Val Best Loss: 15.913448
Epoch loss: 16.452109
train phase, Epoch 22/25, Loss: 14.683778
val phase, Epoch 22/25, Loss: 16.241058
Val Best Loss: 15.913448
Epoch loss: 16.241058
train phase, Epoch 23/25, Loss: 14.347334
val phase, Epoch 23/25, Loss: 17.421168
Val Best Loss: 15.913448
Epoch loss: 17.421168
train phase, Epoch 24/25, Loss: 14.181028
val phase, Epoch 24/25, Loss: 18.251883
Val Best Loss: 15.913448
Epoch loss: 18.251883
train phase, Epoch 25/25, Loss: 14.241070
val phase, Epoch 25/25, Loss: 16.351154
Val Best Loss: 15.913448
Epoch loss: 16.351154
train phase, Epoch 1/12, Loss: 19.893957
val phase, Epoch 1/12, Loss: 17.440360
Val Best Loss: 17.440360
Epoch loss: 17.440360
train phase, Epoch 2/12, Loss: 18.009433
val phase, Epoch 2/12, Loss: 16.562368
Val Best Loss: 16.562368
Epoch loss: 16.562368
train phase, Epoch 3/12, Loss: 17.607272
val phase, Epoch 3/12, Loss: 16.756870
Val Best Loss: 16.562368
Epoch loss: 16.756870
train phase, Epoch 4/12, Loss: 17.372682
val phase, Epoch 4/12, Loss: 18.769717
Val Best Loss: 16.562368
Epoch loss: 18.769717
train phase, Epoch 5/12, Loss: 17.006032
val phase, Epoch 5/12, Loss: 16.177959
Val Best Loss: 16.177959
Epoch loss: 16.177959
train phase, Epoch 6/12, Loss: 17.048876
val phase, Epoch 6/12, Loss: 17.052198
Val Best Loss: 16.177959
Epoch loss: 17.052198
train phase, Epoch 7/12, Loss: 16.569976
val phase, Epoch 7/12, Loss: 16.282254
Val Best Loss: 16.177959
Epoch loss: 16.282254
train phase, Epoch 8/12, Loss: 16.480503
val phase, Epoch 8/12, Loss: 16.505637
Val Best Loss: 16.177959
Epoch loss: 16.505637
train phase, Epoch 9/12, Loss: 16.232448
val phase, Epoch 9/12, Loss: 15.969189
Val Best Loss: 15.969189
Epoch loss: 15.969189
train phase, Epoch 10/12, Loss: 16.257005
val phase, Epoch 10/12, Loss: 16.279575
Val Best Loss: 15.969189
Epoch loss: 16.279575
train phase, Epoch 11/12, Loss: 16.027032
val phase, Epoch 11/12, Loss: 16.199016
Val Best Loss: 15.969189
Epoch loss: 16.199016
train phase, Epoch 12/12, Loss: 15.659209
val phase, Epoch 12/12, Loss: 16.074673
Val Best Loss: 15.969189
Epoch loss: 16.074673
train phase, Epoch 1/25, Loss: 20.157312
val phase, Epoch 1/25, Loss: 17.851488
Val Best Loss: 17.851488
Epoch loss: 17.851488
train phase, Epoch 2/25, Loss: 18.159845
val phase, Epoch 2/25, Loss: 18.185421
Val Best Loss: 17.851488
Epoch loss: 18.185421
train phase, Epoch 3/25, Loss: 17.712401
val phase, Epoch 3/25, Loss: 17.498075
Val Best Loss: 17.498075
Epoch loss: 17.498075
train phase, Epoch 4/25, Loss: 17.937033
val phase, Epoch 4/25, Loss: 17.085733
Val Best Loss: 17.085733
Epoch loss: 17.085733
train phase, Epoch 5/25, Loss: 17.346411
val phase, Epoch 5/25, Loss: 18.932801
Val Best Loss: 17.085733
Epoch loss: 18.932801
train phase, Epoch 6/25, Loss: 17.023775
val phase, Epoch 6/25, Loss: 17.891739
Val Best Loss: 17.085733
Epoch loss: 17.891739
train phase, Epoch 7/25, Loss: 16.741157
val phase, Epoch 7/25, Loss: 16.606445
Val Best Loss: 16.606445
Epoch loss: 16.606445
train phase, Epoch 8/25, Loss: 16.637622
val phase, Epoch 8/25, Loss: 16.576762
Val Best Loss: 16.576762
Epoch loss: 16.576762
train phase, Epoch 9/25, Loss: 16.717560
val phase, Epoch 9/25, Loss: 17.580486
Val Best Loss: 16.576762
Epoch loss: 17.580486
train phase, Epoch 10/25, Loss: 16.395676
val phase, Epoch 10/25, Loss: 16.332303
Val Best Loss: 16.332303
Epoch loss: 16.332303
train phase, Epoch 11/25, Loss: 16.174581
val phase, Epoch 11/25, Loss: 16.058845
Val Best Loss: 16.058845
Epoch loss: 16.058845
train phase, Epoch 12/25, Loss: 16.056474
val phase, Epoch 12/25, Loss: 16.805370
Val Best Loss: 16.058845
Epoch loss: 16.805370
train phase, Epoch 13/25, Loss: 15.895841
val phase, Epoch 13/25, Loss: 16.170759
Val Best Loss: 16.058845
Epoch loss: 16.170759
train phase, Epoch 14/25, Loss: 15.844800
val phase, Epoch 14/25, Loss: 16.912107
Val Best Loss: 16.058845
Epoch loss: 16.912107
train phase, Epoch 15/25, Loss: 15.763827
val phase, Epoch 15/25, Loss: 16.614083
Val Best Loss: 16.058845
Epoch loss: 16.614083
train phase, Epoch 16/25, Loss: 15.540201
val phase, Epoch 16/25, Loss: 16.964051
Val Best Loss: 16.058845
Epoch loss: 16.964051
train phase, Epoch 17/25, Loss: 15.366421
val phase, Epoch 17/25, Loss: 16.407686
Val Best Loss: 16.058845
Epoch loss: 16.407686
train phase, Epoch 18/25, Loss: 15.262456
val phase, Epoch 18/25, Loss: 16.288217
Val Best Loss: 16.058845
Epoch loss: 16.288217
train phase, Epoch 19/25, Loss: 14.868124
val phase, Epoch 19/25, Loss: 16.851598
Val Best Loss: 16.058845
Epoch loss: 16.851598
train phase, Epoch 20/25, Loss: 14.758017
val phase, Epoch 20/25, Loss: 16.986709
Val Best Loss: 16.058845
Epoch loss: 16.986709
train phase, Epoch 21/25, Loss: 14.771053
val phase, Epoch 21/25, Loss: 19.410978
Val Best Loss: 16.058845
Epoch loss: 19.410978
train phase, Epoch 22/25, Loss: 14.286619
val phase, Epoch 22/25, Loss: 16.766737
Val Best Loss: 16.058845
Epoch loss: 16.766737
train phase, Epoch 23/25, Loss: 14.325287
val phase, Epoch 23/25, Loss: 16.472764
Val Best Loss: 16.058845
Epoch loss: 16.472764
train phase, Epoch 24/25, Loss: 14.100318
val phase, Epoch 24/25, Loss: 17.225222
Val Best Loss: 16.058845
Epoch loss: 17.225222
train phase, Epoch 25/25, Loss: 14.076835
val phase, Epoch 25/25, Loss: 16.599423
Val Best Loss: 16.058845
Epoch loss: 16.599423
train phase, Epoch 1/20, Loss: 21.654465
val phase, Epoch 1/20, Loss: 18.099897
Val Best Loss: 18.099897
Epoch loss: 18.099897
train phase, Epoch 2/20, Loss: 17.868372
val phase, Epoch 2/20, Loss: 17.265639
Val Best Loss: 17.265639
Epoch loss: 17.265639
train phase, Epoch 3/20, Loss: 17.671003
val phase, Epoch 3/20, Loss: 17.791682
Val Best Loss: 17.265639
Epoch loss: 17.791682
train phase, Epoch 4/20, Loss: 17.479632
val phase, Epoch 4/20, Loss: 17.216669
Val Best Loss: 17.216669
Epoch loss: 17.216669
train phase, Epoch 5/20, Loss: 17.193815
val phase, Epoch 5/20, Loss: 17.623390
Val Best Loss: 17.216669
Epoch loss: 17.623390
train phase, Epoch 6/20, Loss: 17.028897
val phase, Epoch 6/20, Loss: 17.024796
Val Best Loss: 17.024796
Epoch loss: 17.024796
train phase, Epoch 7/20, Loss: 16.753644
val phase, Epoch 7/20, Loss: 17.431891
Val Best Loss: 17.024796
Epoch loss: 17.431891
train phase, Epoch 8/20, Loss: 16.417004
val phase, Epoch 8/20, Loss: 16.955003
Val Best Loss: 16.955003
Epoch loss: 16.955003
train phase, Epoch 9/20, Loss: 16.488558
val phase, Epoch 9/20, Loss: 17.364445
Val Best Loss: 16.955003
Epoch loss: 17.364445
train phase, Epoch 10/20, Loss: 15.910946
val phase, Epoch 10/20, Loss: 16.105377
Val Best Loss: 16.105377
Epoch loss: 16.105377
train phase, Epoch 11/20, Loss: 15.936187
val phase, Epoch 11/20, Loss: 16.114109
Val Best Loss: 16.105377
Epoch loss: 16.114109
train phase, Epoch 12/20, Loss: 15.631185
val phase, Epoch 12/20, Loss: 16.615007
Val Best Loss: 16.105377[I 2025-07-01 03:26:58,149] Trial 469 finished with value: 15.950800065473624 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.0026707900539622935, 'weight_decay': 2.766157257021032e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:27:42,429] Trial 470 finished with value: 15.858931274576177 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.004267065609594581, 'weight_decay': 6.657129312102471e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:27:42,471] Trial 471 pruned. 
[I 2025-07-01 03:28:31,771] Trial 472 finished with value: 15.878925765250468 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0020586745314849966, 'weight_decay': 4.451196833880142e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:29:13,656] Trial 473 finished with value: 15.821813531310077 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002465047928949112, 'weight_decay': 1.8593300699340186e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:30:16,996] Trial 474 finished with value: 15.82871771497873 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.003124966951901571, 'weight_decay': 1.0021052994990663e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:31:19,970] Trial 475 finished with value: 16.691706853506805 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003612144759497716, 'weight_decay': 1.259136089514758e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:31:20,010] Trial 476 pruned. 
[I 2025-07-01 03:32:09,073] Trial 477 finished with value: 15.984287596793298 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0039054042855922195, 'weight_decay': 2.2768046802310723e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:33:03,200] Trial 478 finished with value: 16.334115344194384 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0028739778228189087, 'weight_decay': 5.685264277591907e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.75}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:33:03,242] Trial 479 pruned. 
[I 2025-07-01 03:34:18,121] Trial 480 finished with value: 15.839468574710981 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 256, 'lr': 0.004362651841032745, 'weight_decay': 3.5304635055364636e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:35:07,571] Trial 481 finished with value: 15.87767037070238 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0025665838027800142, 'weight_decay': 9.314996346524207e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:35:50,741] Trial 482 finished with value: 25.777507543174142 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0031499925316529173, 'weight_decay': 4.476359212911163e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 1}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:37:06,498] Trial 483 finished with value: 16.064588628745852 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002941835872914098, 'weight_decay': 2.5969687057401443e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 32, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:37:51,288] Trial 484 finished with value: 16.169842486523383 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004026444155376668, 'weight_decay': 1.5874692473184126e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 15, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:39:05,326] Trial 485 finished with value: 15.852742818961467 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.00931747078704474, 'weight_decay': 6.185662575930348e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:39:55,690] Trial 486 finished with value: 15.684021869957467 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.003403543859439192, 'weight_decay': 1.9089997439637717e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:40:57,450] Trial 487 finished with value: 15.94629933063249 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 64, 'lr': 0.0023086426273820015, 'weight_decay': 3.1891926199053186e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 25, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:41:32,649] Trial 488 finished with value: 15.703594124523711 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0026462818913075316, 'weight_decay': 4.949919857308835e-06, 'optimizer': 'sgd', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:42:23,255] Trial 489 finished with value: 15.771174210744498 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.008548084553638993, 'weight_decay': 2.19531119888483e-05, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:43:38,623] Trial 490 finished with value: 15.952258683996833 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.003676151647770295, 'weight_decay': 3.832589696809382e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:44:28,435] Trial 491 finished with value: 15.893685169725023 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.0046780726456098105, 'weight_decay': 2.3583814267696526e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:44:28,476] Trial 492 pruned. 
[I 2025-07-01 03:45:29,718] Trial 493 finished with value: 16.457358149228902 and parameters: {'kernel_size': 3, 'channel_list': [32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.5, 'fc_hidden_dim': 128, 'lr': 0.0004734362082091741, 'weight_decay': 1.2779790536718295e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': False, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:45:29,759] Trial 494 pruned. 
[I 2025-07-01 03:45:44,774] Trial 495 finished with value: 16.398248241944575 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0, 'fc_hidden_dim': 128, 'lr': 0.0032601943973266777, 'weight_decay': 7.377038660492239e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 5, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:46:48,649] Trial 496 finished with value: 15.712584620560255 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.004231506567721569, 'weight_decay': 4.076623038037383e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 30, 'batch_size': 64, 'flip_prob': 0.25}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:47:38,281] Trial 497 finished with value: 15.827235273303218 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 128, 'lr': 0.002825174457026955, 'weight_decay': 5.3423869918825505e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.
[I 2025-07-01 03:47:38,319] Trial 498 pruned. 
[I 2025-07-01 03:48:14,149] Trial 499 finished with value: 16.236179679466563 and parameters: {'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.0024284147688251, 'weight_decay': 2.63484733553273e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 128, 'flip_prob': 0.0}. Best is trial 121 with value: 15.493945159799877.

Epoch loss: 16.615007
train phase, Epoch 13/20, Loss: 15.486780
val phase, Epoch 13/20, Loss: 17.135650
Val Best Loss: 16.105377
Epoch loss: 17.135650
train phase, Epoch 14/20, Loss: 15.272303
val phase, Epoch 14/20, Loss: 16.955420
Val Best Loss: 16.105377
Epoch loss: 16.955420
train phase, Epoch 15/20, Loss: 15.010661
val phase, Epoch 15/20, Loss: 16.628335
Val Best Loss: 16.105377
Epoch loss: 16.628335
train phase, Epoch 16/20, Loss: 14.601101
val phase, Epoch 16/20, Loss: 16.827282
Val Best Loss: 16.105377
Epoch loss: 16.827282
train phase, Epoch 17/20, Loss: 14.430626
val phase, Epoch 17/20, Loss: 17.668946
Val Best Loss: 16.105377
Epoch loss: 17.668946
train phase, Epoch 18/20, Loss: 14.217399
val phase, Epoch 18/20, Loss: 16.993868
Val Best Loss: 16.105377
Epoch loss: 16.993868
train phase, Epoch 19/20, Loss: 13.747460
val phase, Epoch 19/20, Loss: 16.926746
Val Best Loss: 16.105377
Epoch loss: 16.926746
train phase, Epoch 20/20, Loss: 13.554380
val phase, Epoch 20/20, Loss: 16.585080
Val Best Loss: 16.105377
Epoch loss: 16.585080
train phase, Epoch 1/20, Loss: 19.748272
val phase, Epoch 1/20, Loss: 17.304916
Val Best Loss: 17.304916
Epoch loss: 17.304916
train phase, Epoch 2/20, Loss: 17.797072
val phase, Epoch 2/20, Loss: 16.945622
Val Best Loss: 16.945622
Epoch loss: 16.945622
train phase, Epoch 3/20, Loss: 17.554446
val phase, Epoch 3/20, Loss: 17.219299
Val Best Loss: 16.945622
Epoch loss: 17.219299
train phase, Epoch 4/20, Loss: 17.198258
val phase, Epoch 4/20, Loss: 16.166539
Val Best Loss: 16.166539
Epoch loss: 16.166539
train phase, Epoch 5/20, Loss: 16.766755
val phase, Epoch 5/20, Loss: 21.644997
Val Best Loss: 16.166539
Epoch loss: 21.644997
train phase, Epoch 6/20, Loss: 16.561409
val phase, Epoch 6/20, Loss: 17.406624
Val Best Loss: 16.166539
Epoch loss: 17.406624
train phase, Epoch 7/20, Loss: 16.711166
val phase, Epoch 7/20, Loss: 16.494226
Val Best Loss: 16.166539
Epoch loss: 16.494226
train phase, Epoch 8/20, Loss: 16.515334
val phase, Epoch 8/20, Loss: 15.988640
Val Best Loss: 15.988640
Epoch loss: 15.988640
train phase, Epoch 9/20, Loss: 16.382193
val phase, Epoch 9/20, Loss: 16.045646
Val Best Loss: 15.988640
Epoch loss: 16.045646
train phase, Epoch 10/20, Loss: 16.064067
val phase, Epoch 10/20, Loss: 16.091692
Val Best Loss: 15.988640
Epoch loss: 16.091692
train phase, Epoch 11/20, Loss: 15.836338
val phase, Epoch 11/20, Loss: 17.617370
Val Best Loss: 15.988640
Epoch loss: 17.617370
train phase, Epoch 12/20, Loss: 15.773876
val phase, Epoch 12/20, Loss: 16.234137
Val Best Loss: 15.988640
Epoch loss: 16.234137
train phase, Epoch 13/20, Loss: 15.588402
val phase, Epoch 13/20, Loss: 16.153415
Val Best Loss: 15.988640
Epoch loss: 16.153415
train phase, Epoch 14/20, Loss: 15.590878
val phase, Epoch 14/20, Loss: 16.090304
Val Best Loss: 15.988640
Epoch loss: 16.090304
train phase, Epoch 15/20, Loss: 15.194944
val phase, Epoch 15/20, Loss: 16.513073
Val Best Loss: 15.988640
Epoch loss: 16.513073
train phase, Epoch 16/20, Loss: 14.928793
val phase, Epoch 16/20, Loss: 16.316498
Val Best Loss: 15.988640
Epoch loss: 16.316498
train phase, Epoch 17/20, Loss: 14.837854
val phase, Epoch 17/20, Loss: 18.829342
Val Best Loss: 15.988640
Epoch loss: 18.829342
train phase, Epoch 18/20, Loss: 14.519777
val phase, Epoch 18/20, Loss: 17.233318
Val Best Loss: 15.988640
Epoch loss: 17.233318
train phase, Epoch 19/20, Loss: 14.688322
val phase, Epoch 19/20, Loss: 15.822673
Val Best Loss: 15.822673
Epoch loss: 15.822673
train phase, Epoch 20/20, Loss: 13.912757
val phase, Epoch 20/20, Loss: 15.984701
Val Best Loss: 15.822673
Epoch loss: 15.984701
train phase, Epoch 1/5, Loss: 19.726359
val phase, Epoch 1/5, Loss: 22.513507
Val Best Loss: 22.513507
Epoch loss: 22.513507
train phase, Epoch 2/5, Loss: 17.837403
val phase, Epoch 2/5, Loss: 17.995720
Val Best Loss: 17.995720
Epoch loss: 17.995720
train phase, Epoch 3/5, Loss: 17.298515
val phase, Epoch 3/5, Loss: 16.231091
Val Best Loss: 16.231091
Epoch loss: 16.231091
train phase, Epoch 4/5, Loss: 17.042856
val phase, Epoch 4/5, Loss: 16.243974
Val Best Loss: 16.231091
Epoch loss: 16.243974
train phase, Epoch 5/5, Loss: 16.771457
val phase, Epoch 5/5, Loss: 16.105897
Val Best Loss: 16.105897
Epoch loss: 16.105897
train phase, Epoch 1/20, Loss: 19.529140
val phase, Epoch 1/20, Loss: 17.512464
Val Best Loss: 17.512464
Epoch loss: 17.512464
train phase, Epoch 2/20, Loss: 17.972088
val phase, Epoch 2/20, Loss: 17.815005
Val Best Loss: 17.512464
Epoch loss: 17.815005
train phase, Epoch 3/20, Loss: 17.443487
val phase, Epoch 3/20, Loss: 16.513282
Val Best Loss: 16.513282
Epoch loss: 16.513282
train phase, Epoch 4/20, Loss: 17.258979
val phase, Epoch 4/20, Loss: 16.246717
Val Best Loss: 16.246717
Epoch loss: 16.246717
train phase, Epoch 5/20, Loss: 16.777977
val phase, Epoch 5/20, Loss: 17.303626
Val Best Loss: 16.246717
Epoch loss: 17.303626
train phase, Epoch 6/20, Loss: 16.642763
val phase, Epoch 6/20, Loss: 16.331666
Val Best Loss: 16.246717
Epoch loss: 16.331666
train phase, Epoch 7/20, Loss: 16.520967
val phase, Epoch 7/20, Loss: 17.881616
Val Best Loss: 16.246717
Epoch loss: 17.881616
train phase, Epoch 8/20, Loss: 16.738655
val phase, Epoch 8/20, Loss: 15.860595
Val Best Loss: 15.860595
Epoch loss: 15.860595
train phase, Epoch 9/20, Loss: 16.117578
val phase, Epoch 9/20, Loss: 16.027003
Val Best Loss: 15.860595
Epoch loss: 16.027003
train phase, Epoch 10/20, Loss: 16.251268
val phase, Epoch 10/20, Loss: 15.836982
Val Best Loss: 15.836982
Epoch loss: 15.836982
train phase, Epoch 11/20, Loss: 16.100263
val phase, Epoch 11/20, Loss: 16.611217
Val Best Loss: 15.836982
Epoch loss: 16.611217
train phase, Epoch 12/20, Loss: 15.793330
val phase, Epoch 12/20, Loss: 16.191583
Val Best Loss: 15.836982
Epoch loss: 16.191583
train phase, Epoch 13/20, Loss: 15.462748
val phase, Epoch 13/20, Loss: 18.081719
Val Best Loss: 15.836982
Epoch loss: 18.081719
train phase, Epoch 14/20, Loss: 15.607033
val phase, Epoch 14/20, Loss: 15.908560
Val Best Loss: 15.836982
Epoch loss: 15.908560
train phase, Epoch 15/20, Loss: 15.308338
val phase, Epoch 15/20, Loss: 16.024912
Val Best Loss: 15.836982
Epoch loss: 16.024912
train phase, Epoch 16/20, Loss: 15.088700
val phase, Epoch 16/20, Loss: 16.670741
Val Best Loss: 15.836982
Epoch loss: 16.670741
train phase, Epoch 17/20, Loss: 15.041152
val phase, Epoch 17/20, Loss: 15.903262
Val Best Loss: 15.836982
Epoch loss: 15.903262
train phase, Epoch 18/20, Loss: 14.685220
val phase, Epoch 18/20, Loss: 17.424145
Val Best Loss: 15.836982
Epoch loss: 17.424145
train phase, Epoch 19/20, Loss: 14.533338
val phase, Epoch 19/20, Loss: 16.200354
Val Best Loss: 15.836982
Epoch loss: 16.200354
train phase, Epoch 20/20, Loss: 14.076679
val phase, Epoch 20/20, Loss: 16.110026
Val Best Loss: 15.836982
Epoch loss: 16.110026
train phase, Epoch 1/20, Loss: 23.743011
val phase, Epoch 1/20, Loss: 17.123761
Val Best Loss: 17.123761
Epoch loss: 17.123761
train phase, Epoch 2/20, Loss: 18.082504
val phase, Epoch 2/20, Loss: 19.505149
Val Best Loss: 17.123761
Epoch loss: 19.505149
train phase, Epoch 3/20, Loss: 18.167659
val phase, Epoch 3/20, Loss: 16.714873
Val Best Loss: 16.714873
Epoch loss: 16.714873
train phase, Epoch 4/20, Loss: 17.192737
val phase, Epoch 4/20, Loss: 16.718525
Val Best Loss: 16.714873
Epoch loss: 16.718525
train phase, Epoch 5/20, Loss: 17.015260
val phase, Epoch 5/20, Loss: 16.370828
Val Best Loss: 16.370828
Epoch loss: 16.370828
train phase, Epoch 6/20, Loss: 16.706836
val phase, Epoch 6/20, Loss: 16.106986
Val Best Loss: 16.106986
Epoch loss: 16.106986
train phase, Epoch 7/20, Loss: 16.320296
val phase, Epoch 7/20, Loss: 16.887610
Val Best Loss: 16.106986
Epoch loss: 16.887610
train phase, Epoch 8/20, Loss: 16.189612
val phase, Epoch 8/20, Loss: 16.823769
Val Best Loss: 16.106986
Epoch loss: 16.823769
train phase, Epoch 9/20, Loss: 16.136580
val phase, Epoch 9/20, Loss: 16.102444
Val Best Loss: 16.102444
Epoch loss: 16.102444
train phase, Epoch 10/20, Loss: 16.032322
val phase, Epoch 10/20, Loss: 15.950800
Val Best Loss: 15.950800
Epoch loss: 15.950800
train phase, Epoch 11/20, Loss: 15.781076
val phase, Epoch 11/20, Loss: 16.760973
Val Best Loss: 15.950800
Epoch loss: 16.760973
train phase, Epoch 12/20, Loss: 15.568119
val phase, Epoch 12/20, Loss: 16.046807
Val Best Loss: 15.950800
Epoch loss: 16.046807
train phase, Epoch 13/20, Loss: 15.277151
val phase, Epoch 13/20, Loss: 17.008735
Val Best Loss: 15.950800
Epoch loss: 17.008735
train phase, Epoch 14/20, Loss: 15.577083
val phase, Epoch 14/20, Loss: 17.962911
Val Best Loss: 15.950800
Epoch loss: 17.962911
train phase, Epoch 15/20, Loss: 14.964955
val phase, Epoch 15/20, Loss: 16.084206
Val Best Loss: 15.950800
Epoch loss: 16.084206
train phase, Epoch 16/20, Loss: 15.049075
val phase, Epoch 16/20, Loss: 16.594979
Val Best Loss: 15.950800
Epoch loss: 16.594979
train phase, Epoch 17/20, Loss: 14.465896
val phase, Epoch 17/20, Loss: 16.930783
Val Best Loss: 15.950800
Epoch loss: 16.930783
train phase, Epoch 18/20, Loss: 14.439480
val phase, Epoch 18/20, Loss: 16.365543
Val Best Loss: 15.950800
Epoch loss: 16.365543
train phase, Epoch 19/20, Loss: 14.223475
val phase, Epoch 19/20, Loss: 16.088644
Val Best Loss: 15.950800
Epoch loss: 16.088644
train phase, Epoch 20/20, Loss: 14.195337
val phase, Epoch 20/20, Loss: 18.597467
Val Best Loss: 15.950800
Epoch loss: 18.597467
train phase, Epoch 1/20, Loss: 21.604276
val phase, Epoch 1/20, Loss: 17.579939
Val Best Loss: 17.579939
Epoch loss: 17.579939
train phase, Epoch 2/20, Loss: 17.980510
val phase, Epoch 2/20, Loss: 17.551882
Val Best Loss: 17.551882
Epoch loss: 17.551882
train phase, Epoch 3/20, Loss: 17.558579
val phase, Epoch 3/20, Loss: 17.433668
Val Best Loss: 17.433668
Epoch loss: 17.433668
train phase, Epoch 4/20, Loss: 17.489878
val phase, Epoch 4/20, Loss: 16.886656
Val Best Loss: 16.886656
Epoch loss: 16.886656
train phase, Epoch 5/20, Loss: 17.358098
val phase, Epoch 5/20, Loss: 16.400803
Val Best Loss: 16.400803
Epoch loss: 16.400803
train phase, Epoch 6/20, Loss: 17.061663
val phase, Epoch 6/20, Loss: 17.793609
Val Best Loss: 16.400803
Epoch loss: 17.793609
train phase, Epoch 7/20, Loss: 16.924599
val phase, Epoch 7/20, Loss: 17.774704
Val Best Loss: 16.400803
Epoch loss: 17.774704
train phase, Epoch 8/20, Loss: 16.498438
val phase, Epoch 8/20, Loss: 16.765361
Val Best Loss: 16.400803
Epoch loss: 16.765361
train phase, Epoch 9/20, Loss: 16.819654
val phase, Epoch 9/20, Loss: 16.165101
Val Best Loss: 16.165101
Epoch loss: 16.165101
train phase, Epoch 10/20, Loss: 16.654909
val phase, Epoch 10/20, Loss: 16.814443
Val Best Loss: 16.165101
Epoch loss: 16.814443
train phase, Epoch 11/20, Loss: 16.394042
val phase, Epoch 11/20, Loss: 15.861462
Val Best Loss: 15.861462
Epoch loss: 15.861462
train phase, Epoch 12/20, Loss: 16.351821
val phase, Epoch 12/20, Loss: 16.134711
Val Best Loss: 15.861462
Epoch loss: 16.134711
train phase, Epoch 13/20, Loss: 15.898044
val phase, Epoch 13/20, Loss: 16.544260
Val Best Loss: 15.861462
Epoch loss: 16.544260
train phase, Epoch 14/20, Loss: 15.775490
val phase, Epoch 14/20, Loss: 15.858931
Val Best Loss: 15.858931
Epoch loss: 15.858931
train phase, Epoch 15/20, Loss: 15.857394
val phase, Epoch 15/20, Loss: 16.311132
Val Best Loss: 15.858931
Epoch loss: 16.311132
train phase, Epoch 16/20, Loss: 15.766998
val phase, Epoch 16/20, Loss: 16.434120
Val Best Loss: 15.858931
Epoch loss: 16.434120
train phase, Epoch 17/20, Loss: 15.273574
val phase, Epoch 17/20, Loss: 16.711529
Val Best Loss: 15.858931
Epoch loss: 16.711529
train phase, Epoch 18/20, Loss: 15.550624
val phase, Epoch 18/20, Loss: 15.890439
Val Best Loss: 15.858931
Epoch loss: 15.890439
train phase, Epoch 19/20, Loss: 14.976008
val phase, Epoch 19/20, Loss: 16.877065
Val Best Loss: 15.858931
Epoch loss: 16.877065
train phase, Epoch 20/20, Loss: 14.974115
val phase, Epoch 20/20, Loss: 16.707763
Val Best Loss: 15.858931
Epoch loss: 16.707763
[Trial 471] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.133527
val phase, Epoch 1/20, Loss: 17.455572
Val Best Loss: 17.455572
Epoch loss: 17.455572
train phase, Epoch 2/20, Loss: 17.981206
val phase, Epoch 2/20, Loss: 17.275559
Val Best Loss: 17.275559
Epoch loss: 17.275559
train phase, Epoch 3/20, Loss: 17.135144
val phase, Epoch 3/20, Loss: 16.617556
Val Best Loss: 16.617556
Epoch loss: 16.617556
train phase, Epoch 4/20, Loss: 16.846048
val phase, Epoch 4/20, Loss: 17.347853
Val Best Loss: 16.617556
Epoch loss: 17.347853
train phase, Epoch 5/20, Loss: 16.545653
val phase, Epoch 5/20, Loss: 15.969711
Val Best Loss: 15.969711
Epoch loss: 15.969711
train phase, Epoch 6/20, Loss: 16.383379
val phase, Epoch 6/20, Loss: 17.255475
Val Best Loss: 15.969711
Epoch loss: 17.255475
train phase, Epoch 7/20, Loss: 16.222034
val phase, Epoch 7/20, Loss: 16.469789
Val Best Loss: 15.969711
Epoch loss: 16.469789
train phase, Epoch 8/20, Loss: 16.000001
val phase, Epoch 8/20, Loss: 15.878926
Val Best Loss: 15.878926
Epoch loss: 15.878926
train phase, Epoch 9/20, Loss: 16.043832
val phase, Epoch 9/20, Loss: 15.969410
Val Best Loss: 15.878926
Epoch loss: 15.969410
train phase, Epoch 10/20, Loss: 15.839210
val phase, Epoch 10/20, Loss: 16.943761
Val Best Loss: 15.878926
Epoch loss: 16.943761
train phase, Epoch 11/20, Loss: 15.639091
val phase, Epoch 11/20, Loss: 15.916728
Val Best Loss: 15.878926
Epoch loss: 15.916728
train phase, Epoch 12/20, Loss: 15.441014
val phase, Epoch 12/20, Loss: 17.391592
Val Best Loss: 15.878926
Epoch loss: 17.391592
train phase, Epoch 13/20, Loss: 15.057025
val phase, Epoch 13/20, Loss: 16.674379
Val Best Loss: 15.878926
Epoch loss: 16.674379
train phase, Epoch 14/20, Loss: 14.941363
val phase, Epoch 14/20, Loss: 16.012388
Val Best Loss: 15.878926
Epoch loss: 16.012388
train phase, Epoch 15/20, Loss: 14.637991
val phase, Epoch 15/20, Loss: 16.395778
Val Best Loss: 15.878926
Epoch loss: 16.395778
train phase, Epoch 16/20, Loss: 14.551153
val phase, Epoch 16/20, Loss: 15.987117
Val Best Loss: 15.878926
Epoch loss: 15.987117
train phase, Epoch 17/20, Loss: 14.225228
val phase, Epoch 17/20, Loss: 16.206500
Val Best Loss: 15.878926
Epoch loss: 16.206500
train phase, Epoch 18/20, Loss: 13.681381
val phase, Epoch 18/20, Loss: 16.420058
Val Best Loss: 15.878926
Epoch loss: 16.420058
train phase, Epoch 19/20, Loss: 13.537070
val phase, Epoch 19/20, Loss: 16.657529
Val Best Loss: 15.878926
Epoch loss: 16.657529
train phase, Epoch 20/20, Loss: 13.202320
val phase, Epoch 20/20, Loss: 16.361470
Val Best Loss: 15.878926
Epoch loss: 16.361470
train phase, Epoch 1/20, Loss: 19.946927
val phase, Epoch 1/20, Loss: 17.554392
Val Best Loss: 17.554392
Epoch loss: 17.554392
train phase, Epoch 2/20, Loss: 18.354070
val phase, Epoch 2/20, Loss: 16.983272
Val Best Loss: 16.983272
Epoch loss: 16.983272
train phase, Epoch 3/20, Loss: 17.456570
val phase, Epoch 3/20, Loss: 16.491419
Val Best Loss: 16.491419
Epoch loss: 16.491419
train phase, Epoch 4/20, Loss: 17.100238
val phase, Epoch 4/20, Loss: 16.753214
Val Best Loss: 16.491419
Epoch loss: 16.753214
train phase, Epoch 5/20, Loss: 17.179202
val phase, Epoch 5/20, Loss: 16.935008
Val Best Loss: 16.491419
Epoch loss: 16.935008
train phase, Epoch 6/20, Loss: 16.760412
val phase, Epoch 6/20, Loss: 18.023659
Val Best Loss: 16.491419
Epoch loss: 18.023659
train phase, Epoch 7/20, Loss: 16.735287
val phase, Epoch 7/20, Loss: 16.590239
Val Best Loss: 16.491419
Epoch loss: 16.590239
train phase, Epoch 8/20, Loss: 16.362655
val phase, Epoch 8/20, Loss: 17.084677
Val Best Loss: 16.491419
Epoch loss: 17.084677
train phase, Epoch 9/20, Loss: 16.121210
val phase, Epoch 9/20, Loss: 16.291307
Val Best Loss: 16.291307
Epoch loss: 16.291307
train phase, Epoch 10/20, Loss: 16.004457
val phase, Epoch 10/20, Loss: 16.952494
Val Best Loss: 16.291307
Epoch loss: 16.952494
train phase, Epoch 11/20, Loss: 16.008947
val phase, Epoch 11/20, Loss: 15.821814
Val Best Loss: 15.821814
Epoch loss: 15.821814
train phase, Epoch 12/20, Loss: 15.617984
val phase, Epoch 12/20, Loss: 16.229931
Val Best Loss: 15.821814
Epoch loss: 16.229931
train phase, Epoch 13/20, Loss: 15.898046
val phase, Epoch 13/20, Loss: 17.025157
Val Best Loss: 15.821814
Epoch loss: 17.025157
train phase, Epoch 14/20, Loss: 15.390847
val phase, Epoch 14/20, Loss: 17.960206
Val Best Loss: 15.821814
Epoch loss: 17.960206
train phase, Epoch 15/20, Loss: 15.263331
val phase, Epoch 15/20, Loss: 16.257980
Val Best Loss: 15.821814
Epoch loss: 16.257980
train phase, Epoch 16/20, Loss: 15.170067
val phase, Epoch 16/20, Loss: 16.480600
Val Best Loss: 15.821814
Epoch loss: 16.480600
train phase, Epoch 17/20, Loss: 15.010883
val phase, Epoch 17/20, Loss: 16.561524
Val Best Loss: 15.821814
Epoch loss: 16.561524
train phase, Epoch 18/20, Loss: 14.971863
val phase, Epoch 18/20, Loss: 16.389199
Val Best Loss: 15.821814
Epoch loss: 16.389199
train phase, Epoch 19/20, Loss: 14.668767
val phase, Epoch 19/20, Loss: 16.445879
Val Best Loss: 15.821814
Epoch loss: 16.445879
train phase, Epoch 20/20, Loss: 14.361141
val phase, Epoch 20/20, Loss: 16.283657
Val Best Loss: 15.821814
Epoch loss: 16.283657
train phase, Epoch 1/20, Loss: 19.783110
val phase, Epoch 1/20, Loss: 19.063372
Val Best Loss: 19.063372
Epoch loss: 19.063372
train phase, Epoch 2/20, Loss: 18.219910
val phase, Epoch 2/20, Loss: 17.593708
Val Best Loss: 17.593708
Epoch loss: 17.593708
train phase, Epoch 3/20, Loss: 17.816881
val phase, Epoch 3/20, Loss: 18.884228
Val Best Loss: 17.593708
Epoch loss: 18.884228
train phase, Epoch 4/20, Loss: 17.658858
val phase, Epoch 4/20, Loss: 16.921446
Val Best Loss: 16.921446
Epoch loss: 16.921446
train phase, Epoch 5/20, Loss: 17.413250
val phase, Epoch 5/20, Loss: 16.670096
Val Best Loss: 16.670096
Epoch loss: 16.670096
train phase, Epoch 6/20, Loss: 16.786510
val phase, Epoch 6/20, Loss: 16.545522
Val Best Loss: 16.545522
Epoch loss: 16.545522
train phase, Epoch 7/20, Loss: 16.661926
val phase, Epoch 7/20, Loss: 16.584642
Val Best Loss: 16.545522
Epoch loss: 16.584642
train phase, Epoch 8/20, Loss: 16.586072
val phase, Epoch 8/20, Loss: 18.912803
Val Best Loss: 16.545522
Epoch loss: 18.912803
train phase, Epoch 9/20, Loss: 16.289922
val phase, Epoch 9/20, Loss: 18.136427
Val Best Loss: 16.545522
Epoch loss: 18.136427
train phase, Epoch 10/20, Loss: 16.113405
val phase, Epoch 10/20, Loss: 16.243867
Val Best Loss: 16.243867
Epoch loss: 16.243867
train phase, Epoch 11/20, Loss: 15.943682
val phase, Epoch 11/20, Loss: 16.727399
Val Best Loss: 16.243867
Epoch loss: 16.727399
train phase, Epoch 12/20, Loss: 16.189454
val phase, Epoch 12/20, Loss: 16.731844
Val Best Loss: 16.243867
Epoch loss: 16.731844
train phase, Epoch 13/20, Loss: 15.933861
val phase, Epoch 13/20, Loss: 15.828718
Val Best Loss: 15.828718
Epoch loss: 15.828718
train phase, Epoch 14/20, Loss: 15.874377
val phase, Epoch 14/20, Loss: 16.989653
Val Best Loss: 15.828718
Epoch loss: 16.989653
train phase, Epoch 15/20, Loss: 15.655101
val phase, Epoch 15/20, Loss: 16.309844
Val Best Loss: 15.828718
Epoch loss: 16.309844
train phase, Epoch 16/20, Loss: 15.535890
val phase, Epoch 16/20, Loss: 16.508989
Val Best Loss: 15.828718
Epoch loss: 16.508989
train phase, Epoch 17/20, Loss: 15.123064
val phase, Epoch 17/20, Loss: 16.150772
Val Best Loss: 15.828718
Epoch loss: 16.150772
train phase, Epoch 18/20, Loss: 15.139609
val phase, Epoch 18/20, Loss: 16.400624
Val Best Loss: 15.828718
Epoch loss: 16.400624
train phase, Epoch 19/20, Loss: 14.914526
val phase, Epoch 19/20, Loss: 15.958084
Val Best Loss: 15.828718
Epoch loss: 15.958084
train phase, Epoch 20/20, Loss: 14.849608
val phase, Epoch 20/20, Loss: 16.440252
Val Best Loss: 15.828718
Epoch loss: 16.440252
train phase, Epoch 1/30, Loss: 29.374215
val phase, Epoch 1/30, Loss: 19.627641
Val Best Loss: 19.627641
Epoch loss: 19.627641
train phase, Epoch 2/30, Loss: 19.067069
val phase, Epoch 2/30, Loss: 18.482011
Val Best Loss: 18.482011
Epoch loss: 18.482011
train phase, Epoch 3/30, Loss: 18.344583
val phase, Epoch 3/30, Loss: 19.661749
Val Best Loss: 18.482011
Epoch loss: 19.661749
train phase, Epoch 4/30, Loss: 18.166914
val phase, Epoch 4/30, Loss: 17.522366
Val Best Loss: 17.522366
Epoch loss: 17.522366
train phase, Epoch 5/30, Loss: 17.820290
val phase, Epoch 5/30, Loss: 21.885712
Val Best Loss: 17.522366
Epoch loss: 21.885712
train phase, Epoch 6/30, Loss: 17.559046
val phase, Epoch 6/30, Loss: 17.440543
Val Best Loss: 17.440543
Epoch loss: 17.440543
train phase, Epoch 7/30, Loss: 17.265941
val phase, Epoch 7/30, Loss: 26.362084
Val Best Loss: 17.440543
Epoch loss: 26.362084
train phase, Epoch 8/30, Loss: 17.393800
val phase, Epoch 8/30, Loss: 19.000699
Val Best Loss: 17.440543
Epoch loss: 19.000699
train phase, Epoch 9/30, Loss: 16.798122
val phase, Epoch 9/30, Loss: 17.496762
Val Best Loss: 17.440543
Epoch loss: 17.496762
train phase, Epoch 10/30, Loss: 16.524980
val phase, Epoch 10/30, Loss: 16.934662
Val Best Loss: 16.934662
Epoch loss: 16.934662
train phase, Epoch 11/30, Loss: 16.382233
val phase, Epoch 11/30, Loss: 16.854915
Val Best Loss: 16.854915
Epoch loss: 16.854915
train phase, Epoch 12/30, Loss: 16.529294
val phase, Epoch 12/30, Loss: 21.862040
Val Best Loss: 16.854915
Epoch loss: 21.862040
train phase, Epoch 13/30, Loss: 16.184272
val phase, Epoch 13/30, Loss: 17.616599
Val Best Loss: 16.854915
Epoch loss: 17.616599
train phase, Epoch 14/30, Loss: 16.132081
val phase, Epoch 14/30, Loss: 16.751984
Val Best Loss: 16.751984
Epoch loss: 16.751984
train phase, Epoch 15/30, Loss: 15.973083
val phase, Epoch 15/30, Loss: 17.673379
Val Best Loss: 16.751984
Epoch loss: 17.673379
train phase, Epoch 16/30, Loss: 15.764546
val phase, Epoch 16/30, Loss: 18.580563
Val Best Loss: 16.751984
Epoch loss: 18.580563
train phase, Epoch 17/30, Loss: 15.926405
val phase, Epoch 17/30, Loss: 18.244144
Val Best Loss: 16.751984
Epoch loss: 18.244144
train phase, Epoch 18/30, Loss: 15.441835
val phase, Epoch 18/30, Loss: 17.718982
Val Best Loss: 16.751984
Epoch loss: 17.718982
train phase, Epoch 19/30, Loss: 15.504583
val phase, Epoch 19/30, Loss: 17.003612
Val Best Loss: 16.751984
Epoch loss: 17.003612
train phase, Epoch 20/30, Loss: 15.116682
val phase, Epoch 20/30, Loss: 16.691707
Val Best Loss: 16.691707
Epoch loss: 16.691707
train phase, Epoch 21/30, Loss: 14.914402
val phase, Epoch 21/30, Loss: 17.315874
Val Best Loss: 16.691707
Epoch loss: 17.315874
train phase, Epoch 22/30, Loss: 14.799107
val phase, Epoch 22/30, Loss: 18.342558
Val Best Loss: 16.691707
Epoch loss: 18.342558
train phase, Epoch 23/30, Loss: 14.397686
val phase, Epoch 23/30, Loss: 18.693436
Val Best Loss: 16.691707
Epoch loss: 18.693436
train phase, Epoch 24/30, Loss: 14.094424
val phase, Epoch 24/30, Loss: 17.780624
Val Best Loss: 16.691707
Epoch loss: 17.780624
train phase, Epoch 25/30, Loss: 13.708829
val phase, Epoch 25/30, Loss: 18.422583
Val Best Loss: 16.691707
Epoch loss: 18.422583
train phase, Epoch 26/30, Loss: 13.218766
val phase, Epoch 26/30, Loss: 18.195648
Val Best Loss: 16.691707
Epoch loss: 18.195648
train phase, Epoch 27/30, Loss: 14.750673
val phase, Epoch 27/30, Loss: 17.782766
Val Best Loss: 16.691707
Epoch loss: 17.782766
train phase, Epoch 28/30, Loss: 12.998971
val phase, Epoch 28/30, Loss: 18.815134
Val Best Loss: 16.691707
Epoch loss: 18.815134
train phase, Epoch 29/30, Loss: 12.665740
val phase, Epoch 29/30, Loss: 18.543810
Val Best Loss: 16.691707
Epoch loss: 18.543810
train phase, Epoch 30/30, Loss: 11.871039
val phase, Epoch 30/30, Loss: 18.919547
Val Best Loss: 16.691707
Epoch loss: 18.919547
[Trial 476] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 20.070023
val phase, Epoch 1/20, Loss: 17.306319
Val Best Loss: 17.306319
Epoch loss: 17.306319
train phase, Epoch 2/20, Loss: 17.872694
val phase, Epoch 2/20, Loss: 16.872826
Val Best Loss: 16.872826
Epoch loss: 16.872826
train phase, Epoch 3/20, Loss: 17.454129
val phase, Epoch 3/20, Loss: 18.035156
Val Best Loss: 16.872826
Epoch loss: 18.035156
train phase, Epoch 4/20, Loss: 17.181639
val phase, Epoch 4/20, Loss: 16.737113
Val Best Loss: 16.737113
Epoch loss: 16.737113
train phase, Epoch 5/20, Loss: 17.395804
val phase, Epoch 5/20, Loss: 17.904593
Val Best Loss: 16.737113
Epoch loss: 17.904593
train phase, Epoch 6/20, Loss: 16.729546
val phase, Epoch 6/20, Loss: 16.438006
Val Best Loss: 16.438006
Epoch loss: 16.438006
train phase, Epoch 7/20, Loss: 16.502866
val phase, Epoch 7/20, Loss: 16.338300
Val Best Loss: 16.338300
Epoch loss: 16.338300
train phase, Epoch 8/20, Loss: 16.476406
val phase, Epoch 8/20, Loss: 16.788680
Val Best Loss: 16.338300
Epoch loss: 16.788680
train phase, Epoch 9/20, Loss: 16.194822
val phase, Epoch 9/20, Loss: 16.479915
Val Best Loss: 16.338300
Epoch loss: 16.479915
train phase, Epoch 10/20, Loss: 16.161226
val phase, Epoch 10/20, Loss: 16.109126
Val Best Loss: 16.109126
Epoch loss: 16.109126
train phase, Epoch 11/20, Loss: 15.838641
val phase, Epoch 11/20, Loss: 17.235592
Val Best Loss: 16.109126
Epoch loss: 17.235592
train phase, Epoch 12/20, Loss: 15.775016
val phase, Epoch 12/20, Loss: 16.804639
Val Best Loss: 16.109126
Epoch loss: 16.804639
train phase, Epoch 13/20, Loss: 15.653684
val phase, Epoch 13/20, Loss: 17.534902
Val Best Loss: 16.109126
Epoch loss: 17.534902
train phase, Epoch 14/20, Loss: 15.411114
val phase, Epoch 14/20, Loss: 16.642090
Val Best Loss: 16.109126
Epoch loss: 16.642090
train phase, Epoch 15/20, Loss: 15.326037
val phase, Epoch 15/20, Loss: 17.849401
Val Best Loss: 16.109126
Epoch loss: 17.849401
train phase, Epoch 16/20, Loss: 15.445349
val phase, Epoch 16/20, Loss: 15.984288
Val Best Loss: 15.984288
Epoch loss: 15.984288
train phase, Epoch 17/20, Loss: 14.963915
val phase, Epoch 17/20, Loss: 16.228047
Val Best Loss: 15.984288
Epoch loss: 16.228047
train phase, Epoch 18/20, Loss: 14.669018
val phase, Epoch 18/20, Loss: 16.793456
Val Best Loss: 15.984288
Epoch loss: 16.793456
train phase, Epoch 19/20, Loss: 14.425185
val phase, Epoch 19/20, Loss: 16.397750
Val Best Loss: 15.984288
Epoch loss: 16.397750
train phase, Epoch 20/20, Loss: 14.551737
val phase, Epoch 20/20, Loss: 16.924910
Val Best Loss: 15.984288
Epoch loss: 16.924910
train phase, Epoch 1/20, Loss: 20.621608
val phase, Epoch 1/20, Loss: 18.917229
Val Best Loss: 18.917229
Epoch loss: 18.917229
train phase, Epoch 2/20, Loss: 18.415967
val phase, Epoch 2/20, Loss: 18.138347
Val Best Loss: 18.138347
Epoch loss: 18.138347
train phase, Epoch 3/20, Loss: 18.157294
val phase, Epoch 3/20, Loss: 18.707008
Val Best Loss: 18.138347
Epoch loss: 18.707008
train phase, Epoch 4/20, Loss: 17.492729
val phase, Epoch 4/20, Loss: 18.203771
Val Best Loss: 18.138347
Epoch loss: 18.203771
train phase, Epoch 5/20, Loss: 17.450019
val phase, Epoch 5/20, Loss: 17.849359
Val Best Loss: 17.849359
Epoch loss: 17.849359
train phase, Epoch 6/20, Loss: 17.192653
val phase, Epoch 6/20, Loss: 19.000798
Val Best Loss: 17.849359
Epoch loss: 19.000798
train phase, Epoch 7/20, Loss: 17.102711
val phase, Epoch 7/20, Loss: 16.529421
Val Best Loss: 16.529421
Epoch loss: 16.529421
train phase, Epoch 8/20, Loss: 16.699576
val phase, Epoch 8/20, Loss: 16.618449
Val Best Loss: 16.529421
Epoch loss: 16.618449
train phase, Epoch 9/20, Loss: 16.530749
val phase, Epoch 9/20, Loss: 16.520443
Val Best Loss: 16.520443
Epoch loss: 16.520443
train phase, Epoch 10/20, Loss: 16.548235
val phase, Epoch 10/20, Loss: 17.219014
Val Best Loss: 16.520443
Epoch loss: 17.219014
train phase, Epoch 11/20, Loss: 16.061781
val phase, Epoch 11/20, Loss: 17.046142
Val Best Loss: 16.520443
Epoch loss: 17.046142
train phase, Epoch 12/20, Loss: 16.197527
val phase, Epoch 12/20, Loss: 16.573546
Val Best Loss: 16.520443
Epoch loss: 16.573546
train phase, Epoch 13/20, Loss: 15.886205
val phase, Epoch 13/20, Loss: 16.959186
Val Best Loss: 16.520443
Epoch loss: 16.959186
train phase, Epoch 14/20, Loss: 15.473327
val phase, Epoch 14/20, Loss: 17.442240
Val Best Loss: 16.520443
Epoch loss: 17.442240
train phase, Epoch 15/20, Loss: 15.586243
val phase, Epoch 15/20, Loss: 16.479921
Val Best Loss: 16.479921
Epoch loss: 16.479921
train phase, Epoch 16/20, Loss: 15.215235
val phase, Epoch 16/20, Loss: 16.438405
Val Best Loss: 16.438405
Epoch loss: 16.438405
train phase, Epoch 17/20, Loss: 14.930073
val phase, Epoch 17/20, Loss: 16.334115
Val Best Loss: 16.334115
Epoch loss: 16.334115
train phase, Epoch 18/20, Loss: 14.492518
val phase, Epoch 18/20, Loss: 16.686913
Val Best Loss: 16.334115
Epoch loss: 16.686913
train phase, Epoch 19/20, Loss: 14.305091
val phase, Epoch 19/20, Loss: 16.720174
Val Best Loss: 16.334115
Epoch loss: 16.720174
train phase, Epoch 20/20, Loss: 14.158766
val phase, Epoch 20/20, Loss: 17.235013
Val Best Loss: 16.334115
Epoch loss: 17.235013
[Trial 479] Skipped due to model construction error: Given input size: (32x10x2). Calculated output size: (32x3x0). Output size is too small
train phase, Epoch 1/30, Loss: 20.069066
val phase, Epoch 1/30, Loss: 19.289006
Val Best Loss: 19.289006
Epoch loss: 19.289006
train phase, Epoch 2/30, Loss: 18.094917
val phase, Epoch 2/30, Loss: 16.538351
Val Best Loss: 16.538351
Epoch loss: 16.538351
train phase, Epoch 3/30, Loss: 17.446892
val phase, Epoch 3/30, Loss: 21.832544
Val Best Loss: 16.538351
Epoch loss: 21.832544
train phase, Epoch 4/30, Loss: 16.915213
val phase, Epoch 4/30, Loss: 16.900106
Val Best Loss: 16.538351
Epoch loss: 16.900106
train phase, Epoch 5/30, Loss: 16.722056
val phase, Epoch 5/30, Loss: 16.905708
Val Best Loss: 16.538351
Epoch loss: 16.905708
train phase, Epoch 6/30, Loss: 16.835624
val phase, Epoch 6/30, Loss: 18.565862
Val Best Loss: 16.538351
Epoch loss: 18.565862
train phase, Epoch 7/30, Loss: 16.226866
val phase, Epoch 7/30, Loss: 17.293922
Val Best Loss: 16.538351
Epoch loss: 17.293922
train phase, Epoch 8/30, Loss: 16.191322
val phase, Epoch 8/30, Loss: 15.839469
Val Best Loss: 15.839469
Epoch loss: 15.839469
train phase, Epoch 9/30, Loss: 16.118334
val phase, Epoch 9/30, Loss: 17.040002
Val Best Loss: 15.839469
Epoch loss: 17.040002
train phase, Epoch 10/30, Loss: 15.646163
val phase, Epoch 10/30, Loss: 16.148396
Val Best Loss: 15.839469
Epoch loss: 16.148396
train phase, Epoch 11/30, Loss: 15.603214
val phase, Epoch 11/30, Loss: 15.895308
Val Best Loss: 15.839469
Epoch loss: 15.895308
train phase, Epoch 12/30, Loss: 15.407049
val phase, Epoch 12/30, Loss: 15.982536
Val Best Loss: 15.839469
Epoch loss: 15.982536
train phase, Epoch 13/30, Loss: 15.155415
val phase, Epoch 13/30, Loss: 15.892145
Val Best Loss: 15.839469
Epoch loss: 15.892145
train phase, Epoch 14/30, Loss: 14.860238
val phase, Epoch 14/30, Loss: 16.043070
Val Best Loss: 15.839469
Epoch loss: 16.043070
train phase, Epoch 15/30, Loss: 14.871003
val phase, Epoch 15/30, Loss: 16.442244
Val Best Loss: 15.839469
Epoch loss: 16.442244
train phase, Epoch 16/30, Loss: 14.620379
val phase, Epoch 16/30, Loss: 16.599251
Val Best Loss: 15.839469
Epoch loss: 16.599251
train phase, Epoch 17/30, Loss: 14.105854
val phase, Epoch 17/30, Loss: 16.507819
Val Best Loss: 15.839469
Epoch loss: 16.507819
train phase, Epoch 18/30, Loss: 13.979471
val phase, Epoch 18/30, Loss: 16.914488
Val Best Loss: 15.839469
Epoch loss: 16.914488
train phase, Epoch 19/30, Loss: 13.614118
val phase, Epoch 19/30, Loss: 18.175918
Val Best Loss: 15.839469
Epoch loss: 18.175918
train phase, Epoch 20/30, Loss: 13.461010
val phase, Epoch 20/30, Loss: 16.719044
Val Best Loss: 15.839469
Epoch loss: 16.719044
train phase, Epoch 21/30, Loss: 13.090775
val phase, Epoch 21/30, Loss: 17.287377
Val Best Loss: 15.839469
Epoch loss: 17.287377
train phase, Epoch 22/30, Loss: 12.546000
val phase, Epoch 22/30, Loss: 17.503369
Val Best Loss: 15.839469
Epoch loss: 17.503369
train phase, Epoch 23/30, Loss: 12.227955
val phase, Epoch 23/30, Loss: 17.802239
Val Best Loss: 15.839469
Epoch loss: 17.802239
train phase, Epoch 24/30, Loss: 11.611863
val phase, Epoch 24/30, Loss: 18.749197
Val Best Loss: 15.839469
Epoch loss: 18.749197
train phase, Epoch 25/30, Loss: 11.175049
val phase, Epoch 25/30, Loss: 18.965067
Val Best Loss: 15.839469
Epoch loss: 18.965067
train phase, Epoch 26/30, Loss: 10.910990
val phase, Epoch 26/30, Loss: 21.713833
Val Best Loss: 15.839469
Epoch loss: 21.713833
train phase, Epoch 27/30, Loss: 10.400221
val phase, Epoch 27/30, Loss: 18.348597
Val Best Loss: 15.839469
Epoch loss: 18.348597
train phase, Epoch 28/30, Loss: 9.617927
val phase, Epoch 28/30, Loss: 20.353179
Val Best Loss: 15.839469
Epoch loss: 20.353179
train phase, Epoch 29/30, Loss: 9.624436
val phase, Epoch 29/30, Loss: 19.544313
Val Best Loss: 15.839469
Epoch loss: 19.544313
train phase, Epoch 30/30, Loss: 8.993576
val phase, Epoch 30/30, Loss: 19.408169
Val Best Loss: 15.839469
Epoch loss: 19.408169
train phase, Epoch 1/20, Loss: 19.814834
val phase, Epoch 1/20, Loss: 21.907160
Val Best Loss: 21.907160
Epoch loss: 21.907160
train phase, Epoch 2/20, Loss: 17.766321
val phase, Epoch 2/20, Loss: 22.301883
Val Best Loss: 21.907160
Epoch loss: 22.301883
train phase, Epoch 3/20, Loss: 17.117904
val phase, Epoch 3/20, Loss: 19.874421
Val Best Loss: 19.874421
Epoch loss: 19.874421
train phase, Epoch 4/20, Loss: 17.069235
val phase, Epoch 4/20, Loss: 17.619365
Val Best Loss: 17.619365
Epoch loss: 17.619365
train phase, Epoch 5/20, Loss: 16.540305
val phase, Epoch 5/20, Loss: 16.778933
Val Best Loss: 16.778933
Epoch loss: 16.778933
train phase, Epoch 6/20, Loss: 16.516090
val phase, Epoch 6/20, Loss: 17.152001
Val Best Loss: 16.778933
Epoch loss: 17.152001
train phase, Epoch 7/20, Loss: 16.626183
val phase, Epoch 7/20, Loss: 16.079106
Val Best Loss: 16.079106
Epoch loss: 16.079106
train phase, Epoch 8/20, Loss: 16.264255
val phase, Epoch 8/20, Loss: 16.828875
Val Best Loss: 16.079106
Epoch loss: 16.828875
train phase, Epoch 9/20, Loss: 16.200619
val phase, Epoch 9/20, Loss: 16.135917
Val Best Loss: 16.079106
Epoch loss: 16.135917
train phase, Epoch 10/20, Loss: 15.857055
val phase, Epoch 10/20, Loss: 17.032453
Val Best Loss: 16.079106
Epoch loss: 17.032453
train phase, Epoch 11/20, Loss: 15.694165
val phase, Epoch 11/20, Loss: 15.976290
Val Best Loss: 15.976290
Epoch loss: 15.976290
train phase, Epoch 12/20, Loss: 15.552666
val phase, Epoch 12/20, Loss: 16.082451
Val Best Loss: 15.976290
Epoch loss: 16.082451
train phase, Epoch 13/20, Loss: 15.356585
val phase, Epoch 13/20, Loss: 16.587359
Val Best Loss: 15.976290
Epoch loss: 16.587359
train phase, Epoch 14/20, Loss: 15.180020
val phase, Epoch 14/20, Loss: 15.877670
Val Best Loss: 15.877670
Epoch loss: 15.877670
train phase, Epoch 15/20, Loss: 14.956919
val phase, Epoch 15/20, Loss: 16.056778
Val Best Loss: 15.877670
Epoch loss: 16.056778
train phase, Epoch 16/20, Loss: 14.688322
val phase, Epoch 16/20, Loss: 16.184853
Val Best Loss: 15.877670
Epoch loss: 16.184853
train phase, Epoch 17/20, Loss: 14.683329
val phase, Epoch 17/20, Loss: 16.678657
Val Best Loss: 15.877670
Epoch loss: 16.678657
train phase, Epoch 18/20, Loss: 14.205409
val phase, Epoch 18/20, Loss: 17.669613
Val Best Loss: 15.877670
Epoch loss: 17.669613
train phase, Epoch 19/20, Loss: 13.944339
val phase, Epoch 19/20, Loss: 16.448331
Val Best Loss: 15.877670
Epoch loss: 16.448331
train phase, Epoch 20/20, Loss: 13.735382
val phase, Epoch 20/20, Loss: 17.917991
Val Best Loss: 15.877670
Epoch loss: 17.917991
train phase, Epoch 1/20, Loss: 20.652369
val phase, Epoch 1/20, Loss: 25.777508
Val Best Loss: 25.777508
Epoch loss: 25.777508
train phase, Epoch 2/20, Loss: 17.406333
val phase, Epoch 2/20, Loss: 32.169711
Val Best Loss: 25.777508
Epoch loss: 32.169711
train phase, Epoch 3/20, Loss: 17.161026
val phase, Epoch 3/20, Loss: 39.618653
Val Best Loss: 25.777508
Epoch loss: 39.618653
train phase, Epoch 4/20, Loss: 16.845388
val phase, Epoch 4/20, Loss: 37.088482
Val Best Loss: 25.777508
Epoch loss: 37.088482
train phase, Epoch 5/20, Loss: 16.609286
val phase, Epoch 5/20, Loss: 41.522884
Val Best Loss: 25.777508
Epoch loss: 41.522884
train phase, Epoch 6/20, Loss: 16.472457
val phase, Epoch 6/20, Loss: 37.106208
Val Best Loss: 25.777508
Epoch loss: 37.106208
train phase, Epoch 7/20, Loss: 16.397651
val phase, Epoch 7/20, Loss: 34.405216
Val Best Loss: 25.777508
Epoch loss: 34.405216
train phase, Epoch 8/20, Loss: 15.832868
val phase, Epoch 8/20, Loss: 44.571670
Val Best Loss: 25.777508
Epoch loss: 44.571670
train phase, Epoch 9/20, Loss: 15.886007
val phase, Epoch 9/20, Loss: 38.139396
Val Best Loss: 25.777508
Epoch loss: 38.139396
train phase, Epoch 10/20, Loss: 15.845513
val phase, Epoch 10/20, Loss: 42.005611
Val Best Loss: 25.777508
Epoch loss: 42.005611
train phase, Epoch 11/20, Loss: 15.389278
val phase, Epoch 11/20, Loss: 51.106173
Val Best Loss: 25.777508
Epoch loss: 51.106173
train phase, Epoch 12/20, Loss: 15.395559
val phase, Epoch 12/20, Loss: 40.384307
Val Best Loss: 25.777508
Epoch loss: 40.384307
train phase, Epoch 13/20, Loss: 15.201996
val phase, Epoch 13/20, Loss: 47.828870
Val Best Loss: 25.777508
Epoch loss: 47.828870
train phase, Epoch 14/20, Loss: 14.992843
val phase, Epoch 14/20, Loss: 41.029325
Val Best Loss: 25.777508
Epoch loss: 41.029325
train phase, Epoch 15/20, Loss: 14.869797
val phase, Epoch 15/20, Loss: 53.279294
Val Best Loss: 25.777508
Epoch loss: 53.279294
train phase, Epoch 16/20, Loss: 14.435030
val phase, Epoch 16/20, Loss: 48.483221
Val Best Loss: 25.777508
Epoch loss: 48.483221
train phase, Epoch 17/20, Loss: 14.383222
val phase, Epoch 17/20, Loss: 53.941547
Val Best Loss: 25.777508
Epoch loss: 53.941547
train phase, Epoch 18/20, Loss: 13.990278
val phase, Epoch 18/20, Loss: 40.814067
Val Best Loss: 25.777508
Epoch loss: 40.814067
train phase, Epoch 19/20, Loss: 13.785337
val phase, Epoch 19/20, Loss: 45.230237
Val Best Loss: 25.777508
Epoch loss: 45.230237
train phase, Epoch 20/20, Loss: 13.351674
val phase, Epoch 20/20, Loss: 54.629224
Val Best Loss: 25.777508
Epoch loss: 54.629224
train phase, Epoch 1/20, Loss: 19.725569
val phase, Epoch 1/20, Loss: 18.882658
Val Best Loss: 18.882658
Epoch loss: 18.882658
train phase, Epoch 2/20, Loss: 18.112185
val phase, Epoch 2/20, Loss: 17.498762
Val Best Loss: 17.498762
Epoch loss: 17.498762
train phase, Epoch 3/20, Loss: 17.707705
val phase, Epoch 3/20, Loss: 16.621152
Val Best Loss: 16.621152
Epoch loss: 16.621152
train phase, Epoch 4/20, Loss: 17.623864
val phase, Epoch 4/20, Loss: 16.726172
Val Best Loss: 16.621152
Epoch loss: 16.726172
train phase, Epoch 5/20, Loss: 17.031471
val phase, Epoch 5/20, Loss: 17.123024
Val Best Loss: 16.621152
Epoch loss: 17.123024
train phase, Epoch 6/20, Loss: 17.201304
val phase, Epoch 6/20, Loss: 17.031056
Val Best Loss: 16.621152
Epoch loss: 17.031056
train phase, Epoch 7/20, Loss: 16.640711
val phase, Epoch 7/20, Loss: 16.703764
Val Best Loss: 16.621152
Epoch loss: 16.703764
train phase, Epoch 8/20, Loss: 16.454355
val phase, Epoch 8/20, Loss: 16.355612
Val Best Loss: 16.355612
Epoch loss: 16.355612
train phase, Epoch 9/20, Loss: 16.237633
val phase, Epoch 9/20, Loss: 16.704892
Val Best Loss: 16.355612
Epoch loss: 16.704892
train phase, Epoch 10/20, Loss: 16.226445
val phase, Epoch 10/20, Loss: 17.118302
Val Best Loss: 16.355612
Epoch loss: 17.118302
train phase, Epoch 11/20, Loss: 16.049558
val phase, Epoch 11/20, Loss: 16.233495
Val Best Loss: 16.233495
Epoch loss: 16.233495
train phase, Epoch 12/20, Loss: 15.693639
val phase, Epoch 12/20, Loss: 16.519561
Val Best Loss: 16.233495
Epoch loss: 16.519561
train phase, Epoch 13/20, Loss: 15.383941
val phase, Epoch 13/20, Loss: 17.727312
Val Best Loss: 16.233495
Epoch loss: 17.727312
train phase, Epoch 14/20, Loss: 15.320197
val phase, Epoch 14/20, Loss: 16.171866
Val Best Loss: 16.171866
Epoch loss: 16.171866
train phase, Epoch 15/20, Loss: 15.006984
val phase, Epoch 15/20, Loss: 16.088222
Val Best Loss: 16.088222
Epoch loss: 16.088222
train phase, Epoch 16/20, Loss: 14.714971
val phase, Epoch 16/20, Loss: 16.403140
Val Best Loss: 16.088222
Epoch loss: 16.403140
train phase, Epoch 17/20, Loss: 14.457202
val phase, Epoch 17/20, Loss: 16.064589
Val Best Loss: 16.064589
Epoch loss: 16.064589
train phase, Epoch 18/20, Loss: 14.327251
val phase, Epoch 18/20, Loss: 18.224867
Val Best Loss: 16.064589
Epoch loss: 18.224867
train phase, Epoch 19/20, Loss: 14.003080
val phase, Epoch 19/20, Loss: 16.485209
Val Best Loss: 16.064589
Epoch loss: 16.485209
train phase, Epoch 20/20, Loss: 13.745431
val phase, Epoch 20/20, Loss: 16.314882
Val Best Loss: 16.064589
Epoch loss: 16.314882
train phase, Epoch 1/15, Loss: 20.092857
val phase, Epoch 1/15, Loss: 17.494722
Val Best Loss: 17.494722
Epoch loss: 17.494722
train phase, Epoch 2/15, Loss: 18.105169
val phase, Epoch 2/15, Loss: 17.483139
Val Best Loss: 17.483139
Epoch loss: 17.483139
train phase, Epoch 3/15, Loss: 17.542982
val phase, Epoch 3/15, Loss: 17.493085
Val Best Loss: 17.483139
Epoch loss: 17.493085
train phase, Epoch 4/15, Loss: 17.721266
val phase, Epoch 4/15, Loss: 17.845178
Val Best Loss: 17.483139
Epoch loss: 17.845178
train phase, Epoch 5/15, Loss: 17.302591
val phase, Epoch 5/15, Loss: 17.519714
Val Best Loss: 17.483139
Epoch loss: 17.519714
train phase, Epoch 6/15, Loss: 17.057908
val phase, Epoch 6/15, Loss: 17.724828
Val Best Loss: 17.483139
Epoch loss: 17.724828
train phase, Epoch 7/15, Loss: 16.682845
val phase, Epoch 7/15, Loss: 16.609040
Val Best Loss: 16.609040
Epoch loss: 16.609040
train phase, Epoch 8/15, Loss: 16.722394
val phase, Epoch 8/15, Loss: 17.815537
Val Best Loss: 16.609040
Epoch loss: 17.815537
train phase, Epoch 9/15, Loss: 16.650132
val phase, Epoch 9/15, Loss: 16.377567
Val Best Loss: 16.377567
Epoch loss: 16.377567
train phase, Epoch 10/15, Loss: 16.655698
val phase, Epoch 10/15, Loss: 17.745895
Val Best Loss: 16.377567
Epoch loss: 17.745895
train phase, Epoch 11/15, Loss: 16.453299
val phase, Epoch 11/15, Loss: 16.175419
Val Best Loss: 16.175419
Epoch loss: 16.175419
train phase, Epoch 12/15, Loss: 16.289347
val phase, Epoch 12/15, Loss: 17.690837
Val Best Loss: 16.175419
Epoch loss: 17.690837
train phase, Epoch 13/15, Loss: 16.026359
val phase, Epoch 13/15, Loss: 16.169842
Val Best Loss: 16.169842
Epoch loss: 16.169842
train phase, Epoch 14/15, Loss: 15.934390
val phase, Epoch 14/15, Loss: 17.199950
Val Best Loss: 16.169842
Epoch loss: 17.199950
train phase, Epoch 15/15, Loss: 15.827570
val phase, Epoch 15/15, Loss: 16.538072
Val Best Loss: 16.169842
Epoch loss: 16.538072
train phase, Epoch 1/30, Loss: 21.059374
val phase, Epoch 1/30, Loss: 18.867918
Val Best Loss: 18.867918
Epoch loss: 18.867918
train phase, Epoch 2/30, Loss: 18.178434
val phase, Epoch 2/30, Loss: 17.876392
Val Best Loss: 17.876392
Epoch loss: 17.876392
train phase, Epoch 3/30, Loss: 17.810600
val phase, Epoch 3/30, Loss: 16.860355
Val Best Loss: 16.860355
Epoch loss: 16.860355
train phase, Epoch 4/30, Loss: 17.366228
val phase, Epoch 4/30, Loss: 16.661042
Val Best Loss: 16.661042
Epoch loss: 16.661042
train phase, Epoch 5/30, Loss: 16.927923
val phase, Epoch 5/30, Loss: 17.074356
Val Best Loss: 16.661042
Epoch loss: 17.074356
train phase, Epoch 6/30, Loss: 17.022304
val phase, Epoch 6/30, Loss: 16.210473
Val Best Loss: 16.210473
Epoch loss: 16.210473
train phase, Epoch 7/30, Loss: 16.608417
val phase, Epoch 7/30, Loss: 17.525433
Val Best Loss: 16.210473
Epoch loss: 17.525433
train phase, Epoch 8/30, Loss: 16.776751
val phase, Epoch 8/30, Loss: 16.323884
Val Best Loss: 16.210473
Epoch loss: 16.323884
train phase, Epoch 9/30, Loss: 16.470278
val phase, Epoch 9/30, Loss: 17.770336
Val Best Loss: 16.210473
Epoch loss: 17.770336
train phase, Epoch 10/30, Loss: 16.284626
val phase, Epoch 10/30, Loss: 17.069134
Val Best Loss: 16.210473
Epoch loss: 17.069134
train phase, Epoch 11/30, Loss: 16.016325
val phase, Epoch 11/30, Loss: 16.220868
Val Best Loss: 16.210473
Epoch loss: 16.220868
train phase, Epoch 12/30, Loss: 15.971329
val phase, Epoch 12/30, Loss: 16.191836
Val Best Loss: 16.191836
Epoch loss: 16.191836
train phase, Epoch 13/30, Loss: 15.794471
val phase, Epoch 13/30, Loss: 16.194417
Val Best Loss: 16.191836
Epoch loss: 16.194417
train phase, Epoch 14/30, Loss: 15.592275
val phase, Epoch 14/30, Loss: 16.165780
Val Best Loss: 16.165780
Epoch loss: 16.165780
train phase, Epoch 15/30, Loss: 15.488297
val phase, Epoch 15/30, Loss: 16.750789
Val Best Loss: 16.165780
Epoch loss: 16.750789
train phase, Epoch 16/30, Loss: 15.232539
val phase, Epoch 16/30, Loss: 16.127212
Val Best Loss: 16.127212
Epoch loss: 16.127212
train phase, Epoch 17/30, Loss: 15.158625
val phase, Epoch 17/30, Loss: 15.852743
Val Best Loss: 15.852743
Epoch loss: 15.852743
train phase, Epoch 18/30, Loss: 15.155890
val phase, Epoch 18/30, Loss: 18.838300
Val Best Loss: 15.852743
Epoch loss: 18.838300
train phase, Epoch 19/30, Loss: 14.804508
val phase, Epoch 19/30, Loss: 17.386889
Val Best Loss: 15.852743
Epoch loss: 17.386889
train phase, Epoch 20/30, Loss: 14.817214
val phase, Epoch 20/30, Loss: 16.047964
Val Best Loss: 15.852743
Epoch loss: 16.047964
train phase, Epoch 21/30, Loss: 14.356991
val phase, Epoch 21/30, Loss: 16.608514
Val Best Loss: 15.852743
Epoch loss: 16.608514
train phase, Epoch 22/30, Loss: 14.052887
val phase, Epoch 22/30, Loss: 16.296801
Val Best Loss: 15.852743
Epoch loss: 16.296801
train phase, Epoch 23/30, Loss: 14.139568
val phase, Epoch 23/30, Loss: 18.623614
Val Best Loss: 15.852743
Epoch loss: 18.623614
train phase, Epoch 24/30, Loss: 13.690490
val phase, Epoch 24/30, Loss: 16.357412
Val Best Loss: 15.852743
Epoch loss: 16.357412
train phase, Epoch 25/30, Loss: 13.523221
val phase, Epoch 25/30, Loss: 16.164623
Val Best Loss: 15.852743
Epoch loss: 16.164623
train phase, Epoch 26/30, Loss: 13.100433
val phase, Epoch 26/30, Loss: 16.589243
Val Best Loss: 15.852743
Epoch loss: 16.589243
train phase, Epoch 27/30, Loss: 12.776994
val phase, Epoch 27/30, Loss: 18.317961
Val Best Loss: 15.852743
Epoch loss: 18.317961
train phase, Epoch 28/30, Loss: 12.608945
val phase, Epoch 28/30, Loss: 17.054781
Val Best Loss: 15.852743
Epoch loss: 17.054781
train phase, Epoch 29/30, Loss: 12.151544
val phase, Epoch 29/30, Loss: 17.230223
Val Best Loss: 15.852743
Epoch loss: 17.230223
train phase, Epoch 30/30, Loss: 12.051790
val phase, Epoch 30/30, Loss: 17.839795
Val Best Loss: 15.852743
Epoch loss: 17.839795
train phase, Epoch 1/20, Loss: 20.149853
val phase, Epoch 1/20, Loss: 18.027981
Val Best Loss: 18.027981
Epoch loss: 18.027981
train phase, Epoch 2/20, Loss: 17.741230
val phase, Epoch 2/20, Loss: 16.673132
Val Best Loss: 16.673132
Epoch loss: 16.673132
train phase, Epoch 3/20, Loss: 17.575941
val phase, Epoch 3/20, Loss: 17.021968
Val Best Loss: 16.673132
Epoch loss: 17.021968
train phase, Epoch 4/20, Loss: 17.250497
val phase, Epoch 4/20, Loss: 16.575225
Val Best Loss: 16.575225
Epoch loss: 16.575225
train phase, Epoch 5/20, Loss: 16.922732
val phase, Epoch 5/20, Loss: 16.278466
Val Best Loss: 16.278466
Epoch loss: 16.278466
train phase, Epoch 6/20, Loss: 16.848129
val phase, Epoch 6/20, Loss: 17.050109
Val Best Loss: 16.278466
Epoch loss: 17.050109
train phase, Epoch 7/20, Loss: 16.480930
val phase, Epoch 7/20, Loss: 16.779693
Val Best Loss: 16.278466
Epoch loss: 16.779693
train phase, Epoch 8/20, Loss: 16.662797
val phase, Epoch 8/20, Loss: 16.092575
Val Best Loss: 16.092575
Epoch loss: 16.092575
train phase, Epoch 9/20, Loss: 16.179210
val phase, Epoch 9/20, Loss: 16.530860
Val Best Loss: 16.092575
Epoch loss: 16.530860
train phase, Epoch 10/20, Loss: 15.852663
val phase, Epoch 10/20, Loss: 16.399337
Val Best Loss: 16.092575
Epoch loss: 16.399337
train phase, Epoch 11/20, Loss: 15.820169
val phase, Epoch 11/20, Loss: 15.876702
Val Best Loss: 15.876702
Epoch loss: 15.876702
train phase, Epoch 12/20, Loss: 15.830498
val phase, Epoch 12/20, Loss: 16.158424
Val Best Loss: 15.876702
Epoch loss: 16.158424
train phase, Epoch 13/20, Loss: 15.514284
val phase, Epoch 13/20, Loss: 15.684022
Val Best Loss: 15.684022
Epoch loss: 15.684022
train phase, Epoch 14/20, Loss: 15.164924
val phase, Epoch 14/20, Loss: 16.425016
Val Best Loss: 15.684022
Epoch loss: 16.425016
train phase, Epoch 15/20, Loss: 14.988666
val phase, Epoch 15/20, Loss: 16.623249
Val Best Loss: 15.684022
Epoch loss: 16.623249
train phase, Epoch 16/20, Loss: 14.878202
val phase, Epoch 16/20, Loss: 16.768184
Val Best Loss: 15.684022
Epoch loss: 16.768184
train phase, Epoch 17/20, Loss: 14.619406
val phase, Epoch 17/20, Loss: 15.899693
Val Best Loss: 15.684022
Epoch loss: 15.899693
train phase, Epoch 18/20, Loss: 14.360336
val phase, Epoch 18/20, Loss: 16.990758
Val Best Loss: 15.684022
Epoch loss: 16.990758
train phase, Epoch 19/20, Loss: 14.123233
val phase, Epoch 19/20, Loss: 16.433987
Val Best Loss: 15.684022
Epoch loss: 16.433987
train phase, Epoch 20/20, Loss: 13.846142
val phase, Epoch 20/20, Loss: 17.157177
Val Best Loss: 15.684022
Epoch loss: 17.157177
train phase, Epoch 1/25, Loss: 20.138930
val phase, Epoch 1/25, Loss: 17.086413
Val Best Loss: 17.086413
Epoch loss: 17.086413
train phase, Epoch 2/25, Loss: 17.632878
val phase, Epoch 2/25, Loss: 17.235476
Val Best Loss: 17.086413
Epoch loss: 17.235476
train phase, Epoch 3/25, Loss: 17.314203
val phase, Epoch 3/25, Loss: 18.681977
Val Best Loss: 17.086413
Epoch loss: 18.681977
train phase, Epoch 4/25, Loss: 16.704866
val phase, Epoch 4/25, Loss: 17.380270
Val Best Loss: 17.086413
Epoch loss: 17.380270
train phase, Epoch 5/25, Loss: 16.766816
val phase, Epoch 5/25, Loss: 16.925113
Val Best Loss: 16.925113
Epoch loss: 16.925113
train phase, Epoch 6/25, Loss: 16.432170
val phase, Epoch 6/25, Loss: 16.083939
Val Best Loss: 16.083939
Epoch loss: 16.083939
train phase, Epoch 7/25, Loss: 16.332761
val phase, Epoch 7/25, Loss: 15.962309
Val Best Loss: 15.962309
Epoch loss: 15.962309
train phase, Epoch 8/25, Loss: 16.021343
val phase, Epoch 8/25, Loss: 16.118383
Val Best Loss: 15.962309
Epoch loss: 16.118383
train phase, Epoch 9/25, Loss: 15.828662
val phase, Epoch 9/25, Loss: 21.968316
Val Best Loss: 15.962309
Epoch loss: 21.968316
train phase, Epoch 10/25, Loss: 15.923989
val phase, Epoch 10/25, Loss: 16.263452
Val Best Loss: 15.962309
Epoch loss: 16.263452
train phase, Epoch 11/25, Loss: 15.586741
val phase, Epoch 11/25, Loss: 16.121706
Val Best Loss: 15.962309
Epoch loss: 16.121706
train phase, Epoch 12/25, Loss: 15.427736
val phase, Epoch 12/25, Loss: 17.216076
Val Best Loss: 15.962309
Epoch loss: 17.216076
train phase, Epoch 13/25, Loss: 15.170478
val phase, Epoch 13/25, Loss: 16.179771
Val Best Loss: 15.962309
Epoch loss: 16.179771
train phase, Epoch 14/25, Loss: 14.997870
val phase, Epoch 14/25, Loss: 16.372095
Val Best Loss: 15.962309
Epoch loss: 16.372095
train phase, Epoch 15/25, Loss: 14.703017
val phase, Epoch 15/25, Loss: 15.998785
Val Best Loss: 15.962309
Epoch loss: 15.998785
train phase, Epoch 16/25, Loss: 14.696237
val phase, Epoch 16/25, Loss: 16.588649
Val Best Loss: 15.962309
Epoch loss: 16.588649
train phase, Epoch 17/25, Loss: 14.207962
val phase, Epoch 17/25, Loss: 16.610952
Val Best Loss: 15.962309
Epoch loss: 16.610952
train phase, Epoch 18/25, Loss: 14.151006
val phase, Epoch 18/25, Loss: 16.146357
Val Best Loss: 15.962309
Epoch loss: 16.146357
train phase, Epoch 19/25, Loss: 13.853799
val phase, Epoch 19/25, Loss: 15.946299
Val Best Loss: 15.946299
Epoch loss: 15.946299
train phase, Epoch 20/25, Loss: 13.568588
val phase, Epoch 20/25, Loss: 17.020862
Val Best Loss: 15.946299
Epoch loss: 17.020862
train phase, Epoch 21/25, Loss: 13.112301
val phase, Epoch 21/25, Loss: 17.003280
Val Best Loss: 15.946299
Epoch loss: 17.003280
train phase, Epoch 22/25, Loss: 12.882372
val phase, Epoch 22/25, Loss: 17.704140
Val Best Loss: 15.946299
Epoch loss: 17.704140
train phase, Epoch 23/25, Loss: 12.351132
val phase, Epoch 23/25, Loss: 17.817347
Val Best Loss: 15.946299
Epoch loss: 17.817347
train phase, Epoch 24/25, Loss: 11.880464
val phase, Epoch 24/25, Loss: 17.467752
Val Best Loss: 15.946299
Epoch loss: 17.467752
train phase, Epoch 25/25, Loss: 11.547072
val phase, Epoch 25/25, Loss: 17.418190
Val Best Loss: 15.946299
Epoch loss: 17.418190
train phase, Epoch 1/20, Loss: 29.389890
val phase, Epoch 1/20, Loss: 17.813750
Val Best Loss: 17.813750
Epoch loss: 17.813750
train phase, Epoch 2/20, Loss: 17.587301
val phase, Epoch 2/20, Loss: 17.425518
Val Best Loss: 17.425518
Epoch loss: 17.425518
train phase, Epoch 3/20, Loss: 17.074839
val phase, Epoch 3/20, Loss: 16.689500
Val Best Loss: 16.689500
Epoch loss: 16.689500
train phase, Epoch 4/20, Loss: 16.783306
val phase, Epoch 4/20, Loss: 16.520148
Val Best Loss: 16.520148
Epoch loss: 16.520148
train phase, Epoch 5/20, Loss: 16.601920
val phase, Epoch 5/20, Loss: 16.642062
Val Best Loss: 16.520148
Epoch loss: 16.642062
train phase, Epoch 6/20, Loss: 16.321121
val phase, Epoch 6/20, Loss: 16.308250
Val Best Loss: 16.308250
Epoch loss: 16.308250
train phase, Epoch 7/20, Loss: 16.185753
val phase, Epoch 7/20, Loss: 16.722077
Val Best Loss: 16.308250
Epoch loss: 16.722077
train phase, Epoch 8/20, Loss: 16.175679
val phase, Epoch 8/20, Loss: 16.556747
Val Best Loss: 16.308250
Epoch loss: 16.556747
train phase, Epoch 9/20, Loss: 15.970777
val phase, Epoch 9/20, Loss: 16.162194
Val Best Loss: 16.162194
Epoch loss: 16.162194
train phase, Epoch 10/20, Loss: 15.785485
val phase, Epoch 10/20, Loss: 16.425273
Val Best Loss: 16.162194
Epoch loss: 16.425273
train phase, Epoch 11/20, Loss: 15.551489
val phase, Epoch 11/20, Loss: 16.001573
Val Best Loss: 16.001573
Epoch loss: 16.001573
train phase, Epoch 12/20, Loss: 15.606909
val phase, Epoch 12/20, Loss: 15.978032
Val Best Loss: 15.978032
Epoch loss: 15.978032
train phase, Epoch 13/20, Loss: 15.402191
val phase, Epoch 13/20, Loss: 16.320670
Val Best Loss: 15.978032
Epoch loss: 16.320670
train phase, Epoch 14/20, Loss: 15.462754
val phase, Epoch 14/20, Loss: 16.038222
Val Best Loss: 15.978032
Epoch loss: 16.038222
train phase, Epoch 15/20, Loss: 15.214399
val phase, Epoch 15/20, Loss: 15.951511
Val Best Loss: 15.951511
Epoch loss: 15.951511
train phase, Epoch 16/20, Loss: 15.164666
val phase, Epoch 16/20, Loss: 16.248766
Val Best Loss: 15.951511
Epoch loss: 16.248766
train phase, Epoch 17/20, Loss: 15.137120
val phase, Epoch 17/20, Loss: 15.876216
Val Best Loss: 15.876216
Epoch loss: 15.876216
train phase, Epoch 18/20, Loss: 14.948215
val phase, Epoch 18/20, Loss: 15.841245
Val Best Loss: 15.841245
Epoch loss: 15.841245
train phase, Epoch 19/20, Loss: 14.859289
val phase, Epoch 19/20, Loss: 15.981900
Val Best Loss: 15.841245
Epoch loss: 15.981900
train phase, Epoch 20/20, Loss: 14.775760
val phase, Epoch 20/20, Loss: 15.703594
Val Best Loss: 15.703594
Epoch loss: 15.703594
train phase, Epoch 1/20, Loss: 20.152665
val phase, Epoch 1/20, Loss: 18.099093
Val Best Loss: 18.099093
Epoch loss: 18.099093
train phase, Epoch 2/20, Loss: 18.626283
val phase, Epoch 2/20, Loss: 16.837760
Val Best Loss: 16.837760
Epoch loss: 16.837760
train phase, Epoch 3/20, Loss: 17.775442
val phase, Epoch 3/20, Loss: 17.037556
Val Best Loss: 16.837760
Epoch loss: 17.037556
train phase, Epoch 4/20, Loss: 17.234282
val phase, Epoch 4/20, Loss: 16.352877
Val Best Loss: 16.352877
Epoch loss: 16.352877
train phase, Epoch 5/20, Loss: 16.923611
val phase, Epoch 5/20, Loss: 17.519228
Val Best Loss: 16.352877
Epoch loss: 17.519228
train phase, Epoch 6/20, Loss: 16.937918
val phase, Epoch 6/20, Loss: 17.143569
Val Best Loss: 16.352877
Epoch loss: 17.143569
train phase, Epoch 7/20, Loss: 16.762317
val phase, Epoch 7/20, Loss: 15.971350
Val Best Loss: 15.971350
Epoch loss: 15.971350
train phase, Epoch 8/20, Loss: 16.505895
val phase, Epoch 8/20, Loss: 16.053489
Val Best Loss: 15.971350
Epoch loss: 16.053489
train phase, Epoch 9/20, Loss: 16.514839
val phase, Epoch 9/20, Loss: 19.364628
Val Best Loss: 15.971350
Epoch loss: 19.364628
train phase, Epoch 10/20, Loss: 16.457588
val phase, Epoch 10/20, Loss: 16.733594
Val Best Loss: 15.971350
Epoch loss: 16.733594
train phase, Epoch 11/20, Loss: 16.094611
val phase, Epoch 11/20, Loss: 16.278738
Val Best Loss: 15.971350
Epoch loss: 16.278738
train phase, Epoch 12/20, Loss: 15.999269
val phase, Epoch 12/20, Loss: 15.929652
Val Best Loss: 15.929652
Epoch loss: 15.929652
train phase, Epoch 13/20, Loss: 15.892311
val phase, Epoch 13/20, Loss: 16.475897
Val Best Loss: 15.929652
Epoch loss: 16.475897
train phase, Epoch 14/20, Loss: 15.682662
val phase, Epoch 14/20, Loss: 15.899032
Val Best Loss: 15.899032
Epoch loss: 15.899032
train phase, Epoch 15/20, Loss: 15.644205
val phase, Epoch 15/20, Loss: 16.069406
Val Best Loss: 15.899032
Epoch loss: 16.069406
train phase, Epoch 16/20, Loss: 15.317661
val phase, Epoch 16/20, Loss: 15.771174
Val Best Loss: 15.771174
Epoch loss: 15.771174
train phase, Epoch 17/20, Loss: 15.080084
val phase, Epoch 17/20, Loss: 16.003878
Val Best Loss: 15.771174
Epoch loss: 16.003878
train phase, Epoch 18/20, Loss: 15.045981
val phase, Epoch 18/20, Loss: 16.692462
Val Best Loss: 15.771174
Epoch loss: 16.692462
train phase, Epoch 19/20, Loss: 14.867779
val phase, Epoch 19/20, Loss: 15.923255
Val Best Loss: 15.771174
Epoch loss: 15.923255
train phase, Epoch 20/20, Loss: 14.649177
val phase, Epoch 20/20, Loss: 18.314626
Val Best Loss: 15.771174
Epoch loss: 18.314626
train phase, Epoch 1/30, Loss: 20.101607
val phase, Epoch 1/30, Loss: 18.693290
Val Best Loss: 18.693290
Epoch loss: 18.693290
train phase, Epoch 2/30, Loss: 17.563572
val phase, Epoch 2/30, Loss: 18.456148
Val Best Loss: 18.456148
Epoch loss: 18.456148
train phase, Epoch 3/30, Loss: 17.333806
val phase, Epoch 3/30, Loss: 17.144665
Val Best Loss: 17.144665
Epoch loss: 17.144665
train phase, Epoch 4/30, Loss: 17.311720
val phase, Epoch 4/30, Loss: 18.126800
Val Best Loss: 17.144665
Epoch loss: 18.126800
train phase, Epoch 5/30, Loss: 16.671846
val phase, Epoch 5/30, Loss: 16.210018
Val Best Loss: 16.210018
Epoch loss: 16.210018
train phase, Epoch 6/30, Loss: 16.551892
val phase, Epoch 6/30, Loss: 16.345719
Val Best Loss: 16.210018
Epoch loss: 16.345719
train phase, Epoch 7/30, Loss: 16.566453
val phase, Epoch 7/30, Loss: 17.032085
Val Best Loss: 16.210018
Epoch loss: 17.032085
train phase, Epoch 8/30, Loss: 16.132270
val phase, Epoch 8/30, Loss: 19.183974
Val Best Loss: 16.210018
Epoch loss: 19.183974
train phase, Epoch 9/30, Loss: 16.084797
val phase, Epoch 9/30, Loss: 16.535859
Val Best Loss: 16.210018
Epoch loss: 16.535859
train phase, Epoch 10/30, Loss: 15.856309
val phase, Epoch 10/30, Loss: 16.240183
Val Best Loss: 16.210018
Epoch loss: 16.240183
train phase, Epoch 11/30, Loss: 16.063105
val phase, Epoch 11/30, Loss: 15.952259
Val Best Loss: 15.952259
Epoch loss: 15.952259
train phase, Epoch 12/30, Loss: 15.752640
val phase, Epoch 12/30, Loss: 16.021945
Val Best Loss: 15.952259
Epoch loss: 16.021945
train phase, Epoch 13/30, Loss: 15.635025
val phase, Epoch 13/30, Loss: 16.278989
Val Best Loss: 15.952259
Epoch loss: 16.278989
train phase, Epoch 14/30, Loss: 15.301653
val phase, Epoch 14/30, Loss: 16.185993
Val Best Loss: 15.952259
Epoch loss: 16.185993
train phase, Epoch 15/30, Loss: 15.358081
val phase, Epoch 15/30, Loss: 17.893721
Val Best Loss: 15.952259
Epoch loss: 17.893721
train phase, Epoch 16/30, Loss: 15.021516
val phase, Epoch 16/30, Loss: 17.637985
Val Best Loss: 15.952259
Epoch loss: 17.637985
train phase, Epoch 17/30, Loss: 14.803621
val phase, Epoch 17/30, Loss: 17.444759
Val Best Loss: 15.952259
Epoch loss: 17.444759
train phase, Epoch 18/30, Loss: 14.535480
val phase, Epoch 18/30, Loss: 17.138400
Val Best Loss: 15.952259
Epoch loss: 17.138400
train phase, Epoch 19/30, Loss: 14.352769
val phase, Epoch 19/30, Loss: 16.744463
Val Best Loss: 15.952259
Epoch loss: 16.744463
train phase, Epoch 20/30, Loss: 14.025693
val phase, Epoch 20/30, Loss: 17.621047
Val Best Loss: 15.952259
Epoch loss: 17.621047
train phase, Epoch 21/30, Loss: 13.498149
val phase, Epoch 21/30, Loss: 16.561020
Val Best Loss: 15.952259
Epoch loss: 16.561020
train phase, Epoch 22/30, Loss: 13.177066
val phase, Epoch 22/30, Loss: 17.574945
Val Best Loss: 15.952259
Epoch loss: 17.574945
train phase, Epoch 23/30, Loss: 12.966110
val phase, Epoch 23/30, Loss: 17.460419
Val Best Loss: 15.952259
Epoch loss: 17.460419
train phase, Epoch 24/30, Loss: 12.697163
val phase, Epoch 24/30, Loss: 17.196431
Val Best Loss: 15.952259
Epoch loss: 17.196431
train phase, Epoch 25/30, Loss: 12.185107
val phase, Epoch 25/30, Loss: 19.779142
Val Best Loss: 15.952259
Epoch loss: 19.779142
train phase, Epoch 26/30, Loss: 11.994273
val phase, Epoch 26/30, Loss: 18.048557
Val Best Loss: 15.952259
Epoch loss: 18.048557
train phase, Epoch 27/30, Loss: 11.419340
val phase, Epoch 27/30, Loss: 17.675729
Val Best Loss: 15.952259
Epoch loss: 17.675729
train phase, Epoch 28/30, Loss: 10.704484
val phase, Epoch 28/30, Loss: 17.865841
Val Best Loss: 15.952259
Epoch loss: 17.865841
train phase, Epoch 29/30, Loss: 10.011991
val phase, Epoch 29/30, Loss: 18.210547
Val Best Loss: 15.952259
Epoch loss: 18.210547
train phase, Epoch 30/30, Loss: 9.576637
val phase, Epoch 30/30, Loss: 18.518325
Val Best Loss: 15.952259
Epoch loss: 18.518325
train phase, Epoch 1/20, Loss: 19.960348
val phase, Epoch 1/20, Loss: 17.741930
Val Best Loss: 17.741930
Epoch loss: 17.741930
train phase, Epoch 2/20, Loss: 17.988521
val phase, Epoch 2/20, Loss: 20.746929
Val Best Loss: 17.741930
Epoch loss: 20.746929
train phase, Epoch 3/20, Loss: 17.388584
val phase, Epoch 3/20, Loss: 17.460788
Val Best Loss: 17.460788
Epoch loss: 17.460788
train phase, Epoch 4/20, Loss: 17.257448
val phase, Epoch 4/20, Loss: 17.482136
Val Best Loss: 17.460788
Epoch loss: 17.482136
train phase, Epoch 5/20, Loss: 17.332163
val phase, Epoch 5/20, Loss: 16.459520
Val Best Loss: 16.459520
Epoch loss: 16.459520
train phase, Epoch 6/20, Loss: 16.522044
val phase, Epoch 6/20, Loss: 17.662612
Val Best Loss: 16.459520
Epoch loss: 17.662612
train phase, Epoch 7/20, Loss: 16.521762
val phase, Epoch 7/20, Loss: 17.094843
Val Best Loss: 16.459520
Epoch loss: 17.094843
train phase, Epoch 8/20, Loss: 16.203455
val phase, Epoch 8/20, Loss: 16.305976
Val Best Loss: 16.305976
Epoch loss: 16.305976
train phase, Epoch 9/20, Loss: 16.267390
val phase, Epoch 9/20, Loss: 16.462738
Val Best Loss: 16.305976
Epoch loss: 16.462738
train phase, Epoch 10/20, Loss: 16.033722
val phase, Epoch 10/20, Loss: 15.893685
Val Best Loss: 15.893685
Epoch loss: 15.893685
train phase, Epoch 11/20, Loss: 15.706067
val phase, Epoch 11/20, Loss: 16.114082
Val Best Loss: 15.893685
Epoch loss: 16.114082
train phase, Epoch 12/20, Loss: 15.666586
val phase, Epoch 12/20, Loss: 17.431204
Val Best Loss: 15.893685
Epoch loss: 17.431204
train phase, Epoch 13/20, Loss: 15.710411
val phase, Epoch 13/20, Loss: 16.123156
Val Best Loss: 15.893685
Epoch loss: 16.123156
train phase, Epoch 14/20, Loss: 15.204978
val phase, Epoch 14/20, Loss: 16.784194
Val Best Loss: 15.893685
Epoch loss: 16.784194
train phase, Epoch 15/20, Loss: 15.267865
val phase, Epoch 15/20, Loss: 16.215262
Val Best Loss: 15.893685
Epoch loss: 16.215262
train phase, Epoch 16/20, Loss: 14.933673
val phase, Epoch 16/20, Loss: 16.764950
Val Best Loss: 15.893685
Epoch loss: 16.764950
train phase, Epoch 17/20, Loss: 14.924186
val phase, Epoch 17/20, Loss: 15.935426
Val Best Loss: 15.893685
Epoch loss: 15.935426
train phase, Epoch 18/20, Loss: 14.376515
val phase, Epoch 18/20, Loss: 16.381245
Val Best Loss: 15.893685
Epoch loss: 16.381245
train phase, Epoch 19/20, Loss: 14.210854
val phase, Epoch 19/20, Loss: 17.290365
Val Best Loss: 15.893685
Epoch loss: 17.290365
train phase, Epoch 20/20, Loss: 13.905143
val phase, Epoch 20/20, Loss: 16.416672
Val Best Loss: 15.893685
Epoch loss: 16.416672
[Trial 492] Skipped due to model construction error: Calculated padded input size per channel: (6 x 3). Kernel size: (5 x 5). Kernel size can't be greater than actual input size
train phase, Epoch 1/20, Loss: 31.212683
val phase, Epoch 1/20, Loss: 19.867687
Val Best Loss: 19.867687
Epoch loss: 19.867687
train phase, Epoch 2/20, Loss: 19.009826
val phase, Epoch 2/20, Loss: 19.175432
Val Best Loss: 19.175432
Epoch loss: 19.175432
train phase, Epoch 3/20, Loss: 18.222935
val phase, Epoch 3/20, Loss: 18.757299
Val Best Loss: 18.757299
Epoch loss: 18.757299
train phase, Epoch 4/20, Loss: 17.869055
val phase, Epoch 4/20, Loss: 17.335403
Val Best Loss: 17.335403
Epoch loss: 17.335403
train phase, Epoch 5/20, Loss: 17.596159
val phase, Epoch 5/20, Loss: 17.254196
Val Best Loss: 17.254196
Epoch loss: 17.254196
train phase, Epoch 6/20, Loss: 17.288907
val phase, Epoch 6/20, Loss: 16.885605
Val Best Loss: 16.885605
Epoch loss: 16.885605
train phase, Epoch 7/20, Loss: 16.923988
val phase, Epoch 7/20, Loss: 17.045190
Val Best Loss: 16.885605
Epoch loss: 17.045190
train phase, Epoch 8/20, Loss: 16.664169
val phase, Epoch 8/20, Loss: 17.828580
Val Best Loss: 16.885605
Epoch loss: 17.828580
train phase, Epoch 9/20, Loss: 16.761474
val phase, Epoch 9/20, Loss: 16.907610
Val Best Loss: 16.885605
Epoch loss: 16.907610
train phase, Epoch 10/20, Loss: 16.432486
val phase, Epoch 10/20, Loss: 16.966853
Val Best Loss: 16.885605
Epoch loss: 16.966853
train phase, Epoch 11/20, Loss: 16.025072
val phase, Epoch 11/20, Loss: 16.909249
Val Best Loss: 16.885605
Epoch loss: 16.909249
train phase, Epoch 12/20, Loss: 15.958185
val phase, Epoch 12/20, Loss: 17.227311
Val Best Loss: 16.885605
Epoch loss: 17.227311
train phase, Epoch 13/20, Loss: 16.141436
val phase, Epoch 13/20, Loss: 16.938741
Val Best Loss: 16.885605
Epoch loss: 16.938741
train phase, Epoch 14/20, Loss: 15.624350
val phase, Epoch 14/20, Loss: 18.235899
Val Best Loss: 16.885605
Epoch loss: 18.235899
train phase, Epoch 15/20, Loss: 15.575123
val phase, Epoch 15/20, Loss: 16.457358
Val Best Loss: 16.457358
Epoch loss: 16.457358
train phase, Epoch 16/20, Loss: 15.362892
val phase, Epoch 16/20, Loss: 17.113331
Val Best Loss: 16.457358
Epoch loss: 17.113331
train phase, Epoch 17/20, Loss: 15.156084
val phase, Epoch 17/20, Loss: 17.096453
Val Best Loss: 16.457358
Epoch loss: 17.096453
train phase, Epoch 18/20, Loss: 15.292492
val phase, Epoch 18/20, Loss: 18.490275
Val Best Loss: 16.457358
Epoch loss: 18.490275
train phase, Epoch 19/20, Loss: 15.015826
val phase, Epoch 19/20, Loss: 17.879557
Val Best Loss: 16.457358
Epoch loss: 17.879557
train phase, Epoch 20/20, Loss: 14.760709
val phase, Epoch 20/20, Loss: 18.616260
Val Best Loss: 16.457358
Epoch loss: 18.616260
[Trial 494] Skipped due to model construction error: Calculated padded input size per channel: (4 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size
train phase, Epoch 1/5, Loss: 19.788809
val phase, Epoch 1/5, Loss: 30.907477
Val Best Loss: 30.907477
Epoch loss: 30.907477
train phase, Epoch 2/5, Loss: 18.084543
val phase, Epoch 2/5, Loss: 17.121426
Val Best Loss: 17.121426
Epoch loss: 17.121426
train phase, Epoch 3/5, Loss: 17.340094
val phase, Epoch 3/5, Loss: 16.642141
Val Best Loss: 16.642141
Epoch loss: 16.642141
train phase, Epoch 4/5, Loss: 17.378396
val phase, Epoch 4/5, Loss: 16.398248
Val Best Loss: 16.398248
Epoch loss: 16.398248
train phase, Epoch 5/5, Loss: 16.917959
val phase, Epoch 5/5, Loss: 16.915460
Val Best Loss: 16.398248
Epoch loss: 16.915460
train phase, Epoch 1/30, Loss: 20.970965
val phase, Epoch 1/30, Loss: 19.057822
Val Best Loss: 19.057822
Epoch loss: 19.057822
train phase, Epoch 2/30, Loss: 18.894362
val phase, Epoch 2/30, Loss: 17.980317
Val Best Loss: 17.980317
Epoch loss: 17.980317
train phase, Epoch 3/30, Loss: 18.533298
val phase, Epoch 3/30, Loss: 17.189110
Val Best Loss: 17.189110
Epoch loss: 17.189110
train phase, Epoch 4/30, Loss: 18.300135
val phase, Epoch 4/30, Loss: 19.120540
Val Best Loss: 17.189110
Epoch loss: 19.120540
train phase, Epoch 5/30, Loss: 17.790621
val phase, Epoch 5/30, Loss: 20.253697
Val Best Loss: 17.189110
Epoch loss: 20.253697
train phase, Epoch 6/30, Loss: 17.762331
val phase, Epoch 6/30, Loss: 16.915901
Val Best Loss: 16.915901
Epoch loss: 16.915901
train phase, Epoch 7/30, Loss: 17.474883
val phase, Epoch 7/30, Loss: 17.380602
Val Best Loss: 16.915901
Epoch loss: 17.380602
train phase, Epoch 8/30, Loss: 17.293575
val phase, Epoch 8/30, Loss: 17.623132
Val Best Loss: 16.915901
Epoch loss: 17.623132
train phase, Epoch 9/30, Loss: 17.196558
val phase, Epoch 9/30, Loss: 16.350039
Val Best Loss: 16.350039
Epoch loss: 16.350039
train phase, Epoch 10/30, Loss: 16.875352
val phase, Epoch 10/30, Loss: 16.074322
Val Best Loss: 16.074322
Epoch loss: 16.074322
train phase, Epoch 11/30, Loss: 16.863699
val phase, Epoch 11/30, Loss: 17.072265
Val Best Loss: 16.074322
Epoch loss: 17.072265
train phase, Epoch 12/30, Loss: 16.615136
val phase, Epoch 12/30, Loss: 16.831252
Val Best Loss: 16.074322
Epoch loss: 16.831252
train phase, Epoch 13/30, Loss: 16.413677
val phase, Epoch 13/30, Loss: 16.403467
Val Best Loss: 16.074322
Epoch loss: 16.403467
train phase, Epoch 14/30, Loss: 16.521106
val phase, Epoch 14/30, Loss: 16.336736
Val Best Loss: 16.074322
Epoch loss: 16.336736
train phase, Epoch 15/30, Loss: 16.405559
val phase, Epoch 15/30, Loss: 16.208144
Val Best Loss: 16.074322
Epoch loss: 16.208144
train phase, Epoch 16/30, Loss: 16.438895
val phase, Epoch 16/30, Loss: 16.237996
Val Best Loss: 16.074322
Epoch loss: 16.237996
train phase, Epoch 17/30, Loss: 16.215265
val phase, Epoch 17/30, Loss: 16.389261
Val Best Loss: 16.074322
Epoch loss: 16.389261
train phase, Epoch 18/30, Loss: 16.107865
val phase, Epoch 18/30, Loss: 15.712585
Val Best Loss: 15.712585
Epoch loss: 15.712585
train phase, Epoch 19/30, Loss: 16.133931
val phase, Epoch 19/30, Loss: 16.212456
Val Best Loss: 15.712585
Epoch loss: 16.212456
train phase, Epoch 20/30, Loss: 16.065986
val phase, Epoch 20/30, Loss: 17.092403
Val Best Loss: 15.712585
Epoch loss: 17.092403
train phase, Epoch 21/30, Loss: 16.150072
val phase, Epoch 21/30, Loss: 16.132623
Val Best Loss: 15.712585
Epoch loss: 16.132623
train phase, Epoch 22/30, Loss: 15.810072
val phase, Epoch 22/30, Loss: 16.019488
Val Best Loss: 15.712585
Epoch loss: 16.019488
train phase, Epoch 23/30, Loss: 15.561558
val phase, Epoch 23/30, Loss: 16.352259
Val Best Loss: 15.712585
Epoch loss: 16.352259
train phase, Epoch 24/30, Loss: 15.673985
val phase, Epoch 24/30, Loss: 16.900924
Val Best Loss: 15.712585
Epoch loss: 16.900924
train phase, Epoch 25/30, Loss: 15.512846
val phase, Epoch 25/30, Loss: 16.116602
Val Best Loss: 15.712585
Epoch loss: 16.116602
train phase, Epoch 26/30, Loss: 15.480831
val phase, Epoch 26/30, Loss: 16.122295
Val Best Loss: 15.712585
Epoch loss: 16.122295
train phase, Epoch 27/30, Loss: 15.555494
val phase, Epoch 27/30, Loss: 16.420377
Val Best Loss: 15.712585
Epoch loss: 16.420377
train phase, Epoch 28/30, Loss: 15.301484
val phase, Epoch 28/30, Loss: 16.721392
Val Best Loss: 15.712585
Epoch loss: 16.721392
train phase, Epoch 29/30, Loss: 15.270403
val phase, Epoch 29/30, Loss: 17.076983
Val Best Loss: 15.712585
Epoch loss: 17.076983
train phase, Epoch 30/30, Loss: 14.916195
val phase, Epoch 30/30, Loss: 16.606882
Val Best Loss: 15.712585
Epoch loss: 16.606882
train phase, Epoch 1/20, Loss: 20.254713
val phase, Epoch 1/20, Loss: 17.452316
Val Best Loss: 17.452316
Epoch loss: 17.452316
train phase, Epoch 2/20, Loss: 18.151965
val phase, Epoch 2/20, Loss: 16.700126
Val Best Loss: 16.700126
Epoch loss: 16.700126
train phase, Epoch 3/20, Loss: 17.401645
val phase, Epoch 3/20, Loss: 16.953305
Val Best Loss: 16.700126
Epoch loss: 16.953305
train phase, Epoch 4/20, Loss: 16.886552
val phase, Epoch 4/20, Loss: 16.938099
Val Best Loss: 16.700126
Epoch loss: 16.938099
train phase, Epoch 5/20, Loss: 16.716292
val phase, Epoch 5/20, Loss: 16.992485
Val Best Loss: 16.700126
Epoch loss: 16.992485
train phase, Epoch 6/20, Loss: 16.635105
val phase, Epoch 6/20, Loss: 19.264193
Val Best Loss: 16.700126
Epoch loss: 19.264193
train phase, Epoch 7/20, Loss: 16.485401
val phase, Epoch 7/20, Loss: 16.462790
Val Best Loss: 16.462790
Epoch loss: 16.462790
train phase, Epoch 8/20, Loss: 16.261115
val phase, Epoch 8/20, Loss: 15.827235
Val Best Loss: 15.827235
Epoch loss: 15.827235
train phase, Epoch 9/20, Loss: 16.101718
val phase, Epoch 9/20, Loss: 17.852749
Val Best Loss: 15.827235
Epoch loss: 17.852749
train phase, Epoch 10/20, Loss: 15.864904
val phase, Epoch 10/20, Loss: 16.139216
Val Best Loss: 15.827235
Epoch loss: 16.139216
train phase, Epoch 11/20, Loss: 15.907426
val phase, Epoch 11/20, Loss: 16.595004
Val Best Loss: 15.827235
Epoch loss: 16.595004
train phase, Epoch 12/20, Loss: 15.646667
val phase, Epoch 12/20, Loss: 17.275258
Val Best Loss: 15.827235
Epoch loss: 17.275258
train phase, Epoch 13/20, Loss: 15.359998
val phase, Epoch 13/20, Loss: 16.465627
Val Best Loss: 15.827235
Epoch loss: 16.465627
train phase, Epoch 14/20, Loss: 15.099319
val phase, Epoch 14/20, Loss: 17.190612
Val Best Loss: 15.827235
Epoch loss: 17.190612
train phase, Epoch 15/20, Loss: 14.971631
val phase, Epoch 15/20, Loss: 16.013047
Val Best Loss: 15.827235
Epoch loss: 16.013047
train phase, Epoch 16/20, Loss: 14.808265
val phase, Epoch 16/20, Loss: 16.525778
Val Best Loss: 15.827235
Epoch loss: 16.525778
train phase, Epoch 17/20, Loss: 14.576651
val phase, Epoch 17/20, Loss: 16.590154
Val Best Loss: 15.827235
Epoch loss: 16.590154
train phase, Epoch 18/20, Loss: 14.305163
val phase, Epoch 18/20, Loss: 16.913966
Val Best Loss: 15.827235
Epoch loss: 16.913966
train phase, Epoch 19/20, Loss: 13.988756
val phase, Epoch 19/20, Loss: 16.200894
Val Best Loss: 15.827235
Epoch loss: 16.200894
train phase, Epoch 20/20, Loss: 13.931532
val phase, Epoch 20/20, Loss: 16.543359
Val Best Loss: 15.827235
Epoch loss: 16.543359
[Trial 498] Skipped due to model construction error: Given input size: (64x5x2). Calculated output size: (64x1x0). Output size is too small
train phase, Epoch 1/20, Loss: 21.447954
val phase, Epoch 1/20, Loss: 17.639523
Val Best Loss: 17.639523
Epoch loss: 17.639523
train phase, Epoch 2/20, Loss: 17.268289
val phase, Epoch 2/20, Loss: 16.892964
Val Best Loss: 16.892964
Epoch loss: 16.892964
train phase, Epoch 3/20, Loss: 17.166591
val phase, Epoch 3/20, Loss: 16.467709
Val Best Loss: 16.467709
Epoch loss: 16.467709
train phase, Epoch 4/20, Loss: 16.801341
val phase, Epoch 4/20, Loss: 16.866534
Val Best Loss: 16.467709
Epoch loss: 16.866534
train phase, Epoch 5/20, Loss: 16.491546
val phase, Epoch 5/20, Loss: 16.780467
Val Best Loss: 16.467709
Epoch loss: 16.780467
train phase, Epoch 6/20, Loss: 16.271277
val phase, Epoch 6/20, Loss: 16.335010
Val Best Loss: 16.335010
Epoch loss: 16.335010
train phase, Epoch 7/20, Loss: 16.023009
val phase, Epoch 7/20, Loss: 16.236180
Val Best Loss: 16.236180
Epoch loss: 16.236180
train phase, Epoch 8/20, Loss: 15.830461
val phase, Epoch 8/20, Loss: 16.542365
Val Best Loss: 16.236180
Epoch loss: 16.542365
train phase, Epoch 9/20, Loss: 15.673121
val phase, Epoch 9/20, Loss: 16.753491
Val Best Loss: 16.236180
Epoch loss: 16.753491
train phase, Epoch 10/20, Loss: 15.470764
val phase, Epoch 10/20, Loss: 16.591481
Val Best Loss: 16.236180
Epoch loss: 16.591481
train phase, Epoch 11/20, Loss: 15.273155
val phase, Epoch 11/20, Loss: 16.745241
Val Best Loss: 16.236180
Epoch loss: 16.745241
train phase, Epoch 12/20, Loss: 15.053854
val phase, Epoch 12/20, Loss: 16.343626
Val Best Loss: 16.236180
Epoch loss: 16.343626
train phase, Epoch 13/20, Loss: 14.993767
val phase, Epoch 13/20, Loss: 17.550259
Val Best Loss: 16.236180
Epoch loss: 17.550259
train phase, Epoch 14/20, Loss: 14.716922
val phase, Epoch 14/20, Loss: 16.583235
Val Best Loss: 16.236180
Epoch loss: 16.583235
train phase, Epoch 15/20, Loss: 14.411184
val phase, Epoch 15/20, Loss: 16.584271
Val Best Loss: 16.236180
Epoch loss: 16.584271
train phase, Epoch 16/20, Loss: 14.126924
val phase, Epoch 16/20, Loss: 18.638240
Val Best Loss: 16.236180
Epoch loss: 18.638240
train phase, Epoch 17/20, Loss: 14.174843
val phase, Epoch 17/20, Loss: 17.235122
Val Best Loss: 16.236180
Epoch loss: 17.235122
train phase, Epoch 18/20, Loss: 13.674630
val phase, Epoch 18/20, Loss: 17.291853
Val Best Loss: 16.236180
Epoch loss: 17.291853
train phase, Epoch 19/20, Loss: 13.398329
val phase, Epoch 19/20, Loss: 17.365073
Val Best Loss: 16.236180
Epoch loss: 17.365073
train phase, Epoch 20/20, Loss: 13.002459
val phase, Epoch 20/20, Loss: 16.707417
Val Best Loss: 16.236180
Epoch loss: 16.707417
Best trial:
FrozenTrial(number=121, state=1, values=[15.493945159799877], datetime_start=datetime.datetime(2025, 6, 30, 22, 56, 43, 671627), datetime_complete=datetime.datetime(2025, 6, 30, 22, 57, 31, 887416), params={'kernel_size': 3, 'channel_list': [16, 32, 64, 128], 'padding': 1, 'pool_kernel': 2, 'dropout_rate': 0.1, 'fc_hidden_dim': 64, 'lr': 0.002991075183277198, 'weight_decay': 1.8660900908876813e-06, 'optimizer': 'adam', 'activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'batchnorm': True, 'epochs': 20, 'batch_size': 64, 'flip_prob': 0.0}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'kernel_size': CategoricalDistribution(choices=(3, 5, 7)), 'channel_list': CategoricalDistribution(choices=([16, 32, 64], [32, 64, 128], [16, 32, 64, 128])), 'padding': CategoricalDistribution(choices=(0, 1)), 'pool_kernel': CategoricalDistribution(choices=(2, 3)), 'dropout_rate': CategoricalDistribution(choices=(0, 0.1, 0.5)), 'fc_hidden_dim': CategoricalDistribution(choices=(64, 128, 256)), 'lr': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'weight_decay': FloatDistribution(high=0.01, log=True, low=1e-06, step=None), 'optimizer': CategoricalDistribution(choices=('adam', 'sgd')), 'activation': CategoricalDistribution(choices=(<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.LeakyReLU'>)), 'batchnorm': CategoricalDistribution(choices=(False, True)), 'epochs': CategoricalDistribution(choices=(5, 10, 12, 15, 20, 25, 30)), 'batch_size': CategoricalDistribution(choices=(32, 64, 128)), 'flip_prob': CategoricalDistribution(choices=(0.0, 0.25, 0.5, 0.75, 1))}, trial_id=121, value=None)
